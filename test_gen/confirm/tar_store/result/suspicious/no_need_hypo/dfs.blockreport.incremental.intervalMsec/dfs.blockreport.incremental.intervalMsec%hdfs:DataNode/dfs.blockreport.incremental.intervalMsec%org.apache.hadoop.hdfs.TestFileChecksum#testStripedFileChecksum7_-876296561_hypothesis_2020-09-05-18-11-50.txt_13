reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-412920400-172.17.0.21-1599329668390:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-4f291015-b369-40e3-a78e-fada593703ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7756823a-cee2-4763-a1c7-1b068e498faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-3c711ec0-ee18-472f-b4e0-d8291b5ca712,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-45108041-2ce5-4d45-9aa9-1921edd1c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-33ee133f-05b3-456f-9d04-73fb2522554c,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-3dd592b2-ba40-4e3c-8a90-d64624c2c853,DISK]]; indices=[0, 1, 2, 3, 5, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-412920400-172.17.0.21-1599329668390:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-4f291015-b369-40e3-a78e-fada593703ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7756823a-cee2-4763-a1c7-1b068e498faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-3c711ec0-ee18-472f-b4e0-d8291b5ca712,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-45108041-2ce5-4d45-9aa9-1921edd1c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-33ee133f-05b3-456f-9d04-73fb2522554c,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-3dd592b2-ba40-4e3c-8a90-d64624c2c853,DISK]]; indices=[0, 1, 2, 3, 5, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1820982848-172.17.0.21-1599329720327:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-e27b8058-02b2-40d7-81c5-3308a44bd724,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-0b187023-f58a-4a20-8d61-b44b7f2f15b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-59370bd4-f5e4-4912-a3cf-dfcece2331ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-0d7ccd57-1330-4dfd-9104-b77d64b1c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-30881736-c07e-4654-8a13-df8f1ffcb4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-840c71c3-bf02-4f01-92d7-1d11f6213510,DISK]]; indices=[0, 1, 2, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1820982848-172.17.0.21-1599329720327:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-e27b8058-02b2-40d7-81c5-3308a44bd724,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-0b187023-f58a-4a20-8d61-b44b7f2f15b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-59370bd4-f5e4-4912-a3cf-dfcece2331ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-0d7ccd57-1330-4dfd-9104-b77d64b1c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-30881736-c07e-4654-8a13-df8f1ffcb4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-840c71c3-bf02-4f01-92d7-1d11f6213510,DISK]]; indices=[0, 1, 2, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-822282348-172.17.0.21-1599329804813:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-18551ff2-480e-4b29-b355-f3378d7bdc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-7a35e1c0-bbd6-48df-b850-db4ede9136f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-4d46a6a0-bc54-4ee8-883b-731e3e0f8706,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6bcfbad9-fe20-4b0c-9d1f-262b6e1a11ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-9b387064-9fe1-4e67-8ed0-9160137f744f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-566662c1-9898-4e75-9a4d-b20b169f401a,DISK]]; indices=[0, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-822282348-172.17.0.21-1599329804813:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-18551ff2-480e-4b29-b355-f3378d7bdc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-7a35e1c0-bbd6-48df-b850-db4ede9136f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-4d46a6a0-bc54-4ee8-883b-731e3e0f8706,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6bcfbad9-fe20-4b0c-9d1f-262b6e1a11ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-9b387064-9fe1-4e67-8ed0-9160137f744f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-566662c1-9898-4e75-9a4d-b20b169f401a,DISK]]; indices=[0, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-867176181-172.17.0.21-1599329947357:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-76832493-a47e-4126-8177-4dac96c32160,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-c567392a-da90-4e65-9741-52458fea872b,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-bf23c4c7-0f9d-489b-9acb-94be57acb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e79f9faf-e1e7-428c-a129-a7c94d1fbb94,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-0165cb8b-ff48-4683-bb12-9a42721d5731,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b908cdcc-b8ac-413f-86c1-f52330ba4499,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-05846dd6-1f7c-41f8-8eda-91b76524ffbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-867176181-172.17.0.21-1599329947357:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-76832493-a47e-4126-8177-4dac96c32160,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-c567392a-da90-4e65-9741-52458fea872b,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-bf23c4c7-0f9d-489b-9acb-94be57acb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-e79f9faf-e1e7-428c-a129-a7c94d1fbb94,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-0165cb8b-ff48-4683-bb12-9a42721d5731,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b908cdcc-b8ac-413f-86c1-f52330ba4499,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-05846dd6-1f7c-41f8-8eda-91b76524ffbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-307400363-172.17.0.21-1599330261701:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-cde0ee52-2764-44b8-a4d5-86de5af9ed59,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-519c5bba-ba1c-4c8e-bae3-414a72c98450,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-38b43bd1-13be-4e3f-a3a7-9479dfa5ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-a0ba0682-9619-404a-aea9-749db256ef69,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-02ac9d67-9bd3-48a4-812f-9e35ddc4b842,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-1e887195-a25c-4065-b9bf-2dc52c83dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-29256e08-b1ef-41a3-82e5-0a03cb60573f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-1dc527b1-a78b-4adb-a5f5-34a44f36bf73,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-307400363-172.17.0.21-1599330261701:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-cde0ee52-2764-44b8-a4d5-86de5af9ed59,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-519c5bba-ba1c-4c8e-bae3-414a72c98450,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-38b43bd1-13be-4e3f-a3a7-9479dfa5ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-a0ba0682-9619-404a-aea9-749db256ef69,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-02ac9d67-9bd3-48a4-812f-9e35ddc4b842,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-1e887195-a25c-4065-b9bf-2dc52c83dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-29256e08-b1ef-41a3-82e5-0a03cb60573f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-1dc527b1-a78b-4adb-a5f5-34a44f36bf73,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1347939620-172.17.0.21-1599330478365:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-7beeb22e-f077-47dc-9986-c88f5ee5ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-e71d9b5c-1ee2-46ea-bf4c-e47cbe6aea50,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-056b3d12-5d3a-40e0-b35e-0fc28d07cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-374d432b-c2e0-4c6a-8f31-492f6af48416,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-69c3f400-f49a-4a8c-a57c-a49c8e1b105a,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-56fb1543-ae4b-4ffe-9741-abaa7f547281,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-3e9d92ab-34e3-4e7f-a376-1c02bae57337,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0e4573a5-e436-43fb-b438-992f54cbe88b,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1347939620-172.17.0.21-1599330478365:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-7beeb22e-f077-47dc-9986-c88f5ee5ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-e71d9b5c-1ee2-46ea-bf4c-e47cbe6aea50,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-056b3d12-5d3a-40e0-b35e-0fc28d07cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-374d432b-c2e0-4c6a-8f31-492f6af48416,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-69c3f400-f49a-4a8c-a57c-a49c8e1b105a,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-56fb1543-ae4b-4ffe-9741-abaa7f547281,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-3e9d92ab-34e3-4e7f-a376-1c02bae57337,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0e4573a5-e436-43fb-b438-992f54cbe88b,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1777758261-172.17.0.21-1599330575448:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-396a4ba1-b852-4a07-aea9-2dd5cac12607,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-4fc0cbac-deae-468b-b60c-0360181b8896,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-4971f6c6-2e66-4dea-81e2-6f0313b03df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-673f8b88-817c-4846-91f2-4f8f8320c559,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-6bfc736e-d7c1-4527-b30b-ca3c9c31b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-ea12db17-1782-4613-8a50-a024d9eabeb2,DISK]]; indices=[0, 1, 2, 3, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1777758261-172.17.0.21-1599330575448:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-396a4ba1-b852-4a07-aea9-2dd5cac12607,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-4fc0cbac-deae-468b-b60c-0360181b8896,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-4971f6c6-2e66-4dea-81e2-6f0313b03df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-673f8b88-817c-4846-91f2-4f8f8320c559,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-6bfc736e-d7c1-4527-b30b-ca3c9c31b55a,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-ea12db17-1782-4613-8a50-a024d9eabeb2,DISK]]; indices=[0, 1, 2, 3, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1495848823-172.17.0.21-1599330877561:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-914a9ede-ac8a-4813-97c1-ee9f351cad43,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7300d27b-cacf-477e-a2fd-57aa0c35ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-c77a3453-21d9-4efa-9b99-62ea7998821f,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-4d3ae783-79c9-42ca-930a-774ba92b6fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-007df209-9cc5-4faf-954e-da8b1e18b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-01439ee3-681d-4f98-a5af-ff341f22ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-9db25e86-afe7-4a36-a83b-a5c249953925,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-f15474eb-f0e3-4e4a-bf65-09c7902399f7,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1495848823-172.17.0.21-1599330877561:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45987,DS-914a9ede-ac8a-4813-97c1-ee9f351cad43,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7300d27b-cacf-477e-a2fd-57aa0c35ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-c77a3453-21d9-4efa-9b99-62ea7998821f,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-4d3ae783-79c9-42ca-930a-774ba92b6fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-007df209-9cc5-4faf-954e-da8b1e18b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-01439ee3-681d-4f98-a5af-ff341f22ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-9db25e86-afe7-4a36-a83b-a5c249953925,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-f15474eb-f0e3-4e4a-bf65-09c7902399f7,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-881431004-172.17.0.21-1599331075583:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-e89f4347-1aeb-4834-a95f-3061800a3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-9eb86082-0181-43e3-8459-743cf6561f00,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9b40342f-3e49-48d8-803b-cc104e8c0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-d8b929c6-8700-4d1a-9ffc-6d1e44f158e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-8e7dc775-1414-4503-ac30-7464810f7ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-478a4881-fae2-4ac3-b552-27e67d6cd8a8,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-881431004-172.17.0.21-1599331075583:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-e89f4347-1aeb-4834-a95f-3061800a3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-9eb86082-0181-43e3-8459-743cf6561f00,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-9b40342f-3e49-48d8-803b-cc104e8c0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-d8b929c6-8700-4d1a-9ffc-6d1e44f158e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-8e7dc775-1414-4503-ac30-7464810f7ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-478a4881-fae2-4ac3-b552-27e67d6cd8a8,DISK]]; indices=[0, 2, 3, 4, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1410400566-172.17.0.21-1599331173199:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-bfa2ac42-f9ea-4d8d-9b08-58236bd19746,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-cf14c83f-d673-4ced-b4cf-6812696f992c,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-091d6c90-422e-451e-b031-494ced28c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-1016ce0c-5a1f-443a-b469-b37c5ec5ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-89f93498-480c-493e-9d13-ed40a53924ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-898541ea-ae93-41ac-9c3d-06b6c5e4cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-60e99151-e07a-4880-86d2-86be3756f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-ef077b9a-6320-4829-a3c2-84da2e1b8272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1410400566-172.17.0.21-1599331173199:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-bfa2ac42-f9ea-4d8d-9b08-58236bd19746,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-cf14c83f-d673-4ced-b4cf-6812696f992c,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-091d6c90-422e-451e-b031-494ced28c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-1016ce0c-5a1f-443a-b469-b37c5ec5ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-89f93498-480c-493e-9d13-ed40a53924ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-898541ea-ae93-41ac-9c3d-06b6c5e4cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-60e99151-e07a-4880-86d2-86be3756f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-ef077b9a-6320-4829-a3c2-84da2e1b8272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-776010176-172.17.0.21-1599331318010:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-a6e83594-50f2-4de0-8f39-c7cadedab25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-7f5e0792-2294-40f5-bc24-e1cf12fb458f,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-0f2cf469-aa23-4018-8798-4f12ca27ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-335671b6-8216-4a8a-a368-758688d774a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-c2a7ffab-c6e9-49a4-b457-49123cc6fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-ffa8017f-fb2e-4726-b375-e29ed8919fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9369eb78-532c-4a69-a86f-c82c2c71e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-776010176-172.17.0.21-1599331318010:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-a6e83594-50f2-4de0-8f39-c7cadedab25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-7f5e0792-2294-40f5-bc24-e1cf12fb458f,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-0f2cf469-aa23-4018-8798-4f12ca27ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-335671b6-8216-4a8a-a368-758688d774a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-c2a7ffab-c6e9-49a4-b457-49123cc6fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-ffa8017f-fb2e-4726-b375-e29ed8919fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9369eb78-532c-4a69-a86f-c82c2c71e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-923021541-172.17.0.21-1599331616295:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-a3de5437-19a3-4693-8700-6d80a1e155db,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-6daf48d8-7dd1-427e-b146-b89e2a3e3337,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-dfebf6c2-9825-436d-bf50-614cd528cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-d90b5dd7-838f-4ca5-93c6-0b7022745210,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-abc51dce-9495-4fdd-875f-5ced0cb409c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-aa06792e-760c-4dae-8e60-85d33995ea77,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-923021541-172.17.0.21-1599331616295:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36675,DS-a3de5437-19a3-4693-8700-6d80a1e155db,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-6daf48d8-7dd1-427e-b146-b89e2a3e3337,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-dfebf6c2-9825-436d-bf50-614cd528cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-d90b5dd7-838f-4ca5-93c6-0b7022745210,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-abc51dce-9495-4fdd-875f-5ced0cb409c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-aa06792e-760c-4dae-8e60-85d33995ea77,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-224615979-172.17.0.21-1599331816194:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-89ec5b87-1d55-4032-a9a4-0f9b8b919215,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-a2990094-be7e-41da-aaef-8884aa86b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-4be731f6-3667-48a0-b2d6-8d73a2b471f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-182223c7-cd10-4487-af45-11f916acca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-9bd8daf1-81cd-486d-8971-5c9cfb2d4d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-fb553348-d5d3-4a7c-aa09-29c247209e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-eeee6f60-ee18-4735-a3dd-d7da0cefaf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-49b4013c-0c58-430b-bb14-8b0834041a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-224615979-172.17.0.21-1599331816194:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-89ec5b87-1d55-4032-a9a4-0f9b8b919215,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-a2990094-be7e-41da-aaef-8884aa86b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-4be731f6-3667-48a0-b2d6-8d73a2b471f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-182223c7-cd10-4487-af45-11f916acca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-9bd8daf1-81cd-486d-8971-5c9cfb2d4d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-fb553348-d5d3-4a7c-aa09-29c247209e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-eeee6f60-ee18-4735-a3dd-d7da0cefaf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-49b4013c-0c58-430b-bb14-8b0834041a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-278204360-172.17.0.21-1599332075708:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-bf76d965-732c-49e5-b9f3-61d5414141e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4fc72381-ef20-481b-9d13-8d93ab7bd7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-d9c67aa9-31ef-4ea8-8397-e349817cc008,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-89340f8b-d541-48d4-bdf0-845dc4188ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-85a5c37b-b9ca-42b3-9d9d-2b93f4ab7c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-0207ad77-6d80-40fc-b299-7023349cd0f7,DISK]]; indices=[3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-278204360-172.17.0.21-1599332075708:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-bf76d965-732c-49e5-b9f3-61d5414141e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4fc72381-ef20-481b-9d13-8d93ab7bd7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-d9c67aa9-31ef-4ea8-8397-e349817cc008,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-89340f8b-d541-48d4-bdf0-845dc4188ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-85a5c37b-b9ca-42b3-9d9d-2b93f4ab7c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-0207ad77-6d80-40fc-b299-7023349cd0f7,DISK]]; indices=[3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2015441246-172.17.0.21-1599332359058:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-6f2e09aa-79d6-4bfc-88c8-7b841c145939,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-93ba9e3c-7d3a-44f7-9333-869d84a48e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-0b5ed4ba-a15a-4cf7-8627-2069f5092ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-d400ec1e-f13b-455c-9104-d81082249e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-6d3849e4-3c99-4eca-a2f1-71e523e78deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-94ec36c1-7447-4f4e-9b3f-099654081d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-ca5f8f84-3565-4ffb-b36b-ea23701b1701,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2015441246-172.17.0.21-1599332359058:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-6f2e09aa-79d6-4bfc-88c8-7b841c145939,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-93ba9e3c-7d3a-44f7-9333-869d84a48e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-0b5ed4ba-a15a-4cf7-8627-2069f5092ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-d400ec1e-f13b-455c-9104-d81082249e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-6d3849e4-3c99-4eca-a2f1-71e523e78deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-94ec36c1-7447-4f4e-9b3f-099654081d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-ca5f8f84-3565-4ffb-b36b-ea23701b1701,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-230522047-172.17.0.21-1599333271439:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43335,DS-d64ee676-0e12-407a-9b86-f92d690dbec7,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-31bddbcc-b9b6-4e21-9bf1-3a94b60b795b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-5c691cd0-af9c-47bc-a916-fdc9bf364ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-12118d30-7226-40e7-93de-c7573532e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-58ccab24-2a96-45e5-bc26-b3059bdc7283,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-f546b7fb-bda2-4ad3-b481-f29cf594cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-1072087b-9cf5-4c4b-808b-3cbda5335720,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d24e767c-be93-4764-b4d2-0ce18ca95ef5,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-230522047-172.17.0.21-1599333271439:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43335,DS-d64ee676-0e12-407a-9b86-f92d690dbec7,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-31bddbcc-b9b6-4e21-9bf1-3a94b60b795b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-5c691cd0-af9c-47bc-a916-fdc9bf364ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-12118d30-7226-40e7-93de-c7573532e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-58ccab24-2a96-45e5-bc26-b3059bdc7283,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-f546b7fb-bda2-4ad3-b481-f29cf594cda8,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-1072087b-9cf5-4c4b-808b-3cbda5335720,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-d24e767c-be93-4764-b4d2-0ce18ca95ef5,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2009494719-172.17.0.21-1599333413251:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-33cffc43-fdd9-4a38-8a2d-27577ff16d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-f289a7ba-c2b8-4823-9204-039eda38ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-876f3d97-221e-4050-bae3-c4c986a2b114,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-b6176162-cc24-4054-9ba0-5a1fd9ab1def,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-260adc20-8c28-453c-bed6-2ff700c3a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-94ff9a9a-a0f8-4e35-80b0-58ccfdc1509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e499d45e-e66d-420e-ad77-9198f76c6225,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2009494719-172.17.0.21-1599333413251:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-33cffc43-fdd9-4a38-8a2d-27577ff16d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-f289a7ba-c2b8-4823-9204-039eda38ed85,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-876f3d97-221e-4050-bae3-c4c986a2b114,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-b6176162-cc24-4054-9ba0-5a1fd9ab1def,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-260adc20-8c28-453c-bed6-2ff700c3a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-94ff9a9a-a0f8-4e35-80b0-58ccfdc1509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e499d45e-e66d-420e-ad77-9198f76c6225,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1947894991-172.17.0.21-1599333554762:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-6a32839d-9e6f-4eb8-9f34-223718817fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-2b668d4a-c2e0-40ce-b0ff-59fa6395ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-a7adc172-21d0-4f1c-8740-cf4e92afd59a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-78f9748a-cb17-4884-8b51-13e01533d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-2a9e013c-518a-4e4b-8680-556d136e3574,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-adc2617c-6748-44c9-8d65-38a2805c7df6,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-68c6c6f8-31d2-46f3-8980-756666ff5916,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-98fcb3ec-c341-4d29-b57d-af901940216e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1947894991-172.17.0.21-1599333554762:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-6a32839d-9e6f-4eb8-9f34-223718817fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-2b668d4a-c2e0-40ce-b0ff-59fa6395ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-a7adc172-21d0-4f1c-8740-cf4e92afd59a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-78f9748a-cb17-4884-8b51-13e01533d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-2a9e013c-518a-4e4b-8680-556d136e3574,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-adc2617c-6748-44c9-8d65-38a2805c7df6,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-68c6c6f8-31d2-46f3-8980-756666ff5916,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-98fcb3ec-c341-4d29-b57d-af901940216e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-492082042-172.17.0.21-1599333988957:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-4928a431-419e-4390-af8d-c70aa493b936,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-73688b2d-7fd1-44f4-8063-44ca525bfc27,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-9d640f47-ea58-450e-b7b1-822e36d9591e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-f07256c8-54c0-421e-a892-7b20f1437ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-5c142c16-fdab-42e3-a4cd-10bb48f990b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-bc7bfc7a-730f-4f19-a725-f4ede8e8270a,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-8e1c381e-f0eb-4fad-90d1-fefc71774ef4,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-492082042-172.17.0.21-1599333988957:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-4928a431-419e-4390-af8d-c70aa493b936,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-73688b2d-7fd1-44f4-8063-44ca525bfc27,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-9d640f47-ea58-450e-b7b1-822e36d9591e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-f07256c8-54c0-421e-a892-7b20f1437ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-5c142c16-fdab-42e3-a4cd-10bb48f990b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-bc7bfc7a-730f-4f19-a725-f4ede8e8270a,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-8e1c381e-f0eb-4fad-90d1-fefc71774ef4,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-447939014-172.17.0.21-1599334597056:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-acd82619-bef8-4468-b9fa-85019ca9fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-8ea92180-8a89-42a6-81de-3c07acd3a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-471b07c3-c0c4-4e8d-a606-ce91ee5b247c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2a9a7c92-6916-4b56-922c-64eaa3057067,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-99d1d1e5-1132-4697-ade8-7e162cf95398,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-2a8b303b-5c23-4a6c-be81-ab4e8c822af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-26c0d05e-b64c-406a-8fd3-4f1884e682eb,DISK]]; indices=[0, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-447939014-172.17.0.21-1599334597056:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-acd82619-bef8-4468-b9fa-85019ca9fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-8ea92180-8a89-42a6-81de-3c07acd3a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-471b07c3-c0c4-4e8d-a606-ce91ee5b247c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2a9a7c92-6916-4b56-922c-64eaa3057067,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-99d1d1e5-1132-4697-ade8-7e162cf95398,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-2a8b303b-5c23-4a6c-be81-ab4e8c822af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-26c0d05e-b64c-406a-8fd3-4f1884e682eb,DISK]]; indices=[0, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-720788637-172.17.0.21-1599334883972:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-f35668a7-7abc-49b7-8f4f-29eaec5e51de,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-f7d50b94-175c-47d0-82b6-34f02b0d01c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-7b9fa524-8c0b-4448-9543-5c64bb9a503c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-99e9c54a-1ca4-468a-ae5a-39a046f0a686,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-26dd4f13-701d-4621-a76d-bd21aaa6c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-86a35757-1bb1-4bcd-902d-c6d5bf6e0c4a,DISK]]; indices=[0, 1, 3, 4, 5, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-720788637-172.17.0.21-1599334883972:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-f35668a7-7abc-49b7-8f4f-29eaec5e51de,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-f7d50b94-175c-47d0-82b6-34f02b0d01c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-7b9fa524-8c0b-4448-9543-5c64bb9a503c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-99e9c54a-1ca4-468a-ae5a-39a046f0a686,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-26dd4f13-701d-4621-a76d-bd21aaa6c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-86a35757-1bb1-4bcd-902d-c6d5bf6e0c4a,DISK]]; indices=[0, 1, 3, 4, 5, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-74311232-172.17.0.21-1599335019376:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39312,DS-4024d25f-db50-4a21-b1b7-7221ea2a996c,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-e01e72ed-c1e1-48ac-a737-f29a32abde42,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-b342d8a7-389d-43fd-a77c-c9ac806c9f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-dd4462ed-6c53-4a9e-bfc3-3a33dd8678b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-6c4d2b68-3575-4442-87ee-002c84864d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-be46bfc3-28ea-4d40-8db5-bc838ce28907,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-46ea9fed-0481-46a6-9636-7e577b6473bc,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-74311232-172.17.0.21-1599335019376:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39312,DS-4024d25f-db50-4a21-b1b7-7221ea2a996c,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-e01e72ed-c1e1-48ac-a737-f29a32abde42,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-b342d8a7-389d-43fd-a77c-c9ac806c9f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-dd4462ed-6c53-4a9e-bfc3-3a33dd8678b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-6c4d2b68-3575-4442-87ee-002c84864d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-be46bfc3-28ea-4d40-8db5-bc838ce28907,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-46ea9fed-0481-46a6-9636-7e577b6473bc,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1282506059-172.17.0.21-1599335493048:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-2c42dcf1-cb08-4bb4-827c-ff5c34dee424,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1b7973be-e55d-415e-bd6d-81a72409d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-047257d5-764e-41d7-a16a-5a146fac1a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-06277d5f-b46d-4133-8866-b6351f115228,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-918edeb2-f7a6-4ddc-a066-25b761abf5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-71439dae-eaa4-4de5-bf01-9a717f4a8330,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-d0a70a8c-9edb-4b44-9b60-591b26e3154a,DISK]]; indices=[0, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1282506059-172.17.0.21-1599335493048:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-2c42dcf1-cb08-4bb4-827c-ff5c34dee424,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1b7973be-e55d-415e-bd6d-81a72409d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-047257d5-764e-41d7-a16a-5a146fac1a90,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-06277d5f-b46d-4133-8866-b6351f115228,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-918edeb2-f7a6-4ddc-a066-25b761abf5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-71439dae-eaa4-4de5-bf01-9a717f4a8330,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-d0a70a8c-9edb-4b44-9b60-591b26e3154a,DISK]]; indices=[0, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2067380214-172.17.0.21-1599335655604:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-1154b5c8-6626-4372-be10-c23cf79348ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ab6d2270-735a-4457-a1e0-a3a6f9ed3a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-3bc86edd-62e8-4efe-9618-60fa60d455ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-dda24479-8ea0-481f-81d1-3d0d818e0078,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-33a8a288-9730-4aee-bed0-4b8784589464,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-2edfb223-adaa-46f3-b9ad-f4106de4f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-d8102586-aaf2-4954-a519-1886daf0b94e,DISK]]; indices=[0, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2067380214-172.17.0.21-1599335655604:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-1154b5c8-6626-4372-be10-c23cf79348ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ab6d2270-735a-4457-a1e0-a3a6f9ed3a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-3bc86edd-62e8-4efe-9618-60fa60d455ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-dda24479-8ea0-481f-81d1-3d0d818e0078,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-33a8a288-9730-4aee-bed0-4b8784589464,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-2edfb223-adaa-46f3-b9ad-f4106de4f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-d8102586-aaf2-4954-a519-1886daf0b94e,DISK]]; indices=[0, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1213887492-172.17.0.21-1599335810897:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-4c09b9fe-76e1-46c0-81e0-f3d8002fad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-e635d30f-a37b-49e4-8c49-47f7b5a25d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-1b3d9108-1bee-42f8-bbc3-5ea10b5b42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-41562e55-e835-415d-a6ad-41c418db7a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-81b87dc2-9358-4a68-8c1f-a0944304aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-afcf2137-5cd8-4c35-8521-85cee6ed2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-436072ea-2362-41cb-bd59-d6feb5a1de88,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-dd47d679-1297-4679-8af8-0e52d925b2a9,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1213887492-172.17.0.21-1599335810897:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-4c09b9fe-76e1-46c0-81e0-f3d8002fad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-e635d30f-a37b-49e4-8c49-47f7b5a25d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-1b3d9108-1bee-42f8-bbc3-5ea10b5b42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-41562e55-e835-415d-a6ad-41c418db7a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-81b87dc2-9358-4a68-8c1f-a0944304aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-afcf2137-5cd8-4c35-8521-85cee6ed2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-436072ea-2362-41cb-bd59-d6feb5a1de88,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-dd47d679-1297-4679-8af8-0e52d925b2a9,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-245458689-172.17.0.21-1599335946815:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-73c4e43e-3d9d-405a-957e-2d6cbabbead4,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-dab11c72-9920-464d-a449-1f5d2d01eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-dd58412b-d4f4-4417-b38f-8f0e8365f907,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-1bf8b564-74a0-406d-a1e7-770a033a8042,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-6e8b616d-9935-4e9c-95ef-88efbd3ca66d,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4223287d-933e-45e3-80bf-cdf61d18ab90,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-245458689-172.17.0.21-1599335946815:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-73c4e43e-3d9d-405a-957e-2d6cbabbead4,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-dab11c72-9920-464d-a449-1f5d2d01eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-dd58412b-d4f4-4417-b38f-8f0e8365f907,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-1bf8b564-74a0-406d-a1e7-770a033a8042,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-6e8b616d-9935-4e9c-95ef-88efbd3ca66d,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-4223287d-933e-45e3-80bf-cdf61d18ab90,DISK]]; indices=[1, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1522728603-172.17.0.21-1599336083683:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-0a8ade2c-eac8-4507-b5f4-88301adb6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-82eef705-6944-430c-9eb1-22f9ef2e88f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-4e1b0b8b-931e-4ab3-8786-639a88c9fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-334dd7fb-b874-48aa-971b-b1b201285ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-1a4be000-bb80-4b63-820a-cb67c7ca75ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-4a0908fb-edeb-40c1-ad77-aea71b380ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-788b0620-2e4c-47e8-a04d-e0c71e47a687,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-c5476fb4-6863-4eb6-a537-62559410d4e9,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1522728603-172.17.0.21-1599336083683:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-0a8ade2c-eac8-4507-b5f4-88301adb6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-82eef705-6944-430c-9eb1-22f9ef2e88f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-4e1b0b8b-931e-4ab3-8786-639a88c9fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-334dd7fb-b874-48aa-971b-b1b201285ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-1a4be000-bb80-4b63-820a-cb67c7ca75ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-4a0908fb-edeb-40c1-ad77-aea71b380ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-788b0620-2e4c-47e8-a04d-e0c71e47a687,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-c5476fb4-6863-4eb6-a537-62559410d4e9,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
Warn: test org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7 has not been updated !
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1766072752-172.17.0.21-1599337117221:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-6c07771e-5b61-447f-a487-040909a9c790,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9189269f-7e89-43da-b213-a34236b24296,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-bd59ccf7-54b3-4112-808d-e2714361d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-46001755-0250-4da4-9238-13c8d474af84,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-4f2b6487-38aa-48f6-a089-2c35093a843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0055143b-7635-4d61-bd39-dcfed270c7a4,DISK]]; indices=[0, 1, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1766072752-172.17.0.21-1599337117221:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-6c07771e-5b61-447f-a487-040909a9c790,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-9189269f-7e89-43da-b213-a34236b24296,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-bd59ccf7-54b3-4112-808d-e2714361d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-46001755-0250-4da4-9238-13c8d474af84,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-4f2b6487-38aa-48f6-a089-2c35093a843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0055143b-7635-4d61-bd39-dcfed270c7a4,DISK]]; indices=[0, 1, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-998055351-172.17.0.21-1599337450335:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-49b6a8ec-b46a-4031-a223-ca4e76e397ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b33d1b33-ddae-49b4-940b-3b712d7bc754,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-1ede7375-bd9e-46b7-8004-8ec697d3a788,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-576d8ea0-aae4-45a5-b258-7080bab3cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-31fccb11-9e83-4026-9822-ad4ffdce6bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-25a733bb-d051-4c7e-be1b-647d20583b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-d17093a5-4e31-4336-80ca-0108f2f5919c,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ca75d167-ee8f-46e4-9d76-d607155d4943,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-998055351-172.17.0.21-1599337450335:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-49b6a8ec-b46a-4031-a223-ca4e76e397ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b33d1b33-ddae-49b4-940b-3b712d7bc754,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-1ede7375-bd9e-46b7-8004-8ec697d3a788,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-576d8ea0-aae4-45a5-b258-7080bab3cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-31fccb11-9e83-4026-9822-ad4ffdce6bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-25a733bb-d051-4c7e-be1b-647d20583b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-d17093a5-4e31-4336-80ca-0108f2f5919c,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ca75d167-ee8f-46e4-9d76-d607155d4943,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-571059029-172.17.0.21-1599337608478:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-7e29558e-019b-4bff-8fd3-71ebbba42dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-1f4cdf7d-1ab1-4222-b790-b6f58a3f15e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7bb63f83-d9d3-49e2-917b-085449987dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3ec7250c-41ac-4e6a-b043-6ef667a30351,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-af202081-b289-4ba5-b718-a02c80700df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-3647a24c-8518-4424-bf16-3c4c8a573fce,DISK]]; indices=[0, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-571059029-172.17.0.21-1599337608478:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-7e29558e-019b-4bff-8fd3-71ebbba42dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-1f4cdf7d-1ab1-4222-b790-b6f58a3f15e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7bb63f83-d9d3-49e2-917b-085449987dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-3ec7250c-41ac-4e6a-b043-6ef667a30351,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-af202081-b289-4ba5-b718-a02c80700df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-3647a24c-8518-4424-bf16-3c4c8a573fce,DISK]]; indices=[0, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2057739618-172.17.0.21-1599337765082:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-a19520fd-6430-40ab-987c-a0120aa9b608,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-8c81ff1b-d9db-4bc7-a21a-cfe2e19dbc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-419980fc-61d1-4f40-94c1-d6ef8bc13552,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2def89f7-25f7-4c2b-a349-195e902fcfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f860a917-a785-48c7-8b73-ed8c1bf1abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-9181448d-feec-4fb1-9d7d-32bb937b11bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fa3e139f-b61b-4c45-bdfb-10261358df17,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ad9c4e61-3114-40ee-a7bd-266bd479d625,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2057739618-172.17.0.21-1599337765082:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-a19520fd-6430-40ab-987c-a0120aa9b608,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-8c81ff1b-d9db-4bc7-a21a-cfe2e19dbc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-419980fc-61d1-4f40-94c1-d6ef8bc13552,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2def89f7-25f7-4c2b-a349-195e902fcfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f860a917-a785-48c7-8b73-ed8c1bf1abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-9181448d-feec-4fb1-9d7d-32bb937b11bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fa3e139f-b61b-4c45-bdfb-10261358df17,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ad9c4e61-3114-40ee-a7bd-266bd479d625,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 27 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 8394
