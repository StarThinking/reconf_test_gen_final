reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41552,DS-b1d21866-480b-40b2-beea-21ed3b1c9d4e,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41552,DS-b1d21866-480b-40b2-beea-21ed3b1c9d4e,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36125,DS-5a9f87a7-94a6-4b32-9336-fe2f64ed8579,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36125,DS-5a9f87a7-94a6-4b32-9336-fe2f64ed8579,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41289,DS-4eaad471-9bd0-4ce5-8043-32b04dd9afb3,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41289,DS-4eaad471-9bd0-4ce5-8043-32b04dd9afb3,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41021,DS-cb491720-ef89-42a8-a0da-bd7c31309195,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41021,DS-cb491720-ef89-42a8-a0da-bd7c31309195,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34502,DS-bd86c1e2-7c75-47c0-a407-596a07e1504c,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34502,DS-bd86c1e2-7c75-47c0-a407-596a07e1504c,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46599,DS-f7ce5e84-0510-4d70-b8f5-6754b7eadf18,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:46599,DS-f7ce5e84-0510-4d70-b8f5-6754b7eadf18,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36191,DS-3ac9ea64-f15e-43f5-8dce-f98ff9f3e99a,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36191,DS-3ac9ea64-f15e-43f5-8dce-f98ff9f3e99a,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36877,DS-6fefe198-1f56-4ba1-8577-6e8661109e10,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36877,DS-6fefe198-1f56-4ba1-8577-6e8661109e10,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38355,DS-402996d5-4d12-430c-9c78-502c7d8dab7a,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38355,DS-402996d5-4d12-430c-9c78-502c7d8dab7a,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39523,DS-8392aab9-7299-4894-b4c3-78e289d18507,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39523,DS-8392aab9-7299-4894-b4c3-78e289d18507,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 597
