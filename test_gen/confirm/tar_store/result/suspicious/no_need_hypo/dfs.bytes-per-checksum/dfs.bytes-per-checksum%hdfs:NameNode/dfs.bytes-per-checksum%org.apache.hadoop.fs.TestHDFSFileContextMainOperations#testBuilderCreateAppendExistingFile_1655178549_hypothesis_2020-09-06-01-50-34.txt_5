reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34308,DS-5cc4af38-19e9-44d2-840e-c87a66b9beba,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34308,DS-5cc4af38-19e9-44d2-840e-c87a66b9beba,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38807,DS-b7e6863f-db5e-4858-b2c0-8815867d55a9,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38807,DS-b7e6863f-db5e-4858-b2c0-8815867d55a9,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36195,DS-1f453aab-4de6-4db1-ae9b-df568334d997,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36195,DS-1f453aab-4de6-4db1-ae9b-df568334d997,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36171,DS-b6efc921-b17b-4b0a-b05a-8d7c04f2eaa4,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36171,DS-b6efc921-b17b-4b0a-b05a-8d7c04f2eaa4,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39413,DS-7e093425-e755-4bd3-8719-784867352edc,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39413,DS-7e093425-e755-4bd3-8719-784867352edc,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41022,DS-917cee61-0145-4106-abdf-fed3936fa87b,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41022,DS-917cee61-0145-4106-abdf-fed3936fa87b,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:37232,DS-f6657c66-d27d-4ed9-acf2-a5d0145bfab7,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:37232,DS-f6657c66-d27d-4ed9-acf2-a5d0145bfab7,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44749,DS-a6d54fd3-f353-4a97-92d5-444b16641932,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:44749,DS-a6d54fd3-f353-4a97-92d5-444b16641932,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38086,DS-8882ab3d-0194-47f1-baaa-19256edbde85,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:38086,DS-8882ab3d-0194-47f1-baaa-19256edbde85,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 32
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testBuilderCreateAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35630,DS-c6811be5-945e-40d2-8d48-7ab465509f5a,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35630,DS-c6811be5-945e-40d2-8d48-7ab465509f5a,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 682
