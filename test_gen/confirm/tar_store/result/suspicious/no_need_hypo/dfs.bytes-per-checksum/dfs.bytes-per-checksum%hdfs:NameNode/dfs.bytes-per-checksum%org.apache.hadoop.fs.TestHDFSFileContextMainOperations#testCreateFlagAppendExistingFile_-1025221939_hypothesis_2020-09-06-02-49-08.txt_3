reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45284,DS-27014ea4-9398-4e4f-8639-4fe9c500ac68,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:45284,DS-27014ea4-9398-4e4f-8639-4fe9c500ac68,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41732,DS-66ababe5-1d19-4836-939d-6de65145f80d,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:41732,DS-66ababe5-1d19-4836-939d-6de65145f80d,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:33318,DS-a46b0759-d7db-4842-a97e-c981e9b45843,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:33318,DS-a46b0759-d7db-4842-a97e-c981e9b45843,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35488,DS-8a213ffd-6c54-4bef-8a3d-099217d6f2fd,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:35488,DS-8a213ffd-6c54-4bef-8a3d-099217d6f2fd,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36055,DS-36e0c07f-d704-4b33-a114-dae86aa3b864,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36055,DS-36e0c07f-d704-4b33-a114-dae86aa3b864,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b50d08b-1307-471e-b99a-10267c24bc0c,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b50d08b-1307-471e-b99a-10267c24bc0c,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39144,DS-823210b7-d475-4951-902e-faa7b6221feb,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:39144,DS-823210b7-d475-4951-902e-faa7b6221feb,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34836,DS-f3915e15-056c-4f38-ba6e-a622ad702a60,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34836,DS-f3915e15-056c-4f38-ba6e-a622ad702a60,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34327,DS-5d59b481-869b-4336-ad11-e9665434e936,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:34327,DS-5d59b481-869b-4336-ad11-e9665434e936,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.fs.TestHDFSFileContextMainOperations#testCreateFlagAppendExistingFile
reconfPoint: 1
result: -1
failureMessage: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36996,DS-12479580-50a3-409a-b845-a12be3d2ed3d,DISK]] are bad. Aborting...
stackTrace: java.io.IOException: All datanodes [DatanodeInfoWithStorage[127.0.0.1:36996,DS-12479580-50a3-409a-b845-a12be3d2ed3d,DISK]] are bad. Aborting...
	at org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1561)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1495)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 647
