reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-faec2133-a712-49ab-a072-0f09e126d326,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-b409cd4b-13d5-4dcf-90d4-0dd3ecea80b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-faec2133-a712-49ab-a072-0f09e126d326,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-b409cd4b-13d5-4dcf-90d4-0dd3ecea80b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-faec2133-a712-49ab-a072-0f09e126d326,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-b409cd4b-13d5-4dcf-90d4-0dd3ecea80b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45044,DS-faec2133-a712-49ab-a072-0f09e126d326,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-b409cd4b-13d5-4dcf-90d4-0dd3ecea80b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-56f9bc90-126d-4488-bb4a-2a4701a60eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-89a40796-0bbb-47a5-8cdd-987c2a03404f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-56f9bc90-126d-4488-bb4a-2a4701a60eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-89a40796-0bbb-47a5-8cdd-987c2a03404f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-56f9bc90-126d-4488-bb4a-2a4701a60eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-89a40796-0bbb-47a5-8cdd-987c2a03404f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-56f9bc90-126d-4488-bb4a-2a4701a60eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-89a40796-0bbb-47a5-8cdd-987c2a03404f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-d78da1d7-dc87-4148-8bc7-8cca8ed736ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0c84c30f-2e98-47d5-846c-1d8da1efba63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-d78da1d7-dc87-4148-8bc7-8cca8ed736ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0c84c30f-2e98-47d5-846c-1d8da1efba63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-d78da1d7-dc87-4148-8bc7-8cca8ed736ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0c84c30f-2e98-47d5-846c-1d8da1efba63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-d78da1d7-dc87-4148-8bc7-8cca8ed736ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0c84c30f-2e98-47d5-846c-1d8da1efba63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e5110aaa-2fbf-4118-9cd8-c63c511a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fd7f4006-d49c-4867-b4db-c6cfc6fa5e99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e5110aaa-2fbf-4118-9cd8-c63c511a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fd7f4006-d49c-4867-b4db-c6cfc6fa5e99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e5110aaa-2fbf-4118-9cd8-c63c511a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fd7f4006-d49c-4867-b4db-c6cfc6fa5e99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-e5110aaa-2fbf-4118-9cd8-c63c511a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fd7f4006-d49c-4867-b4db-c6cfc6fa5e99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-0a527c7e-f04e-4d3f-b664-489abf72a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-dd5828cd-e51e-4141-9d42-964c5dc814d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-0a527c7e-f04e-4d3f-b664-489abf72a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-dd5828cd-e51e-4141-9d42-964c5dc814d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-0a527c7e-f04e-4d3f-b664-489abf72a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-dd5828cd-e51e-4141-9d42-964c5dc814d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-0a527c7e-f04e-4d3f-b664-489abf72a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-dd5828cd-e51e-4141-9d42-964c5dc814d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-b97259cd-19d7-44e8-b100-e047bc4e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-8274ea2b-7f7d-46aa-8ad0-d89dccf8c53d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-b97259cd-19d7-44e8-b100-e047bc4e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-8274ea2b-7f7d-46aa-8ad0-d89dccf8c53d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-b97259cd-19d7-44e8-b100-e047bc4e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-8274ea2b-7f7d-46aa-8ad0-d89dccf8c53d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-b97259cd-19d7-44e8-b100-e047bc4e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-8274ea2b-7f7d-46aa-8ad0-d89dccf8c53d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9dc6e534-c4e0-448b-83a6-38e81a5c8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ceb3acf8-32ef-41b1-ad5b-911eb84d93ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9dc6e534-c4e0-448b-83a6-38e81a5c8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ceb3acf8-32ef-41b1-ad5b-911eb84d93ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9dc6e534-c4e0-448b-83a6-38e81a5c8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ceb3acf8-32ef-41b1-ad5b-911eb84d93ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9dc6e534-c4e0-448b-83a6-38e81a5c8cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ceb3acf8-32ef-41b1-ad5b-911eb84d93ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-136acae0-a205-4409-a285-c700f26dccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-a0f087c2-5051-4c82-98ea-cde2dfd524c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-a0f087c2-5051-4c82-98ea-cde2dfd524c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-136acae0-a205-4409-a285-c700f26dccb2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-136acae0-a205-4409-a285-c700f26dccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-a0f087c2-5051-4c82-98ea-cde2dfd524c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-a0f087c2-5051-4c82-98ea-cde2dfd524c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-136acae0-a205-4409-a285-c700f26dccb2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-03056808-02ca-4e8d-8dcf-58fa158660cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6d85aae3-d149-46e3-be3f-f1a9a414b678,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-03056808-02ca-4e8d-8dcf-58fa158660cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6d85aae3-d149-46e3-be3f-f1a9a414b678,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-03056808-02ca-4e8d-8dcf-58fa158660cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6d85aae3-d149-46e3-be3f-f1a9a414b678,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-03056808-02ca-4e8d-8dcf-58fa158660cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-6d85aae3-d149-46e3-be3f-f1a9a414b678,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testSecondaryNameNodeWithSavedLeases
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-ae02d059-c92f-423f-a633-718b15392922,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-6956920d-5b6c-4f5a-a3bd-148ad819fb9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-6956920d-5b6c-4f5a-a3bd-148ad819fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-ae02d059-c92f-423f-a633-718b15392922,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-ae02d059-c92f-423f-a633-718b15392922,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-6956920d-5b6c-4f5a-a3bd-148ad819fb9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-6956920d-5b6c-4f5a-a3bd-148ad819fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-ae02d059-c92f-423f-a633-718b15392922,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 723
