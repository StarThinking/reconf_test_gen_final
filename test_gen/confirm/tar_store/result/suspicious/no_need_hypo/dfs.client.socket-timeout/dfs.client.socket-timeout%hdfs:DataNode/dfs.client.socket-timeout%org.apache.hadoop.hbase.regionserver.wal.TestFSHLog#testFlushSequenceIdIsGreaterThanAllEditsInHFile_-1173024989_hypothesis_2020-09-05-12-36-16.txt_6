reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-43ba5f16-022f-43b2-9417-b929cb1d2df3,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-5971d8ce-e74d-407e-8915-af76231f3814,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-43ba5f16-022f-43b2-9417-b929cb1d2df3,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-5971d8ce-e74d-407e-8915-af76231f3814,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-43ba5f16-022f-43b2-9417-b929cb1d2df3,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-5971d8ce-e74d-407e-8915-af76231f3814,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-43ba5f16-022f-43b2-9417-b929cb1d2df3,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-5971d8ce-e74d-407e-8915-af76231f3814,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-ffd43c31-a162-4537-8aa4-b1463d623852,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-c8d399d9-7a1d-4145-8488-549071935bec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-ffd43c31-a162-4537-8aa4-b1463d623852,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-c8d399d9-7a1d-4145-8488-549071935bec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-ffd43c31-a162-4537-8aa4-b1463d623852,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-c8d399d9-7a1d-4145-8488-549071935bec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-ffd43c31-a162-4537-8aa4-b1463d623852,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-c8d399d9-7a1d-4145-8488-549071935bec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-45ea1387-b8ec-4b05-8bbb-5bbe99bed7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b2618f85-f723-4d07-b9cc-1abff1c21bd5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-45ea1387-b8ec-4b05-8bbb-5bbe99bed7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b2618f85-f723-4d07-b9cc-1abff1c21bd5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-45ea1387-b8ec-4b05-8bbb-5bbe99bed7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b2618f85-f723-4d07-b9cc-1abff1c21bd5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-45ea1387-b8ec-4b05-8bbb-5bbe99bed7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b2618f85-f723-4d07-b9cc-1abff1c21bd5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-476f0524-87e7-46a8-a90d-faec1c873900,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-40fc992b-597a-49a5-b79a-055614b75083,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-476f0524-87e7-46a8-a90d-faec1c873900,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-40fc992b-597a-49a5-b79a-055614b75083,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-476f0524-87e7-46a8-a90d-faec1c873900,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-40fc992b-597a-49a5-b79a-055614b75083,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-476f0524-87e7-46a8-a90d-faec1c873900,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-40fc992b-597a-49a5-b79a-055614b75083,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-6978352c-f466-4855-8df5-e93a11e3d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a15a0eba-9170-431d-8ed0-64ff58f8011a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-a15a0eba-9170-431d-8ed0-64ff58f8011a,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-6978352c-f466-4855-8df5-e93a11e3d82c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41829,DS-6978352c-f466-4855-8df5-e93a11e3d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-a15a0eba-9170-431d-8ed0-64ff58f8011a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-a15a0eba-9170-431d-8ed0-64ff58f8011a,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-6978352c-f466-4855-8df5-e93a11e3d82c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-911b6592-418d-43e5-9bb5-85581e50b1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-1828867f-c36b-434d-868e-bad1c53e2317,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-1828867f-c36b-434d-868e-bad1c53e2317,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-911b6592-418d-43e5-9bb5-85581e50b1c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-911b6592-418d-43e5-9bb5-85581e50b1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-1828867f-c36b-434d-868e-bad1c53e2317,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-1828867f-c36b-434d-868e-bad1c53e2317,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-911b6592-418d-43e5-9bb5-85581e50b1c5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-249347ac-2149-490c-a5d2-3f3efe9e82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-d45d6b0d-2337-4f07-8033-b74e7c4c7a8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33500,DS-d45d6b0d-2337-4f07-8033-b74e7c4c7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-249347ac-2149-490c-a5d2-3f3efe9e82bf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-249347ac-2149-490c-a5d2-3f3efe9e82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-d45d6b0d-2337-4f07-8033-b74e7c4c7a8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33500,DS-d45d6b0d-2337-4f07-8033-b74e7c4c7a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-249347ac-2149-490c-a5d2-3f3efe9e82bf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43434,DS-937970e4-c7ed-4557-8333-1922ce2b887c,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-7b77e6d9-25d5-47ae-9e14-a9620effee86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46441,DS-7b77e6d9-25d5-47ae-9e14-a9620effee86,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-937970e4-c7ed-4557-8333-1922ce2b887c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43434,DS-937970e4-c7ed-4557-8333-1922ce2b887c,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-7b77e6d9-25d5-47ae-9e14-a9620effee86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46441,DS-7b77e6d9-25d5-47ae-9e14-a9620effee86,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-937970e4-c7ed-4557-8333-1922ce2b887c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-6ecd35ab-2574-4582-9acc-e571db9a7644,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-48c13ae0-2ae2-47da-b60c-cb37f5d8fa45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-6ecd35ab-2574-4582-9acc-e571db9a7644,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-48c13ae0-2ae2-47da-b60c-cb37f5d8fa45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-6ecd35ab-2574-4582-9acc-e571db9a7644,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-48c13ae0-2ae2-47da-b60c-cb37f5d8fa45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-6ecd35ab-2574-4582-9acc-e571db9a7644,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-48c13ae0-2ae2-47da-b60c-cb37f5d8fa45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-3e75b97d-3f5c-49ae-92d4-0ccb0bad1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-f281ea28-6c3b-4545-adf0-f30a5bfebbb8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39129,DS-f281ea28-6c3b-4545-adf0-f30a5bfebbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-3e75b97d-3f5c-49ae-92d4-0ccb0bad1e18,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34684,DS-3e75b97d-3f5c-49ae-92d4-0ccb0bad1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-f281ea28-6c3b-4545-adf0-f30a5bfebbb8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39129,DS-f281ea28-6c3b-4545-adf0-f30a5bfebbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-3e75b97d-3f5c-49ae-92d4-0ccb0bad1e18,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1528
