reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-fb80c7b6-b6a0-404b-9e37-183823e65930,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-3aea0edf-991a-49be-b498-7153c40d90b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-fb80c7b6-b6a0-404b-9e37-183823e65930,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-3aea0edf-991a-49be-b498-7153c40d90b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-fb80c7b6-b6a0-404b-9e37-183823e65930,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-3aea0edf-991a-49be-b498-7153c40d90b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-fb80c7b6-b6a0-404b-9e37-183823e65930,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-3aea0edf-991a-49be-b498-7153c40d90b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-b174c849-3cf4-449d-a0c0-977e2dc07919,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a3f27002-9193-4cbb-b2cc-633ddcdf1922,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-b174c849-3cf4-449d-a0c0-977e2dc07919,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a3f27002-9193-4cbb-b2cc-633ddcdf1922,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-b174c849-3cf4-449d-a0c0-977e2dc07919,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a3f27002-9193-4cbb-b2cc-633ddcdf1922,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-b174c849-3cf4-449d-a0c0-977e2dc07919,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-a3f27002-9193-4cbb-b2cc-633ddcdf1922,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-6e6b4ece-8afd-43fe-9d87-4c01ab1648f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-740b5d94-0f8c-4612-b316-5cc85fbcc545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-740b5d94-0f8c-4612-b316-5cc85fbcc545,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-6e6b4ece-8afd-43fe-9d87-4c01ab1648f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-6e6b4ece-8afd-43fe-9d87-4c01ab1648f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-740b5d94-0f8c-4612-b316-5cc85fbcc545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-740b5d94-0f8c-4612-b316-5cc85fbcc545,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-6e6b4ece-8afd-43fe-9d87-4c01ab1648f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-d7cf0e59-ce93-4f61-a194-d1aff0aa9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-87369801-5b9b-402d-9974-5f71ed00d4be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-d7cf0e59-ce93-4f61-a194-d1aff0aa9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-87369801-5b9b-402d-9974-5f71ed00d4be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-d7cf0e59-ce93-4f61-a194-d1aff0aa9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-87369801-5b9b-402d-9974-5f71ed00d4be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-d7cf0e59-ce93-4f61-a194-d1aff0aa9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-87369801-5b9b-402d-9974-5f71ed00d4be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-801d653d-fc11-4018-92f7-83aab94522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-79d7ae6c-0e72-4435-8196-eef2a6a58bdc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-801d653d-fc11-4018-92f7-83aab94522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-79d7ae6c-0e72-4435-8196-eef2a6a58bdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-801d653d-fc11-4018-92f7-83aab94522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-79d7ae6c-0e72-4435-8196-eef2a6a58bdc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-801d653d-fc11-4018-92f7-83aab94522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-79d7ae6c-0e72-4435-8196-eef2a6a58bdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-e3089607-0e56-4623-a394-e6b17711f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-65cb70f8-0559-4a65-aec5-74660b4bc245,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-e3089607-0e56-4623-a394-e6b17711f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-65cb70f8-0559-4a65-aec5-74660b4bc245,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-e3089607-0e56-4623-a394-e6b17711f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-65cb70f8-0559-4a65-aec5-74660b4bc245,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-e3089607-0e56-4623-a394-e6b17711f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-65cb70f8-0559-4a65-aec5-74660b4bc245,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-b3193633-8601-4ab5-a506-fdf364c18f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-a116b245-d144-4ebb-9586-bb47c3c1a3ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-b3193633-8601-4ab5-a506-fdf364c18f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-a116b245-d144-4ebb-9586-bb47c3c1a3ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-b3193633-8601-4ab5-a506-fdf364c18f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-a116b245-d144-4ebb-9586-bb47c3c1a3ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-b3193633-8601-4ab5-a506-fdf364c18f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-a116b245-d144-4ebb-9586-bb47c3c1a3ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-cd416ed8-e48c-49d9-a3c1-bf661b168443,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1fba9bf3-72c6-4bde-9013-e74c0537f1be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-cd416ed8-e48c-49d9-a3c1-bf661b168443,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1fba9bf3-72c6-4bde-9013-e74c0537f1be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-cd416ed8-e48c-49d9-a3c1-bf661b168443,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1fba9bf3-72c6-4bde-9013-e74c0537f1be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-cd416ed8-e48c-49d9-a3c1-bf661b168443,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1fba9bf3-72c6-4bde-9013-e74c0537f1be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-e4134933-1809-426a-a748-f44882ee87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2c950d4b-c59e-4924-9df0-dd80e2d18143,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-e4134933-1809-426a-a748-f44882ee87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2c950d4b-c59e-4924-9df0-dd80e2d18143,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-e4134933-1809-426a-a748-f44882ee87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2c950d4b-c59e-4924-9df0-dd80e2d18143,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-e4134933-1809-426a-a748-f44882ee87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-2c950d4b-c59e-4924-9df0-dd80e2d18143,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testWriteOverGracefulFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-80e62049-fb11-40e5-8333-fc30f6abce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-f4dd5d1a-8772-464a-9605-aade48afebaa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-80e62049-fb11-40e5-8333-fc30f6abce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-f4dd5d1a-8772-464a-9605-aade48afebaa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-80e62049-fb11-40e5-8333-fc30f6abce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-f4dd5d1a-8772-464a-9605-aade48afebaa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-80e62049-fb11-40e5-8333-fc30f6abce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-f4dd5d1a-8772-464a-9605-aade48afebaa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 800
