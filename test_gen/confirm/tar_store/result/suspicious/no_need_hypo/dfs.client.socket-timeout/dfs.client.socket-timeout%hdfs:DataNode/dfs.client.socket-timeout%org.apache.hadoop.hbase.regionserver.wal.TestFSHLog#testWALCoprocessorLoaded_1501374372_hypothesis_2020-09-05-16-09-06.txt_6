reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-bf25427f-0a12-4839-9951-f2afb0d11980,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-10d91fb8-6501-4de5-81b2-fc4e9d7e587f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-bf25427f-0a12-4839-9951-f2afb0d11980,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-10d91fb8-6501-4de5-81b2-fc4e9d7e587f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-bf25427f-0a12-4839-9951-f2afb0d11980,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-10d91fb8-6501-4de5-81b2-fc4e9d7e587f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-bf25427f-0a12-4839-9951-f2afb0d11980,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-10d91fb8-6501-4de5-81b2-fc4e9d7e587f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a074d26b-1fc7-4533-a26d-11c754609c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6a5299df-fa3d-4105-a145-8c29af55bf6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a074d26b-1fc7-4533-a26d-11c754609c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6a5299df-fa3d-4105-a145-8c29af55bf6a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a074d26b-1fc7-4533-a26d-11c754609c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6a5299df-fa3d-4105-a145-8c29af55bf6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a074d26b-1fc7-4533-a26d-11c754609c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6a5299df-fa3d-4105-a145-8c29af55bf6a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-499c50d2-3fe4-4f7c-8c20-c9f30cd98941,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-09c37aaf-0e65-47e2-99e7-0a9943549bee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-499c50d2-3fe4-4f7c-8c20-c9f30cd98941,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-09c37aaf-0e65-47e2-99e7-0a9943549bee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-499c50d2-3fe4-4f7c-8c20-c9f30cd98941,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-09c37aaf-0e65-47e2-99e7-0a9943549bee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-499c50d2-3fe4-4f7c-8c20-c9f30cd98941,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-09c37aaf-0e65-47e2-99e7-0a9943549bee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-3a796ef5-e13c-4891-b3bb-a24ee5fca769,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-a80c317f-3919-4bb7-85b0-a2a612f46b01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-a80c317f-3919-4bb7-85b0-a2a612f46b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-3a796ef5-e13c-4891-b3bb-a24ee5fca769,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-3a796ef5-e13c-4891-b3bb-a24ee5fca769,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-a80c317f-3919-4bb7-85b0-a2a612f46b01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-a80c317f-3919-4bb7-85b0-a2a612f46b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-3a796ef5-e13c-4891-b3bb-a24ee5fca769,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-43b9d0d6-8a83-4011-bcce-c370814640cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-e57eca4d-534a-40a2-808d-844c1c18c066,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-e57eca4d-534a-40a2-808d-844c1c18c066,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-43b9d0d6-8a83-4011-bcce-c370814640cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43115,DS-43b9d0d6-8a83-4011-bcce-c370814640cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-e57eca4d-534a-40a2-808d-844c1c18c066,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-e57eca4d-534a-40a2-808d-844c1c18c066,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-43b9d0d6-8a83-4011-bcce-c370814640cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-8db5bf9c-a1e3-4b76-9a0c-fa148f14bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-8beb0f1e-0727-49ab-a949-008156d5bc7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-8db5bf9c-a1e3-4b76-9a0c-fa148f14bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-8beb0f1e-0727-49ab-a949-008156d5bc7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-8db5bf9c-a1e3-4b76-9a0c-fa148f14bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-8beb0f1e-0727-49ab-a949-008156d5bc7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-8db5bf9c-a1e3-4b76-9a0c-fa148f14bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-8beb0f1e-0727-49ab-a949-008156d5bc7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44244,DS-2f7470e2-92cd-4435-bf14-f79707d87a34,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-9f8bac90-1807-4bf1-b1b2-b3b1a00f10e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-9f8bac90-1807-4bf1-b1b2-b3b1a00f10e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-2f7470e2-92cd-4435-bf14-f79707d87a34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44244,DS-2f7470e2-92cd-4435-bf14-f79707d87a34,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-9f8bac90-1807-4bf1-b1b2-b3b1a00f10e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-9f8bac90-1807-4bf1-b1b2-b3b1a00f10e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-2f7470e2-92cd-4435-bf14-f79707d87a34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-df78be72-b931-4b6e-b833-b5952a638838,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4f1fcfb4-de09-49b2-abcf-e2fa85a0bb88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-df78be72-b931-4b6e-b833-b5952a638838,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4f1fcfb4-de09-49b2-abcf-e2fa85a0bb88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-df78be72-b931-4b6e-b833-b5952a638838,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4f1fcfb4-de09-49b2-abcf-e2fa85a0bb88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-df78be72-b931-4b6e-b833-b5952a638838,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4f1fcfb4-de09-49b2-abcf-e2fa85a0bb88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-af973cac-41cc-48f2-b481-d85d8e0a9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-c8a907d5-f5dd-4e39-b2ae-7d8282dca1ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-c8a907d5-f5dd-4e39-b2ae-7d8282dca1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-af973cac-41cc-48f2-b481-d85d8e0a9b30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-af973cac-41cc-48f2-b481-d85d8e0a9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-c8a907d5-f5dd-4e39-b2ae-7d8282dca1ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-c8a907d5-f5dd-4e39-b2ae-7d8282dca1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-af973cac-41cc-48f2-b481-d85d8e0a9b30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-fb127dc6-819b-4cdb-92ec-36ae4ca7a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-b0a882aa-384c-4ff5-8176-afd493590e25,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-b0a882aa-384c-4ff5-8176-afd493590e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-fb127dc6-819b-4cdb-92ec-36ae4ca7a7be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-fb127dc6-819b-4cdb-92ec-36ae4ca7a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-b0a882aa-384c-4ff5-8176-afd493590e25,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-b0a882aa-384c-4ff5-8176-afd493590e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-fb127dc6-819b-4cdb-92ec-36ae4ca7a7be,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1342
