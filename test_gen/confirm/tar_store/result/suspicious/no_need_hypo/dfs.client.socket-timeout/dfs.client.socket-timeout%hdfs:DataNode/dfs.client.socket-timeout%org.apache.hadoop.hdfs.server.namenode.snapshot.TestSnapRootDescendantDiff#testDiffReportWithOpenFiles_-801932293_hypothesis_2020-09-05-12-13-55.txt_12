reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-20f3abdb-b16b-4f2f-9108-185eeb3bf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-06acd7d1-f477-4cbd-a68b-7a2feab2d320,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-20f3abdb-b16b-4f2f-9108-185eeb3bf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-06acd7d1-f477-4cbd-a68b-7a2feab2d320,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-20f3abdb-b16b-4f2f-9108-185eeb3bf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-06acd7d1-f477-4cbd-a68b-7a2feab2d320,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-20f3abdb-b16b-4f2f-9108-185eeb3bf3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-06acd7d1-f477-4cbd-a68b-7a2feab2d320,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-254dcb24-2cd6-4c11-bd73-e4aa155962fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3ff7c01b-c66f-4385-920e-8a823b51b3d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-254dcb24-2cd6-4c11-bd73-e4aa155962fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3ff7c01b-c66f-4385-920e-8a823b51b3d7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-254dcb24-2cd6-4c11-bd73-e4aa155962fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3ff7c01b-c66f-4385-920e-8a823b51b3d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-254dcb24-2cd6-4c11-bd73-e4aa155962fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-3ff7c01b-c66f-4385-920e-8a823b51b3d7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-e61339ad-6ef2-42ec-9472-94fd63b64fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-f1a59bd5-5330-46dc-b139-35f388f015ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-f1a59bd5-5330-46dc-b139-35f388f015ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e61339ad-6ef2-42ec-9472-94fd63b64fbc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41351,DS-e61339ad-6ef2-42ec-9472-94fd63b64fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-f1a59bd5-5330-46dc-b139-35f388f015ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-f1a59bd5-5330-46dc-b139-35f388f015ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e61339ad-6ef2-42ec-9472-94fd63b64fbc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33938,DS-dfc1537c-bce4-4d64-8a27-7ee33432e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-97986a4a-2f64-4e64-9bd3-f67b4eb06a6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-97986a4a-2f64-4e64-9bd3-f67b4eb06a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-dfc1537c-bce4-4d64-8a27-7ee33432e0b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33938,DS-dfc1537c-bce4-4d64-8a27-7ee33432e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-97986a4a-2f64-4e64-9bd3-f67b4eb06a6a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-97986a4a-2f64-4e64-9bd3-f67b4eb06a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-dfc1537c-bce4-4d64-8a27-7ee33432e0b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-5d513812-6fca-45a9-b80c-ae7b51234d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c783e0b1-951b-4489-ae5a-d71eaf372d81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-5d513812-6fca-45a9-b80c-ae7b51234d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c783e0b1-951b-4489-ae5a-d71eaf372d81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-5d513812-6fca-45a9-b80c-ae7b51234d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c783e0b1-951b-4489-ae5a-d71eaf372d81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-5d513812-6fca-45a9-b80c-ae7b51234d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c783e0b1-951b-4489-ae5a-d71eaf372d81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-d2e80e0f-ff63-43bd-9017-f715e4d84772,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-d2e80e0f-ff63-43bd-9017-f715e4d84772,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-d2e80e0f-ff63-43bd-9017-f715e4d84772,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-d2e80e0f-ff63-43bd-9017-f715e4d84772,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-2549de21-d3a0-4397-af3d-a0e06dacff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-82298e05-b685-4bc8-9249-3025bd2491ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-2549de21-d3a0-4397-af3d-a0e06dacff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-82298e05-b685-4bc8-9249-3025bd2491ab,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-2549de21-d3a0-4397-af3d-a0e06dacff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-82298e05-b685-4bc8-9249-3025bd2491ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-2549de21-d3a0-4397-af3d-a0e06dacff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-82298e05-b685-4bc8-9249-3025bd2491ab,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-104a8ae9-6aa2-41d5-a81d-cc69689a1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-21db014f-c731-4bd4-ae70-0338ff81d1b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-21db014f-c731-4bd4-ae70-0338ff81d1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-104a8ae9-6aa2-41d5-a81d-cc69689a1adf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-104a8ae9-6aa2-41d5-a81d-cc69689a1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-21db014f-c731-4bd4-ae70-0338ff81d1b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-21db014f-c731-4bd4-ae70-0338ff81d1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-104a8ae9-6aa2-41d5-a81d-cc69689a1adf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-ff44c9bb-425d-48b2-8846-71da468f9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-1b612ad0-0301-454a-8ace-0c4155fa6771,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-1b612ad0-0301-454a-8ace-0c4155fa6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-ff44c9bb-425d-48b2-8846-71da468f9d1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-ff44c9bb-425d-48b2-8846-71da468f9d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-1b612ad0-0301-454a-8ace-0c4155fa6771,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-1b612ad0-0301-454a-8ace-0c4155fa6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-ff44c9bb-425d-48b2-8846-71da468f9d1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-d6356846-8c84-4e91-bff6-95cc3d60b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1bce89d8-bff5-4825-b77c-ed405f441b7e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-1bce89d8-bff5-4825-b77c-ed405f441b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d6356846-8c84-4e91-bff6-95cc3d60b7e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-d6356846-8c84-4e91-bff6-95cc3d60b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1bce89d8-bff5-4825-b77c-ed405f441b7e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-1bce89d8-bff5-4825-b77c-ed405f441b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d6356846-8c84-4e91-bff6-95cc3d60b7e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 800
