reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-260eb510-2a14-480f-8751-4541431db662,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-56abb3ec-ff7a-4a65-a848-6e6a191e8dbd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-260eb510-2a14-480f-8751-4541431db662,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-56abb3ec-ff7a-4a65-a848-6e6a191e8dbd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-260eb510-2a14-480f-8751-4541431db662,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-56abb3ec-ff7a-4a65-a848-6e6a191e8dbd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43574,DS-260eb510-2a14-480f-8751-4541431db662,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-56abb3ec-ff7a-4a65-a848-6e6a191e8dbd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-f54cec76-5e90-4224-b4bc-e1a83c076e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-321050aa-ffb6-4379-859d-77e44a3c8749,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-321050aa-ffb6-4379-859d-77e44a3c8749,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f54cec76-5e90-4224-b4bc-e1a83c076e49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-f54cec76-5e90-4224-b4bc-e1a83c076e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-321050aa-ffb6-4379-859d-77e44a3c8749,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-321050aa-ffb6-4379-859d-77e44a3c8749,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f54cec76-5e90-4224-b4bc-e1a83c076e49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-65a18e16-ff02-4e19-a391-52917db7d423,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-28f557a7-3eb6-4847-81ae-786a10579f8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-65a18e16-ff02-4e19-a391-52917db7d423,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-28f557a7-3eb6-4847-81ae-786a10579f8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-65a18e16-ff02-4e19-a391-52917db7d423,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-28f557a7-3eb6-4847-81ae-786a10579f8b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-65a18e16-ff02-4e19-a391-52917db7d423,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-28f557a7-3eb6-4847-81ae-786a10579f8b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-24d74a34-b519-496b-850c-40075cfa2588,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-5597e997-6ab4-430f-951b-7f759869026b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-24d74a34-b519-496b-850c-40075cfa2588,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-5597e997-6ab4-430f-951b-7f759869026b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-24d74a34-b519-496b-850c-40075cfa2588,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-5597e997-6ab4-430f-951b-7f759869026b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-24d74a34-b519-496b-850c-40075cfa2588,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-5597e997-6ab4-430f-951b-7f759869026b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-fba77a20-6574-4b0b-96e4-f27a2ef76645,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-1c74717a-b2ab-4c5b-a47f-a9958473f6bc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41381,DS-1c74717a-b2ab-4c5b-a47f-a9958473f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-fba77a20-6574-4b0b-96e4-f27a2ef76645,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-fba77a20-6574-4b0b-96e4-f27a2ef76645,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-1c74717a-b2ab-4c5b-a47f-a9958473f6bc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41381,DS-1c74717a-b2ab-4c5b-a47f-a9958473f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-fba77a20-6574-4b0b-96e4-f27a2ef76645,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-21a9e211-1b9e-460d-bd2c-6acfbce9a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-108eace5-bf1f-4a47-baa8-b4395eb2e453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-108eace5-bf1f-4a47-baa8-b4395eb2e453,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-21a9e211-1b9e-460d-bd2c-6acfbce9a1d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-21a9e211-1b9e-460d-bd2c-6acfbce9a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-108eace5-bf1f-4a47-baa8-b4395eb2e453,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-108eace5-bf1f-4a47-baa8-b4395eb2e453,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-21a9e211-1b9e-460d-bd2c-6acfbce9a1d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-6afe065a-db5e-46ef-b3a8-fcde820092f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-b6942898-27c7-4bea-ba15-d9df4392407c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41745,DS-b6942898-27c7-4bea-ba15-d9df4392407c,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-6afe065a-db5e-46ef-b3a8-fcde820092f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-6afe065a-db5e-46ef-b3a8-fcde820092f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-b6942898-27c7-4bea-ba15-d9df4392407c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41745,DS-b6942898-27c7-4bea-ba15-d9df4392407c,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-6afe065a-db5e-46ef-b3a8-fcde820092f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-78d7f34c-04e9-49fd-956b-2f9a1d19afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-37307592-90d3-46f2-ae24-255b3a58b3fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-37307592-90d3-46f2-ae24-255b3a58b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-78d7f34c-04e9-49fd-956b-2f9a1d19afbc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34142,DS-78d7f34c-04e9-49fd-956b-2f9a1d19afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-37307592-90d3-46f2-ae24-255b3a58b3fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-37307592-90d3-46f2-ae24-255b3a58b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-78d7f34c-04e9-49fd-956b-2f9a1d19afbc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-9b7f9285-0a6e-41f7-86bf-53372cf49541,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-8ef78002-237c-4bfd-9742-eea36a1a96b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-8ef78002-237c-4bfd-9742-eea36a1a96b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-9b7f9285-0a6e-41f7-86bf-53372cf49541,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-9b7f9285-0a6e-41f7-86bf-53372cf49541,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-8ef78002-237c-4bfd-9742-eea36a1a96b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-8ef78002-237c-4bfd-9742-eea36a1a96b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-9b7f9285-0a6e-41f7-86bf-53372cf49541,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALComparator
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-5d8ab747-20ca-4114-99ff-e4dfe18d4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b4796d40-c08e-4930-9dac-f1e396930569,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-5d8ab747-20ca-4114-99ff-e4dfe18d4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b4796d40-c08e-4930-9dac-f1e396930569,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-5d8ab747-20ca-4114-99ff-e4dfe18d4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b4796d40-c08e-4930-9dac-f1e396930569,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-5d8ab747-20ca-4114-99ff-e4dfe18d4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b4796d40-c08e-4930-9dac-f1e396930569,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1132
