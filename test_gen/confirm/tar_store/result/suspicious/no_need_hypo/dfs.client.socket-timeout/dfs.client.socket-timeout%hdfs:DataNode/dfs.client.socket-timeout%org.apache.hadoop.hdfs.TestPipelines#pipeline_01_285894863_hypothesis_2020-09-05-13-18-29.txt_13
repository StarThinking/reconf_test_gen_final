reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d4e9eca-526e-463a-b293-d248ffadac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-236ff886-9540-4c29-9cbd-f9f70e7e3303,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d4e9eca-526e-463a-b293-d248ffadac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-236ff886-9540-4c29-9cbd-f9f70e7e3303,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d4e9eca-526e-463a-b293-d248ffadac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-236ff886-9540-4c29-9cbd-f9f70e7e3303,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d4e9eca-526e-463a-b293-d248ffadac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-236ff886-9540-4c29-9cbd-f9f70e7e3303,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-70bb84c0-2c48-4f2a-84eb-02b62f426edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-a2add73e-4b90-40ac-8e64-870bf4b60758,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-a2add73e-4b90-40ac-8e64-870bf4b60758,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-70bb84c0-2c48-4f2a-84eb-02b62f426edc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-70bb84c0-2c48-4f2a-84eb-02b62f426edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-a2add73e-4b90-40ac-8e64-870bf4b60758,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-a2add73e-4b90-40ac-8e64-870bf4b60758,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-70bb84c0-2c48-4f2a-84eb-02b62f426edc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45262,DS-806a6a50-3546-4c34-be8a-2ae895ae8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-891f78c6-d83f-43b6-a8ff-8c84ea609688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-891f78c6-d83f-43b6-a8ff-8c84ea609688,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-806a6a50-3546-4c34-be8a-2ae895ae8f6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45262,DS-806a6a50-3546-4c34-be8a-2ae895ae8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-891f78c6-d83f-43b6-a8ff-8c84ea609688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38173,DS-891f78c6-d83f-43b6-a8ff-8c84ea609688,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-806a6a50-3546-4c34-be8a-2ae895ae8f6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.TestPipelines.pipeline_01(TestPipelines.java:109)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-f2301203-760a-43a0-ab92-82b07f0822af,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5d71ef11-f401-431c-890e-68c46317a321,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-f2301203-760a-43a0-ab92-82b07f0822af,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5d71ef11-f401-431c-890e-68c46317a321,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-f2301203-760a-43a0-ab92-82b07f0822af,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5d71ef11-f401-431c-890e-68c46317a321,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-f2301203-760a-43a0-ab92-82b07f0822af,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5d71ef11-f401-431c-890e-68c46317a321,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-f86d9342-a8a5-43ad-972f-0c89c0be62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-4efc1dbd-36e8-4020-bb83-b26def41c3c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-f86d9342-a8a5-43ad-972f-0c89c0be62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-4efc1dbd-36e8-4020-bb83-b26def41c3c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-f86d9342-a8a5-43ad-972f-0c89c0be62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-4efc1dbd-36e8-4020-bb83-b26def41c3c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-f86d9342-a8a5-43ad-972f-0c89c0be62cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-4efc1dbd-36e8-4020-bb83-b26def41c3c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-fd8d8340-0a09-44ab-b1ed-41cfe7d2e616,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-6a9593d4-5876-4a1d-9896-5df688f9b771,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-6a9593d4-5876-4a1d-9896-5df688f9b771,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-fd8d8340-0a09-44ab-b1ed-41cfe7d2e616,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-fd8d8340-0a09-44ab-b1ed-41cfe7d2e616,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-6a9593d4-5876-4a1d-9896-5df688f9b771,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-6a9593d4-5876-4a1d-9896-5df688f9b771,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-fd8d8340-0a09-44ab-b1ed-41cfe7d2e616,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-cfdd871e-1f44-4445-87ea-354fd1b504fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b16d1b4d-030c-4903-b10d-5c22a7cc6a3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-cfdd871e-1f44-4445-87ea-354fd1b504fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b16d1b4d-030c-4903-b10d-5c22a7cc6a3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-cfdd871e-1f44-4445-87ea-354fd1b504fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b16d1b4d-030c-4903-b10d-5c22a7cc6a3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-cfdd871e-1f44-4445-87ea-354fd1b504fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-b16d1b4d-030c-4903-b10d-5c22a7cc6a3d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-01c4f833-35c9-4325-9432-18391c18d751,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-3a1d2ace-7941-4fed-85e3-58dfbb21ff6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-01c4f833-35c9-4325-9432-18391c18d751,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-3a1d2ace-7941-4fed-85e3-58dfbb21ff6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-01c4f833-35c9-4325-9432-18391c18d751,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-3a1d2ace-7941-4fed-85e3-58dfbb21ff6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-01c4f833-35c9-4325-9432-18391c18d751,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-3a1d2ace-7941-4fed-85e3-58dfbb21ff6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-e979ff3d-33d5-4bbf-bc0d-728ad2c6f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-bc70514a-197b-4aaf-80ff-2efb3db903a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-bc70514a-197b-4aaf-80ff-2efb3db903a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-e979ff3d-33d5-4bbf-bc0d-728ad2c6f883,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-e979ff3d-33d5-4bbf-bc0d-728ad2c6f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-bc70514a-197b-4aaf-80ff-2efb3db903a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-bc70514a-197b-4aaf-80ff-2efb3db903a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-e979ff3d-33d5-4bbf-bc0d-728ad2c6f883,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-1d2c55ae-3c26-44ab-9351-5aa62afc2c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-5906abec-ae63-4da9-bc27-a5dd20b3a06a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-5906abec-ae63-4da9-bc27-a5dd20b3a06a,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-1d2c55ae-3c26-44ab-9351-5aa62afc2c5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-1d2c55ae-3c26-44ab-9351-5aa62afc2c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-5906abec-ae63-4da9-bc27-a5dd20b3a06a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-5906abec-ae63-4da9-bc27-a5dd20b3a06a,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-1d2c55ae-3c26-44ab-9351-5aa62afc2c5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-f8935d3b-985f-4209-a707-38971a9fc720,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-f8935d3b-985f-4209-a707-38971a9fc720,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-f8935d3b-985f-4209-a707-38971a9fc720,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-f8935d3b-985f-4209-a707-38971a9fc720,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-f60c1302-9545-4c4b-b848-1fad1fcf49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-75c5db20-7945-483f-a33d-540e7a222d88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-f60c1302-9545-4c4b-b848-1fad1fcf49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-75c5db20-7945-483f-a33d-540e7a222d88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-f60c1302-9545-4c4b-b848-1fad1fcf49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-75c5db20-7945-483f-a33d-540e7a222d88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-f60c1302-9545-4c4b-b848-1fad1fcf49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-75c5db20-7945-483f-a33d-540e7a222d88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-59cdc7e1-d870-4568-b605-ce922ffdea18,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-602e38d4-688d-407a-a168-f19ed666423d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-59cdc7e1-d870-4568-b605-ce922ffdea18,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-602e38d4-688d-407a-a168-f19ed666423d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-59cdc7e1-d870-4568-b605-ce922ffdea18,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-602e38d4-688d-407a-a168-f19ed666423d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-59cdc7e1-d870-4568-b605-ce922ffdea18,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-602e38d4-688d-407a-a168-f19ed666423d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.TestPipelines.pipeline_01(TestPipelines.java:109)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-d7484cd3-9283-496f-8890-a3875f02f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-84c62245-747b-49b1-a7f2-4a42638b7fb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-d7484cd3-9283-496f-8890-a3875f02f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-84c62245-747b-49b1-a7f2-4a42638b7fb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-d7484cd3-9283-496f-8890-a3875f02f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-84c62245-747b-49b1-a7f2-4a42638b7fb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-d7484cd3-9283-496f-8890-a3875f02f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-84c62245-747b-49b1-a7f2-4a42638b7fb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-f0b5f846-8873-42ae-8ce1-11e45cfae89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-51dddd87-0ed9-4835-ab2f-fe60efba11b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-51dddd87-0ed9-4835-ab2f-fe60efba11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f0b5f846-8873-42ae-8ce1-11e45cfae89a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-f0b5f846-8873-42ae-8ce1-11e45cfae89a,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-51dddd87-0ed9-4835-ab2f-fe60efba11b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-51dddd87-0ed9-4835-ab2f-fe60efba11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f0b5f846-8873-42ae-8ce1-11e45cfae89a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-77bcf41c-2b8f-4677-9a8b-7af3708ab7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-14843bd6-271b-457a-9ec8-ab5682c43c9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-77bcf41c-2b8f-4677-9a8b-7af3708ab7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-14843bd6-271b-457a-9ec8-ab5682c43c9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-77bcf41c-2b8f-4677-9a8b-7af3708ab7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-14843bd6-271b-457a-9ec8-ab5682c43c9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36522,DS-77bcf41c-2b8f-4677-9a8b-7af3708ab7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-14843bd6-271b-457a-9ec8-ab5682c43c9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-17af7e8b-57e3-40f8-86f0-7c62292061e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-a0cc85ea-2c7b-4e78-8456-78ed08ea9ebe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-17af7e8b-57e3-40f8-86f0-7c62292061e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-a0cc85ea-2c7b-4e78-8456-78ed08ea9ebe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-17af7e8b-57e3-40f8-86f0-7c62292061e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-a0cc85ea-2c7b-4e78-8456-78ed08ea9ebe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-17af7e8b-57e3-40f8-86f0-7c62292061e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-a0cc85ea-2c7b-4e78-8456-78ed08ea9ebe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-c4f861da-d8e4-4192-b400-1bee81b64491,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-6a15bfe6-be01-4f85-859c-1d3e909ea4a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-c4f861da-d8e4-4192-b400-1bee81b64491,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-6a15bfe6-be01-4f85-859c-1d3e909ea4a0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-c4f861da-d8e4-4192-b400-1bee81b64491,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-6a15bfe6-be01-4f85-859c-1d3e909ea4a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38676,DS-c4f861da-d8e4-4192-b400-1bee81b64491,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-6a15bfe6-be01-4f85-859c-1d3e909ea4a0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-f914d1b0-15ce-43e4-96ae-a3fc1a8b4153,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-7293ccfe-3a0d-4bc0-b69f-a3d2ca500ac5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-7293ccfe-3a0d-4bc0-b69f-a3d2ca500ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-f914d1b0-15ce-43e4-96ae-a3fc1a8b4153,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-f914d1b0-15ce-43e4-96ae-a3fc1a8b4153,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-7293ccfe-3a0d-4bc0-b69f-a3d2ca500ac5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-7293ccfe-3a0d-4bc0-b69f-a3d2ca500ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-f914d1b0-15ce-43e4-96ae-a3fc1a8b4153,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36438,DS-4fed54c1-a7c3-4fa8-b16a-893bed245042,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-ea63b2ad-f435-4dd4-b9ce-138caa320951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-ea63b2ad-f435-4dd4-b9ce-138caa320951,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-4fed54c1-a7c3-4fa8-b16a-893bed245042,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36438,DS-4fed54c1-a7c3-4fa8-b16a-893bed245042,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-ea63b2ad-f435-4dd4-b9ce-138caa320951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-ea63b2ad-f435-4dd4-b9ce-138caa320951,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-4fed54c1-a7c3-4fa8-b16a-893bed245042,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-199ddc6d-c5a9-4ada-8789-c1962451b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9c202bb0-8b9c-4564-9c0c-50f826f5656e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-199ddc6d-c5a9-4ada-8789-c1962451b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9c202bb0-8b9c-4564-9c0c-50f826f5656e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-199ddc6d-c5a9-4ada-8789-c1962451b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9c202bb0-8b9c-4564-9c0c-50f826f5656e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-199ddc6d-c5a9-4ada-8789-c1962451b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9c202bb0-8b9c-4564-9c0c-50f826f5656e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-1067aa17-8716-455a-a0a6-a579dc761304,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-138d1303-5688-42cd-865c-d4506a4e6b80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-138d1303-5688-42cd-865c-d4506a4e6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-1067aa17-8716-455a-a0a6-a579dc761304,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-1067aa17-8716-455a-a0a6-a579dc761304,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-138d1303-5688-42cd-865c-d4506a4e6b80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-138d1303-5688-42cd-865c-d4506a4e6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-1067aa17-8716-455a-a0a6-a579dc761304,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e615fb4-a2ba-48ce-a1be-b511ad19bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f1349b61-b3aa-4bbf-82b3-c2be1caa03d3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-f1349b61-b3aa-4bbf-82b3-c2be1caa03d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e615fb4-a2ba-48ce-a1be-b511ad19bf16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e615fb4-a2ba-48ce-a1be-b511ad19bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f1349b61-b3aa-4bbf-82b3-c2be1caa03d3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-f1349b61-b3aa-4bbf-82b3-c2be1caa03d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e615fb4-a2ba-48ce-a1be-b511ad19bf16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-36d1e6a3-2c69-4a8e-b516-cda678226a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e082cc9a-b089-4919-b0aa-4454e33cea5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-36d1e6a3-2c69-4a8e-b516-cda678226a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e082cc9a-b089-4919-b0aa-4454e33cea5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-36d1e6a3-2c69-4a8e-b516-cda678226a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e082cc9a-b089-4919-b0aa-4454e33cea5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-36d1e6a3-2c69-4a8e-b516-cda678226a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e082cc9a-b089-4919-b0aa-4454e33cea5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-51d77c42-98c7-4b72-a945-56785688e205,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-254b7f0b-93b5-4d20-b662-20b736df3a93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-51d77c42-98c7-4b72-a945-56785688e205,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-254b7f0b-93b5-4d20-b662-20b736df3a93,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-51d77c42-98c7-4b72-a945-56785688e205,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-254b7f0b-93b5-4d20-b662-20b736df3a93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-51d77c42-98c7-4b72-a945-56785688e205,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-254b7f0b-93b5-4d20-b662-20b736df3a93,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-10cca801-f8ac-4b21-9290-b8abebf2b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-a7aa76cd-d54a-4ac0-8778-4124e0b2c193,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-a7aa76cd-d54a-4ac0-8778-4124e0b2c193,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-10cca801-f8ac-4b21-9290-b8abebf2b5e7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-10cca801-f8ac-4b21-9290-b8abebf2b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-a7aa76cd-d54a-4ac0-8778-4124e0b2c193,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-a7aa76cd-d54a-4ac0-8778-4124e0b2c193,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-10cca801-f8ac-4b21-9290-b8abebf2b5e7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-44a24c56-1a5e-4669-a508-ab4b65f9202c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bdc2aa6c-2833-4462-89d1-ed1f1c1aee21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-44a24c56-1a5e-4669-a508-ab4b65f9202c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bdc2aa6c-2833-4462-89d1-ed1f1c1aee21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-44a24c56-1a5e-4669-a508-ab4b65f9202c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bdc2aa6c-2833-4462-89d1-ed1f1c1aee21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-44a24c56-1a5e-4669-a508-ab4b65f9202c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-bdc2aa6c-2833-4462-89d1-ed1f1c1aee21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5c65ea4-e20b-4e4d-835f-a4b7f75e4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-ea7197a4-7ec7-4e78-a016-188c204cfeaa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-ea7197a4-7ec7-4e78-a016-188c204cfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5c65ea4-e20b-4e4d-835f-a4b7f75e4c88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5c65ea4-e20b-4e4d-835f-a4b7f75e4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-ea7197a4-7ec7-4e78-a016-188c204cfeaa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-ea7197a4-7ec7-4e78-a016-188c204cfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5c65ea4-e20b-4e4d-835f-a4b7f75e4c88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-7467f184-617d-4da1-af8f-b314920fd7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-244ee49a-0cc7-4155-9ac5-01105a68dca8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-244ee49a-0cc7-4155-9ac5-01105a68dca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-7467f184-617d-4da1-af8f-b314920fd7fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-7467f184-617d-4da1-af8f-b314920fd7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-244ee49a-0cc7-4155-9ac5-01105a68dca8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-244ee49a-0cc7-4155-9ac5-01105a68dca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-7467f184-617d-4da1-af8f-b314920fd7fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-1c09321d-117a-430a-ad26-add8e28d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-15bf5ffc-e3e9-4e53-ae5b-ff7dc3603921,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-1c09321d-117a-430a-ad26-add8e28d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-15bf5ffc-e3e9-4e53-ae5b-ff7dc3603921,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-1c09321d-117a-430a-ad26-add8e28d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-15bf5ffc-e3e9-4e53-ae5b-ff7dc3603921,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-1c09321d-117a-430a-ad26-add8e28d2003,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-15bf5ffc-e3e9-4e53-ae5b-ff7dc3603921,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-8cfd52be-db3e-44c5-9e6b-cf96316c95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-31ec13bd-b085-400c-8734-e7a532e93fb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-8cfd52be-db3e-44c5-9e6b-cf96316c95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-31ec13bd-b085-400c-8734-e7a532e93fb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-8cfd52be-db3e-44c5-9e6b-cf96316c95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-31ec13bd-b085-400c-8734-e7a532e93fb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-8cfd52be-db3e-44c5-9e6b-cf96316c95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-31ec13bd-b085-400c-8734-e7a532e93fb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-f4e93f66-810b-492d-8388-061030d35adc,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-8f0807ad-8e20-445f-b2c3-29189ee003e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-f4e93f66-810b-492d-8388-061030d35adc,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-8f0807ad-8e20-445f-b2c3-29189ee003e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-f4e93f66-810b-492d-8388-061030d35adc,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-8f0807ad-8e20-445f-b2c3-29189ee003e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36507,DS-f4e93f66-810b-492d-8388-061030d35adc,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-8f0807ad-8e20-445f-b2c3-29189ee003e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-81288780-4b1c-4191-a083-751b73124d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-baa589db-177e-4be1-9c7d-9ee016efa28c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-81288780-4b1c-4191-a083-751b73124d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-baa589db-177e-4be1-9c7d-9ee016efa28c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-81288780-4b1c-4191-a083-751b73124d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-baa589db-177e-4be1-9c7d-9ee016efa28c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-81288780-4b1c-4191-a083-751b73124d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-baa589db-177e-4be1-9c7d-9ee016efa28c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-a5bc1fa5-2605-47c0-b6fd-99fa5850cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-8b963d98-4876-4cc2-98b5-86dde0af0159,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-8b963d98-4876-4cc2-98b5-86dde0af0159,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-a5bc1fa5-2605-47c0-b6fd-99fa5850cbff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-a5bc1fa5-2605-47c0-b6fd-99fa5850cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-8b963d98-4876-4cc2-98b5-86dde0af0159,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-8b963d98-4876-4cc2-98b5-86dde0af0159,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-a5bc1fa5-2605-47c0-b6fd-99fa5850cbff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-ca49d384-5cf5-4f1d-97cb-05d5968ac824,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d9cd75be-dca8-4336-bc2f-03a0e5117696,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-ca49d384-5cf5-4f1d-97cb-05d5968ac824,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d9cd75be-dca8-4336-bc2f-03a0e5117696,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-ca49d384-5cf5-4f1d-97cb-05d5968ac824,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d9cd75be-dca8-4336-bc2f-03a0e5117696,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-ca49d384-5cf5-4f1d-97cb-05d5968ac824,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d9cd75be-dca8-4336-bc2f-03a0e5117696,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-4bb8458a-a666-43e6-8891-c1a0129313d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-4bb8458a-a666-43e6-8891-c1a0129313d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-4bb8458a-a666-43e6-8891-c1a0129313d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-4bb8458a-a666-43e6-8891-c1a0129313d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-f0f909c9-d34e-43d4-8459-40005241fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9aa60aa0-a833-4fd1-9a83-b812b5ad49bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-f0f909c9-d34e-43d4-8459-40005241fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9aa60aa0-a833-4fd1-9a83-b812b5ad49bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-f0f909c9-d34e-43d4-8459-40005241fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9aa60aa0-a833-4fd1-9a83-b812b5ad49bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-f0f909c9-d34e-43d4-8459-40005241fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9aa60aa0-a833-4fd1-9a83-b812b5ad49bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-437d592e-d859-421c-9d6d-0502f2c61b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-456bfa54-9912-43e3-b3e1-338b596785c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-437d592e-d859-421c-9d6d-0502f2c61b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-456bfa54-9912-43e3-b3e1-338b596785c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-437d592e-d859-421c-9d6d-0502f2c61b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-456bfa54-9912-43e3-b3e1-338b596785c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-437d592e-d859-421c-9d6d-0502f2c61b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-456bfa54-9912-43e3-b3e1-338b596785c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34885,DS-6ba8d2d3-8c7d-4073-988b-884c926c445e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-122d7c96-8a85-4c91-b09b-8a5c0107a55a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-122d7c96-8a85-4c91-b09b-8a5c0107a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6ba8d2d3-8c7d-4073-988b-884c926c445e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34885,DS-6ba8d2d3-8c7d-4073-988b-884c926c445e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-122d7c96-8a85-4c91-b09b-8a5c0107a55a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-122d7c96-8a85-4c91-b09b-8a5c0107a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6ba8d2d3-8c7d-4073-988b-884c926c445e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ad4c7a9f-9b0a-4219-8d1e-1d0bd2476fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-1347e172-b362-4fdb-8e00-a267e15acf66,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ad4c7a9f-9b0a-4219-8d1e-1d0bd2476fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-1347e172-b362-4fdb-8e00-a267e15acf66,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ad4c7a9f-9b0a-4219-8d1e-1d0bd2476fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-1347e172-b362-4fdb-8e00-a267e15acf66,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-ad4c7a9f-9b0a-4219-8d1e-1d0bd2476fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-1347e172-b362-4fdb-8e00-a267e15acf66,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-fd00f088-1b9b-4c18-9ba1-46b66784df54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-b31214a1-7bbf-43e1-9bdb-3e7d7753b825,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-fd00f088-1b9b-4c18-9ba1-46b66784df54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-b31214a1-7bbf-43e1-9bdb-3e7d7753b825,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-fd00f088-1b9b-4c18-9ba1-46b66784df54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-b31214a1-7bbf-43e1-9bdb-3e7d7753b825,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-fd00f088-1b9b-4c18-9ba1-46b66784df54,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-b31214a1-7bbf-43e1-9bdb-3e7d7753b825,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-89cb52eb-6816-4d89-9196-61de2f220c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bbc0e0b8-6892-47c0-9615-3fdf661f2d58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-89cb52eb-6816-4d89-9196-61de2f220c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bbc0e0b8-6892-47c0-9615-3fdf661f2d58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-89cb52eb-6816-4d89-9196-61de2f220c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bbc0e0b8-6892-47c0-9615-3fdf661f2d58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-89cb52eb-6816-4d89-9196-61de2f220c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bbc0e0b8-6892-47c0-9615-3fdf661f2d58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33704,DS-e9a0c904-cc3c-434c-bcd2-6e8f1fcf695f,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f544f813-9636-484d-947d-7c4fe7d26558,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-f544f813-9636-484d-947d-7c4fe7d26558,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-e9a0c904-cc3c-434c-bcd2-6e8f1fcf695f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33704,DS-e9a0c904-cc3c-434c-bcd2-6e8f1fcf695f,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-f544f813-9636-484d-947d-7c4fe7d26558,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-f544f813-9636-484d-947d-7c4fe7d26558,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-e9a0c904-cc3c-434c-bcd2-6e8f1fcf695f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-55f89f61-101f-4a99-8cb2-4b4621f4b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a7a3e938-010e-416b-896f-0ea2bcb640ba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-55f89f61-101f-4a99-8cb2-4b4621f4b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a7a3e938-010e-416b-896f-0ea2bcb640ba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-55f89f61-101f-4a99-8cb2-4b4621f4b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a7a3e938-010e-416b-896f-0ea2bcb640ba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-55f89f61-101f-4a99-8cb2-4b4621f4b5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a7a3e938-010e-416b-896f-0ea2bcb640ba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5d7430db-cab6-4c42-b2ce-6d562ff692a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-2a7f4548-5855-4090-a739-0600be1c762f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5d7430db-cab6-4c42-b2ce-6d562ff692a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-2a7f4548-5855-4090-a739-0600be1c762f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5d7430db-cab6-4c42-b2ce-6d562ff692a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-2a7f4548-5855-4090-a739-0600be1c762f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5d7430db-cab6-4c42-b2ce-6d562ff692a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-2a7f4548-5855-4090-a739-0600be1c762f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a048f12-ca0e-41dd-9a0a-9b0da0893eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-ac45c971-7dc2-4ccc-839c-b354150b8376,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a048f12-ca0e-41dd-9a0a-9b0da0893eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-ac45c971-7dc2-4ccc-839c-b354150b8376,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a048f12-ca0e-41dd-9a0a-9b0da0893eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-ac45c971-7dc2-4ccc-839c-b354150b8376,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a048f12-ca0e-41dd-9a0a-9b0da0893eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-ac45c971-7dc2-4ccc-839c-b354150b8376,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-c98c1a4f-921a-45f6-8830-901be929b2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5acad21-5d0e-4f59-b8fb-f95cf0549e6c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5acad21-5d0e-4f59-b8fb-f95cf0549e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-c98c1a4f-921a-45f6-8830-901be929b2f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-c98c1a4f-921a-45f6-8830-901be929b2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5acad21-5d0e-4f59-b8fb-f95cf0549e6c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39055,DS-f5acad21-5d0e-4f59-b8fb-f95cf0549e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-c98c1a4f-921a-45f6-8830-901be929b2f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-f511dabb-9aad-4de2-a93a-810bd903f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1e704b8f-a812-46f6-bb5a-443d8893b156,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-f511dabb-9aad-4de2-a93a-810bd903f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1e704b8f-a812-46f6-bb5a-443d8893b156,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-f511dabb-9aad-4de2-a93a-810bd903f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1e704b8f-a812-46f6-bb5a-443d8893b156,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41616,DS-f511dabb-9aad-4de2-a93a-810bd903f1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-1e704b8f-a812-46f6-bb5a-443d8893b156,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-40826772-4dbe-4cb5-9603-8b8bb1266ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2b85c2a5-3482-4ce9-832a-399f41c168a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-40826772-4dbe-4cb5-9603-8b8bb1266ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2b85c2a5-3482-4ce9-832a-399f41c168a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-40826772-4dbe-4cb5-9603-8b8bb1266ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2b85c2a5-3482-4ce9-832a-399f41c168a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-40826772-4dbe-4cb5-9603-8b8bb1266ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-2b85c2a5-3482-4ce9-832a-399f41c168a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-594147c4-88ff-4109-b42c-9a702bb16edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-2caa940f-ef2c-4673-8671-0d463adf1797,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-594147c4-88ff-4109-b42c-9a702bb16edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-2caa940f-ef2c-4673-8671-0d463adf1797,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-594147c4-88ff-4109-b42c-9a702bb16edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-2caa940f-ef2c-4673-8671-0d463adf1797,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39186,DS-594147c4-88ff-4109-b42c-9a702bb16edd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-2caa940f-ef2c-4673-8671-0d463adf1797,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-4bc3b9f7-c97e-4360-ad1f-cf5b2382377e,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c0ad0f28-c597-4b4b-9c6c-1c057f58f6c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-4bc3b9f7-c97e-4360-ad1f-cf5b2382377e,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c0ad0f28-c597-4b4b-9c6c-1c057f58f6c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-4bc3b9f7-c97e-4360-ad1f-cf5b2382377e,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c0ad0f28-c597-4b4b-9c6c-1c057f58f6c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-4bc3b9f7-c97e-4360-ad1f-cf5b2382377e,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c0ad0f28-c597-4b4b-9c6c-1c057f58f6c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-28c81869-8875-4720-bec5-c11b5ce978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b6fc3fe3-175a-46cd-b978-58f629928973,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-28c81869-8875-4720-bec5-c11b5ce978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b6fc3fe3-175a-46cd-b978-58f629928973,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-28c81869-8875-4720-bec5-c11b5ce978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b6fc3fe3-175a-46cd-b978-58f629928973,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-28c81869-8875-4720-bec5-c11b5ce978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b6fc3fe3-175a-46cd-b978-58f629928973,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 0
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestPipelines#pipeline_01
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dd587088-4545-456e-b27a-2d5df3824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-140ea83b-a591-415b-b003-02cb1387e49d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dd587088-4545-456e-b27a-2d5df3824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-140ea83b-a591-415b-b003-02cb1387e49d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dd587088-4545-456e-b27a-2d5df3824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-140ea83b-a591-415b-b003-02cb1387e49d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dd587088-4545-456e-b27a-2d5df3824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-140ea83b-a591-415b-b003-02cb1387e49d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)


v1v2 failed with probability 46 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 3914
