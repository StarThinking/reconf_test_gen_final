reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-fe816a65-9138-4781-a9e9-793d51e3d026,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-752473c1-04fa-4afa-a009-ff180b11f84c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-fe816a65-9138-4781-a9e9-793d51e3d026,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-752473c1-04fa-4afa-a009-ff180b11f84c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-fe816a65-9138-4781-a9e9-793d51e3d026,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-752473c1-04fa-4afa-a009-ff180b11f84c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-fe816a65-9138-4781-a9e9-793d51e3d026,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-752473c1-04fa-4afa-a009-ff180b11f84c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-5efa2950-c7bc-4070-a83d-ad9336c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7632674d-4b54-4c87-91d4-1e97850de28d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-5efa2950-c7bc-4070-a83d-ad9336c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7632674d-4b54-4c87-91d4-1e97850de28d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-5efa2950-c7bc-4070-a83d-ad9336c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7632674d-4b54-4c87-91d4-1e97850de28d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-5efa2950-c7bc-4070-a83d-ad9336c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7632674d-4b54-4c87-91d4-1e97850de28d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-b774aa5f-c877-463f-b693-df79d08e4255,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e56cf7b-1dd0-46ed-9a27-5f156f6d7bf3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-b774aa5f-c877-463f-b693-df79d08e4255,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e56cf7b-1dd0-46ed-9a27-5f156f6d7bf3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-b774aa5f-c877-463f-b693-df79d08e4255,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e56cf7b-1dd0-46ed-9a27-5f156f6d7bf3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-b774aa5f-c877-463f-b693-df79d08e4255,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-9e56cf7b-1dd0-46ed-9a27-5f156f6d7bf3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-bd8514d6-6c22-4664-9321-3a9139194368,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-afc16319-3a0e-4039-8a3e-9a71e2822027,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-bd8514d6-6c22-4664-9321-3a9139194368,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-afc16319-3a0e-4039-8a3e-9a71e2822027,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-bd8514d6-6c22-4664-9321-3a9139194368,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-afc16319-3a0e-4039-8a3e-9a71e2822027,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-bd8514d6-6c22-4664-9321-3a9139194368,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-afc16319-3a0e-4039-8a3e-9a71e2822027,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-4398f187-0ea4-4c48-9187-c0182e293d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4cf8a71a-fdd5-445c-b456-47c6391abb50,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-4398f187-0ea4-4c48-9187-c0182e293d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4cf8a71a-fdd5-445c-b456-47c6391abb50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-4398f187-0ea4-4c48-9187-c0182e293d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4cf8a71a-fdd5-445c-b456-47c6391abb50,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35075,DS-4398f187-0ea4-4c48-9187-c0182e293d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-4cf8a71a-fdd5-445c-b456-47c6391abb50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-7fd9bf7f-d44a-41f2-8573-4836045b3304,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08d91957-bab2-4861-87fb-ef4a341f8d9b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-7fd9bf7f-d44a-41f2-8573-4836045b3304,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08d91957-bab2-4861-87fb-ef4a341f8d9b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-7fd9bf7f-d44a-41f2-8573-4836045b3304,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08d91957-bab2-4861-87fb-ef4a341f8d9b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35201,DS-7fd9bf7f-d44a-41f2-8573-4836045b3304,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08d91957-bab2-4861-87fb-ef4a341f8d9b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36306,DS-ce9888ea-d00e-419d-b28f-15e74bbf1360,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-cc942f6e-a45a-480c-aadf-f9d2c50b8ab4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-cc942f6e-a45a-480c-aadf-f9d2c50b8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ce9888ea-d00e-419d-b28f-15e74bbf1360,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36306,DS-ce9888ea-d00e-419d-b28f-15e74bbf1360,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-cc942f6e-a45a-480c-aadf-f9d2c50b8ab4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-cc942f6e-a45a-480c-aadf-f9d2c50b8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ce9888ea-d00e-419d-b28f-15e74bbf1360,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-7933c100-c025-4522-87e0-a732bc8df9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8221c9f2-3bae-493f-989f-5eea0fc2d447,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-8221c9f2-3bae-493f-989f-5eea0fc2d447,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-7933c100-c025-4522-87e0-a732bc8df9ef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-7933c100-c025-4522-87e0-a732bc8df9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8221c9f2-3bae-493f-989f-5eea0fc2d447,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41160,DS-8221c9f2-3bae-493f-989f-5eea0fc2d447,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-7933c100-c025-4522-87e0-a732bc8df9ef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-790c08cd-75d5-4c37-8345-096f6b4744ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-1fe38f96-c712-4970-8615-fe88654294fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-790c08cd-75d5-4c37-8345-096f6b4744ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-1fe38f96-c712-4970-8615-fe88654294fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-790c08cd-75d5-4c37-8345-096f6b4744ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-1fe38f96-c712-4970-8615-fe88654294fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-790c08cd-75d5-4c37-8345-096f6b4744ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-1fe38f96-c712-4970-8615-fe88654294fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-7c0e7829-dd55-48ba-a7f5-9c7291d769dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-56c9c8d8-a8a8-489a-b35f-fe50e34e04a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-7c0e7829-dd55-48ba-a7f5-9c7291d769dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-56c9c8d8-a8a8-489a-b35f-fe50e34e04a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-7c0e7829-dd55-48ba-a7f5-9c7291d769dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-56c9c8d8-a8a8-489a-b35f-fe50e34e04a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38896,DS-7c0e7829-dd55-48ba-a7f5-9c7291d769dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-56c9c8d8-a8a8-489a-b35f-fe50e34e04a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-796960f6-3c91-4274-a118-726d21cf01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-4ffde662-7302-419c-965a-7e9a34144752,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-4ffde662-7302-419c-965a-7e9a34144752,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-796960f6-3c91-4274-a118-726d21cf01f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-796960f6-3c91-4274-a118-726d21cf01f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-4ffde662-7302-419c-965a-7e9a34144752,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-4ffde662-7302-419c-965a-7e9a34144752,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-796960f6-3c91-4274-a118-726d21cf01f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-7193cc69-9c3d-4808-84a8-a1783d0dbf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-2af5575e-2f85-40b4-ac3d-929c77e39914,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-2af5575e-2f85-40b4-ac3d-929c77e39914,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-7193cc69-9c3d-4808-84a8-a1783d0dbf6d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-7193cc69-9c3d-4808-84a8-a1783d0dbf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-2af5575e-2f85-40b4-ac3d-929c77e39914,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-2af5575e-2f85-40b4-ac3d-929c77e39914,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-7193cc69-9c3d-4808-84a8-a1783d0dbf6d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-3c3f6891-2473-4cd5-b89d-1315cd10bdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4d6ec0e3-b40f-4719-a10f-8c2e057fe018,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-3c3f6891-2473-4cd5-b89d-1315cd10bdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4d6ec0e3-b40f-4719-a10f-8c2e057fe018,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-3c3f6891-2473-4cd5-b89d-1315cd10bdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4d6ec0e3-b40f-4719-a10f-8c2e057fe018,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-3c3f6891-2473-4cd5-b89d-1315cd10bdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4d6ec0e3-b40f-4719-a10f-8c2e057fe018,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f369815d-41f2-4aa3-b066-c40804446f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a2f8582a-f965-4ccf-9819-c0d30d7e6b44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f369815d-41f2-4aa3-b066-c40804446f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a2f8582a-f965-4ccf-9819-c0d30d7e6b44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f369815d-41f2-4aa3-b066-c40804446f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a2f8582a-f965-4ccf-9819-c0d30d7e6b44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-f369815d-41f2-4aa3-b066-c40804446f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a2f8582a-f965-4ccf-9819-c0d30d7e6b44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-3265845e-21ee-4021-a3e5-03cc51070bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0fe9de9-ed3d-496e-8623-85b80bb6bfd7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-3265845e-21ee-4021-a3e5-03cc51070bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0fe9de9-ed3d-496e-8623-85b80bb6bfd7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-3265845e-21ee-4021-a3e5-03cc51070bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0fe9de9-ed3d-496e-8623-85b80bb6bfd7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-3265845e-21ee-4021-a3e5-03cc51070bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0fe9de9-ed3d-496e-8623-85b80bb6bfd7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-1617dde5-4a21-4596-ab8a-7eef4fed50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-cc563f8f-a651-41af-99e2-1e6d0614cf42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-1617dde5-4a21-4596-ab8a-7eef4fed50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-cc563f8f-a651-41af-99e2-1e6d0614cf42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-1617dde5-4a21-4596-ab8a-7eef4fed50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-cc563f8f-a651-41af-99e2-1e6d0614cf42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-1617dde5-4a21-4596-ab8a-7eef4fed50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-cc563f8f-a651-41af-99e2-1e6d0614cf42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-e6b4d361-eedf-4e2c-a38c-048ce7668591,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-907009cc-3f6b-495b-a8b0-7d3f5dd9bb93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-907009cc-3f6b-495b-a8b0-7d3f5dd9bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-e6b4d361-eedf-4e2c-a38c-048ce7668591,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-e6b4d361-eedf-4e2c-a38c-048ce7668591,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-907009cc-3f6b-495b-a8b0-7d3f5dd9bb93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-907009cc-3f6b-495b-a8b0-7d3f5dd9bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-e6b4d361-eedf-4e2c-a38c-048ce7668591,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-5a5230f0-f29b-45ca-bb1c-f8b9a6441be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-ff1a2fe0-36ed-4a56-8177-13fe4c2a30b9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-5a5230f0-f29b-45ca-bb1c-f8b9a6441be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-ff1a2fe0-36ed-4a56-8177-13fe4c2a30b9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-5a5230f0-f29b-45ca-bb1c-f8b9a6441be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-ff1a2fe0-36ed-4a56-8177-13fe4c2a30b9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-5a5230f0-f29b-45ca-bb1c-f8b9a6441be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-ff1a2fe0-36ed-4a56-8177-13fe4c2a30b9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-7b8f7c4f-d607-456a-9d53-38a539dbb651,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-7de049a0-ca12-4afd-b630-a429decef8b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-7b8f7c4f-d607-456a-9d53-38a539dbb651,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-7de049a0-ca12-4afd-b630-a429decef8b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-7b8f7c4f-d607-456a-9d53-38a539dbb651,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-7de049a0-ca12-4afd-b630-a429decef8b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-7b8f7c4f-d607-456a-9d53-38a539dbb651,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-7de049a0-ca12-4afd-b630-a429decef8b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-08839858-8d9e-4a61-b2e9-aa4de397942c,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f4b13642-ecf5-4aa8-99b8-4f6379efdb34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-08839858-8d9e-4a61-b2e9-aa4de397942c,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f4b13642-ecf5-4aa8-99b8-4f6379efdb34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-08839858-8d9e-4a61-b2e9-aa4de397942c,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f4b13642-ecf5-4aa8-99b8-4f6379efdb34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-08839858-8d9e-4a61-b2e9-aa4de397942c,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f4b13642-ecf5-4aa8-99b8-4f6379efdb34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-63cc8f6e-ed8a-49c5-a0f6-d8930a301d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-fc12b775-6d8e-426a-99e3-77505ab44b19,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-63cc8f6e-ed8a-49c5-a0f6-d8930a301d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-fc12b775-6d8e-426a-99e3-77505ab44b19,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-63cc8f6e-ed8a-49c5-a0f6-d8930a301d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-fc12b775-6d8e-426a-99e3-77505ab44b19,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-63cc8f6e-ed8a-49c5-a0f6-d8930a301d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-fc12b775-6d8e-426a-99e3-77505ab44b19,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-8d982e67-1b1d-470b-a447-7180e40f191a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5ecb9a19-29bb-4765-bbe8-d5d6138d1e1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-8d982e67-1b1d-470b-a447-7180e40f191a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5ecb9a19-29bb-4765-bbe8-d5d6138d1e1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-8d982e67-1b1d-470b-a447-7180e40f191a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5ecb9a19-29bb-4765-bbe8-d5d6138d1e1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-8d982e67-1b1d-470b-a447-7180e40f191a,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-5ecb9a19-29bb-4765-bbe8-d5d6138d1e1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-5da89ddb-d1ca-4e6d-bdb3-41d66e5b159d,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-5982ce5a-adf4-4407-a391-00a897ad4c34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-5982ce5a-adf4-4407-a391-00a897ad4c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-5da89ddb-d1ca-4e6d-bdb3-41d66e5b159d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-5da89ddb-d1ca-4e6d-bdb3-41d66e5b159d,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-5982ce5a-adf4-4407-a391-00a897ad4c34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-5982ce5a-adf4-4407-a391-00a897ad4c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-5da89ddb-d1ca-4e6d-bdb3-41d66e5b159d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-54b6d522-2266-4a6b-aa28-efa2466bbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6f9e1a35-5336-4973-b8e0-cf653b975753,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-54b6d522-2266-4a6b-aa28-efa2466bbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6f9e1a35-5336-4973-b8e0-cf653b975753,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-54b6d522-2266-4a6b-aa28-efa2466bbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6f9e1a35-5336-4973-b8e0-cf653b975753,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-54b6d522-2266-4a6b-aa28-efa2466bbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6f9e1a35-5336-4973-b8e0-cf653b975753,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-12ceef12-f6da-4328-a5ae-663d774e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2c6ae64-fd67-46ef-8e91-33f6d6f95c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-12ceef12-f6da-4328-a5ae-663d774e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2c6ae64-fd67-46ef-8e91-33f6d6f95c27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-12ceef12-f6da-4328-a5ae-663d774e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2c6ae64-fd67-46ef-8e91-33f6d6f95c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-12ceef12-f6da-4328-a5ae-663d774e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-d2c6ae64-fd67-46ef-8e91-33f6d6f95c27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-7203a2e9-2c3f-4ad3-8b48-e3bba2384e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-40107664-f676-4a8a-8011-1c99cc8e2c53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-7203a2e9-2c3f-4ad3-8b48-e3bba2384e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-40107664-f676-4a8a-8011-1c99cc8e2c53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-7203a2e9-2c3f-4ad3-8b48-e3bba2384e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-40107664-f676-4a8a-8011-1c99cc8e2c53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46706,DS-7203a2e9-2c3f-4ad3-8b48-e3bba2384e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-40107664-f676-4a8a-8011-1c99cc8e2c53,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-6676c3a7-9446-4327-b4b6-c5430f952622,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-78a51950-6ea8-4f32-93b2-8926764f8bc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-6676c3a7-9446-4327-b4b6-c5430f952622,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-78a51950-6ea8-4f32-93b2-8926764f8bc7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-6676c3a7-9446-4327-b4b6-c5430f952622,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-78a51950-6ea8-4f32-93b2-8926764f8bc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-6676c3a7-9446-4327-b4b6-c5430f952622,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-78a51950-6ea8-4f32-93b2-8926764f8bc7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-b343f75e-4616-4baf-ba7a-1bd1b3bafb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f4e398c7-864d-477d-904c-bb6c31379287,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-b343f75e-4616-4baf-ba7a-1bd1b3bafb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f4e398c7-864d-477d-904c-bb6c31379287,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-b343f75e-4616-4baf-ba7a-1bd1b3bafb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f4e398c7-864d-477d-904c-bb6c31379287,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-b343f75e-4616-4baf-ba7a-1bd1b3bafb52,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f4e398c7-864d-477d-904c-bb6c31379287,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-7109f640-bd3a-46f6-813f-f1ae98e93613,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-552d06c9-8347-410e-a6ab-27ab6a3d8f3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42611,DS-552d06c9-8347-410e-a6ab-27ab6a3d8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7109f640-bd3a-46f6-813f-f1ae98e93613,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-7109f640-bd3a-46f6-813f-f1ae98e93613,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-552d06c9-8347-410e-a6ab-27ab6a3d8f3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42611,DS-552d06c9-8347-410e-a6ab-27ab6a3d8f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7109f640-bd3a-46f6-813f-f1ae98e93613,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-c5823694-9f1a-4aa8-b2b3-1b25b11226e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-221472fd-ae29-426b-bab5-e926da929af5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-c5823694-9f1a-4aa8-b2b3-1b25b11226e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-221472fd-ae29-426b-bab5-e926da929af5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-c5823694-9f1a-4aa8-b2b3-1b25b11226e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-221472fd-ae29-426b-bab5-e926da929af5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-c5823694-9f1a-4aa8-b2b3-1b25b11226e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-221472fd-ae29-426b-bab5-e926da929af5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-2f29c4b2-e7da-4ee7-acae-1e53b40a3acc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-f60b248f-abe6-44f2-a2c4-61bca974b4c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-f60b248f-abe6-44f2-a2c4-61bca974b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-2f29c4b2-e7da-4ee7-acae-1e53b40a3acc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-2f29c4b2-e7da-4ee7-acae-1e53b40a3acc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-f60b248f-abe6-44f2-a2c4-61bca974b4c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-f60b248f-abe6-44f2-a2c4-61bca974b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-2f29c4b2-e7da-4ee7-acae-1e53b40a3acc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-ef5d5365-54ed-40ac-86e8-f878230f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a9841d3c-3783-4251-9599-1a3fa7f6768d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-ef5d5365-54ed-40ac-86e8-f878230f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a9841d3c-3783-4251-9599-1a3fa7f6768d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-ef5d5365-54ed-40ac-86e8-f878230f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a9841d3c-3783-4251-9599-1a3fa7f6768d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-ef5d5365-54ed-40ac-86e8-f878230f3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a9841d3c-3783-4251-9599-1a3fa7f6768d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1d1ba30e-4a2a-4191-9571-f885c0e37826,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-65706443-499a-41a7-bcd1-04afdfc278c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1d1ba30e-4a2a-4191-9571-f885c0e37826,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-65706443-499a-41a7-bcd1-04afdfc278c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1d1ba30e-4a2a-4191-9571-f885c0e37826,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-65706443-499a-41a7-bcd1-04afdfc278c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1d1ba30e-4a2a-4191-9571-f885c0e37826,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-65706443-499a-41a7-bcd1-04afdfc278c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-c72e9a91-a468-4c13-9ca7-e3ec9c040798,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-1f224cc5-ce24-44be-9750-c0861c9a0236,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-1f224cc5-ce24-44be-9750-c0861c9a0236,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-c72e9a91-a468-4c13-9ca7-e3ec9c040798,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-c72e9a91-a468-4c13-9ca7-e3ec9c040798,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-1f224cc5-ce24-44be-9750-c0861c9a0236,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-1f224cc5-ce24-44be-9750-c0861c9a0236,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-c72e9a91-a468-4c13-9ca7-e3ec9c040798,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-754fc0aa-952d-4fb5-b127-24cdd1b5ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6b98478-9db3-48b9-8168-c77c3eab70e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-754fc0aa-952d-4fb5-b127-24cdd1b5ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6b98478-9db3-48b9-8168-c77c3eab70e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-754fc0aa-952d-4fb5-b127-24cdd1b5ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6b98478-9db3-48b9-8168-c77c3eab70e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-754fc0aa-952d-4fb5-b127-24cdd1b5ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6b98478-9db3-48b9-8168-c77c3eab70e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-c93f8dd2-4c8e-4e28-956b-fa4ed1eaeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-b0894c67-2d3e-43f3-bc0b-223293aa9d85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-c93f8dd2-4c8e-4e28-956b-fa4ed1eaeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-b0894c67-2d3e-43f3-bc0b-223293aa9d85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-c93f8dd2-4c8e-4e28-956b-fa4ed1eaeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-b0894c67-2d3e-43f3-bc0b-223293aa9d85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-c93f8dd2-4c8e-4e28-956b-fa4ed1eaeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-b0894c67-2d3e-43f3-bc0b-223293aa9d85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-af546b53-01d0-4e99-8195-afc9edd7bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-0a5334a1-90b3-46b2-99d0-5b92df43d266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-af546b53-01d0-4e99-8195-afc9edd7bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-0a5334a1-90b3-46b2-99d0-5b92df43d266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-af546b53-01d0-4e99-8195-afc9edd7bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-0a5334a1-90b3-46b2-99d0-5b92df43d266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-af546b53-01d0-4e99-8195-afc9edd7bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-0a5334a1-90b3-46b2-99d0-5b92df43d266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-0500f28e-631b-4d5d-b19d-38790c6dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-bc3ffd4c-6206-4307-8821-62b57213b6a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-0500f28e-631b-4d5d-b19d-38790c6dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-bc3ffd4c-6206-4307-8821-62b57213b6a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-0500f28e-631b-4d5d-b19d-38790c6dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-bc3ffd4c-6206-4307-8821-62b57213b6a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-0500f28e-631b-4d5d-b19d-38790c6dc252,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-bc3ffd4c-6206-4307-8821-62b57213b6a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-b5a96d9d-e12a-44bd-8264-d26409913549,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-bd933986-6db6-45f6-9427-0db069c9c61e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-b5a96d9d-e12a-44bd-8264-d26409913549,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-bd933986-6db6-45f6-9427-0db069c9c61e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-b5a96d9d-e12a-44bd-8264-d26409913549,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-bd933986-6db6-45f6-9427-0db069c9c61e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38622,DS-b5a96d9d-e12a-44bd-8264-d26409913549,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-bd933986-6db6-45f6-9427-0db069c9c61e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-0aa2c1aa-4106-40aa-a692-a8412d2fbc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-03b2b35a-c5ad-4068-a86e-0210ecf81962,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-0aa2c1aa-4106-40aa-a692-a8412d2fbc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-03b2b35a-c5ad-4068-a86e-0210ecf81962,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-0aa2c1aa-4106-40aa-a692-a8412d2fbc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-03b2b35a-c5ad-4068-a86e-0210ecf81962,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-0aa2c1aa-4106-40aa-a692-a8412d2fbc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-03b2b35a-c5ad-4068-a86e-0210ecf81962,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-3a92eb79-7c1d-44de-9801-ca0c56385599,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-69b0d756-b2ef-4235-b799-562754c6f119,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-69b0d756-b2ef-4235-b799-562754c6f119,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-3a92eb79-7c1d-44de-9801-ca0c56385599,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-3a92eb79-7c1d-44de-9801-ca0c56385599,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-69b0d756-b2ef-4235-b799-562754c6f119,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-69b0d756-b2ef-4235-b799-562754c6f119,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-3a92eb79-7c1d-44de-9801-ca0c56385599,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8709536-6c04-4273-a274-f3935d827cce,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-24dadd5f-34d9-4d6f-8c1a-d827f7d16ecb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-24dadd5f-34d9-4d6f-8c1a-d827f7d16ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8709536-6c04-4273-a274-f3935d827cce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8709536-6c04-4273-a274-f3935d827cce,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-24dadd5f-34d9-4d6f-8c1a-d827f7d16ecb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-24dadd5f-34d9-4d6f-8c1a-d827f7d16ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d8709536-6c04-4273-a274-f3935d827cce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-79cbe2d3-b867-450d-ae3a-5e14ea71f865,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-6e861674-a043-4897-ab18-4ae2a73c0687,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-6e861674-a043-4897-ab18-4ae2a73c0687,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-79cbe2d3-b867-450d-ae3a-5e14ea71f865,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-79cbe2d3-b867-450d-ae3a-5e14ea71f865,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-6e861674-a043-4897-ab18-4ae2a73c0687,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-6e861674-a043-4897-ab18-4ae2a73c0687,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-79cbe2d3-b867-450d-ae3a-5e14ea71f865,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-32d900c6-4b20-43c4-a93c-93a0d30593cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-a9367d3b-22cc-4cbf-97e1-7e43d94b9597,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-32d900c6-4b20-43c4-a93c-93a0d30593cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-a9367d3b-22cc-4cbf-97e1-7e43d94b9597,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-32d900c6-4b20-43c4-a93c-93a0d30593cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-a9367d3b-22cc-4cbf-97e1-7e43d94b9597,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-32d900c6-4b20-43c4-a93c-93a0d30593cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-a9367d3b-22cc-4cbf-97e1-7e43d94b9597,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-3074582e-87c9-4358-a943-fec2bbbae24b,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-40a9ce12-5788-41ab-b4a5-2002e98f4bef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-40a9ce12-5788-41ab-b4a5-2002e98f4bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3074582e-87c9-4358-a943-fec2bbbae24b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-3074582e-87c9-4358-a943-fec2bbbae24b,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-40a9ce12-5788-41ab-b4a5-2002e98f4bef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-40a9ce12-5788-41ab-b4a5-2002e98f4bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3074582e-87c9-4358-a943-fec2bbbae24b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-07f3d0fa-2911-40f1-af62-4dd924e29295,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-1a9bf80c-7d4c-4090-a03c-d452f02222e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-1a9bf80c-7d4c-4090-a03c-d452f02222e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-07f3d0fa-2911-40f1-af62-4dd924e29295,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-07f3d0fa-2911-40f1-af62-4dd924e29295,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-1a9bf80c-7d4c-4090-a03c-d452f02222e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-1a9bf80c-7d4c-4090-a03c-d452f02222e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-07f3d0fa-2911-40f1-af62-4dd924e29295,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-8b2a2e35-1985-4526-b462-85af4c2d8108,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-72bf3270-3c4a-475c-b182-9b3d638a38fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-8b2a2e35-1985-4526-b462-85af4c2d8108,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-72bf3270-3c4a-475c-b182-9b3d638a38fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-8b2a2e35-1985-4526-b462-85af4c2d8108,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-72bf3270-3c4a-475c-b182-9b3d638a38fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-8b2a2e35-1985-4526-b462-85af4c2d8108,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-72bf3270-3c4a-475c-b182-9b3d638a38fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-f7298f79-0fcb-469a-a24d-9062a01d33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5d4a668f-7074-41ef-bea3-09c8c95ea4bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-f7298f79-0fcb-469a-a24d-9062a01d33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5d4a668f-7074-41ef-bea3-09c8c95ea4bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-f7298f79-0fcb-469a-a24d-9062a01d33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5d4a668f-7074-41ef-bea3-09c8c95ea4bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-f7298f79-0fcb-469a-a24d-9062a01d33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5d4a668f-7074-41ef-bea3-09c8c95ea4bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-8378958f-ead6-472a-8047-4ef6d6a8a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-d5a36342-3fa3-45c8-a987-d39bcb439dac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46129,DS-d5a36342-3fa3-45c8-a987-d39bcb439dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8378958f-ead6-472a-8047-4ef6d6a8a5a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-8378958f-ead6-472a-8047-4ef6d6a8a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-d5a36342-3fa3-45c8-a987-d39bcb439dac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46129,DS-d5a36342-3fa3-45c8-a987-d39bcb439dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8378958f-ead6-472a-8047-4ef6d6a8a5a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-49295aa6-ddff-4d10-8a62-a25f3e8fe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-162934a1-4e7f-48a8-9927-7c2b4a0c1fdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-49295aa6-ddff-4d10-8a62-a25f3e8fe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-162934a1-4e7f-48a8-9927-7c2b4a0c1fdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-49295aa6-ddff-4d10-8a62-a25f3e8fe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-162934a1-4e7f-48a8-9927-7c2b4a0c1fdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-49295aa6-ddff-4d10-8a62-a25f3e8fe0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-162934a1-4e7f-48a8-9927-7c2b4a0c1fdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-8e047f80-f7bc-415e-83a3-ca000f86e883,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8551463c-df12-4f67-94fb-6277d2068863,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-8e047f80-f7bc-415e-83a3-ca000f86e883,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8551463c-df12-4f67-94fb-6277d2068863,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-8e047f80-f7bc-415e-83a3-ca000f86e883,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8551463c-df12-4f67-94fb-6277d2068863,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-8e047f80-f7bc-415e-83a3-ca000f86e883,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8551463c-df12-4f67-94fb-6277d2068863,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 49 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 3817
