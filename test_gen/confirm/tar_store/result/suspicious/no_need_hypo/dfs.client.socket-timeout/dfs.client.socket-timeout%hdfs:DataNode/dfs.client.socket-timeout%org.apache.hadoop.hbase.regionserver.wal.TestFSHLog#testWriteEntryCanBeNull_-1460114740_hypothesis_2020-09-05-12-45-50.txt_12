reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44840,DS-b56521a4-f620-4552-aaad-71cd235963b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3f687614-0e6e-47c0-b687-f80af7992b59,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44840,DS-b56521a4-f620-4552-aaad-71cd235963b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3f687614-0e6e-47c0-b687-f80af7992b59,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44840,DS-b56521a4-f620-4552-aaad-71cd235963b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3f687614-0e6e-47c0-b687-f80af7992b59,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44840,DS-b56521a4-f620-4552-aaad-71cd235963b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-3f687614-0e6e-47c0-b687-f80af7992b59,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38604,DS-281ecfae-7541-4c9c-881e-b5c95b9654c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-6d39caf1-3864-41ce-9643-e8ea60da29ef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-6d39caf1-3864-41ce-9643-e8ea60da29ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-281ecfae-7541-4c9c-881e-b5c95b9654c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38604,DS-281ecfae-7541-4c9c-881e-b5c95b9654c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-6d39caf1-3864-41ce-9643-e8ea60da29ef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-6d39caf1-3864-41ce-9643-e8ea60da29ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-281ecfae-7541-4c9c-881e-b5c95b9654c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-2397e694-9960-425f-ac35-acb22cbb8950,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e007694-5295-4dcd-a3f3-9344cf6e1455,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e007694-5295-4dcd-a3f3-9344cf6e1455,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-2397e694-9960-425f-ac35-acb22cbb8950,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-2397e694-9960-425f-ac35-acb22cbb8950,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e007694-5295-4dcd-a3f3-9344cf6e1455,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e007694-5295-4dcd-a3f3-9344cf6e1455,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-2397e694-9960-425f-ac35-acb22cbb8950,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-9737b452-9326-45d6-8e2e-7deda13648fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-a6fb9c86-78a4-4182-9a4d-d93d90ab5f62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39696,DS-a6fb9c86-78a4-4182-9a4d-d93d90ab5f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-9737b452-9326-45d6-8e2e-7deda13648fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-9737b452-9326-45d6-8e2e-7deda13648fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-a6fb9c86-78a4-4182-9a4d-d93d90ab5f62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39696,DS-a6fb9c86-78a4-4182-9a4d-d93d90ab5f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-9737b452-9326-45d6-8e2e-7deda13648fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-0ae06147-2c66-4944-8e43-2d80d45e8ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-e4291be7-4493-4b97-ab97-a4a189f43198,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-e4291be7-4493-4b97-ab97-a4a189f43198,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0ae06147-2c66-4944-8e43-2d80d45e8ef7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-0ae06147-2c66-4944-8e43-2d80d45e8ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-e4291be7-4493-4b97-ab97-a4a189f43198,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-e4291be7-4493-4b97-ab97-a4a189f43198,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0ae06147-2c66-4944-8e43-2d80d45e8ef7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-8b616a44-28c7-4eaf-b724-ee05fd3abc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eaf3d8ca-2a1b-44c1-ae32-a8e20eedc571,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-8b616a44-28c7-4eaf-b724-ee05fd3abc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eaf3d8ca-2a1b-44c1-ae32-a8e20eedc571,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-8b616a44-28c7-4eaf-b724-ee05fd3abc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eaf3d8ca-2a1b-44c1-ae32-a8e20eedc571,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-8b616a44-28c7-4eaf-b724-ee05fd3abc59,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-eaf3d8ca-2a1b-44c1-ae32-a8e20eedc571,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-ec6e0f2c-089c-4c70-8705-8caa206bc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-39229429-33a5-47b7-bb3e-eb9ab87d645c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-ec6e0f2c-089c-4c70-8705-8caa206bc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-39229429-33a5-47b7-bb3e-eb9ab87d645c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-ec6e0f2c-089c-4c70-8705-8caa206bc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-39229429-33a5-47b7-bb3e-eb9ab87d645c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-ec6e0f2c-089c-4c70-8705-8caa206bc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-39229429-33a5-47b7-bb3e-eb9ab87d645c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-4a6ccdad-11d5-4806-997b-585e8adf8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-4e587d3c-16dd-4e47-94ba-029db5cb879f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-4a6ccdad-11d5-4806-997b-585e8adf8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-4e587d3c-16dd-4e47-94ba-029db5cb879f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-4a6ccdad-11d5-4806-997b-585e8adf8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-4e587d3c-16dd-4e47-94ba-029db5cb879f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45483,DS-4a6ccdad-11d5-4806-997b-585e8adf8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-4e587d3c-16dd-4e47-94ba-029db5cb879f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-9ca574db-cfd3-4e0d-8429-aa54143001e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-6b021466-a353-477a-92e9-07fbb23393a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-6b021466-a353-477a-92e9-07fbb23393a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-9ca574db-cfd3-4e0d-8429-aa54143001e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-9ca574db-cfd3-4e0d-8429-aa54143001e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-6b021466-a353-477a-92e9-07fbb23393a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-6b021466-a353-477a-92e9-07fbb23393a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-9ca574db-cfd3-4e0d-8429-aa54143001e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWriteEntryCanBeNull
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-efc7ff0b-fc30-4b02-89f9-8eaff56cbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1a88758a-06f3-4591-a1cb-a5df51bee4e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-efc7ff0b-fc30-4b02-89f9-8eaff56cbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1a88758a-06f3-4591-a1cb-a5df51bee4e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-efc7ff0b-fc30-4b02-89f9-8eaff56cbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1a88758a-06f3-4591-a1cb-a5df51bee4e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32956,DS-efc7ff0b-fc30-4b02-89f9-8eaff56cbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1a88758a-06f3-4591-a1cb-a5df51bee4e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1352
