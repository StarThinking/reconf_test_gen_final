reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-ac873fc0-2bda-4a42-a427-3de0777ded25,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2c6afea7-8352-4968-8138-66484cf60e45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-ac873fc0-2bda-4a42-a427-3de0777ded25,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2c6afea7-8352-4968-8138-66484cf60e45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-ac873fc0-2bda-4a42-a427-3de0777ded25,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2c6afea7-8352-4968-8138-66484cf60e45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-ac873fc0-2bda-4a42-a427-3de0777ded25,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2c6afea7-8352-4968-8138-66484cf60e45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38082,DS-5ccfd9c5-aa4c-488d-b124-8721384c9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-67fe0b53-46b3-480a-be4b-25d7f15303c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38082,DS-5ccfd9c5-aa4c-488d-b124-8721384c9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-67fe0b53-46b3-480a-be4b-25d7f15303c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38082,DS-5ccfd9c5-aa4c-488d-b124-8721384c9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-67fe0b53-46b3-480a-be4b-25d7f15303c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38082,DS-5ccfd9c5-aa4c-488d-b124-8721384c9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-67fe0b53-46b3-480a-be4b-25d7f15303c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-77e07ef6-1854-463b-b167-b44fda9761d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-7c0e5220-b18f-4d0c-99f8-8f0849ede334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-7c0e5220-b18f-4d0c-99f8-8f0849ede334,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-77e07ef6-1854-463b-b167-b44fda9761d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-77e07ef6-1854-463b-b167-b44fda9761d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-7c0e5220-b18f-4d0c-99f8-8f0849ede334,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-7c0e5220-b18f-4d0c-99f8-8f0849ede334,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-77e07ef6-1854-463b-b167-b44fda9761d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-78b20506-db1a-4547-bbd9-88c2e0dce3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-85ff7900-be17-430e-93b6-e42aec01bb2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-78b20506-db1a-4547-bbd9-88c2e0dce3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-85ff7900-be17-430e-93b6-e42aec01bb2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-78b20506-db1a-4547-bbd9-88c2e0dce3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-85ff7900-be17-430e-93b6-e42aec01bb2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-78b20506-db1a-4547-bbd9-88c2e0dce3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-85ff7900-be17-430e-93b6-e42aec01bb2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-d832905b-a06a-4655-8b42-3fa6f44be1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-be1f4db7-5cd0-4604-a9ba-aef95e5ac025,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-d832905b-a06a-4655-8b42-3fa6f44be1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-be1f4db7-5cd0-4604-a9ba-aef95e5ac025,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-d832905b-a06a-4655-8b42-3fa6f44be1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-be1f4db7-5cd0-4604-a9ba-aef95e5ac025,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-d832905b-a06a-4655-8b42-3fa6f44be1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-be1f4db7-5cd0-4604-a9ba-aef95e5ac025,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41102,DS-fefe1d05-c87e-4516-9ace-5c4441a7f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b0c972b7-7c1d-46ce-9bff-0c5f976b5b79,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41102,DS-fefe1d05-c87e-4516-9ace-5c4441a7f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b0c972b7-7c1d-46ce-9bff-0c5f976b5b79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41102,DS-fefe1d05-c87e-4516-9ace-5c4441a7f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b0c972b7-7c1d-46ce-9bff-0c5f976b5b79,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41102,DS-fefe1d05-c87e-4516-9ace-5c4441a7f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b0c972b7-7c1d-46ce-9bff-0c5f976b5b79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-05dfea75-4fb3-47f6-a847-457a12e5659b,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-26459b7f-58c6-49c3-a8fb-e2d7d11a0fa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-26459b7f-58c6-49c3-a8fb-e2d7d11a0fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-05dfea75-4fb3-47f6-a847-457a12e5659b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-05dfea75-4fb3-47f6-a847-457a12e5659b,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-26459b7f-58c6-49c3-a8fb-e2d7d11a0fa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-26459b7f-58c6-49c3-a8fb-e2d7d11a0fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-05dfea75-4fb3-47f6-a847-457a12e5659b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-bcaf30e9-2227-45d5-97ac-744463fd28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e20ad6b2-e34a-4f74-9e30-4868701e0daa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-bcaf30e9-2227-45d5-97ac-744463fd28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e20ad6b2-e34a-4f74-9e30-4868701e0daa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-bcaf30e9-2227-45d5-97ac-744463fd28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e20ad6b2-e34a-4f74-9e30-4868701e0daa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-bcaf30e9-2227-45d5-97ac-744463fd28c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e20ad6b2-e34a-4f74-9e30-4868701e0daa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-1edee14c-7d87-4af7-a565-f02834aef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6d97f567-bea7-40bf-90b7-01a1519c1438,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-1edee14c-7d87-4af7-a565-f02834aef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6d97f567-bea7-40bf-90b7-01a1519c1438,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-1edee14c-7d87-4af7-a565-f02834aef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6d97f567-bea7-40bf-90b7-01a1519c1438,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-1edee14c-7d87-4af7-a565-f02834aef6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-6d97f567-bea7-40bf-90b7-01a1519c1438,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b75832da-8b16-43c9-b3e9-5d707d78cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-fd8a6bc7-d82b-4506-a9c2-f5eeeed4e0d3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b75832da-8b16-43c9-b3e9-5d707d78cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-fd8a6bc7-d82b-4506-a9c2-f5eeeed4e0d3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b75832da-8b16-43c9-b3e9-5d707d78cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-fd8a6bc7-d82b-4506-a9c2-f5eeeed4e0d3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b75832da-8b16-43c9-b3e9-5d707d78cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-fd8a6bc7-d82b-4506-a9c2-f5eeeed4e0d3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: test timed out after 30000 milliseconds
stackTrace: java.lang.Exception: test timed out after 30000 milliseconds
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:776)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.doWriteOverFailoverTest(TestPipelinesFailover.java:194)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testAllocateBlockAfterCrashFailover(TestPipelinesFailover.java:132)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-15076ce4-1707-4161-8022-a661aa4ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-8435f8ec-74bf-4dd3-a0b6-576aa084524e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-15076ce4-1707-4161-8022-a661aa4ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-8435f8ec-74bf-4dd3-a0b6-576aa084524e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-15076ce4-1707-4161-8022-a661aa4ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-8435f8ec-74bf-4dd3-a0b6-576aa084524e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-15076ce4-1707-4161-8022-a661aa4ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-8435f8ec-74bf-4dd3-a0b6-576aa084524e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-a3c39536-966f-469a-ae85-b718b18aa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-0380acea-7aa2-4d46-b163-7b95f8efa7a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-a3c39536-966f-469a-ae85-b718b18aa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-0380acea-7aa2-4d46-b163-7b95f8efa7a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-a3c39536-966f-469a-ae85-b718b18aa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-0380acea-7aa2-4d46-b163-7b95f8efa7a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-a3c39536-966f-469a-ae85-b718b18aa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-0380acea-7aa2-4d46-b163-7b95f8efa7a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-b81e855f-7106-4c8c-9a53-595184f39bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-76d5f22b-fc93-4723-ad58-6c979b863dc5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-b81e855f-7106-4c8c-9a53-595184f39bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-76d5f22b-fc93-4723-ad58-6c979b863dc5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-b81e855f-7106-4c8c-9a53-595184f39bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-76d5f22b-fc93-4723-ad58-6c979b863dc5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-b81e855f-7106-4c8c-9a53-595184f39bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-76d5f22b-fc93-4723-ad58-6c979b863dc5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46256,DS-03105c9c-c746-46d1-b68c-25b0ff1062a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-a27626f5-39f1-4695-9673-3b91e4e3e431,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-a27626f5-39f1-4695-9673-3b91e4e3e431,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-03105c9c-c746-46d1-b68c-25b0ff1062a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46256,DS-03105c9c-c746-46d1-b68c-25b0ff1062a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-a27626f5-39f1-4695-9673-3b91e4e3e431,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-a27626f5-39f1-4695-9673-3b91e4e3e431,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-03105c9c-c746-46d1-b68c-25b0ff1062a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-6a472416-d3c1-41f7-8fec-b0c1b9cea249,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-f087e0a8-ee87-4432-a91f-7c682b0ddc52,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-6a472416-d3c1-41f7-8fec-b0c1b9cea249,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-f087e0a8-ee87-4432-a91f-7c682b0ddc52,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-6a472416-d3c1-41f7-8fec-b0c1b9cea249,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-f087e0a8-ee87-4432-a91f-7c682b0ddc52,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39244,DS-6a472416-d3c1-41f7-8fec-b0c1b9cea249,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-f087e0a8-ee87-4432-a91f-7c682b0ddc52,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-8c41a5d8-389a-4398-8cce-18c5c1a1dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9aa71b60-f7c7-4e4b-99e7-5921e4391d07,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-8c41a5d8-389a-4398-8cce-18c5c1a1dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9aa71b60-f7c7-4e4b-99e7-5921e4391d07,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-8c41a5d8-389a-4398-8cce-18c5c1a1dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9aa71b60-f7c7-4e4b-99e7-5921e4391d07,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-8c41a5d8-389a-4398-8cce-18c5c1a1dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9aa71b60-f7c7-4e4b-99e7-5921e4391d07,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-020f9daf-adfb-49b1-98b1-85c51dff7985,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-95867170-d07f-4395-9a74-92ef218b35c4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-020f9daf-adfb-49b1-98b1-85c51dff7985,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-95867170-d07f-4395-9a74-92ef218b35c4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-020f9daf-adfb-49b1-98b1-85c51dff7985,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-95867170-d07f-4395-9a74-92ef218b35c4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-020f9daf-adfb-49b1-98b1-85c51dff7985,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-95867170-d07f-4395-9a74-92ef218b35c4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-d2120f07-b27e-4ad6-8d53-d947dbf11bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4aae1c57-d449-4161-ae16-dca15c6abbf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-d2120f07-b27e-4ad6-8d53-d947dbf11bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4aae1c57-d449-4161-ae16-dca15c6abbf5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-d2120f07-b27e-4ad6-8d53-d947dbf11bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4aae1c57-d449-4161-ae16-dca15c6abbf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-d2120f07-b27e-4ad6-8d53-d947dbf11bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4aae1c57-d449-4161-ae16-dca15c6abbf5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2a1f995b-f0f7-4604-a3f1-0b609fb32b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-52af46b5-a3f5-41fa-b5e0-d013410a5a0b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2a1f995b-f0f7-4604-a3f1-0b609fb32b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-52af46b5-a3f5-41fa-b5e0-d013410a5a0b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2a1f995b-f0f7-4604-a3f1-0b609fb32b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-52af46b5-a3f5-41fa-b5e0-d013410a5a0b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2a1f995b-f0f7-4604-a3f1-0b609fb32b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-52af46b5-a3f5-41fa-b5e0-d013410a5a0b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-ff3c8a6d-9979-41dd-b1a8-8a9632d0e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ce099db-10bb-4880-8d30-03850a3ee2fc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-ff3c8a6d-9979-41dd-b1a8-8a9632d0e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ce099db-10bb-4880-8d30-03850a3ee2fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-ff3c8a6d-9979-41dd-b1a8-8a9632d0e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ce099db-10bb-4880-8d30-03850a3ee2fc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-ff3c8a6d-9979-41dd-b1a8-8a9632d0e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5ce099db-10bb-4880-8d30-03850a3ee2fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7cdf224-c5f2-473c-841a-4f1e67cb5647,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-260cc756-f706-4aba-a8f3-44c4958f2013,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7cdf224-c5f2-473c-841a-4f1e67cb5647,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-260cc756-f706-4aba-a8f3-44c4958f2013,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7cdf224-c5f2-473c-841a-4f1e67cb5647,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-260cc756-f706-4aba-a8f3-44c4958f2013,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7cdf224-c5f2-473c-841a-4f1e67cb5647,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-260cc756-f706-4aba-a8f3-44c4958f2013,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-751e79e8-02f2-429b-af45-ece7609ff6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-584ac793-42e6-4c53-b6db-113924aa5e16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-751e79e8-02f2-429b-af45-ece7609ff6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-584ac793-42e6-4c53-b6db-113924aa5e16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-751e79e8-02f2-429b-af45-ece7609ff6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-584ac793-42e6-4c53-b6db-113924aa5e16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-751e79e8-02f2-429b-af45-ece7609ff6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-584ac793-42e6-4c53-b6db-113924aa5e16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-51587a7d-88f3-4db3-9d45-1e72c748f836,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0e33f654-4af6-45c7-a41c-f90710fed623,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-51587a7d-88f3-4db3-9d45-1e72c748f836,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0e33f654-4af6-45c7-a41c-f90710fed623,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-51587a7d-88f3-4db3-9d45-1e72c748f836,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0e33f654-4af6-45c7-a41c-f90710fed623,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-51587a7d-88f3-4db3-9d45-1e72c748f836,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0e33f654-4af6-45c7-a41c-f90710fed623,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-9746c856-a8c1-41ee-bb19-ce370a9056c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4e2bbe71-558a-4743-8d20-e52119096958,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-9746c856-a8c1-41ee-bb19-ce370a9056c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4e2bbe71-558a-4743-8d20-e52119096958,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-9746c856-a8c1-41ee-bb19-ce370a9056c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4e2bbe71-558a-4743-8d20-e52119096958,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-9746c856-a8c1-41ee-bb19-ce370a9056c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-4e2bbe71-558a-4743-8d20-e52119096958,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-e658e887-3557-4481-9276-42b98a54351e,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4a487324-c7bd-4013-ae88-93ab3ca4d616,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-4a487324-c7bd-4013-ae88-93ab3ca4d616,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-e658e887-3557-4481-9276-42b98a54351e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-e658e887-3557-4481-9276-42b98a54351e,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4a487324-c7bd-4013-ae88-93ab3ca4d616,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-4a487324-c7bd-4013-ae88-93ab3ca4d616,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-e658e887-3557-4481-9276-42b98a54351e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d6cef2b9-eca0-407d-b88a-9b0e36ebcc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c73a4256-6809-4ef5-b2e1-72d9e3b797ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d6cef2b9-eca0-407d-b88a-9b0e36ebcc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c73a4256-6809-4ef5-b2e1-72d9e3b797ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d6cef2b9-eca0-407d-b88a-9b0e36ebcc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c73a4256-6809-4ef5-b2e1-72d9e3b797ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-d6cef2b9-eca0-407d-b88a-9b0e36ebcc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c73a4256-6809-4ef5-b2e1-72d9e3b797ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-6b2e8a29-aa61-452e-ba06-a10e2cb5f596,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-e7407919-27b8-4a30-98f4-9473445a128e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-e7407919-27b8-4a30-98f4-9473445a128e,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-6b2e8a29-aa61-452e-ba06-a10e2cb5f596,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-6b2e8a29-aa61-452e-ba06-a10e2cb5f596,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-e7407919-27b8-4a30-98f4-9473445a128e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44231,DS-e7407919-27b8-4a30-98f4-9473445a128e,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-6b2e8a29-aa61-452e-ba06-a10e2cb5f596,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-58105b91-81b1-4d52-a30c-e7902ad6c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7c739ba0-baa8-4f78-9115-146535ed8060,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-58105b91-81b1-4d52-a30c-e7902ad6c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7c739ba0-baa8-4f78-9115-146535ed8060,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-58105b91-81b1-4d52-a30c-e7902ad6c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7c739ba0-baa8-4f78-9115-146535ed8060,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-58105b91-81b1-4d52-a30c-e7902ad6c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7c739ba0-baa8-4f78-9115-146535ed8060,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-732256f1-e956-4fc7-8326-8dd3d9231e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ac781a16-bf86-4dbd-ad1b-8f1153134bdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-732256f1-e956-4fc7-8326-8dd3d9231e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ac781a16-bf86-4dbd-ad1b-8f1153134bdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-732256f1-e956-4fc7-8326-8dd3d9231e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ac781a16-bf86-4dbd-ad1b-8f1153134bdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-732256f1-e956-4fc7-8326-8dd3d9231e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-ac781a16-bf86-4dbd-ad1b-8f1153134bdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-84c0b5a7-d99c-4770-811b-e83ff643e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-0cce9f83-3e94-49a0-81ee-2e2b13ed4434,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-84c0b5a7-d99c-4770-811b-e83ff643e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-0cce9f83-3e94-49a0-81ee-2e2b13ed4434,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-84c0b5a7-d99c-4770-811b-e83ff643e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-0cce9f83-3e94-49a0-81ee-2e2b13ed4434,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-84c0b5a7-d99c-4770-811b-e83ff643e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-0cce9f83-3e94-49a0-81ee-2e2b13ed4434,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-e0126813-0260-4dd2-aaa0-dfe773ea70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-37a3ead7-8a34-4b3c-83c4-bc2dbdcc92a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-e0126813-0260-4dd2-aaa0-dfe773ea70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-37a3ead7-8a34-4b3c-83c4-bc2dbdcc92a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-e0126813-0260-4dd2-aaa0-dfe773ea70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-37a3ead7-8a34-4b3c-83c4-bc2dbdcc92a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-e0126813-0260-4dd2-aaa0-dfe773ea70e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-37a3ead7-8a34-4b3c-83c4-bc2dbdcc92a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-4e2f2b3d-a106-42e9-add6-83fe69d2d62a,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-8f328ebc-daa7-4a8a-895d-51eda35b3596,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-4e2f2b3d-a106-42e9-add6-83fe69d2d62a,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-8f328ebc-daa7-4a8a-895d-51eda35b3596,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-4e2f2b3d-a106-42e9-add6-83fe69d2d62a,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-8f328ebc-daa7-4a8a-895d-51eda35b3596,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-4e2f2b3d-a106-42e9-add6-83fe69d2d62a,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-8f328ebc-daa7-4a8a-895d-51eda35b3596,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-2da23e14-1aee-486f-bd2e-c27e0c155f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-eb5e1746-0f79-474d-bf9f-284122ca1fa9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-2da23e14-1aee-486f-bd2e-c27e0c155f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-eb5e1746-0f79-474d-bf9f-284122ca1fa9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-2da23e14-1aee-486f-bd2e-c27e0c155f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-eb5e1746-0f79-474d-bf9f-284122ca1fa9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43915,DS-2da23e14-1aee-486f-bd2e-c27e0c155f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-eb5e1746-0f79-474d-bf9f-284122ca1fa9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-c896e4a5-b967-4436-a240-1c957a5a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-33734685-0fa6-483a-9081-49168fa4551b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-c896e4a5-b967-4436-a240-1c957a5a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-33734685-0fa6-483a-9081-49168fa4551b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-c896e4a5-b967-4436-a240-1c957a5a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-33734685-0fa6-483a-9081-49168fa4551b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41479,DS-c896e4a5-b967-4436-a240-1c957a5a2c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-33734685-0fa6-483a-9081-49168fa4551b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-6f8c860e-74cf-4052-aaf6-ec772e5b1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-8f250336-a4ad-4295-a105-865b86b37ead,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-8f250336-a4ad-4295-a105-865b86b37ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-6f8c860e-74cf-4052-aaf6-ec772e5b1f2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-6f8c860e-74cf-4052-aaf6-ec772e5b1f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-8f250336-a4ad-4295-a105-865b86b37ead,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-8f250336-a4ad-4295-a105-865b86b37ead,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-6f8c860e-74cf-4052-aaf6-ec772e5b1f2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-e75df107-d8e2-4373-8f29-8303b70c78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-859aeb84-76b3-4053-a28d-5f8ab992402b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-e75df107-d8e2-4373-8f29-8303b70c78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-859aeb84-76b3-4053-a28d-5f8ab992402b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-e75df107-d8e2-4373-8f29-8303b70c78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-859aeb84-76b3-4053-a28d-5f8ab992402b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-e75df107-d8e2-4373-8f29-8303b70c78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-859aeb84-76b3-4053-a28d-5f8ab992402b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38667,DS-1853199f-0423-4a67-8dc9-e5fcc50bb25e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c1d85a94-2b14-447b-820c-01d61142010b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-c1d85a94-2b14-447b-820c-01d61142010b,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1853199f-0423-4a67-8dc9-e5fcc50bb25e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38667,DS-1853199f-0423-4a67-8dc9-e5fcc50bb25e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c1d85a94-2b14-447b-820c-01d61142010b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-c1d85a94-2b14-447b-820c-01d61142010b,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1853199f-0423-4a67-8dc9-e5fcc50bb25e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-ac71b084-5dbd-456e-bf4f-266175f999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-f25303ae-5831-4f47-aaa9-c828fe961a21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-ac71b084-5dbd-456e-bf4f-266175f999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-f25303ae-5831-4f47-aaa9-c828fe961a21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-ac71b084-5dbd-456e-bf4f-266175f999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-f25303ae-5831-4f47-aaa9-c828fe961a21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-ac71b084-5dbd-456e-bf4f-266175f999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-f25303ae-5831-4f47-aaa9-c828fe961a21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-af518d27-f4d8-4727-8b9e-5b57b55bfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b829e222-bae7-4db9-8964-61e132ac6dad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-b829e222-bae7-4db9-8964-61e132ac6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-af518d27-f4d8-4727-8b9e-5b57b55bfe3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-af518d27-f4d8-4727-8b9e-5b57b55bfe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b829e222-bae7-4db9-8964-61e132ac6dad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-b829e222-bae7-4db9-8964-61e132ac6dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-af518d27-f4d8-4727-8b9e-5b57b55bfe3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-4b1499b9-2b6f-4d8e-b273-415b9ed5b905,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4b9d84c2-970b-47be-ad12-dbb4aee078b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-4b1499b9-2b6f-4d8e-b273-415b9ed5b905,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4b9d84c2-970b-47be-ad12-dbb4aee078b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-4b1499b9-2b6f-4d8e-b273-415b9ed5b905,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4b9d84c2-970b-47be-ad12-dbb4aee078b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-4b1499b9-2b6f-4d8e-b273-415b9ed5b905,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4b9d84c2-970b-47be-ad12-dbb4aee078b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-e3494d77-7091-440a-a682-7ffbbbb799c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-ae3e40fe-6193-4b29-b3e9-0f48da96c24e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-e3494d77-7091-440a-a682-7ffbbbb799c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-ae3e40fe-6193-4b29-b3e9-0f48da96c24e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-e3494d77-7091-440a-a682-7ffbbbb799c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-ae3e40fe-6193-4b29-b3e9-0f48da96c24e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-e3494d77-7091-440a-a682-7ffbbbb799c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-ae3e40fe-6193-4b29-b3e9-0f48da96c24e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-a47b227d-3e9a-4e8b-9bda-e8c10d9393e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-d74fd1db-2066-4678-b923-7fbd60db33d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-d74fd1db-2066-4678-b923-7fbd60db33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-a47b227d-3e9a-4e8b-9bda-e8c10d9393e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-a47b227d-3e9a-4e8b-9bda-e8c10d9393e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-d74fd1db-2066-4678-b923-7fbd60db33d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-d74fd1db-2066-4678-b923-7fbd60db33d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-a47b227d-3e9a-4e8b-9bda-e8c10d9393e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-5e902b4e-9122-4f64-aa9b-19e331bfa9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-0dad10d3-1210-410a-bada-f63a7ea05c2e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-0dad10d3-1210-410a-bada-f63a7ea05c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-5e902b4e-9122-4f64-aa9b-19e331bfa9d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-5e902b4e-9122-4f64-aa9b-19e331bfa9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-0dad10d3-1210-410a-bada-f63a7ea05c2e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-0dad10d3-1210-410a-bada-f63a7ea05c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-5e902b4e-9122-4f64-aa9b-19e331bfa9d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d882f0cf-a274-4bb8-bac1-b9562c2bc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-29be8ca8-9a25-47e3-aa86-0b96516a382f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-29be8ca8-9a25-47e3-aa86-0b96516a382f,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-d882f0cf-a274-4bb8-bac1-b9562c2bc8d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d882f0cf-a274-4bb8-bac1-b9562c2bc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-29be8ca8-9a25-47e3-aa86-0b96516a382f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-29be8ca8-9a25-47e3-aa86-0b96516a382f,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-d882f0cf-a274-4bb8-bac1-b9562c2bc8d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d6afb3a6-423c-4992-a22c-03ddee373d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-e570509f-05fd-4cea-ad80-06151f2dee99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-e570509f-05fd-4cea-ad80-06151f2dee99,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-d6afb3a6-423c-4992-a22c-03ddee373d54,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d6afb3a6-423c-4992-a22c-03ddee373d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-e570509f-05fd-4cea-ad80-06151f2dee99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-e570509f-05fd-4cea-ad80-06151f2dee99,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-d6afb3a6-423c-4992-a22c-03ddee373d54,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-c667ec41-04eb-41b3-b596-0b506a87cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-db356c2d-40bd-42a2-9f9c-25eb476b3be3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-c667ec41-04eb-41b3-b596-0b506a87cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-db356c2d-40bd-42a2-9f9c-25eb476b3be3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-c667ec41-04eb-41b3-b596-0b506a87cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-db356c2d-40bd-42a2-9f9c-25eb476b3be3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-c667ec41-04eb-41b3-b596-0b506a87cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-db356c2d-40bd-42a2-9f9c-25eb476b3be3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-eefffc6e-daf0-4599-a581-1ec26cb37d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1463b370-c2c0-4f4e-a084-287296526f0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-1463b370-c2c0-4f4e-a084-287296526f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-eefffc6e-daf0-4599-a581-1ec26cb37d61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-eefffc6e-daf0-4599-a581-1ec26cb37d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1463b370-c2c0-4f4e-a084-287296526f0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-1463b370-c2c0-4f4e-a084-287296526f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-eefffc6e-daf0-4599-a581-1ec26cb37d61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-09101ee4-a208-4566-ba26-26441ff7953c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-30665fde-ca98-4cdc-9e44-4822eff0db71,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-09101ee4-a208-4566-ba26-26441ff7953c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-30665fde-ca98-4cdc-9e44-4822eff0db71,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-09101ee4-a208-4566-ba26-26441ff7953c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-30665fde-ca98-4cdc-9e44-4822eff0db71,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-09101ee4-a208-4566-ba26-26441ff7953c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-30665fde-ca98-4cdc-9e44-4822eff0db71,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-0b940d74-d9a7-4d3c-b218-39d90c5c3413,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-364f3130-e1d6-4639-8e9b-11c4115a533e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-364f3130-e1d6-4639-8e9b-11c4115a533e,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-0b940d74-d9a7-4d3c-b218-39d90c5c3413,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-0b940d74-d9a7-4d3c-b218-39d90c5c3413,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-364f3130-e1d6-4639-8e9b-11c4115a533e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-364f3130-e1d6-4639-8e9b-11c4115a533e,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-0b940d74-d9a7-4d3c-b218-39d90c5c3413,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-e05deb10-11ef-4eeb-872b-a6f23fd87c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0f404370-30a9-4468-a5e8-5df6377b9ef8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-e05deb10-11ef-4eeb-872b-a6f23fd87c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0f404370-30a9-4468-a5e8-5df6377b9ef8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-e05deb10-11ef-4eeb-872b-a6f23fd87c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0f404370-30a9-4468-a5e8-5df6377b9ef8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-e05deb10-11ef-4eeb-872b-a6f23fd87c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0f404370-30a9-4468-a5e8-5df6377b9ef8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover#testAllocateBlockAfterCrashFailover
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f9f806ce-44c4-4b34-b5c8-c73e79dc5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-c252b1b6-088b-4fc4-8421-8b115d9ef0bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f9f806ce-44c4-4b34-b5c8-c73e79dc5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-c252b1b6-088b-4fc4-8421-8b115d9ef0bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f9f806ce-44c4-4b34-b5c8-c73e79dc5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-c252b1b6-088b-4fc4-8421-8b115d9ef0bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f9f806ce-44c4-4b34-b5c8-c73e79dc5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-c252b1b6-088b-4fc4-8421-8b115d9ef0bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 43 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 4778
