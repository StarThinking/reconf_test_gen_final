reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1317581501-172.17.0.11-1599305615249:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-e4a6a9ac-4261-4265-b7d5-dea315ac1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-68933e77-b28f-43dd-a07f-2b67e280c41e,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-a58cfbbb-61f2-4d7f-92a1-31e34047d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f97f6d5c-4838-4d8c-93e3-4f250f097cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-9029d884-e86c-4138-a511-cf3184140d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-3c468197-5762-4dd3-b8ce-d304209afaec,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-04819bab-5bbd-49b7-9619-ce9149528875,DISK]]; indices=[0, 1, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1317581501-172.17.0.11-1599305615249:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-e4a6a9ac-4261-4265-b7d5-dea315ac1c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-68933e77-b28f-43dd-a07f-2b67e280c41e,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-a58cfbbb-61f2-4d7f-92a1-31e34047d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f97f6d5c-4838-4d8c-93e3-4f250f097cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-9029d884-e86c-4138-a511-cf3184140d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-3c468197-5762-4dd3-b8ce-d304209afaec,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-04819bab-5bbd-49b7-9619-ce9149528875,DISK]]; indices=[0, 1, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1363437594-172.17.0.11-1599305704046:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36274,DS-f1d98853-f6d8-4272-923e-40c4ced4a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-6389fbfe-96b5-4c24-ab39-38c56560ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-cd89e987-5275-4aa4-9224-53e853f1cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-466e7161-35b3-4598-ac07-bf620bc9f437,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-17fd7ef6-6dcd-4c81-996d-f94bf3872521,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-71d7f8c8-0d57-4de7-8926-6a6ebdfc7066,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-6a493d2e-b005-410f-9267-0e93878f325b,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-884e68a3-d894-4be1-a567-8a88d2c92e9e,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1363437594-172.17.0.11-1599305704046:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36274,DS-f1d98853-f6d8-4272-923e-40c4ced4a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-6389fbfe-96b5-4c24-ab39-38c56560ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-cd89e987-5275-4aa4-9224-53e853f1cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-466e7161-35b3-4598-ac07-bf620bc9f437,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-17fd7ef6-6dcd-4c81-996d-f94bf3872521,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-71d7f8c8-0d57-4de7-8926-6a6ebdfc7066,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-6a493d2e-b005-410f-9267-0e93878f325b,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-884e68a3-d894-4be1-a567-8a88d2c92e9e,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-401470679-172.17.0.11-1599306263984:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-6231de29-0cbc-4377-921c-a4ca0d74d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-411c964c-52b2-4f75-a062-4b9103f2f834,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-0e0171af-4749-4a38-8c0b-b803f3a7cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-897e1429-8ef1-4e45-845b-d8247aa03599,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-cd255949-5e5e-4437-b860-7d118899d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-38de342d-4d0a-405e-8261-9373ee7815ab,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-401470679-172.17.0.11-1599306263984:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-6231de29-0cbc-4377-921c-a4ca0d74d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-411c964c-52b2-4f75-a062-4b9103f2f834,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-0e0171af-4749-4a38-8c0b-b803f3a7cd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-897e1429-8ef1-4e45-845b-d8247aa03599,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-cd255949-5e5e-4437-b860-7d118899d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-38de342d-4d0a-405e-8261-9373ee7815ab,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-763247188-172.17.0.11-1599306527347:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-aeac8536-9c58-41e3-9365-abf8e35f5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-ff847c92-6d51-4185-b0f7-8cd99fbe5ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-b6debbcd-c897-4c37-8ead-d2f8d2ef7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-9772cc82-6767-44e2-a9cd-145235e8aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-d496fd05-1ed5-4254-bcc1-c560d3e40b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-f6a0097b-056d-441b-bd74-11ca401febdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-242018eb-352c-4132-bfc5-113b215cea15,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b292e873-804a-4e27-9a90-d943e32f2363,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-763247188-172.17.0.11-1599306527347:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-aeac8536-9c58-41e3-9365-abf8e35f5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-ff847c92-6d51-4185-b0f7-8cd99fbe5ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-b6debbcd-c897-4c37-8ead-d2f8d2ef7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-9772cc82-6767-44e2-a9cd-145235e8aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-d496fd05-1ed5-4254-bcc1-c560d3e40b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-f6a0097b-056d-441b-bd74-11ca401febdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-242018eb-352c-4132-bfc5-113b215cea15,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b292e873-804a-4e27-9a90-d943e32f2363,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1673173481-172.17.0.11-1599306927301:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46575,DS-b702ef09-8805-41f4-8061-ff4c76d7c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-1bdb8229-2bde-4df9-87f7-064b81a53eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-3310b7b5-a829-4e2c-bef8-b12353bf13e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-4fb095ed-ca1d-4511-b9c1-c63a5629f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-52907c7c-2315-43ad-b29b-2e1db9c1ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-7de9aef4-5f10-4397-9efc-915dab574e8c,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1673173481-172.17.0.11-1599306927301:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46575,DS-b702ef09-8805-41f4-8061-ff4c76d7c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-1bdb8229-2bde-4df9-87f7-064b81a53eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-3310b7b5-a829-4e2c-bef8-b12353bf13e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-4fb095ed-ca1d-4511-b9c1-c63a5629f6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-52907c7c-2315-43ad-b29b-2e1db9c1ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-7de9aef4-5f10-4397-9efc-915dab574e8c,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-365217574-172.17.0.11-1599307573789:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-7a6f7d04-d8e6-47ab-99b3-d20f1a96eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ec7c3e11-e2b6-4377-a4e2-39a5ae14343f,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-4965099e-76f7-42d2-bb79-f66a91f65226,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-f0c9cad2-c88a-43d9-88c3-cbae76797dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-131ca0f0-74ca-4160-a3fa-f6e057043768,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-9b25cade-0511-4bee-81df-6434d669259c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-5fc7dfd6-fe51-4c27-a060-f07acc63a9b3,DISK]]; indices=[0, 1, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-365217574-172.17.0.11-1599307573789:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-7a6f7d04-d8e6-47ab-99b3-d20f1a96eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ec7c3e11-e2b6-4377-a4e2-39a5ae14343f,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-4965099e-76f7-42d2-bb79-f66a91f65226,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-f0c9cad2-c88a-43d9-88c3-cbae76797dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-131ca0f0-74ca-4160-a3fa-f6e057043768,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-9b25cade-0511-4bee-81df-6434d669259c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-5fc7dfd6-fe51-4c27-a060-f07acc63a9b3,DISK]]; indices=[0, 1, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-404488082-172.17.0.11-1599308070026:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-74e2b145-3fea-493e-835d-dd058227b118,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-1cdbb446-8d7a-4922-8c85-3948b76bcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-47c9548f-ad1b-428c-bd79-a9bd9c002629,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-8b396e9c-f07c-40a6-ba35-fdc6e6459d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-cd7b8406-d08a-452d-9d3b-de5421b693b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-14389d6a-db61-4557-ac61-2cb57fe27641,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-6639e84e-c451-4766-b983-29304d555e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-56cc177c-8acc-4116-86b7-4510e49ccc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-404488082-172.17.0.11-1599308070026:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-74e2b145-3fea-493e-835d-dd058227b118,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-1cdbb446-8d7a-4922-8c85-3948b76bcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-47c9548f-ad1b-428c-bd79-a9bd9c002629,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-8b396e9c-f07c-40a6-ba35-fdc6e6459d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-cd7b8406-d08a-452d-9d3b-de5421b693b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-14389d6a-db61-4557-ac61-2cb57fe27641,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-6639e84e-c451-4766-b983-29304d555e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-56cc177c-8acc-4116-86b7-4510e49ccc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1543832671-172.17.0.11-1599308319562:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-15d65267-21df-4851-8390-fe4a3c572f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-5f1133ac-fcb5-46a1-97a4-f12068cf8565,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-6c9e43bf-b8e9-4e69-bf84-fa98a24a19ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-211b1a58-93b8-457c-bc51-a909ccf3c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-0f5975ce-d52b-4461-915e-939b03a31950,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2339cfcf-e061-4ecf-b9be-7dcd037617b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-7a8b632a-cf6e-4624-831c-4a004a8d5ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-52fab4c8-e3e8-4a19-92e6-7e5d96311bdb,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1543832671-172.17.0.11-1599308319562:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-15d65267-21df-4851-8390-fe4a3c572f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-5f1133ac-fcb5-46a1-97a4-f12068cf8565,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-6c9e43bf-b8e9-4e69-bf84-fa98a24a19ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-211b1a58-93b8-457c-bc51-a909ccf3c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-0f5975ce-d52b-4461-915e-939b03a31950,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2339cfcf-e061-4ecf-b9be-7dcd037617b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-7a8b632a-cf6e-4624-831c-4a004a8d5ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-52fab4c8-e3e8-4a19-92e6-7e5d96311bdb,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-348714224-172.17.0.11-1599308377394:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-34ee36f6-5157-4f5a-b728-e8fc1a5dc6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-7e2d5af3-ce8a-4d59-9365-9005663cbd48,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-eaf3f001-686f-45f6-a5f7-809c5a2c1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-83bd4815-0b56-4ea0-914b-1a27465aada8,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3da2bd8e-f44c-454e-b5a0-cc4288c227c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-1a2cb0d1-d9cb-4a1f-be93-9be68458c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-0947fccb-a62c-4aa8-a1f1-987a0d9b09cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-b971ee16-be99-422b-9468-d76412256b38,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-348714224-172.17.0.11-1599308377394:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-34ee36f6-5157-4f5a-b728-e8fc1a5dc6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-7e2d5af3-ce8a-4d59-9365-9005663cbd48,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-eaf3f001-686f-45f6-a5f7-809c5a2c1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-83bd4815-0b56-4ea0-914b-1a27465aada8,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3da2bd8e-f44c-454e-b5a0-cc4288c227c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-1a2cb0d1-d9cb-4a1f-be93-9be68458c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-0947fccb-a62c-4aa8-a1f1-987a0d9b09cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-b971ee16-be99-422b-9468-d76412256b38,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-725679337-172.17.0.11-1599308687599:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-2ce35e2f-c2f9-448e-ba47-a06714b947de,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-ef142ec3-552c-49db-b28b-d9c7b6696f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cc0233d1-db2c-4828-b10f-0a4eb9936057,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a3b12869-7504-4e83-936b-ccb2b339342a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-7756efa4-85be-4465-8b13-487f74310663,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-d4c86911-9575-4bc1-8bcc-bc62a905f973,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-13d02bc0-3175-471f-ac12-ad2b2ea583a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-51846eee-f322-4820-a128-a5a4b67c6667,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-725679337-172.17.0.11-1599308687599:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-2ce35e2f-c2f9-448e-ba47-a06714b947de,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-ef142ec3-552c-49db-b28b-d9c7b6696f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cc0233d1-db2c-4828-b10f-0a4eb9936057,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a3b12869-7504-4e83-936b-ccb2b339342a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-7756efa4-85be-4465-8b13-487f74310663,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-d4c86911-9575-4bc1-8bcc-bc62a905f973,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-13d02bc0-3175-471f-ac12-ad2b2ea583a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-51846eee-f322-4820-a128-a5a4b67c6667,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2064498983-172.17.0.11-1599308846010:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-b6bd0098-978f-4789-aa8d-64c745599198,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-0f83b47d-8474-4d47-bdd9-472f0936dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f1e4d2f8-a991-427b-9b68-ad017ed71250,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2aff08a9-f0d6-47d2-a2a4-e5b6b7ab6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-822e2e28-776f-4c09-8864-3f8a19203ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-55f100a5-8ea3-46e8-9c15-61c99cedec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-9071abe8-bf6e-4578-b6f0-492d660045ae,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2064498983-172.17.0.11-1599308846010:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-b6bd0098-978f-4789-aa8d-64c745599198,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-0f83b47d-8474-4d47-bdd9-472f0936dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-f1e4d2f8-a991-427b-9b68-ad017ed71250,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2aff08a9-f0d6-47d2-a2a4-e5b6b7ab6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-822e2e28-776f-4c09-8864-3f8a19203ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-55f100a5-8ea3-46e8-9c15-61c99cedec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-9071abe8-bf6e-4578-b6f0-492d660045ae,DISK]]; indices=[0, 1, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-91835121-172.17.0.11-1599309481425:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-239b9dc4-5dc3-4aa7-9b8e-473958887b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-a90ff733-9bcb-463f-9161-4003ddb2a996,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-eafd1425-12dd-48dd-95df-721aab0a0378,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-349ebc69-c1d8-4b80-a3de-ec608dd0c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-405fd828-a6c4-463e-a8b9-e7f589b68e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-e104dbd7-8556-4e2c-a26a-b970e079341f,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-91835121-172.17.0.11-1599309481425:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-239b9dc4-5dc3-4aa7-9b8e-473958887b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-a90ff733-9bcb-463f-9161-4003ddb2a996,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-eafd1425-12dd-48dd-95df-721aab0a0378,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-349ebc69-c1d8-4b80-a3de-ec608dd0c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-405fd828-a6c4-463e-a8b9-e7f589b68e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-e104dbd7-8556-4e2c-a26a-b970e079341f,DISK]]; indices=[1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1426841275-172.17.0.11-1599310283171:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-43b8d50f-f382-4885-a459-3e7cac22f330,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-b49c3b40-8738-4aeb-8076-dfcea99e6854,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-2992d709-888a-421f-b48f-2ab6f2e7748e,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-31f8a919-bbf3-442a-95e0-ac6345269fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-7936252a-c672-470b-bc44-11589543ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-be48c8ce-fa31-467d-a3a5-2df1e30e9a1a,DISK]]; indices=[1, 2, 3, 4, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1426841275-172.17.0.11-1599310283171:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-43b8d50f-f382-4885-a459-3e7cac22f330,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-b49c3b40-8738-4aeb-8076-dfcea99e6854,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-2992d709-888a-421f-b48f-2ab6f2e7748e,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-31f8a919-bbf3-442a-95e0-ac6345269fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-7936252a-c672-470b-bc44-11589543ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-be48c8ce-fa31-467d-a3a5-2df1e30e9a1a,DISK]]; indices=[1, 2, 3, 4, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1450651752-172.17.0.11-1599310611498:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44587,DS-dd3e72a9-ca15-494a-a6cd-43690e8aebee,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-942b1aca-0f72-4bca-89b4-04f910d166d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e2471018-1ce3-4fb5-8105-0d3a36e1b658,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-51e64f86-2df4-4a31-9550-5d10d1d90630,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4763fd20-ef5c-49a8-bbf2-39ca07a34440,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-a1cde98b-9e10-4a10-85ac-38e6074093d2,DISK]]; indices=[0, 1, 2, 4, 5, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1450651752-172.17.0.11-1599310611498:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44587,DS-dd3e72a9-ca15-494a-a6cd-43690e8aebee,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-942b1aca-0f72-4bca-89b4-04f910d166d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e2471018-1ce3-4fb5-8105-0d3a36e1b658,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-51e64f86-2df4-4a31-9550-5d10d1d90630,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4763fd20-ef5c-49a8-bbf2-39ca07a34440,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-a1cde98b-9e10-4a10-85ac-38e6074093d2,DISK]]; indices=[0, 1, 2, 4, 5, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1552124498-172.17.0.11-1599310936737:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-2063ce25-c2a2-4a7a-8cc6-f25d142a0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-b4a26ada-0b32-464e-86cb-dc9c00fdb559,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1e502118-15c1-44aa-8d86-30c8aa3a9fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-7e722c2a-3d6e-443f-99e4-bfa278ffbc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-006a601e-20c9-4035-b816-4705b8e6b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-2b4f311c-8569-4e59-9896-3c998419043d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-5b8fda59-a0cb-441e-8a86-070b9c6842f8,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1552124498-172.17.0.11-1599310936737:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-2063ce25-c2a2-4a7a-8cc6-f25d142a0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-b4a26ada-0b32-464e-86cb-dc9c00fdb559,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1e502118-15c1-44aa-8d86-30c8aa3a9fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-7e722c2a-3d6e-443f-99e4-bfa278ffbc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-006a601e-20c9-4035-b816-4705b8e6b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-2b4f311c-8569-4e59-9896-3c998419043d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-5b8fda59-a0cb-441e-8a86-070b9c6842f8,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1269827949-172.17.0.11-1599311105997:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-3f331eea-27cf-4bb3-990d-3d9b8bca1401,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-9a76ae38-b1be-410e-8a50-45183823a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-e83784b5-a508-4921-98ea-28786fded742,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-126caf6e-1bc7-41ad-bcf6-2e01cfa0fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e74ab50f-8dab-4ba5-a79a-2324ddb50aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-9cb7a09d-1145-4f0d-b707-f2e88888f216,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-4eff4ac1-f888-4548-87b3-6046adab64ac,DISK]]; indices=[0, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1269827949-172.17.0.11-1599311105997:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-3f331eea-27cf-4bb3-990d-3d9b8bca1401,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-9a76ae38-b1be-410e-8a50-45183823a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-e83784b5-a508-4921-98ea-28786fded742,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-126caf6e-1bc7-41ad-bcf6-2e01cfa0fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e74ab50f-8dab-4ba5-a79a-2324ddb50aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-9cb7a09d-1145-4f0d-b707-f2e88888f216,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-4eff4ac1-f888-4548-87b3-6046adab64ac,DISK]]; indices=[0, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1440792902-172.17.0.11-1599311263338:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-a842961e-622d-465c-8b7b-4b0fa1b306ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-399e75d6-9f79-4c03-b431-8fdf81fa46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9ebc475e-2469-4a51-81f4-8a9479993c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-18ca6db7-7c7b-48cf-bf1f-12ff6aae771f,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-5d40eb58-9c21-4b73-95e4-bbce9c0bec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-3747e0ff-05d7-411d-9368-43f86184c640,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-376740bf-0b5d-4a51-ba93-66077ca5855a,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-7760bd79-3f30-43ba-826b-d6df9e0730dc,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1440792902-172.17.0.11-1599311263338:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-a842961e-622d-465c-8b7b-4b0fa1b306ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-399e75d6-9f79-4c03-b431-8fdf81fa46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-9ebc475e-2469-4a51-81f4-8a9479993c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-18ca6db7-7c7b-48cf-bf1f-12ff6aae771f,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-5d40eb58-9c21-4b73-95e4-bbce9c0bec79,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-3747e0ff-05d7-411d-9368-43f86184c640,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-376740bf-0b5d-4a51-ba93-66077ca5855a,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-7760bd79-3f30-43ba-826b-d6df9e0730dc,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-735922393-172.17.0.11-1599311743931:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45648,DS-e74dc4e6-5a90-4f66-85b6-0e8da0ea2b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-0b438748-90fb-4db9-a4a8-da159dcf16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-d73886be-57f7-4bce-991a-cafb1dc507ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-6f2b5999-e9de-44b5-8f2a-1ac7ce5cb630,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-f1c58fb4-a781-46d0-82b3-8a66a71ced9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-7e8bcc85-1b55-4ae7-b272-562d97141828,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-d1a368fa-b084-4bd2-9fd7-dd84aac8b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-311e14ba-3866-4664-971a-4e9c6d1a797f,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-735922393-172.17.0.11-1599311743931:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45648,DS-e74dc4e6-5a90-4f66-85b6-0e8da0ea2b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-0b438748-90fb-4db9-a4a8-da159dcf16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-d73886be-57f7-4bce-991a-cafb1dc507ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-6f2b5999-e9de-44b5-8f2a-1ac7ce5cb630,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-f1c58fb4-a781-46d0-82b3-8a66a71ced9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-7e8bcc85-1b55-4ae7-b272-562d97141828,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-d1a368fa-b084-4bd2-9fd7-dd84aac8b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-311e14ba-3866-4664-971a-4e9c6d1a797f,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-544021047-172.17.0.11-1599311894030:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-ab1e7ba4-0890-4d89-842f-1442ade69b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-9ccad8fe-b34a-4a18-92e4-65b479e064e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-dc623ccf-fff3-4a7b-9be9-8539b03f50ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8438c6c8-af82-4393-8c45-edbaf768ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-1e48e084-c4a3-4191-9df9-7a3fe1854ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c8645964-60e0-4e4a-8b13-2cc693e6bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-ff064350-c3b5-48b7-a768-0f58cb4ccad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-97e86f01-cd4d-429b-b108-25beea4755b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-544021047-172.17.0.11-1599311894030:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-ab1e7ba4-0890-4d89-842f-1442ade69b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-9ccad8fe-b34a-4a18-92e4-65b479e064e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-dc623ccf-fff3-4a7b-9be9-8539b03f50ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8438c6c8-af82-4393-8c45-edbaf768ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-1e48e084-c4a3-4191-9df9-7a3fe1854ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c8645964-60e0-4e4a-8b13-2cc693e6bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-ff064350-c3b5-48b7-a768-0f58cb4ccad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-97e86f01-cd4d-429b-b108-25beea4755b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1722108794-172.17.0.11-1599312386732:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-013a512b-a361-4b49-8b50-2368c0c16704,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-28e664b8-d2cc-4dd2-b8c6-46fbcc424c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5c243ba3-55aa-4c4b-93c8-3f915b3aa42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-0696cae4-4f1f-4386-8517-e6e3236fbb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-832f28c8-520d-401b-828c-238c991f8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-2361d16b-ce33-41a9-92e6-0b4c9d30d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-e4feba6b-2a38-4463-8cb2-3f5cb81ccbc3,DISK]]; indices=[1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1722108794-172.17.0.11-1599312386732:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-013a512b-a361-4b49-8b50-2368c0c16704,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-28e664b8-d2cc-4dd2-b8c6-46fbcc424c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5c243ba3-55aa-4c4b-93c8-3f915b3aa42d,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-0696cae4-4f1f-4386-8517-e6e3236fbb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-832f28c8-520d-401b-828c-238c991f8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-2361d16b-ce33-41a9-92e6-0b4c9d30d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-e4feba6b-2a38-4463-8cb2-3f5cb81ccbc3,DISK]]; indices=[1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1462478619-172.17.0.11-1599312543035:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-64216e46-6bc2-4ca9-b795-f508ba9cbe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e6d82a2f-1e80-406b-9342-661e9b77415c,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-fa993bb6-2ea3-49c6-8db4-e8419ab56335,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-e3678d7f-3bdc-4f05-991b-5161a7a3fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-991ecf34-37ca-41c5-bd67-06fafc8055cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2b98cfc4-1c6e-4652-9343-2e2c8e342239,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cd408ed6-2819-4b3c-93e2-7ab9a317887e,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ad1f464c-80ab-407b-ace5-96b665201f7c,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1462478619-172.17.0.11-1599312543035:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-64216e46-6bc2-4ca9-b795-f508ba9cbe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e6d82a2f-1e80-406b-9342-661e9b77415c,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-fa993bb6-2ea3-49c6-8db4-e8419ab56335,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-e3678d7f-3bdc-4f05-991b-5161a7a3fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-991ecf34-37ca-41c5-bd67-06fafc8055cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2b98cfc4-1c6e-4652-9343-2e2c8e342239,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cd408ed6-2819-4b3c-93e2-7ab9a317887e,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ad1f464c-80ab-407b-ace5-96b665201f7c,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1609458437-172.17.0.11-1599312718735:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-0d8a5810-5a71-4b26-86e6-65f61eac7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b9e62910-6d58-477d-bb93-40c1926b6653,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7aeda7b3-18b7-489a-8da6-9731f7ffce27,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-25ed90dc-46a0-4e1f-84a2-433f07d131b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-7f3b3472-2f75-4596-b080-0f6a55a819d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-10c31b0d-b016-4e0e-8431-8fc086114d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-79039243-f877-4961-b760-884f7c7660a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-4af5bd13-8d0f-4b5d-a0c0-a574be930353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1609458437-172.17.0.11-1599312718735:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-0d8a5810-5a71-4b26-86e6-65f61eac7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b9e62910-6d58-477d-bb93-40c1926b6653,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7aeda7b3-18b7-489a-8da6-9731f7ffce27,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-25ed90dc-46a0-4e1f-84a2-433f07d131b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-7f3b3472-2f75-4596-b080-0f6a55a819d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-10c31b0d-b016-4e0e-8431-8fc086114d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-79039243-f877-4961-b760-884f7c7660a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-4af5bd13-8d0f-4b5d-a0c0-a574be930353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 19 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 8087
