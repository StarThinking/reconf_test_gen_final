reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1961226644-172.17.0.9-1599371048729:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-ba1f1226-e2aa-43f4-b795-c4dfe37f1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-1eaa3a5a-30c5-4533-822f-b450c514bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-63890f51-4a02-4a72-b73d-226741b7a057,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-14027aa4-eb8f-485a-b582-91bf3fd82fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-b8608443-5c16-4f5b-b3ee-317cf2248d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-5a2c077a-6814-4ded-b072-da3f8b9033d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-a67a1275-4511-4820-837b-53d809e911c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-9b96f231-8e1b-4223-a29c-3b62c0781329,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1961226644-172.17.0.9-1599371048729:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-ba1f1226-e2aa-43f4-b795-c4dfe37f1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-1eaa3a5a-30c5-4533-822f-b450c514bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-63890f51-4a02-4a72-b73d-226741b7a057,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-14027aa4-eb8f-485a-b582-91bf3fd82fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-b8608443-5c16-4f5b-b3ee-317cf2248d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-5a2c077a-6814-4ded-b072-da3f8b9033d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-a67a1275-4511-4820-837b-53d809e911c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-9b96f231-8e1b-4223-a29c-3b62c0781329,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-671588182-172.17.0.9-1599371184177:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-9f6c49c6-6f25-467e-b72f-044172cee260,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-e06f5848-a737-4404-b42a-8da903b93a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-303e667a-d006-4932-b7a6-56db1a822abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-843f1497-a0f8-4b19-8aff-11e99d633627,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-238b9293-8e28-487f-8038-7eca568dce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-8336a9a3-9d9d-4817-a0ab-44c1e4f06404,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-671588182-172.17.0.9-1599371184177:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-9f6c49c6-6f25-467e-b72f-044172cee260,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-e06f5848-a737-4404-b42a-8da903b93a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-303e667a-d006-4932-b7a6-56db1a822abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-843f1497-a0f8-4b19-8aff-11e99d633627,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-238b9293-8e28-487f-8038-7eca568dce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-8336a9a3-9d9d-4817-a0ab-44c1e4f06404,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-864898225-172.17.0.9-1599371278060:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-34f9c4e3-285e-484d-b05f-a4f6e6253faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-fc76204e-85ed-4d2f-bf4b-e2aa242a7092,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-31f91e1d-099e-418c-9055-4deff5568df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-f9efa6cb-839e-4be2-baa6-338ad92310e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-a82851ca-fcf6-4d32-99a0-1b72b56a00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-d3dc43fc-80f1-43ca-85d2-50d1376d7309,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-ae7104c3-2b7c-43f4-bd47-09725e4561f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2c09ef1b-3d76-4015-b4a9-9e98d65cd86f,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-864898225-172.17.0.9-1599371278060:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-34f9c4e3-285e-484d-b05f-a4f6e6253faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-fc76204e-85ed-4d2f-bf4b-e2aa242a7092,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-31f91e1d-099e-418c-9055-4deff5568df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-f9efa6cb-839e-4be2-baa6-338ad92310e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-a82851ca-fcf6-4d32-99a0-1b72b56a00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-d3dc43fc-80f1-43ca-85d2-50d1376d7309,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-ae7104c3-2b7c-43f4-bd47-09725e4561f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-2c09ef1b-3d76-4015-b4a9-9e98d65cd86f,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-160532055-172.17.0.9-1599371334940:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-e6e0bc54-2b54-4351-ad2a-5dec5c83a009,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-70961dae-e8ce-43de-b9f9-5b72089bd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-89ea6e91-b397-4df6-8d36-d56b0877f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-7d5b2430-1a71-41e7-81ee-66186f0719f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-8de42ff1-2013-47b0-b9c2-1f9d2dad18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-a62bf6ea-d35d-47eb-a7e5-c8a0e60c44c4,DISK]]; indices=[0, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-160532055-172.17.0.9-1599371334940:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-e6e0bc54-2b54-4351-ad2a-5dec5c83a009,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-70961dae-e8ce-43de-b9f9-5b72089bd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-89ea6e91-b397-4df6-8d36-d56b0877f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-7d5b2430-1a71-41e7-81ee-66186f0719f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-8de42ff1-2013-47b0-b9c2-1f9d2dad18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-a62bf6ea-d35d-47eb-a7e5-c8a0e60c44c4,DISK]]; indices=[0, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-80050973-172.17.0.9-1599372837508:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-13d34045-b481-4296-bc18-81261d8889a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f772ba81-0b55-4b95-98d7-80e777c1245c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-fab68d5d-da04-4517-9577-26be89daa1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-07988250-2661-4a71-892f-1ec39d195ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-527a01d2-1f67-40e8-9624-502379e7d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-d1ac145c-32e8-4528-b4b1-a46b5494cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-74fdf957-f9d4-4f24-bd55-caa78efe2edb,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-80050973-172.17.0.9-1599372837508:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-13d34045-b481-4296-bc18-81261d8889a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f772ba81-0b55-4b95-98d7-80e777c1245c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-fab68d5d-da04-4517-9577-26be89daa1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-07988250-2661-4a71-892f-1ec39d195ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-527a01d2-1f67-40e8-9624-502379e7d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-d1ac145c-32e8-4528-b4b1-a46b5494cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-74fdf957-f9d4-4f24-bd55-caa78efe2edb,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-789594593-172.17.0.9-1599372977771:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-cce1a6db-8ba7-4c69-baa9-9637fea650bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-43710847-2951-4f2b-9dfd-cb2344b06c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-bdecf498-5202-4d98-94f0-042a4c6e5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-fc32fd5d-c58d-4d97-9488-f66dd85492d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-b2b74b35-cc42-40d4-a8da-16561cba00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b4213b27-fe04-4b5d-893e-7f3b70f9955b,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-79812162-5bce-474a-aa87-74410c764174,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-a3e1603c-118b-404b-b168-99b187d6fbed,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-789594593-172.17.0.9-1599372977771:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-cce1a6db-8ba7-4c69-baa9-9637fea650bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-43710847-2951-4f2b-9dfd-cb2344b06c61,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-bdecf498-5202-4d98-94f0-042a4c6e5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-fc32fd5d-c58d-4d97-9488-f66dd85492d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-b2b74b35-cc42-40d4-a8da-16561cba00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b4213b27-fe04-4b5d-893e-7f3b70f9955b,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-79812162-5bce-474a-aa87-74410c764174,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-a3e1603c-118b-404b-b168-99b187d6fbed,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1557878501-172.17.0.9-1599373274100:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-24a52f4b-b6b0-4804-96fb-241904073d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-cfb13723-bcc1-496e-aba6-3c1ffc54ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-53481972-2e65-4bb9-bf29-2b859cfd5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-6ce38066-399b-4571-8a6c-0af502e051a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5037e82e-36aa-4bd1-b80e-5baadab1b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-c111f467-161a-4d1c-9905-891f4403f046,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-d54c28b1-c330-4936-9883-257331d65794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1557878501-172.17.0.9-1599373274100:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-24a52f4b-b6b0-4804-96fb-241904073d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-cfb13723-bcc1-496e-aba6-3c1ffc54ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-53481972-2e65-4bb9-bf29-2b859cfd5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-6ce38066-399b-4571-8a6c-0af502e051a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5037e82e-36aa-4bd1-b80e-5baadab1b2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-c111f467-161a-4d1c-9905-891f4403f046,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-d54c28b1-c330-4936-9883-257331d65794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1126989765-172.17.0.9-1599373434564:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-88aba6fd-14f4-4594-87f9-ffcdf84b2427,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-7e3730e5-b1d5-417f-8177-b5cd45ab9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-cd3771a7-fcc3-4d44-b2b5-4bdc6b6e355a,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-208a6189-b811-40b6-8c1a-6200c36f20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e3186112-ee9c-4bcb-b38b-119fc898b239,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-e25f2cee-9eb2-4c64-9837-94036c8eac06,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-5863b2be-7df3-491a-b00c-6ed71fa328fc,DISK]]; indices=[0, 1, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1126989765-172.17.0.9-1599373434564:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-88aba6fd-14f4-4594-87f9-ffcdf84b2427,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-7e3730e5-b1d5-417f-8177-b5cd45ab9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-cd3771a7-fcc3-4d44-b2b5-4bdc6b6e355a,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-208a6189-b811-40b6-8c1a-6200c36f20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e3186112-ee9c-4bcb-b38b-119fc898b239,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-e25f2cee-9eb2-4c64-9837-94036c8eac06,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-5863b2be-7df3-491a-b00c-6ed71fa328fc,DISK]]; indices=[0, 1, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1482932975-172.17.0.9-1599373580181:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-27ab2890-ccaa-41ea-b11b-be4094682c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-730e1c0b-3f20-4b56-82ce-24e2638ad5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-acff074e-5585-4477-a152-2d25bb8cd21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-f20713b3-d234-4197-ae91-7c20d1bb97ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-03968b12-a8b9-4c7d-b67e-e399f4fe39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-4b0e8c83-9461-4686-a4b5-f2f643fc7f4f,DISK]]; indices=[2, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1482932975-172.17.0.9-1599373580181:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-27ab2890-ccaa-41ea-b11b-be4094682c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-730e1c0b-3f20-4b56-82ce-24e2638ad5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-acff074e-5585-4477-a152-2d25bb8cd21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-f20713b3-d234-4197-ae91-7c20d1bb97ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-03968b12-a8b9-4c7d-b67e-e399f4fe39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-4b0e8c83-9461-4686-a4b5-f2f643fc7f4f,DISK]]; indices=[2, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1549853163-172.17.0.9-1599373750820:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-c43484bf-4d5a-42b2-90c1-4aa3872db0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8ae622fa-de1d-4b9f-be70-f17429b9e336,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-adc71b4e-59d6-4898-9401-4d599a74e487,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-edac0511-ec78-42dc-9642-0891b1cf034d,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-f2a7947e-5beb-4db0-a860-91d0db9e5534,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-23df355b-6d08-49fd-930f-c58dfe674a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-2ee734da-7b8c-4072-9d44-713a06e2dfe8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1549853163-172.17.0.9-1599373750820:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-c43484bf-4d5a-42b2-90c1-4aa3872db0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8ae622fa-de1d-4b9f-be70-f17429b9e336,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-adc71b4e-59d6-4898-9401-4d599a74e487,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-edac0511-ec78-42dc-9642-0891b1cf034d,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-f2a7947e-5beb-4db0-a860-91d0db9e5534,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-23df355b-6d08-49fd-930f-c58dfe674a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-2ee734da-7b8c-4072-9d44-713a06e2dfe8,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-631173286-172.17.0.9-1599374006683:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-e0656c1f-20d0-41c3-b43b-9e4f37ac433e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-52385113-1ebf-4efc-9751-56beb859e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-a8caecfa-755d-460a-b7dc-a7cc0cad77fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-1097f928-43d5-4565-9fca-a1ebd6334066,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-1763bcf9-82e1-468a-9bac-685f7b1c4c04,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a1a6a23c-81d5-417f-929f-533415a12b1c,DISK]]; indices=[0, 1, 3, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-631173286-172.17.0.9-1599374006683:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-e0656c1f-20d0-41c3-b43b-9e4f37ac433e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-52385113-1ebf-4efc-9751-56beb859e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-a8caecfa-755d-460a-b7dc-a7cc0cad77fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-1097f928-43d5-4565-9fca-a1ebd6334066,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-1763bcf9-82e1-468a-9bac-685f7b1c4c04,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a1a6a23c-81d5-417f-929f-533415a12b1c,DISK]]; indices=[0, 1, 3, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1278384483-172.17.0.9-1599374071276:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-5d4193a3-10bf-4bf1-81d8-d1fbb595a417,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-b9061201-ceb3-486c-8ea6-863f8fe9ff16,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a5a0aa0d-a373-4430-bc2a-33161ec860f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-53e8441a-bbaa-41e5-81c5-71fa85df758c,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-b4d06a1f-d2da-45d1-8346-732d4e567afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-f0ebd05d-2065-4aff-8221-3324cca0f950,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-968fb581-1772-4089-8e62-a305f0b9c4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-945b7ee8-83e2-4723-b2fd-38c2e772aaff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1278384483-172.17.0.9-1599374071276:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-5d4193a3-10bf-4bf1-81d8-d1fbb595a417,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-b9061201-ceb3-486c-8ea6-863f8fe9ff16,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a5a0aa0d-a373-4430-bc2a-33161ec860f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-53e8441a-bbaa-41e5-81c5-71fa85df758c,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-b4d06a1f-d2da-45d1-8346-732d4e567afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-f0ebd05d-2065-4aff-8221-3324cca0f950,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-968fb581-1772-4089-8e62-a305f0b9c4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-945b7ee8-83e2-4723-b2fd-38c2e772aaff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-915171614-172.17.0.9-1599374250916:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33576,DS-f721bd47-59b3-40bd-a37b-0738cca776bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-942af399-e130-48aa-be4e-61c3aeb8c664,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-b408a96e-0c34-41ee-a71e-10b229eba85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-dbe04b01-2d6c-4ce7-ac31-7bcc5e16555c,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-55860408-2ec2-4ad4-bec2-00c907d00ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-a9e6a30e-d528-46ad-9f1c-f4eff51e0e67,DISK]]; indices=[2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-915171614-172.17.0.9-1599374250916:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33576,DS-f721bd47-59b3-40bd-a37b-0738cca776bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-942af399-e130-48aa-be4e-61c3aeb8c664,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-b408a96e-0c34-41ee-a71e-10b229eba85c,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-dbe04b01-2d6c-4ce7-ac31-7bcc5e16555c,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-55860408-2ec2-4ad4-bec2-00c907d00ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-a9e6a30e-d528-46ad-9f1c-f4eff51e0e67,DISK]]; indices=[2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1986778830-172.17.0.9-1599375441388:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-6be0b15a-74ca-49d3-9982-4f34db1622db,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-892b65ed-3bfd-4ffa-a17f-09ec5c1f0967,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-b389d4fc-f936-43f8-a697-04278a682a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-16d99eb6-7b9a-4664-831a-c71adabb99e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-33cce4f4-259c-4e66-8549-cbb01e6df830,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-e253a444-9ae6-4886-b106-6c222fcd26c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-1f8445aa-1ac6-4a20-a550-801b741a5912,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1986778830-172.17.0.9-1599375441388:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-6be0b15a-74ca-49d3-9982-4f34db1622db,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-892b65ed-3bfd-4ffa-a17f-09ec5c1f0967,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-b389d4fc-f936-43f8-a697-04278a682a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-16d99eb6-7b9a-4664-831a-c71adabb99e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-33cce4f4-259c-4e66-8549-cbb01e6df830,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-e253a444-9ae6-4886-b106-6c222fcd26c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-1f8445aa-1ac6-4a20-a550-801b741a5912,DISK]]; indices=[0, 1, 2, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-414787706-172.17.0.9-1599375736324:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-38fc1602-23ce-44bb-a4e8-cfc867cb783c,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-8c94c9d9-29b2-4fd5-abf4-778bc94dbbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e7c28783-4f2c-4b4d-9a29-2cf9e3f247ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-16efbd10-e8c9-4468-958b-ceda1982df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-62a667db-ba5a-4283-920a-30f6a0f383e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-dfd99f62-f574-493d-a2e7-f36d317ea692,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-414787706-172.17.0.9-1599375736324:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-38fc1602-23ce-44bb-a4e8-cfc867cb783c,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-8c94c9d9-29b2-4fd5-abf4-778bc94dbbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e7c28783-4f2c-4b4d-9a29-2cf9e3f247ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-16efbd10-e8c9-4468-958b-ceda1982df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-62a667db-ba5a-4283-920a-30f6a0f383e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-dfd99f62-f574-493d-a2e7-f36d317ea692,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-122062137-172.17.0.9-1599376872412:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-7236b73c-76dd-4eca-bcd8-44672a412f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-464d7104-b76f-472e-9db0-a32579ecf47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-0adb30fa-1bf2-4742-b5c5-a910240b351e,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-44d7c71d-68d5-4bcb-972a-6a61b9c083b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-d3515160-0ef5-4bfc-ab15-65d1a55a3d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-ffb9493c-9f98-4757-ace6-6c0e15b64d50,DISK]]; indices=[0, 1, 2, 3, 4, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-122062137-172.17.0.9-1599376872412:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-7236b73c-76dd-4eca-bcd8-44672a412f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-464d7104-b76f-472e-9db0-a32579ecf47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-0adb30fa-1bf2-4742-b5c5-a910240b351e,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-44d7c71d-68d5-4bcb-972a-6a61b9c083b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-d3515160-0ef5-4bfc-ab15-65d1a55a3d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-ffb9493c-9f98-4757-ace6-6c0e15b64d50,DISK]]; indices=[0, 1, 2, 3, 4, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1092677142-172.17.0.9-1599377043881:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-0584190a-67c9-49ad-877a-fc61044aba47,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-763fafea-3b20-43d0-a0e6-3c5371c1fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-c9831144-953a-4f97-862d-4869d354d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d4d5e192-e5d5-47cb-978d-536e05153d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-4344f501-ba9c-4d98-a869-85cfd474fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-004d813d-db22-4618-8974-a02af1ed995f,DISK]]; indices=[0, 1, 3, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1092677142-172.17.0.9-1599377043881:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-0584190a-67c9-49ad-877a-fc61044aba47,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-763fafea-3b20-43d0-a0e6-3c5371c1fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-c9831144-953a-4f97-862d-4869d354d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d4d5e192-e5d5-47cb-978d-536e05153d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-4344f501-ba9c-4d98-a869-85cfd474fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-004d813d-db22-4618-8974-a02af1ed995f,DISK]]; indices=[0, 1, 3, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1161590803-172.17.0.9-1599377844579:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-9bc8ae63-1576-4446-8d67-decf1e43ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-9822642c-351a-40c3-8eda-29f3f847ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-ae2d442e-4e9a-4db7-9605-8c07ac9100be,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-8b3b229d-6916-44af-aa20-9dd74e66e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-ce12b01a-404d-4f2c-84cc-0b638cf20e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5c3dcac5-3a2f-4f6d-ae8b-0b6c0e794ca8,DISK]]; indices=[0, 2, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1161590803-172.17.0.9-1599377844579:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-9bc8ae63-1576-4446-8d67-decf1e43ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-9822642c-351a-40c3-8eda-29f3f847ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-ae2d442e-4e9a-4db7-9605-8c07ac9100be,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-8b3b229d-6916-44af-aa20-9dd74e66e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-ce12b01a-404d-4f2c-84cc-0b638cf20e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5c3dcac5-3a2f-4f6d-ae8b-0b6c0e794ca8,DISK]]; indices=[0, 2, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1844534286-172.17.0.9-1599378340923:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-9d61ce7c-b10a-4660-afaf-07333940363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-eaab1cbf-7ad7-429a-93fc-f9aa00f0a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-d2878cfb-5d26-4b7d-83f5-5b55f76ef8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-6795ccdb-adbf-4c66-bf71-3a04ebd97bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-604662ff-fc99-4d5a-84d1-d247f9080757,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-617d022c-766c-4a2e-8c27-e5575a55c278,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-99de7fc8-1a17-47ec-a95f-9802d761da01,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-538fddc8-6645-4a96-8bc0-e39322bf4699,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1844534286-172.17.0.9-1599378340923:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-9d61ce7c-b10a-4660-afaf-07333940363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-eaab1cbf-7ad7-429a-93fc-f9aa00f0a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-d2878cfb-5d26-4b7d-83f5-5b55f76ef8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-6795ccdb-adbf-4c66-bf71-3a04ebd97bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-604662ff-fc99-4d5a-84d1-d247f9080757,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-617d022c-766c-4a2e-8c27-e5575a55c278,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-99de7fc8-1a17-47ec-a95f-9802d761da01,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-538fddc8-6645-4a96-8bc0-e39322bf4699,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-263730980-172.17.0.9-1599378495102:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-1ff10053-372f-44fe-babf-1c2abdd70e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-6f67d5cc-fdb2-4017-92ec-a9f436f2d021,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-ccfc097d-689b-40db-8877-35ea313e846d,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-8cdd810e-3750-4e8b-a38f-58fe72e95359,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-07517e95-fd8e-42ea-a894-d636f21398c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-2db8266e-9df2-45ee-81cc-55afd6f09df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-1530ac1a-d800-4673-a5c7-674ffc911726,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-f5cf200b-9092-4d74-9b55-7ff55380f766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-263730980-172.17.0.9-1599378495102:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-1ff10053-372f-44fe-babf-1c2abdd70e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-6f67d5cc-fdb2-4017-92ec-a9f436f2d021,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-ccfc097d-689b-40db-8877-35ea313e846d,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-8cdd810e-3750-4e8b-a38f-58fe72e95359,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-07517e95-fd8e-42ea-a894-d636f21398c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-2db8266e-9df2-45ee-81cc-55afd6f09df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-1530ac1a-d800-4673-a5c7-674ffc911726,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-f5cf200b-9092-4d74-9b55-7ff55380f766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 18 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 7873
