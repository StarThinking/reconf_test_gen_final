reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-321be19e-6af9-4c80-823c-19b6fc622807,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-ac9ecc55-bea5-460a-9edb-001903010175,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-ac9ecc55-bea5-460a-9edb-001903010175,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-321be19e-6af9-4c80-823c-19b6fc622807,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-321be19e-6af9-4c80-823c-19b6fc622807,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-ac9ecc55-bea5-460a-9edb-001903010175,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-ac9ecc55-bea5-460a-9edb-001903010175,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-321be19e-6af9-4c80-823c-19b6fc622807,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-36cb279b-2fff-41c2-8e5b-14ee8448bb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-aa0ff97d-dfc0-457b-9faa-d589d1612738,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-aa0ff97d-dfc0-457b-9faa-d589d1612738,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-36cb279b-2fff-41c2-8e5b-14ee8448bb46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-36cb279b-2fff-41c2-8e5b-14ee8448bb46,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-aa0ff97d-dfc0-457b-9faa-d589d1612738,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-aa0ff97d-dfc0-457b-9faa-d589d1612738,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-36cb279b-2fff-41c2-8e5b-14ee8448bb46,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-a8a92749-f93d-4401-a797-fb6c73cc0449,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-37891fe4-5ff5-4d49-bbeb-fe3e70dd12fc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-a8a92749-f93d-4401-a797-fb6c73cc0449,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-37891fe4-5ff5-4d49-bbeb-fe3e70dd12fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-a8a92749-f93d-4401-a797-fb6c73cc0449,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-37891fe4-5ff5-4d49-bbeb-fe3e70dd12fc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-a8a92749-f93d-4401-a797-fb6c73cc0449,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-37891fe4-5ff5-4d49-bbeb-fe3e70dd12fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-b5a39e69-39ee-4ca4-b688-fb60032edf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e17bee73-0069-49c3-a543-d2723eb599df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-b5a39e69-39ee-4ca4-b688-fb60032edf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e17bee73-0069-49c3-a543-d2723eb599df,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-b5a39e69-39ee-4ca4-b688-fb60032edf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e17bee73-0069-49c3-a543-d2723eb599df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-b5a39e69-39ee-4ca4-b688-fb60032edf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e17bee73-0069-49c3-a543-d2723eb599df,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-00f3e9fe-c492-439e-8b6c-4a084e111657,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-79cbb307-e547-4265-8ad9-9549b0742024,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-00f3e9fe-c492-439e-8b6c-4a084e111657,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-79cbb307-e547-4265-8ad9-9549b0742024,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-00f3e9fe-c492-439e-8b6c-4a084e111657,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-79cbb307-e547-4265-8ad9-9549b0742024,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-00f3e9fe-c492-439e-8b6c-4a084e111657,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-79cbb307-e547-4265-8ad9-9549b0742024,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-c4958f14-efcd-45cd-ae68-1479c4477b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-70e2ca41-ef4b-4e10-9a5e-8e927492a069,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-70e2ca41-ef4b-4e10-9a5e-8e927492a069,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-c4958f14-efcd-45cd-ae68-1479c4477b8c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-c4958f14-efcd-45cd-ae68-1479c4477b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-70e2ca41-ef4b-4e10-9a5e-8e927492a069,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-70e2ca41-ef4b-4e10-9a5e-8e927492a069,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-c4958f14-efcd-45cd-ae68-1479c4477b8c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-b85cc076-7026-436a-9c4c-0eafe603e954,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-317a9957-0c6d-4098-99cd-b882a6cc31d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-b85cc076-7026-436a-9c4c-0eafe603e954,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-317a9957-0c6d-4098-99cd-b882a6cc31d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-b85cc076-7026-436a-9c4c-0eafe603e954,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-317a9957-0c6d-4098-99cd-b882a6cc31d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-b85cc076-7026-436a-9c4c-0eafe603e954,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-317a9957-0c6d-4098-99cd-b882a6cc31d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-33d18753-38f1-482d-95ff-3255f0aed26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d5841a2a-b6b1-44af-8c0b-1624d90ed60b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-33d18753-38f1-482d-95ff-3255f0aed26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d5841a2a-b6b1-44af-8c0b-1624d90ed60b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-33d18753-38f1-482d-95ff-3255f0aed26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d5841a2a-b6b1-44af-8c0b-1624d90ed60b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-33d18753-38f1-482d-95ff-3255f0aed26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d5841a2a-b6b1-44af-8c0b-1624d90ed60b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-66c5f93a-f68d-4444-aaf3-55cb33995dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d09c6463-b0b7-4fe2-8ddb-47e59203e3ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-66c5f93a-f68d-4444-aaf3-55cb33995dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d09c6463-b0b7-4fe2-8ddb-47e59203e3ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-66c5f93a-f68d-4444-aaf3-55cb33995dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d09c6463-b0b7-4fe2-8ddb-47e59203e3ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-66c5f93a-f68d-4444-aaf3-55cb33995dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-d09c6463-b0b7-4fe2-8ddb-47e59203e3ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-0ab1c56f-86f0-4dee-9692-6a6a15b680c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-ca06a8b0-a262-4abe-8baa-9e2803a7db38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-ca06a8b0-a262-4abe-8baa-9e2803a7db38,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-0ab1c56f-86f0-4dee-9692-6a6a15b680c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-0ab1c56f-86f0-4dee-9692-6a6a15b680c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-ca06a8b0-a262-4abe-8baa-9e2803a7db38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-ca06a8b0-a262-4abe-8baa-9e2803a7db38,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-0ab1c56f-86f0-4dee-9692-6a6a15b680c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 18
v1v1v2v2 failed with probability 0 out of 18
result: might be true error
Total execution time in seconds : 2108
