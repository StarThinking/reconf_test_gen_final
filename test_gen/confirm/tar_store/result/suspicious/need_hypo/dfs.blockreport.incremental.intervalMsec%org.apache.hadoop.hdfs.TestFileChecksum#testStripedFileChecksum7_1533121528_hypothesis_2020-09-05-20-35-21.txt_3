reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-68081461-172.17.0.16-1599338288900:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-bebe6106-00fe-43f7-a025-25024d9b7311,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-ed70af4d-a4e9-4560-a12c-3f4bb31ec875,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-e75620a6-b43f-47d3-9ed0-cf07d62de262,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-20a4c5b0-bee4-47ab-a4f8-c0f34d04ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-39805ac2-e945-4638-976c-0532e2e0c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-1b7e28b0-1200-453f-9d56-2b3702d21857,DISK]]; indices=[0, 1, 3, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-68081461-172.17.0.16-1599338288900:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-bebe6106-00fe-43f7-a025-25024d9b7311,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-ed70af4d-a4e9-4560-a12c-3f4bb31ec875,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-e75620a6-b43f-47d3-9ed0-cf07d62de262,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-20a4c5b0-bee4-47ab-a4f8-c0f34d04ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-39805ac2-e945-4638-976c-0532e2e0c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-1b7e28b0-1200-453f-9d56-2b3702d21857,DISK]]; indices=[0, 1, 3, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-828478136-172.17.0.16-1599338521397:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-09563ac3-baa4-4b36-9dff-9c7a21b6e3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-364c0cd2-b40b-4415-83fa-18bc88b87260,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-613d97c6-bce7-41e7-9fe0-908c52ff7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-e2d0e67e-42e8-4379-8c8b-ffcbc36fa7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-9152b26b-052e-4b0a-b9ee-7c6407e18d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-90a972b0-72be-4493-895b-e4f612507f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-11989d62-e893-4bc3-81bd-627fe9c5ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-9694542c-eb24-45bc-bd63-a0ea2ce4f1d6,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-828478136-172.17.0.16-1599338521397:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-09563ac3-baa4-4b36-9dff-9c7a21b6e3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-364c0cd2-b40b-4415-83fa-18bc88b87260,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-613d97c6-bce7-41e7-9fe0-908c52ff7d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-e2d0e67e-42e8-4379-8c8b-ffcbc36fa7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-9152b26b-052e-4b0a-b9ee-7c6407e18d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-90a972b0-72be-4493-895b-e4f612507f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-11989d62-e893-4bc3-81bd-627fe9c5ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-9694542c-eb24-45bc-bd63-a0ea2ce4f1d6,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1468518408-172.17.0.16-1599338853146:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41326,DS-c03a6f41-65ff-4e79-99a8-ccfb1de20125,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-ea0f0ca7-6151-4399-8ad8-009d86254156,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-85fa21fe-e53f-46f3-b8ac-1375c4546e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-6f464b1f-4f74-4b89-af1b-fbdfd42cc576,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-7bb2cbc3-12fe-4cf6-8b0c-8c6e53237f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-54c547af-d846-46cf-acdb-74b81a99c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-47702039-ebab-45c7-aa7c-ac12853f0300,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1468518408-172.17.0.16-1599338853146:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41326,DS-c03a6f41-65ff-4e79-99a8-ccfb1de20125,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-ea0f0ca7-6151-4399-8ad8-009d86254156,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-85fa21fe-e53f-46f3-b8ac-1375c4546e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-6f464b1f-4f74-4b89-af1b-fbdfd42cc576,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-7bb2cbc3-12fe-4cf6-8b0c-8c6e53237f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-54c547af-d846-46cf-acdb-74b81a99c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-47702039-ebab-45c7-aa7c-ac12853f0300,DISK]]; indices=[1, 2, 3, 4, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-115459424-172.17.0.16-1599340250259:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-505cadbb-cea3-4bea-b6df-3be5b9176e65,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8c2b1dfe-9638-48b1-81b5-2c348585b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-6dc3d170-3e5f-4494-943e-f866cd5c2219,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-abf02c1a-fdcc-4b0c-bec8-979a22581f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-8b325e71-34fd-48a0-b30f-84ebb7f07306,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-516fc9e1-d828-460f-92d4-6a36d3ba6f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-52fbaf53-1527-4210-ad54-e736e60252af,DISK]]; indices=[1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-115459424-172.17.0.16-1599340250259:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-505cadbb-cea3-4bea-b6df-3be5b9176e65,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-8c2b1dfe-9638-48b1-81b5-2c348585b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-6dc3d170-3e5f-4494-943e-f866cd5c2219,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-abf02c1a-fdcc-4b0c-bec8-979a22581f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-8b325e71-34fd-48a0-b30f-84ebb7f07306,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-516fc9e1-d828-460f-92d4-6a36d3ba6f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-52fbaf53-1527-4210-ad54-e736e60252af,DISK]]; indices=[1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-12618290-172.17.0.16-1599340559411:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-a1d8f68a-8414-447a-99bf-a79501f4f579,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-f35c9e7a-59de-46b0-9e95-b700810fe762,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-20e50540-90ca-4bfd-bfaf-d2b191b8bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-7a5c6963-26b4-4a84-8e09-cc1483e2ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-0e280ae7-4843-4a5c-a62a-693cadb78baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f74c039d-3fa4-41b1-bdb6-5bc266a8a082,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-2aca49f3-c0d5-44b5-8d62-4b250c250a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-a47d092f-ea47-4a13-a403-6758804407fb,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-12618290-172.17.0.16-1599340559411:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-a1d8f68a-8414-447a-99bf-a79501f4f579,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-f35c9e7a-59de-46b0-9e95-b700810fe762,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-20e50540-90ca-4bfd-bfaf-d2b191b8bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-7a5c6963-26b4-4a84-8e09-cc1483e2ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-0e280ae7-4843-4a5c-a62a-693cadb78baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f74c039d-3fa4-41b1-bdb6-5bc266a8a082,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-2aca49f3-c0d5-44b5-8d62-4b250c250a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-a47d092f-ea47-4a13-a403-6758804407fb,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-966118237-172.17.0.16-1599340804982:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41394,DS-f59e333b-03ef-4344-84c6-697da2093f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-cfef1cef-599e-49dd-bbf0-257ceab76ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c024ff33-adad-4720-bab6-641443964249,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-a15f2d9c-d2d2-4c06-a9c7-1a701bdb6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-9a7793a9-340b-4c62-b6f3-5493d11e63eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-ccdc0309-b105-4e17-9348-5f1c8f4c5f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-3b206a85-0c4c-4a56-93eb-03369722a220,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-966118237-172.17.0.16-1599340804982:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41394,DS-f59e333b-03ef-4344-84c6-697da2093f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-cfef1cef-599e-49dd-bbf0-257ceab76ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c024ff33-adad-4720-bab6-641443964249,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-a15f2d9c-d2d2-4c06-a9c7-1a701bdb6f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-9a7793a9-340b-4c62-b6f3-5493d11e63eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-ccdc0309-b105-4e17-9348-5f1c8f4c5f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-3b206a85-0c4c-4a56-93eb-03369722a220,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-452211031-172.17.0.16-1599340930281:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-b9ef380b-4da1-486f-afac-0705ca30529d,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-dacf040a-725c-412e-8707-8950d8f8bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-84f77bed-600e-40af-aa24-bcf87d47306d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-e2e8d31a-2471-4e44-8b8e-e69cf7d1739b,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-70f32918-7217-440c-bb02-793c52638671,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-ec9ce5d9-de7c-451f-8b8c-e5f59b2add22,DISK]]; indices=[2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-452211031-172.17.0.16-1599340930281:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-b9ef380b-4da1-486f-afac-0705ca30529d,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-dacf040a-725c-412e-8707-8950d8f8bee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-84f77bed-600e-40af-aa24-bcf87d47306d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-e2e8d31a-2471-4e44-8b8e-e69cf7d1739b,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-70f32918-7217-440c-bb02-793c52638671,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-ec9ce5d9-de7c-451f-8b8c-e5f59b2add22,DISK]]; indices=[2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1672088-172.17.0.16-1599341313520:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-14f0a2d9-3eda-450c-9532-326920e53626,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-f60baabd-8e95-42cc-9718-4313ee0feb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-aefddd2d-0fb6-4003-963b-30f716e35c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-aa85616d-c983-4d2a-b70b-a8fa36cde49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-0fe3d364-84c9-43af-aadf-1ef56d20e965,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-1fbe6f8c-b5bf-41e8-b92b-c6b7d410001e,DISK]]; indices=[0, 2, 3, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1672088-172.17.0.16-1599341313520:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-14f0a2d9-3eda-450c-9532-326920e53626,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-f60baabd-8e95-42cc-9718-4313ee0feb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-aefddd2d-0fb6-4003-963b-30f716e35c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-aa85616d-c983-4d2a-b70b-a8fa36cde49b,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-0fe3d364-84c9-43af-aadf-1ef56d20e965,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-1fbe6f8c-b5bf-41e8-b92b-c6b7d410001e,DISK]]; indices=[0, 2, 3, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1954483743-172.17.0.16-1599341361729:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-a99bf31a-35cc-4f9c-a6a2-20bd94e77bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-3d7ca07e-7b6b-4b31-8a09-5a5e7d7eb659,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f949437e-38ac-4e67-8220-850f3a0a6255,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f7eb939d-4cc3-4c27-a6b5-2a0e18c2c415,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-3b7504cb-3280-4cb5-be95-154c7ceb5b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-28075fb3-28c5-4ccb-9a8f-20312b341d42,DISK]]; indices=[0, 1, 2, 5, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1954483743-172.17.0.16-1599341361729:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-a99bf31a-35cc-4f9c-a6a2-20bd94e77bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-3d7ca07e-7b6b-4b31-8a09-5a5e7d7eb659,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f949437e-38ac-4e67-8220-850f3a0a6255,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f7eb939d-4cc3-4c27-a6b5-2a0e18c2c415,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-3b7504cb-3280-4cb5-be95-154c7ceb5b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-28075fb3-28c5-4ccb-9a8f-20312b341d42,DISK]]; indices=[0, 1, 2, 5, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1345234631-172.17.0.16-1599342335913:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-b3344314-4b04-46a6-8e02-c9a11ef560f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-147d2fae-d704-49b4-9f6b-a9e4a9d73782,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-a7632f29-a6ef-4367-a464-b3cde20bb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-6fa45b33-efb3-4be4-aef9-1658e9f27575,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-29d3da11-3ea6-4154-9a2f-1495af20d012,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-4acb255b-5c86-40c1-929d-f4f2742109da,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-7ae49771-0b10-4f8a-89cb-151a0655945e,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a6895f4c-8878-4245-b955-165880dc7bc5,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1345234631-172.17.0.16-1599342335913:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-b3344314-4b04-46a6-8e02-c9a11ef560f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-147d2fae-d704-49b4-9f6b-a9e4a9d73782,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-a7632f29-a6ef-4367-a464-b3cde20bb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-6fa45b33-efb3-4be4-aef9-1658e9f27575,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-29d3da11-3ea6-4154-9a2f-1495af20d012,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-4acb255b-5c86-40c1-929d-f4f2742109da,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-7ae49771-0b10-4f8a-89cb-151a0655945e,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a6895f4c-8878-4245-b955-165880dc7bc5,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1995932866-172.17.0.16-1599342600915:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-f9b80e38-a878-40e8-8a25-064a85ca1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-46394b7e-f7ff-4bc9-981f-8c9bf5982afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-1d6e77b7-3a98-46f8-9a2a-b2594005c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-08d4c65d-f1b6-4707-bd0f-6a6ac5a43198,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-ddf4a971-702c-4230-9636-5accbc372232,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-cee450c9-606e-44d9-95e5-0d3e544e09b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-3ca74bd4-4e99-4cf7-be41-edf2eb4d3a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-3505798e-a3ff-41e3-9eef-6276132c762e,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1995932866-172.17.0.16-1599342600915:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-f9b80e38-a878-40e8-8a25-064a85ca1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-46394b7e-f7ff-4bc9-981f-8c9bf5982afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-1d6e77b7-3a98-46f8-9a2a-b2594005c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-08d4c65d-f1b6-4707-bd0f-6a6ac5a43198,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-ddf4a971-702c-4230-9636-5accbc372232,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-cee450c9-606e-44d9-95e5-0d3e544e09b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-3ca74bd4-4e99-4cf7-be41-edf2eb4d3a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-3505798e-a3ff-41e3-9eef-6276132c762e,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1270503072-172.17.0.16-1599342872379:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-faa44829-35bc-477e-8bca-99d4c2e16214,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-5de4c07d-8aea-4a6f-92f0-7a92cfbe420a,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a428331e-8984-475b-b05d-ea8dfbf6285b,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a405a21d-e5a3-41d8-a3c9-6f9dc2258c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-a775ef65-46d5-498a-be13-a01436021aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-833b01e7-7aff-4c34-8e8e-9b34a4805fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-636e6823-5d00-4786-bbee-ec8ea5aeb46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-e84168bd-17c0-441e-ad64-305a17ea657e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1270503072-172.17.0.16-1599342872379:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-faa44829-35bc-477e-8bca-99d4c2e16214,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-5de4c07d-8aea-4a6f-92f0-7a92cfbe420a,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-a428331e-8984-475b-b05d-ea8dfbf6285b,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a405a21d-e5a3-41d8-a3c9-6f9dc2258c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-a775ef65-46d5-498a-be13-a01436021aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-833b01e7-7aff-4c34-8e8e-9b34a4805fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-636e6823-5d00-4786-bbee-ec8ea5aeb46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-e84168bd-17c0-441e-ad64-305a17ea657e,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-40701546-172.17.0.16-1599343000321:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-c83d82d1-7ae8-4810-b9b7-06d3ab150a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-e57ea588-4bfd-4803-83ed-b3ef445bc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-b87f5e4a-e40f-4bea-b0f7-06dea4a8cf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-18d1a81a-cf00-4351-bbda-f274fd51880e,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-b4d35b40-4e3e-4060-ace2-1649d6e0f484,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d6245891-be21-4c36-bb6b-c93bcc2f2b21,DISK]]; indices=[0, 1, 2, 3, 4, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-40701546-172.17.0.16-1599343000321:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-c83d82d1-7ae8-4810-b9b7-06d3ab150a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-e57ea588-4bfd-4803-83ed-b3ef445bc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-b87f5e4a-e40f-4bea-b0f7-06dea4a8cf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-18d1a81a-cf00-4351-bbda-f274fd51880e,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-b4d35b40-4e3e-4060-ace2-1649d6e0f484,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d6245891-be21-4c36-bb6b-c93bcc2f2b21,DISK]]; indices=[0, 1, 2, 3, 4, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2107761699-172.17.0.16-1599343272361:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-d86b0f38-d7f8-49a3-ac60-5c2f86059be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-f10db0f4-aa5c-4520-9427-dda664f399bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-bb284f2b-d652-4028-9f65-ddbbf6a20869,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6c9dd914-a97f-4ae6-b801-54cf3092e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-6dee886b-da2a-4843-82e9-a78507cf96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-ce842ad7-e8b8-4c56-a8d7-22815e97c95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f67f2a60-c8b4-4e39-be07-9c66a8f9f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-3fdb4c23-26db-40c1-87e4-8096cf19b1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2107761699-172.17.0.16-1599343272361:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-d86b0f38-d7f8-49a3-ac60-5c2f86059be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-f10db0f4-aa5c-4520-9427-dda664f399bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-bb284f2b-d652-4028-9f65-ddbbf6a20869,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6c9dd914-a97f-4ae6-b801-54cf3092e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-6dee886b-da2a-4843-82e9-a78507cf96e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-ce842ad7-e8b8-4c56-a8d7-22815e97c95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f67f2a60-c8b4-4e39-be07-9c66a8f9f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-3fdb4c23-26db-40c1-87e4-8096cf19b1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1432223424-172.17.0.16-1599344158087:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-51b8c0ce-2689-46a0-99a0-c63be8100c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7a87e65d-5ab1-475e-aea7-631196a86be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-5acc166a-8d6b-4e81-a968-d702f414d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-9551512c-7818-443c-a2de-4e67d2c41e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-96744cdf-cb60-4821-b321-8b76bff18ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-c73ece8b-2319-4cb2-b38d-cc204f31eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-0705007c-644c-498f-bd76-f26fd3e56ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-437ce448-dcd0-4cf6-bd8d-b1b215dca897,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1432223424-172.17.0.16-1599344158087:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-51b8c0ce-2689-46a0-99a0-c63be8100c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7a87e65d-5ab1-475e-aea7-631196a86be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-5acc166a-8d6b-4e81-a968-d702f414d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-9551512c-7818-443c-a2de-4e67d2c41e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-96744cdf-cb60-4821-b321-8b76bff18ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-c73ece8b-2319-4cb2-b38d-cc204f31eb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-0705007c-644c-498f-bd76-f26fd3e56ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-437ce448-dcd0-4cf6-bd8d-b1b215dca897,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 6867
