reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-251475be-808a-4b4a-908d-19711ddb18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-612e9cd0-6057-4033-ab3a-59e52910d387,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-612e9cd0-6057-4033-ab3a-59e52910d387,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-251475be-808a-4b4a-908d-19711ddb18f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-251475be-808a-4b4a-908d-19711ddb18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-612e9cd0-6057-4033-ab3a-59e52910d387,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41769,DS-612e9cd0-6057-4033-ab3a-59e52910d387,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-251475be-808a-4b4a-908d-19711ddb18f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-47b7c334-00b9-429d-a2f7-a44ebda7938b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-47b7c334-00b9-429d-a2f7-a44ebda7938b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-47b7c334-00b9-429d-a2f7-a44ebda7938b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-47b7c334-00b9-429d-a2f7-a44ebda7938b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-281e170d-ce30-45fe-8d36-8751d1af6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-1939bc3a-9d7d-4073-99c7-6a59db2a96a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-1939bc3a-9d7d-4073-99c7-6a59db2a96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-281e170d-ce30-45fe-8d36-8751d1af6e34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-281e170d-ce30-45fe-8d36-8751d1af6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-1939bc3a-9d7d-4073-99c7-6a59db2a96a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-1939bc3a-9d7d-4073-99c7-6a59db2a96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-281e170d-ce30-45fe-8d36-8751d1af6e34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35771,DS-1f621bad-c7f2-4f23-a0e5-98b1eafb2976,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-8b486daf-849e-47e0-80e4-01c2605b9fe4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-8b486daf-849e-47e0-80e4-01c2605b9fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-1f621bad-c7f2-4f23-a0e5-98b1eafb2976,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35771,DS-1f621bad-c7f2-4f23-a0e5-98b1eafb2976,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-8b486daf-849e-47e0-80e4-01c2605b9fe4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-8b486daf-849e-47e0-80e4-01c2605b9fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-1f621bad-c7f2-4f23-a0e5-98b1eafb2976,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-abb3b93f-b0c8-4251-96a1-f0cb8b9635ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-49aaf254-9a39-433d-b132-6099991231d2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-abb3b93f-b0c8-4251-96a1-f0cb8b9635ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-49aaf254-9a39-433d-b132-6099991231d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-abb3b93f-b0c8-4251-96a1-f0cb8b9635ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-49aaf254-9a39-433d-b132-6099991231d2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-abb3b93f-b0c8-4251-96a1-f0cb8b9635ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-49aaf254-9a39-433d-b132-6099991231d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-519a7c84-46cd-403c-a345-1c91e335424d,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-48cc981a-c3f0-4f51-a3fb-8ef2cc2038e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-48cc981a-c3f0-4f51-a3fb-8ef2cc2038e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-519a7c84-46cd-403c-a345-1c91e335424d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-519a7c84-46cd-403c-a345-1c91e335424d,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-48cc981a-c3f0-4f51-a3fb-8ef2cc2038e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-48cc981a-c3f0-4f51-a3fb-8ef2cc2038e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-519a7c84-46cd-403c-a345-1c91e335424d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-cb9dc7ec-48ac-4c50-b2ed-26fb8a792310,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-69924d0c-394c-443b-9220-623459d5acaf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-cb9dc7ec-48ac-4c50-b2ed-26fb8a792310,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-69924d0c-394c-443b-9220-623459d5acaf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-cb9dc7ec-48ac-4c50-b2ed-26fb8a792310,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-69924d0c-394c-443b-9220-623459d5acaf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-cb9dc7ec-48ac-4c50-b2ed-26fb8a792310,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-69924d0c-394c-443b-9220-623459d5acaf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-81d5f0de-b2e1-42ca-b48e-874be3d392cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b9b40fbf-209f-4c16-8cfc-e09d3fcf48f6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-81d5f0de-b2e1-42ca-b48e-874be3d392cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b9b40fbf-209f-4c16-8cfc-e09d3fcf48f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-81d5f0de-b2e1-42ca-b48e-874be3d392cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b9b40fbf-209f-4c16-8cfc-e09d3fcf48f6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-81d5f0de-b2e1-42ca-b48e-874be3d392cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b9b40fbf-209f-4c16-8cfc-e09d3fcf48f6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-6507d845-d348-489c-93a5-fcf12e3bede0,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-661ad5cb-4f5f-44ab-b5b9-d2c732270e06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-661ad5cb-4f5f-44ab-b5b9-d2c732270e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-6507d845-d348-489c-93a5-fcf12e3bede0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40453,DS-6507d845-d348-489c-93a5-fcf12e3bede0,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-661ad5cb-4f5f-44ab-b5b9-d2c732270e06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-661ad5cb-4f5f-44ab-b5b9-d2c732270e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-6507d845-d348-489c-93a5-fcf12e3bede0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-7d393d69-3af4-459a-a25a-65fec4686f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-94f04782-3747-4735-b945-4fae9bc57804,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-7d393d69-3af4-459a-a25a-65fec4686f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-94f04782-3747-4735-b945-4fae9bc57804,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-7d393d69-3af4-459a-a25a-65fec4686f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-94f04782-3747-4735-b945-4fae9bc57804,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-7d393d69-3af4-459a-a25a-65fec4686f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-94f04782-3747-4735-b945-4fae9bc57804,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 13
v1v1v2v2 failed with probability 0 out of 13
result: might be true error
Total execution time in seconds : 952
