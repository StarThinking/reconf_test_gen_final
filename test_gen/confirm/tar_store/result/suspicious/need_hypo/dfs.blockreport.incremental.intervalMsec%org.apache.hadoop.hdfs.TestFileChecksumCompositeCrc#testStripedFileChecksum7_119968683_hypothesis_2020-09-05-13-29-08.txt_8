reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-398922920-172.17.0.12-1599312635140:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-efb96e00-1b60-47ef-8bd8-b5241e2fc817,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-a3315c63-a6ad-4985-82f5-4d491c263e16,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-d8eb169c-13fb-408d-b8d5-debaff4f6a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-b2c55457-5539-4f4e-b1c1-e09b02547147,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-5290dcce-c554-4884-97ae-e8c043fa08d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-c8c1a96e-fe67-4b41-98bf-696fa5f888f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-08b2eb79-e909-4deb-b885-f4730d83f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-171093ec-b2d5-44ab-a240-3469b1a877a5,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-398922920-172.17.0.12-1599312635140:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-efb96e00-1b60-47ef-8bd8-b5241e2fc817,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-a3315c63-a6ad-4985-82f5-4d491c263e16,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-d8eb169c-13fb-408d-b8d5-debaff4f6a65,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-b2c55457-5539-4f4e-b1c1-e09b02547147,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-5290dcce-c554-4884-97ae-e8c043fa08d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-c8c1a96e-fe67-4b41-98bf-696fa5f888f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-08b2eb79-e909-4deb-b885-f4730d83f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-171093ec-b2d5-44ab-a240-3469b1a877a5,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1296678826-172.17.0.12-1599312831592:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-7c127d14-46a5-406d-ae8f-e19d389e6640,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-8ae435d6-4763-4445-bae7-5df71d605898,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-6e6e1f2e-2a19-4543-989c-6ac00c3c1374,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-fff7d3fb-41af-4f21-828b-df26e27cec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-44313190-7a79-40e1-a6e0-4d950572d076,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-3bb643a8-3279-4a65-865b-fc938a25f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-edb0e692-3884-4bf6-b559-95f827b5e032,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1296678826-172.17.0.12-1599312831592:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-7c127d14-46a5-406d-ae8f-e19d389e6640,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-8ae435d6-4763-4445-bae7-5df71d605898,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-6e6e1f2e-2a19-4543-989c-6ac00c3c1374,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-fff7d3fb-41af-4f21-828b-df26e27cec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-44313190-7a79-40e1-a6e0-4d950572d076,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-3bb643a8-3279-4a65-865b-fc938a25f13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-edb0e692-3884-4bf6-b559-95f827b5e032,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-696639981-172.17.0.12-1599313688452:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-e0c158a6-c677-4908-8a96-6b0e2320de59,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-39262a08-3c57-4a93-b7ea-2f32611a427f,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-70ff3f9a-6f06-4c08-8b8e-6f4029c6666b,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-b6c07df1-0413-4896-9ea6-c64e27ae28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-a5edede5-71b0-41bb-b7ee-145a30f4aec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-ce531f86-12c8-4d0e-9ce8-3bbf45830a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-d99d48a4-a4c7-4d1b-a9be-cdda0a79078a,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-fcb49c74-1978-4181-8ac7-1df1536a1180,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-696639981-172.17.0.12-1599313688452:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-e0c158a6-c677-4908-8a96-6b0e2320de59,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-39262a08-3c57-4a93-b7ea-2f32611a427f,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-70ff3f9a-6f06-4c08-8b8e-6f4029c6666b,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-b6c07df1-0413-4896-9ea6-c64e27ae28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-a5edede5-71b0-41bb-b7ee-145a30f4aec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-ce531f86-12c8-4d0e-9ce8-3bbf45830a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-d99d48a4-a4c7-4d1b-a9be-cdda0a79078a,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-fcb49c74-1978-4181-8ac7-1df1536a1180,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1721745654-172.17.0.12-1599313753394:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-d99424fd-b036-439c-a4f3-568f2ce359a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-32cd546f-2958-4827-89c3-83af96fe897c,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-bc18134c-44bb-48dc-a37f-ffbdd06f6846,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-4c25a542-ebde-49c9-8cc0-523630c7104b,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-82785ac4-0431-4546-8c0d-786fb10309a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-b3377e7e-98a1-4623-87fd-3dd68292ca39,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-bb4b2d1c-cf01-46de-8245-e3666ece84f1,DISK]]; indices=[0, 1, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1721745654-172.17.0.12-1599313753394:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-d99424fd-b036-439c-a4f3-568f2ce359a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-32cd546f-2958-4827-89c3-83af96fe897c,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-bc18134c-44bb-48dc-a37f-ffbdd06f6846,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-4c25a542-ebde-49c9-8cc0-523630c7104b,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-82785ac4-0431-4546-8c0d-786fb10309a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-b3377e7e-98a1-4623-87fd-3dd68292ca39,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-bb4b2d1c-cf01-46de-8245-e3666ece84f1,DISK]]; indices=[0, 1, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-42703130-172.17.0.12-1599313905435:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45253,DS-e0368746-e0ff-4a1f-8a96-429f591f4127,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-4eab300a-9b41-488d-8827-1fa6c58e6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1891309d-dc60-4b57-958d-4969279dfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2900233d-3548-44d6-8976-40149f65aede,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ab622595-3957-4e22-8fca-2985936d6923,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-916b15ac-e8c7-4a11-ab10-0c71bfe95c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0f13cc4c-c49e-4188-a090-f0f23f8f4c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-de4b025d-af08-4e3a-9693-aee96a647158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-42703130-172.17.0.12-1599313905435:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:45253,DS-e0368746-e0ff-4a1f-8a96-429f591f4127,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-4eab300a-9b41-488d-8827-1fa6c58e6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1891309d-dc60-4b57-958d-4969279dfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2900233d-3548-44d6-8976-40149f65aede,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ab622595-3957-4e22-8fca-2985936d6923,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-916b15ac-e8c7-4a11-ab10-0c71bfe95c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0f13cc4c-c49e-4188-a090-f0f23f8f4c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-de4b025d-af08-4e3a-9693-aee96a647158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1146619751-172.17.0.12-1599314408694:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-293b2bc7-6eb1-4f49-a68c-cc06f1624c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-d7acd278-e4cc-4869-bb18-c0a64e821c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-724f2a5e-eb0c-4ce5-b6c8-b20fee355388,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c3f1820a-6570-4b1b-b577-be7a968ea039,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-c94c2be4-fe41-448e-89d1-79a471a099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-d9ab9618-737b-4ee2-8b76-fd5c5898ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-72a3db3a-4f21-45a9-9bca-66109bf2da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-90b47a6e-e834-4962-9312-350bbb6b8639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1146619751-172.17.0.12-1599314408694:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-293b2bc7-6eb1-4f49-a68c-cc06f1624c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-d7acd278-e4cc-4869-bb18-c0a64e821c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-724f2a5e-eb0c-4ce5-b6c8-b20fee355388,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c3f1820a-6570-4b1b-b577-be7a968ea039,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-c94c2be4-fe41-448e-89d1-79a471a099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-d9ab9618-737b-4ee2-8b76-fd5c5898ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-72a3db3a-4f21-45a9-9bca-66109bf2da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-90b47a6e-e834-4962-9312-350bbb6b8639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-143922591-172.17.0.12-1599314656695:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-26bd2e03-3072-4799-bbed-0c478386a507,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-11facd1c-ac7e-48bb-9722-14e092abb982,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-61ff3eed-e65f-4c7a-8f14-da7ca24f37af,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-8f170f8e-e1b8-4dad-9dca-adf996420872,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-8b80ab81-fd5d-4377-893e-aac5d7c9f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-203fd7fd-b79a-48c7-b2a3-36fd67cfb4e0,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-143922591-172.17.0.12-1599314656695:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-26bd2e03-3072-4799-bbed-0c478386a507,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-11facd1c-ac7e-48bb-9722-14e092abb982,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-61ff3eed-e65f-4c7a-8f14-da7ca24f37af,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-8f170f8e-e1b8-4dad-9dca-adf996420872,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-8b80ab81-fd5d-4377-893e-aac5d7c9f89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-203fd7fd-b79a-48c7-b2a3-36fd67cfb4e0,DISK]]; indices=[0, 2, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1158361115-172.17.0.12-1599314999230:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-865de5f1-d365-4f56-9846-0286386989f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-f9d735af-d027-4fb9-8646-efade219d79d,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-1879db88-be5f-464a-8c43-5572256e959a,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-6c28efe1-4cb8-4b45-8413-82592e018dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-b0b9a28d-3a65-45a5-bac4-c82d46e82a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a32ed5f9-3516-4f7a-9661-e5893ed70898,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-53b9001e-81e7-46b6-91a2-a4284973ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-95d4d6c4-f9bd-4aac-88c7-7cab0d7abb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1158361115-172.17.0.12-1599314999230:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-865de5f1-d365-4f56-9846-0286386989f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-f9d735af-d027-4fb9-8646-efade219d79d,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-1879db88-be5f-464a-8c43-5572256e959a,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-6c28efe1-4cb8-4b45-8413-82592e018dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-b0b9a28d-3a65-45a5-bac4-c82d46e82a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a32ed5f9-3516-4f7a-9661-e5893ed70898,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-53b9001e-81e7-46b6-91a2-a4284973ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-95d4d6c4-f9bd-4aac-88c7-7cab0d7abb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1559113591-172.17.0.12-1599315152810:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-d36fbc5f-08fe-46e1-bd05-8a0aa7078810,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-767538f5-7ee7-42d6-b221-c94ee90e8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-fe10000d-24a1-4f26-a766-3885f7866c20,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-24c86fa8-ef6f-462b-b4fb-4c1eeb3f33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-b8d5d605-2d65-4672-a01b-1bea76ab5a53,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-be809ce1-eec5-4ba0-9572-092c2c2f8a67,DISK]]; indices=[0, 1, 3, 4, 5, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1559113591-172.17.0.12-1599315152810:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-d36fbc5f-08fe-46e1-bd05-8a0aa7078810,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-767538f5-7ee7-42d6-b221-c94ee90e8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-fe10000d-24a1-4f26-a766-3885f7866c20,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-24c86fa8-ef6f-462b-b4fb-4c1eeb3f33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-b8d5d605-2d65-4672-a01b-1bea76ab5a53,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-be809ce1-eec5-4ba0-9572-092c2c2f8a67,DISK]]; indices=[0, 1, 3, 4, 5, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1556794522-172.17.0.12-1599315453467:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-a12faaf1-86a5-4766-84fd-605cf6f5cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-856c8e73-e955-4412-8f8e-bcd015e725a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-e2b2bc78-646f-4ec2-b4d4-676b59adb6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-6376b4c7-7173-4980-85d0-82da9f28c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-3e53bd5d-4343-474e-93ad-f77431c3031c,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-2cbe941d-13b5-46d0-91b0-1fe5f2583807,DISK]]; indices=[0, 1, 3, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1556794522-172.17.0.12-1599315453467:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-a12faaf1-86a5-4766-84fd-605cf6f5cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-856c8e73-e955-4412-8f8e-bcd015e725a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-e2b2bc78-646f-4ec2-b4d4-676b59adb6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-6376b4c7-7173-4980-85d0-82da9f28c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-3e53bd5d-4343-474e-93ad-f77431c3031c,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-2cbe941d-13b5-46d0-91b0-1fe5f2583807,DISK]]; indices=[0, 1, 3, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2026579251-172.17.0.12-1599315543372:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-d90a56e2-1af2-4327-aa23-d33a3014c524,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-05c8f942-2dfd-4094-b68a-30b8512039aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-16e44d5e-37e6-459a-9bbf-59d4a4574ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-cc9909a4-f2b0-4691-a3db-4155b7b1c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-f273a866-647e-4f1d-a3c1-ce557d58b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-23c0ed80-e9e0-4e79-b7cd-f75fc1ce2cff,DISK]]; indices=[0, 1, 2, 4, 5, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-2026579251-172.17.0.12-1599315543372:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-d90a56e2-1af2-4327-aa23-d33a3014c524,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-05c8f942-2dfd-4094-b68a-30b8512039aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-16e44d5e-37e6-459a-9bbf-59d4a4574ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-cc9909a4-f2b0-4691-a3db-4155b7b1c0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-f273a866-647e-4f1d-a3c1-ce557d58b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-23c0ed80-e9e0-4e79-b7cd-f75fc1ce2cff,DISK]]; indices=[0, 1, 2, 4, 5, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-158365781-172.17.0.12-1599315773086:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-ea776895-b5b8-4c8c-b6f2-f82bd05110ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-802f28b7-4dd7-481f-b111-d9921ca9545b,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-b6449073-46ca-4a42-80d1-1d9d6728e558,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-af900040-ddcc-44f2-9128-0c754f4b257b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-8ef8261d-d489-4c86-b0b6-9b3386f27edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-9c5e7b15-737a-4977-a84a-46f4d098e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-7faf899b-03de-450c-86a8-76a73316e9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-17b312b2-de11-49cb-9d8d-01653ef6f3ee,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-158365781-172.17.0.12-1599315773086:blk_-9223372036854775520_1018; getBlockSize()=37748736; corrupt=false; offset=264241152; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-ea776895-b5b8-4c8c-b6f2-f82bd05110ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-802f28b7-4dd7-481f-b111-d9921ca9545b,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-b6449073-46ca-4a42-80d1-1d9d6728e558,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-af900040-ddcc-44f2-9128-0c754f4b257b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-8ef8261d-d489-4c86-b0b6-9b3386f27edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-9c5e7b15-737a-4977-a84a-46f4d098e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-7faf899b-03de-450c-86a8-76a73316e9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-17b312b2-de11-49cb-9d8d-01653ef6f3ee,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-497537982-172.17.0.12-1599316449074:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-a42adcec-c33d-464d-b747-bc1e53e81276,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-08de3873-b311-4229-bd7b-7f7e9b7ed16d,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-0e54343e-5036-414a-a936-552a9d8eabdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d27dcb9b-f1f6-4fbe-b0d0-bdac035bd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-a827dc6e-764a-42ec-a2a9-68c5b282c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-97d3074c-8053-44eb-b446-890f43f087b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ae309056-79a2-41e5-9806-8dcba0778765,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-823adacb-c554-4a7c-ad25-48aa640f0911,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-497537982-172.17.0.12-1599316449074:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-a42adcec-c33d-464d-b747-bc1e53e81276,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-08de3873-b311-4229-bd7b-7f7e9b7ed16d,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-0e54343e-5036-414a-a936-552a9d8eabdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-d27dcb9b-f1f6-4fbe-b0d0-bdac035bd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-a827dc6e-764a-42ec-a2a9-68c5b282c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-97d3074c-8053-44eb-b446-890f43f087b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ae309056-79a2-41e5-9806-8dcba0778765,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-823adacb-c554-4a7c-ad25-48aa640f0911,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-701387737-172.17.0.12-1599316778415:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-4e3a1a1b-72ff-4bc2-81e8-6485f1843748,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-e5333121-ec43-4e2d-a2bd-4332fc177dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-f8e4ae4f-ce37-4d71-9549-d2141aefddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-4eb525bd-2a43-4740-869d-7eb50e737bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-22c13f84-386b-43b3-b18c-acc512d2a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1ea2100d-b3ad-4b84-832a-c2b12f37ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-8c300729-88a7-4f20-b120-5c39a3407c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-1ce28197-001e-41e9-a360-ed32797e17fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-701387737-172.17.0.12-1599316778415:blk_-9223372036854775552_1016; getBlockSize()=37748736; corrupt=false; offset=188743680; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-4e3a1a1b-72ff-4bc2-81e8-6485f1843748,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-e5333121-ec43-4e2d-a2bd-4332fc177dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-f8e4ae4f-ce37-4d71-9549-d2141aefddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-4eb525bd-2a43-4740-869d-7eb50e737bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-22c13f84-386b-43b3-b18c-acc512d2a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1ea2100d-b3ad-4b84-832a-c2b12f37ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-8c300729-88a7-4f20-b120-5c39a3407c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-1ce28197-001e-41e9-a360-ed32797e17fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-26031174-172.17.0.12-1599317101994:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-40cc8c3b-c07b-43ed-bdc4-7cf932246899,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-2b1323ce-1d22-4650-b40f-aa2481b599fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-8ae47ed0-58f2-4d42-a2ff-aac79c016079,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-30335855-31d8-44d2-93f0-4c2926866380,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-3c43cb43-dcc0-4301-9b98-5fe4455a1f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-72b14c2e-0ee1-4c57-8719-1e6d75020187,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-26031174-172.17.0.12-1599317101994:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-40cc8c3b-c07b-43ed-bdc4-7cf932246899,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-2b1323ce-1d22-4650-b40f-aa2481b599fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-8ae47ed0-58f2-4d42-a2ff-aac79c016079,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-30335855-31d8-44d2-93f0-4c2926866380,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-3c43cb43-dcc0-4301-9b98-5fe4455a1f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-72b14c2e-0ee1-4c57-8719-1e6d75020187,DISK]]; indices=[1, 2, 3, 4, 5, 6]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1265985180-172.17.0.12-1599317977895:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44892,DS-82d30559-8e27-4f96-9764-3c38cf8a5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-18fd587c-e53b-4aca-a452-e3d986a924ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-cdaa2808-a6e9-41dd-8cc9-e6dd46321c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-95bc273d-922f-42bb-89f8-1d282264f894,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-b62873fe-10ed-43c9-a81c-d0ee80764579,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-0daf2727-307c-4e26-892c-d50ff912276a,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-546abf4c-4102-4b66-b8cf-97d0df85eac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1265985180-172.17.0.12-1599317977895:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:44892,DS-82d30559-8e27-4f96-9764-3c38cf8a5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-18fd587c-e53b-4aca-a452-e3d986a924ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-cdaa2808-a6e9-41dd-8cc9-e6dd46321c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-95bc273d-922f-42bb-89f8-1d282264f894,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-b62873fe-10ed-43c9-a81c-d0ee80764579,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-0daf2727-307c-4e26-892c-d50ff912276a,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-546abf4c-4102-4b66-b8cf-97d0df85eac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-785025518-172.17.0.12-1599318133446:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:35460,DS-99f6b8df-fceb-4c5d-9930-7bebe6a36168,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-a7e475f7-4da5-4a51-9b1b-8047f523d552,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-78a901e2-5211-4796-aad2-afd2596e7411,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-4514f6da-e28a-43fe-939e-83676f6699cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-86b7672c-7b83-4ed0-a8ed-1a8ebad6721c,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-854e1a45-d4cc-4f8e-99c2-f04af9e648f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-11900bf4-269b-450a-8d9a-ed3da5f5650b,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3d65ad2c-b945-4c2b-b26d-747e41a32e1b,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-785025518-172.17.0.12-1599318133446:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:35460,DS-99f6b8df-fceb-4c5d-9930-7bebe6a36168,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-a7e475f7-4da5-4a51-9b1b-8047f523d552,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-78a901e2-5211-4796-aad2-afd2596e7411,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-4514f6da-e28a-43fe-939e-83676f6699cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-86b7672c-7b83-4ed0-a8ed-1a8ebad6721c,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-854e1a45-d4cc-4f8e-99c2-f04af9e648f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-11900bf4-269b-450a-8d9a-ed3da5f5650b,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3d65ad2c-b945-4c2b-b26d-747e41a32e1b,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-972052432-172.17.0.12-1599318279835:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-df465688-710d-4534-9b56-1aaf29b50276,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-176c73e2-9073-4d6c-aed2-4980a4b96a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-1f29ef20-7068-485a-b25b-ab8c105ab025,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-5b357b02-02bb-4058-b81b-386bfe8b7ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-33d7f258-c161-4092-bd57-aa1e4daa5b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-50836088-a741-4a23-b8dc-fba53719d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-ee1cb9e6-5fe4-4764-bbb7-81681ae1873c,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-4691ed1f-15a7-42db-bddb-5cb1f13a40d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-972052432-172.17.0.12-1599318279835:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-df465688-710d-4534-9b56-1aaf29b50276,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-176c73e2-9073-4d6c-aed2-4980a4b96a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-1f29ef20-7068-485a-b25b-ab8c105ab025,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-5b357b02-02bb-4058-b81b-386bfe8b7ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-33d7f258-c161-4092-bd57-aa1e4daa5b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-50836088-a741-4a23-b8dc-fba53719d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-ee1cb9e6-5fe4-4764-bbb7-81681ae1873c,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-4691ed1f-15a7-42db-bddb-5cb1f13a40d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1330177897-172.17.0.12-1599318771418:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-b72503f8-649f-4fd8-91b3-3d2d2ebcd872,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-3ad7ed37-d194-4518-aab4-dc575de3638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-0cf72430-bb66-4213-8103-d3810897e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-39a5e524-797b-4109-9eb4-4c8d1948c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-4e071931-7bac-49eb-a77c-ee21fb4e3f75,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-912b7598-31ae-4b17-9ea0-5f06838a9838,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-69bb1e16-c817-43c6-b636-9727202d6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-3676788a-3167-48f0-beb1-2123ed80c98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1330177897-172.17.0.12-1599318771418:blk_-9223372036854775536_1017; getBlockSize()=37748736; corrupt=false; offset=226492416; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-b72503f8-649f-4fd8-91b3-3d2d2ebcd872,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-3ad7ed37-d194-4518-aab4-dc575de3638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-0cf72430-bb66-4213-8103-d3810897e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-39a5e524-797b-4109-9eb4-4c8d1948c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-4e071931-7bac-49eb-a77c-ee21fb4e3f75,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-912b7598-31ae-4b17-9ea0-5f06838a9838,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-69bb1e16-c817-43c6-b636-9727202d6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-3676788a-3167-48f0-beb1-2123ed80c98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-521766926-172.17.0.12-1599319088120:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-9647bf12-1815-456b-bdca-f3ec96fd9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-cd68d776-b204-4725-9879-76bde94ea090,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-a32a751d-bc2a-4fb6-9af8-4f9fee46666a,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-9406ce63-c7b5-4eca-bd0b-f240421fa022,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-cc109076-09a4-4616-af9b-510ae2671085,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-2fc39241-6b20-455f-85e8-edff7f93aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-81a86a51-5bb1-43f4-a86a-d141b5e5d736,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-521766926-172.17.0.12-1599319088120:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-9647bf12-1815-456b-bdca-f3ec96fd9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-cd68d776-b204-4725-9879-76bde94ea090,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-a32a751d-bc2a-4fb6-9af8-4f9fee46666a,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-9406ce63-c7b5-4eca-bd0b-f240421fa022,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-cc109076-09a4-4616-af9b-510ae2671085,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-2fc39241-6b20-455f-85e8-edff7f93aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-81a86a51-5bb1-43f4-a86a-d141b5e5d736,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-876776157-172.17.0.12-1599319423377:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-1ae8b112-0ec3-4d87-9b36-deab915cc725,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-dc7cc31a-777b-49be-9b86-e1d9e579a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-f4d2f32a-3384-4866-ab08-4fba733b52b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-28ee3c70-46c3-4852-9a4c-10665964c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-87442074-d194-48bd-ae52-dd5ab394233e,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-d72b35bb-af86-4368-bd63-a045be0ae779,DISK]]; indices=[1, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-876776157-172.17.0.12-1599319423377:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-1ae8b112-0ec3-4d87-9b36-deab915cc725,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-dc7cc31a-777b-49be-9b86-e1d9e579a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-f4d2f32a-3384-4866-ab08-4fba733b52b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-28ee3c70-46c3-4852-9a4c-10665964c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-87442074-d194-48bd-ae52-dd5ab394233e,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-d72b35bb-af86-4368-bd63-a045be0ae779,DISK]]; indices=[1, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-260939709-172.17.0.12-1599319945343:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-467ee495-3b31-42c4-a29e-c711a5bc6f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-c1e95bab-384b-454a-a970-e67a337519d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-85dc2dc7-1e15-45c5-8940-1a2cc9ba4892,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-608fa30f-f225-4be8-93c3-223d5b390c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-849c0252-6555-4695-b37b-f3e15a9667d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-501b411a-f4b6-4ff4-8ef5-6893af6c132e,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-1aab0968-2953-4d5c-a2ec-e0b1fadbccbd,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-260939709-172.17.0.12-1599319945343:blk_-9223372036854775504_1019; getBlockSize()=37748736; corrupt=false; offset=301989888; locs=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-467ee495-3b31-42c4-a29e-c711a5bc6f42,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-c1e95bab-384b-454a-a970-e67a337519d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-85dc2dc7-1e15-45c5-8940-1a2cc9ba4892,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-608fa30f-f225-4be8-93c3-223d5b390c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-849c0252-6555-4695-b37b-f3e15a9667d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-501b411a-f4b6-4ff4-8ef5-6893af6c132e,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-1aab0968-2953-4d5c-a2ec-e0b1fadbccbd,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1841036105-172.17.0.12-1599320108313:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-63f40a82-1172-4021-a77f-dcecb927b3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-614c2162-c258-469c-be7e-97e8832e31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-a527f0f7-68d3-4650-a310-98280d94bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-b2a82f29-b8cd-4c76-85ce-6ea793aa559e,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-db7e2c93-0dbd-40a0-900e-ee608367ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-4a1cec79-d1d0-4971-abb4-856397273132,DISK]]; indices=[2, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1841036105-172.17.0.12-1599320108313:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-63f40a82-1172-4021-a77f-dcecb927b3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-614c2162-c258-469c-be7e-97e8832e31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-a527f0f7-68d3-4650-a310-98280d94bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-b2a82f29-b8cd-4c76-85ce-6ea793aa559e,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-db7e2c93-0dbd-40a0-900e-ee608367ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-4a1cec79-d1d0-4971-abb4-856397273132,DISK]]; indices=[2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksum7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1112764129-172.17.0.12-1599320215718:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-01d33b60-a8b2-44d6-819d-5a7b7ea2e19c,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d5f303fc-b5e7-4f77-8159-bb00c824afec,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-7cdd17e1-4b12-41ac-8f9a-bdbdc5d2953b,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-d6b71577-670c-4208-8436-6d9caa5b1229,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-313e0c09-74d5-4ce0-808f-8f2bb8bb97cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-885bc8f0-8137-46c9-9137-f829a2d20804,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2b046a25-f839-452d-830a-06170ac15b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-589d5ae5-30c4-4ad5-9d35-95f6ccded9b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1112764129-172.17.0.12-1599320215718:blk_-9223372036854775488_1020; getBlockSize()=37748736; corrupt=false; offset=339738624; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-01d33b60-a8b2-44d6-819d-5a7b7ea2e19c,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d5f303fc-b5e7-4f77-8159-bb00c824afec,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-7cdd17e1-4b12-41ac-8f9a-bdbdc5d2953b,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-d6b71577-670c-4208-8436-6d9caa5b1229,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-313e0c09-74d5-4ce0-808f-8f2bb8bb97cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-885bc8f0-8137-46c9-9137-f829a2d20804,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-2b046a25-f839-452d-830a-06170ac15b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-589d5ae5-30c4-4ad5-9d35-95f6ccded9b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum(TestFileChecksum.java:202)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksum7(TestFileChecksum.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 19 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 8069
