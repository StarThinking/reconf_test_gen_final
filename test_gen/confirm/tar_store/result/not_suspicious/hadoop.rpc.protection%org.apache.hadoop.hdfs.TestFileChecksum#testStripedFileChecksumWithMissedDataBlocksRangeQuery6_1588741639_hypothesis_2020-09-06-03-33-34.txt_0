reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327267819-172.17.0.5-1599363227848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-a7918054-4803-47e2-b026-a3c50b66f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-0b13061d-c1d1-463d-8c4c-dbe81859d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-4a79c787-0788-4878-bff7-f04fdd19735f,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-f01f4724-1112-4ead-af87-108e7114c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-bd1170e3-97da-4c68-9697-f8f0d71313cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-94df46fb-cd2e-435c-af79-6a5c6bd9e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-ce484584-087f-4208-8258-14099cad3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-823dbd9a-543a-44fa-8e4a-d05662c96ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327267819-172.17.0.5-1599363227848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-a7918054-4803-47e2-b026-a3c50b66f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-0b13061d-c1d1-463d-8c4c-dbe81859d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-4a79c787-0788-4878-bff7-f04fdd19735f,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-f01f4724-1112-4ead-af87-108e7114c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-bd1170e3-97da-4c68-9697-f8f0d71313cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-94df46fb-cd2e-435c-af79-6a5c6bd9e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-ce484584-087f-4208-8258-14099cad3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-823dbd9a-543a-44fa-8e4a-d05662c96ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428885853-172.17.0.5-1599363403543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-586c7023-51df-4225-a278-ee3988273e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-3b8c2364-13d1-4577-9da1-52ad023abc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b14a01a5-3fca-4f68-ab29-412bde73d246,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-327e6580-7edb-45ec-b4dc-81c794678f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2a74c945-0521-4398-b28d-89680de2a688,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-9dae805e-7ed7-4b07-afd3-7ecd2035c602,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-bf1fbc12-9952-4357-943e-f961e533390b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-06bb93dd-070f-4d15-a309-06475b41a91d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428885853-172.17.0.5-1599363403543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-586c7023-51df-4225-a278-ee3988273e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-3b8c2364-13d1-4577-9da1-52ad023abc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b14a01a5-3fca-4f68-ab29-412bde73d246,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-327e6580-7edb-45ec-b4dc-81c794678f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2a74c945-0521-4398-b28d-89680de2a688,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-9dae805e-7ed7-4b07-afd3-7ecd2035c602,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-bf1fbc12-9952-4357-943e-f961e533390b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-06bb93dd-070f-4d15-a309-06475b41a91d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969514306-172.17.0.5-1599363630232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-346f40ba-f107-45b6-bb30-08c7b79c9227,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-e078a344-2929-440d-99f6-620d04c93222,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-42de87c8-ee57-4e45-8a1f-eab67a17d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-bcc3f13a-eea0-4ed4-96e4-c40adaea652a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-8960a4c5-5c64-4448-a287-d887a3217716,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e24c9627-680e-4763-92c3-9d89bad9e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-03b1637f-5256-4593-af3a-fd314aee0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-cf1f3199-610c-44d6-a187-34f0c1b8b2bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969514306-172.17.0.5-1599363630232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-346f40ba-f107-45b6-bb30-08c7b79c9227,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-e078a344-2929-440d-99f6-620d04c93222,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-42de87c8-ee57-4e45-8a1f-eab67a17d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-bcc3f13a-eea0-4ed4-96e4-c40adaea652a,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-8960a4c5-5c64-4448-a287-d887a3217716,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e24c9627-680e-4763-92c3-9d89bad9e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-03b1637f-5256-4593-af3a-fd314aee0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-cf1f3199-610c-44d6-a187-34f0c1b8b2bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128421744-172.17.0.5-1599363729798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-c5a80d72-cf45-4175-ae7e-9afb8c1adada,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-7ce054f6-5540-4561-9ed6-f9c78988c112,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-873e6119-5995-49c1-944d-f5c9299376d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-19a0b981-b113-4a33-ba08-79e6ad1af425,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-f866797d-6ec2-462e-82ed-0419e028be84,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-09aa94e7-ce92-41f4-8f1c-5b14e9f43d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-2bf083c3-e4f6-4268-8cf2-4e76b7630539,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-3dce1274-d7c6-4291-ba28-79b85673e0b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128421744-172.17.0.5-1599363729798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-c5a80d72-cf45-4175-ae7e-9afb8c1adada,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-7ce054f6-5540-4561-9ed6-f9c78988c112,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-873e6119-5995-49c1-944d-f5c9299376d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-19a0b981-b113-4a33-ba08-79e6ad1af425,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-f866797d-6ec2-462e-82ed-0419e028be84,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-09aa94e7-ce92-41f4-8f1c-5b14e9f43d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-2bf083c3-e4f6-4268-8cf2-4e76b7630539,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-3dce1274-d7c6-4291-ba28-79b85673e0b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131518902-172.17.0.5-1599363872906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-dec36a9f-7175-4bd9-811e-19d6a691010c,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-780a238e-0942-40dd-9f1f-aeab0f183b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-1fa0b696-30c7-4c1e-9d18-4faff759d507,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-e34d568e-e974-45cb-9e1d-6b64688fce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-ba8e9b18-669f-4e3f-bd5c-e9fcdf240fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-2eea3ecc-efdc-4b76-9157-4fed1df7ff55,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-d1a48722-402d-40a2-9698-a1c962e915e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-3db85707-2cea-43c5-b7f2-860aa28ec49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131518902-172.17.0.5-1599363872906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-dec36a9f-7175-4bd9-811e-19d6a691010c,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-780a238e-0942-40dd-9f1f-aeab0f183b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-1fa0b696-30c7-4c1e-9d18-4faff759d507,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-e34d568e-e974-45cb-9e1d-6b64688fce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-ba8e9b18-669f-4e3f-bd5c-e9fcdf240fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-2eea3ecc-efdc-4b76-9157-4fed1df7ff55,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-d1a48722-402d-40a2-9698-a1c962e915e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-3db85707-2cea-43c5-b7f2-860aa28ec49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969147914-172.17.0.5-1599364191155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-69714c02-b603-40cd-b962-e458d93321aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-9ce1df8f-9c43-4e97-934b-56bd84f3961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-72db8fa1-f2d8-4421-8d5d-a7637da6ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-7472eb58-7e89-4d1f-a36a-fdebf2aab5af,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-43f28b8d-b88a-4f41-bf17-3328047a77e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-1d6ff754-dd57-4736-ac18-ad78561fd09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b05b9353-4f6f-487b-8127-6f5cf5cb9800,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-71ba7b72-c0c3-44fd-9764-af9cdbdb6d1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969147914-172.17.0.5-1599364191155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-69714c02-b603-40cd-b962-e458d93321aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-9ce1df8f-9c43-4e97-934b-56bd84f3961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-72db8fa1-f2d8-4421-8d5d-a7637da6ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-7472eb58-7e89-4d1f-a36a-fdebf2aab5af,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-43f28b8d-b88a-4f41-bf17-3328047a77e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-1d6ff754-dd57-4736-ac18-ad78561fd09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b05b9353-4f6f-487b-8127-6f5cf5cb9800,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-71ba7b72-c0c3-44fd-9764-af9cdbdb6d1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108136388-172.17.0.5-1599364409568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44755,DS-823fde3b-7cf9-4647-9423-dadb28a599f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7ce28837-a29d-46ad-b4aa-054eb4c6ef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e2f66768-4542-4c91-a983-a5c7c747d297,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-e1c3fb1a-74fd-4118-9f58-305a20f07cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-98113b73-ed7e-46f4-81bb-8cdd2965d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-64f5183c-f5b4-4c71-aa8f-426dfce6c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bafa0281-aa98-4b2d-9a51-146e32fa693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-18d42bf3-507f-407e-a50e-9812ef3f8865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108136388-172.17.0.5-1599364409568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44755,DS-823fde3b-7cf9-4647-9423-dadb28a599f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-7ce28837-a29d-46ad-b4aa-054eb4c6ef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e2f66768-4542-4c91-a983-a5c7c747d297,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-e1c3fb1a-74fd-4118-9f58-305a20f07cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-98113b73-ed7e-46f4-81bb-8cdd2965d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-64f5183c-f5b4-4c71-aa8f-426dfce6c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bafa0281-aa98-4b2d-9a51-146e32fa693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-18d42bf3-507f-407e-a50e-9812ef3f8865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185494215-172.17.0.5-1599364651227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-a622e8e7-e806-4a28-b62a-68b8dd5d80f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ee73df15-f7c5-44a9-8cd7-31f9d0704170,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-7c59dc03-5047-4d8c-92f5-db81d1a7dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-6aca78e5-2fdf-4ee0-be59-db7c931ef46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-87874983-e909-4f6f-bef5-378492dee156,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-a909a60d-2293-4140-9641-adea0b3854f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6d142c2a-fb6c-44ee-8269-0bee24fa3445,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-92e54b4c-a158-436c-b3bb-f272556ba02f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185494215-172.17.0.5-1599364651227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-a622e8e7-e806-4a28-b62a-68b8dd5d80f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ee73df15-f7c5-44a9-8cd7-31f9d0704170,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-7c59dc03-5047-4d8c-92f5-db81d1a7dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-6aca78e5-2fdf-4ee0-be59-db7c931ef46a,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-87874983-e909-4f6f-bef5-378492dee156,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-a909a60d-2293-4140-9641-adea0b3854f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-6d142c2a-fb6c-44ee-8269-0bee24fa3445,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-92e54b4c-a158-436c-b3bb-f272556ba02f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855427741-172.17.0.5-1599364823542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41751,DS-98ee4ac8-02fe-403e-9096-8e2d2e0822d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-b7ce956f-5a4c-4150-8b5e-8b9eaafa812d,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3ff418db-6393-4c31-b8e8-b88986ce6a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-2af5bd1f-3954-4328-94f5-d89ae32121f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-81c40f84-89b2-4b66-aa2c-9a6cd8b8363a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-e1cca6b7-600e-4b6e-bf75-53acd907b030,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-0c95c56e-fb07-4585-b1c1-e2c9448c9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-8c3526e6-fc9b-43f1-a551-75d740c416a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855427741-172.17.0.5-1599364823542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41751,DS-98ee4ac8-02fe-403e-9096-8e2d2e0822d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-b7ce956f-5a4c-4150-8b5e-8b9eaafa812d,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3ff418db-6393-4c31-b8e8-b88986ce6a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-2af5bd1f-3954-4328-94f5-d89ae32121f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-81c40f84-89b2-4b66-aa2c-9a6cd8b8363a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-e1cca6b7-600e-4b6e-bf75-53acd907b030,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-0c95c56e-fb07-4585-b1c1-e2c9448c9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-8c3526e6-fc9b-43f1-a551-75d740c416a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017808863-172.17.0.5-1599364991926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-05674978-770f-43b0-bf23-eee630d1dcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-1f73bb7e-755a-4809-94b7-2961145c1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-fc7228ab-20a3-48f2-8925-0ea6317a54fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-cb87c0fd-748f-4625-a153-9581a70ef543,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4717b55c-1527-414c-b616-20f308b55c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-382c1d90-8421-4f11-9427-1774fbf1b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-4f0549d8-1d73-4f39-8424-52a2314b3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-0831a0da-b6c0-434c-ae2e-e99b3b7c05d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017808863-172.17.0.5-1599364991926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-05674978-770f-43b0-bf23-eee630d1dcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-1f73bb7e-755a-4809-94b7-2961145c1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-fc7228ab-20a3-48f2-8925-0ea6317a54fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-cb87c0fd-748f-4625-a153-9581a70ef543,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4717b55c-1527-414c-b616-20f308b55c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-382c1d90-8421-4f11-9427-1774fbf1b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-4f0549d8-1d73-4f39-8424-52a2314b3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-0831a0da-b6c0-434c-ae2e-e99b3b7c05d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104349512-172.17.0.5-1599365146324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-b25432b0-87ce-4303-845b-4fa35e3eb8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-75cead86-0a3a-40c3-adeb-6ac8b0352429,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-9b99d86a-bfb1-4f5a-ad4f-9299ad83b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-a9676395-7dbb-4117-97c3-149c082a0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-9dedaa23-39a7-4c11-8ac0-3e2d06742192,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-71ad0a36-df6f-4aa7-acad-31874fad59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-87fa0ac6-cf3c-4812-9cd9-0907c576aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-c2763c8b-acc4-485f-be80-25daeacaaf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104349512-172.17.0.5-1599365146324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-b25432b0-87ce-4303-845b-4fa35e3eb8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-75cead86-0a3a-40c3-adeb-6ac8b0352429,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-9b99d86a-bfb1-4f5a-ad4f-9299ad83b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-a9676395-7dbb-4117-97c3-149c082a0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-9dedaa23-39a7-4c11-8ac0-3e2d06742192,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-71ad0a36-df6f-4aa7-acad-31874fad59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-87fa0ac6-cf3c-4812-9cd9-0907c576aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-c2763c8b-acc4-485f-be80-25daeacaaf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501849776-172.17.0.5-1599365507925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-38e21132-aca5-42d2-b622-850a0eacf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e4b9329a-9139-4e07-81ce-13aec5c3dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-d9fbefbe-da7e-4a17-90af-149d457acf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-2f6db472-2cd3-4632-8415-c64a57f5e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-14f5576a-60dc-4cf4-bcd4-5f75d17ca376,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-e7ed1c0e-59ae-4c7a-9449-252024ae64e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fd9ba41a-92fc-4b58-8288-7b6d06f1df43,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-724ae83b-0d1a-4da8-80c2-3cd9bb471e26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501849776-172.17.0.5-1599365507925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-38e21132-aca5-42d2-b622-850a0eacf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e4b9329a-9139-4e07-81ce-13aec5c3dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-d9fbefbe-da7e-4a17-90af-149d457acf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-2f6db472-2cd3-4632-8415-c64a57f5e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-14f5576a-60dc-4cf4-bcd4-5f75d17ca376,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-e7ed1c0e-59ae-4c7a-9449-252024ae64e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fd9ba41a-92fc-4b58-8288-7b6d06f1df43,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-724ae83b-0d1a-4da8-80c2-3cd9bb471e26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717123988-172.17.0.5-1599365773740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-a32fe6df-ba9a-45bf-bfc6-de8edd0b7ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-c5100040-7467-4004-9cc0-5f72d3104aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-09207fe9-69fe-4152-a28a-58e7756f224c,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-5613aab5-845e-4bbf-b442-a031a2577667,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-a3f80dad-f3db-4675-b913-a5c5d6da5c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-2c0856ab-eb30-4995-bd01-169eff0d09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-0066dd17-69f8-456b-9859-70c53db5b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0256a0ef-d6c9-4193-b551-6605a36cca43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717123988-172.17.0.5-1599365773740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-a32fe6df-ba9a-45bf-bfc6-de8edd0b7ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-c5100040-7467-4004-9cc0-5f72d3104aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-09207fe9-69fe-4152-a28a-58e7756f224c,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-5613aab5-845e-4bbf-b442-a031a2577667,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-a3f80dad-f3db-4675-b913-a5c5d6da5c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-2c0856ab-eb30-4995-bd01-169eff0d09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-0066dd17-69f8-456b-9859-70c53db5b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0256a0ef-d6c9-4193-b551-6605a36cca43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849129981-172.17.0.5-1599365836272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-65859117-0222-4661-8d51-59a5cd5a7de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0afa6282-9dd4-4752-9c81-8cadc498ac86,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d5a76967-ed27-4846-9ef9-025effa0b396,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-c1e0c03d-2c0d-4978-a554-e5005e372f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-facb96fb-2704-4f94-9d95-5a31f69cbd25,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c22b9616-49d3-4b78-9e83-35ef8aca7a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-89b85c54-5ba9-4f6a-9d70-b3014664b006,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-7f986eac-95d1-4996-9821-6bb2c64bcb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849129981-172.17.0.5-1599365836272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-65859117-0222-4661-8d51-59a5cd5a7de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0afa6282-9dd4-4752-9c81-8cadc498ac86,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d5a76967-ed27-4846-9ef9-025effa0b396,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-c1e0c03d-2c0d-4978-a554-e5005e372f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-facb96fb-2704-4f94-9d95-5a31f69cbd25,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c22b9616-49d3-4b78-9e83-35ef8aca7a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-89b85c54-5ba9-4f6a-9d70-b3014664b006,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-7f986eac-95d1-4996-9821-6bb2c64bcb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876623782-172.17.0.5-1599365999594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-4c4ea93f-242e-4e9c-aad2-d08feca9168b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-4093a0b5-10dd-415b-9589-a2989fab4e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-61498583-8db5-4434-af5e-8a1963d0e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-038d8fc1-3081-4b45-a5aa-1b3c0f3ff15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-b40366e9-fa2e-468a-bf7a-63f1c734e090,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-66ae626f-42d4-496c-a3b8-7f22ceda435a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2a49fb48-1aa2-4cfe-b7bc-86fc8b616a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-a46dbe67-ee26-4967-a600-851f7b76a4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876623782-172.17.0.5-1599365999594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-4c4ea93f-242e-4e9c-aad2-d08feca9168b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-4093a0b5-10dd-415b-9589-a2989fab4e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-61498583-8db5-4434-af5e-8a1963d0e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-038d8fc1-3081-4b45-a5aa-1b3c0f3ff15e,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-b40366e9-fa2e-468a-bf7a-63f1c734e090,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-66ae626f-42d4-496c-a3b8-7f22ceda435a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2a49fb48-1aa2-4cfe-b7bc-86fc8b616a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-a46dbe67-ee26-4967-a600-851f7b76a4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086048383-172.17.0.5-1599366421461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-f5d7f49f-ef14-4e8c-a274-16a0692e7f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-ea30d03e-5f72-4f9a-961f-b06813075bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-9f27a83a-cf9b-482d-be2b-967c188022ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-9a4ee704-05e3-41a7-819d-0ee69f26b530,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-736ce07a-b2b7-47ed-a737-7ca9b3cf0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a7564516-085f-43fc-b75d-5fa202906a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-0b6f7653-a45d-41f6-9c54-41bc8ee2e134,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-6bc5d438-5084-4151-9775-88bd6179712e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086048383-172.17.0.5-1599366421461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-f5d7f49f-ef14-4e8c-a274-16a0692e7f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-ea30d03e-5f72-4f9a-961f-b06813075bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-9f27a83a-cf9b-482d-be2b-967c188022ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-9a4ee704-05e3-41a7-819d-0ee69f26b530,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-736ce07a-b2b7-47ed-a737-7ca9b3cf0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a7564516-085f-43fc-b75d-5fa202906a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-0b6f7653-a45d-41f6-9c54-41bc8ee2e134,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-6bc5d438-5084-4151-9775-88bd6179712e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399214280-172.17.0.5-1599366834659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-c2c261e6-d8d8-4014-9d77-f72e3cf790b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-e37062ed-65c0-4af6-9437-e7739322878b,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-c6b67059-2c77-4cf3-a3c2-0e1ff24efa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-f1317df0-c9af-455e-bb45-3604e93669ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ec21820a-04d9-46da-863b-7a472973cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-650a5cdc-fd88-4a1c-80f0-60daab1f4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-b0f89512-06cf-40fe-93b2-9732edc18db7,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-b692c975-64a4-4051-be9b-8272700bac73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399214280-172.17.0.5-1599366834659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-c2c261e6-d8d8-4014-9d77-f72e3cf790b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-e37062ed-65c0-4af6-9437-e7739322878b,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-c6b67059-2c77-4cf3-a3c2-0e1ff24efa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-f1317df0-c9af-455e-bb45-3604e93669ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ec21820a-04d9-46da-863b-7a472973cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-650a5cdc-fd88-4a1c-80f0-60daab1f4dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-b0f89512-06cf-40fe-93b2-9732edc18db7,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-b692c975-64a4-4051-be9b-8272700bac73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083173931-172.17.0.5-1599366874352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-2579af43-42bd-463e-9bd5-e2023ff87e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-b1f90246-5778-4048-a47c-c06043900271,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-1aa1876f-e86f-4f4d-b783-708615128c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-d99bb8d6-7d62-4652-9b7f-08bf350533de,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-05f581d7-f1af-416c-8177-2aebddacd0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-7fe90c52-9016-4bdc-a842-c84703c3887e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-4cb3be39-b5a9-41b4-9162-dc4f99df728c,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-cd3a22cb-17aa-4336-b87f-ac34f8258325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083173931-172.17.0.5-1599366874352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36236,DS-2579af43-42bd-463e-9bd5-e2023ff87e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-b1f90246-5778-4048-a47c-c06043900271,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-1aa1876f-e86f-4f4d-b783-708615128c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-d99bb8d6-7d62-4652-9b7f-08bf350533de,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-05f581d7-f1af-416c-8177-2aebddacd0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-7fe90c52-9016-4bdc-a842-c84703c3887e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-4cb3be39-b5a9-41b4-9162-dc4f99df728c,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-cd3a22cb-17aa-4336-b87f-ac34f8258325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341720327-172.17.0.5-1599366913227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-5216bd2d-0372-49f6-bb4b-dbb993569581,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-7807a340-1203-4f7a-b96b-4fa93bff1074,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-dd318eed-d269-4a0c-ab62-6567ee2c124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-70d977fe-1b4c-4b28-9be1-67f7138bc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-156c5914-4a25-46af-b30f-8b50d9b0ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-4b576271-63ba-4f8d-a448-5cba6c2db41b,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-a0e27d53-91cd-4ac2-8bc3-b240d3fdee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-105e04e5-3b5b-40fd-9711-a6d9c56b8867,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341720327-172.17.0.5-1599366913227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-5216bd2d-0372-49f6-bb4b-dbb993569581,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-7807a340-1203-4f7a-b96b-4fa93bff1074,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-dd318eed-d269-4a0c-ab62-6567ee2c124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-70d977fe-1b4c-4b28-9be1-67f7138bc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-156c5914-4a25-46af-b30f-8b50d9b0ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-4b576271-63ba-4f8d-a448-5cba6c2db41b,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-a0e27d53-91cd-4ac2-8bc3-b240d3fdee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-105e04e5-3b5b-40fd-9711-a6d9c56b8867,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973345538-172.17.0.5-1599367082629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-efcc0eed-4a2a-4ecb-88d1-672939e2c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-178afe55-7643-4b97-bd64-5781c661aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-1638da07-9322-4e47-8779-cce7fb9f2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-53cd18f1-9557-4bf3-9e3d-38dff125d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-8848d459-b598-4c51-8ec2-92ab6e5712fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-a3013c0d-da70-40cb-80a7-6c84e37ee033,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-b64e17b9-4346-4d14-b456-bea9dd4eec79,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-237e7483-974b-4716-ad3c-f5a56b76a8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973345538-172.17.0.5-1599367082629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-efcc0eed-4a2a-4ecb-88d1-672939e2c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-178afe55-7643-4b97-bd64-5781c661aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-1638da07-9322-4e47-8779-cce7fb9f2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-53cd18f1-9557-4bf3-9e3d-38dff125d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-8848d459-b598-4c51-8ec2-92ab6e5712fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-a3013c0d-da70-40cb-80a7-6c84e37ee033,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-b64e17b9-4346-4d14-b456-bea9dd4eec79,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-237e7483-974b-4716-ad3c-f5a56b76a8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644812677-172.17.0.5-1599367269903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-8996bb4b-124a-4e31-a429-7b094eaf0773,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-a1d6c9bb-dfcc-46b4-9882-dddcc95a6104,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-29078061-1fe5-4015-befe-6ddb4f8ae1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3abf5532-41d3-4984-a29d-df71e8a1f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-43472dec-9125-474a-b171-652190312502,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-ce4559c2-1987-42d3-8d36-a75fc66ad034,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-84ed7aec-0504-4295-96b3-75425c3bda92,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-6c9fe6df-69e7-44c0-bf15-24836a16a5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644812677-172.17.0.5-1599367269903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-8996bb4b-124a-4e31-a429-7b094eaf0773,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-a1d6c9bb-dfcc-46b4-9882-dddcc95a6104,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-29078061-1fe5-4015-befe-6ddb4f8ae1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3abf5532-41d3-4984-a29d-df71e8a1f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-43472dec-9125-474a-b171-652190312502,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-ce4559c2-1987-42d3-8d36-a75fc66ad034,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-84ed7aec-0504-4295-96b3-75425c3bda92,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-6c9fe6df-69e7-44c0-bf15-24836a16a5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065826368-172.17.0.5-1599367308233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-f2d782e4-859e-417a-a1bb-05a32df6219a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-99f046b4-53a6-4d73-acea-789f62e100f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c204e614-bf11-4a8d-8eb7-738a024b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-c7e52123-8750-4c02-948c-96de4fb9775e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-064082aa-03ed-4b0a-82aa-1ad8a4f32ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2ca050da-eff8-4d94-a35e-804415a8757f,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-b310ac0b-800a-4cad-83d6-da9c4c815004,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-18ba2cf2-ef8c-4c6e-bda2-4e1e1f96f7f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065826368-172.17.0.5-1599367308233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-f2d782e4-859e-417a-a1bb-05a32df6219a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-99f046b4-53a6-4d73-acea-789f62e100f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c204e614-bf11-4a8d-8eb7-738a024b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-c7e52123-8750-4c02-948c-96de4fb9775e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-064082aa-03ed-4b0a-82aa-1ad8a4f32ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2ca050da-eff8-4d94-a35e-804415a8757f,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-b310ac0b-800a-4cad-83d6-da9c4c815004,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-18ba2cf2-ef8c-4c6e-bda2-4e1e1f96f7f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904247430-172.17.0.5-1599367352621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36034,DS-63ac9812-5f39-454f-bf0a-da7a2541be27,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-66121860-835b-4537-9171-7c28ad326eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-c72242d4-1668-40cc-9443-729a37a35529,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-30a54153-998a-4985-8815-2532e9effe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-04783ce5-a8af-4732-a6ad-3fdd88b09a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-9027c241-5b03-4d7b-84e0-7048499eada6,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-08391d03-4d56-4f38-8df5-ba02a7a2d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0ecd2897-1ecd-411a-b54f-1c081726910e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904247430-172.17.0.5-1599367352621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36034,DS-63ac9812-5f39-454f-bf0a-da7a2541be27,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-66121860-835b-4537-9171-7c28ad326eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-c72242d4-1668-40cc-9443-729a37a35529,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-30a54153-998a-4985-8815-2532e9effe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-04783ce5-a8af-4732-a6ad-3fdd88b09a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-9027c241-5b03-4d7b-84e0-7048499eada6,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-08391d03-4d56-4f38-8df5-ba02a7a2d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0ecd2897-1ecd-411a-b54f-1c081726910e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318877822-172.17.0.5-1599367430166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-012b8ec0-aeed-451a-ae39-6e21f33a50e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d9bb528b-618b-46ff-96e6-767cb1e11351,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d3cf4c0b-f6dc-4c76-82ca-4398929ab0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-e81115b2-c82b-4aac-b3a6-e33119af588a,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-c0d97f08-d776-490c-bf9a-6f8f1edaa4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-b12c8067-5190-41fc-bb37-59685ea66fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-4fc29b66-3863-4dc6-b91f-380e575278a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-f06a9b2b-19de-4bb0-8584-a2234befc9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318877822-172.17.0.5-1599367430166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-012b8ec0-aeed-451a-ae39-6e21f33a50e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d9bb528b-618b-46ff-96e6-767cb1e11351,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d3cf4c0b-f6dc-4c76-82ca-4398929ab0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-e81115b2-c82b-4aac-b3a6-e33119af588a,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-c0d97f08-d776-490c-bf9a-6f8f1edaa4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-b12c8067-5190-41fc-bb37-59685ea66fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-4fc29b66-3863-4dc6-b91f-380e575278a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-f06a9b2b-19de-4bb0-8584-a2234befc9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535505743-172.17.0.5-1599367516550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-71841619-8555-4047-8a0c-16d5085419a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-5b9bb440-33c5-4c07-9faf-cec72f08fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6094cb26-34f9-4bf4-a505-d02a9da9cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-d836f91d-d4d5-49e0-8a0e-8520cf0915a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-9016845f-4275-418a-b208-2113d8acb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-056584eb-c53e-4127-a24f-35c10a70f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-1505cde1-e5c9-416e-8941-c191e78bb995,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-5eb8c63a-39fd-4317-985e-4eb2c0d64844,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535505743-172.17.0.5-1599367516550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-71841619-8555-4047-8a0c-16d5085419a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-5b9bb440-33c5-4c07-9faf-cec72f08fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6094cb26-34f9-4bf4-a505-d02a9da9cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-d836f91d-d4d5-49e0-8a0e-8520cf0915a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-9016845f-4275-418a-b208-2113d8acb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-056584eb-c53e-4127-a24f-35c10a70f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-1505cde1-e5c9-416e-8941-c191e78bb995,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-5eb8c63a-39fd-4317-985e-4eb2c0d64844,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4384987-172.17.0.5-1599367792256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-7f4a5aa9-e5e0-4e22-88e5-425472342696,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-fcc780b8-79c5-495c-88f4-85cae428ae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-2674bc38-fbb2-4067-a51c-44fd95aebcea,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-c1d438df-ff76-48fa-849a-727000f7f207,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-70af6a06-c211-4cdf-9788-e34160e7aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c1fd8391-3837-4aa2-b3af-a57f849a14b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-1dd981ff-f1ab-4d0f-a566-f3902508e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9b72e99c-0fe2-4f31-8218-7a2e22413039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4384987-172.17.0.5-1599367792256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-7f4a5aa9-e5e0-4e22-88e5-425472342696,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-fcc780b8-79c5-495c-88f4-85cae428ae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-2674bc38-fbb2-4067-a51c-44fd95aebcea,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-c1d438df-ff76-48fa-849a-727000f7f207,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-70af6a06-c211-4cdf-9788-e34160e7aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c1fd8391-3837-4aa2-b3af-a57f849a14b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-1dd981ff-f1ab-4d0f-a566-f3902508e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9b72e99c-0fe2-4f31-8218-7a2e22413039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295229059-172.17.0.5-1599368133346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-2171a713-7a33-4b8a-b4ff-4c98478f8a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-bfa75cc2-71b3-4efb-b4a3-c370200e03cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8c6184dd-7716-4e6d-a27e-5dda66e13c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-868e9464-8dab-47a7-b278-c8fef73faaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-d392245c-2e6f-4d4d-bf07-427c069fc5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-88983504-4718-488c-a780-5a6ba6bff687,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-768be642-73bf-45a0-87e8-b1f3049a2e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-7cc5801b-d240-4196-92aa-02e9f230fe6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295229059-172.17.0.5-1599368133346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-2171a713-7a33-4b8a-b4ff-4c98478f8a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-bfa75cc2-71b3-4efb-b4a3-c370200e03cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8c6184dd-7716-4e6d-a27e-5dda66e13c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-868e9464-8dab-47a7-b278-c8fef73faaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-d392245c-2e6f-4d4d-bf07-427c069fc5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-88983504-4718-488c-a780-5a6ba6bff687,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-768be642-73bf-45a0-87e8-b1f3049a2e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-7cc5801b-d240-4196-92aa-02e9f230fe6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815467441-172.17.0.5-1599368259553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-d16ccbbe-1ded-4207-93e0-0c94cf7e5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-db31b989-c0cb-4925-9766-db93260329ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-6e9c7f39-4651-4b4b-af53-db8f45469c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-284f8823-4dad-47d2-86ef-958fa815e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-0ae533c5-03fa-4b04-bdbb-953cb0eeab28,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7c5fb941-0e2a-4175-8c2e-903b210c3210,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-e4c77280-9905-4543-a0eb-796ede66346e,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-ae3cc0d1-9fae-4ba8-a70f-ae119ebe74bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815467441-172.17.0.5-1599368259553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-d16ccbbe-1ded-4207-93e0-0c94cf7e5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-db31b989-c0cb-4925-9766-db93260329ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-6e9c7f39-4651-4b4b-af53-db8f45469c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-284f8823-4dad-47d2-86ef-958fa815e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-0ae533c5-03fa-4b04-bdbb-953cb0eeab28,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7c5fb941-0e2a-4175-8c2e-903b210c3210,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-e4c77280-9905-4543-a0eb-796ede66346e,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-ae3cc0d1-9fae-4ba8-a70f-ae119ebe74bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349528555-172.17.0.5-1599368376582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-46e4ad77-6736-48bf-ae52-bb3ea160a348,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-f5e1ac18-7427-497b-9d5a-89e670b31f94,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-1554402c-06c8-470d-9a3a-bc7d85461f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-4487985a-8a35-4b17-958e-fa6a84a0595a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-425ae764-9dda-499a-bf5d-eb922e937d13,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-48b9785e-b257-4bf4-954b-e73a527f554a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e73812ee-a1b2-47e3-8b3d-85334a5d5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6c88647a-098b-4c3b-a753-93aad19e62ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349528555-172.17.0.5-1599368376582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-46e4ad77-6736-48bf-ae52-bb3ea160a348,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-f5e1ac18-7427-497b-9d5a-89e670b31f94,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-1554402c-06c8-470d-9a3a-bc7d85461f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-4487985a-8a35-4b17-958e-fa6a84a0595a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-425ae764-9dda-499a-bf5d-eb922e937d13,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-48b9785e-b257-4bf4-954b-e73a527f554a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e73812ee-a1b2-47e3-8b3d-85334a5d5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-6c88647a-098b-4c3b-a753-93aad19e62ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841384988-172.17.0.5-1599368602650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-3bdc68d6-c3ef-476e-9a1e-64e9a760861c,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-aee25176-9236-443b-93d0-516ee497bede,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-77e39167-70ec-4804-af3f-f44b8dab6e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-9dfc2c51-f149-4858-b6cc-b292053f935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-7476817d-00fb-4095-8d1b-ec2075157ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-9c66707b-1eee-493d-b380-538a99b411f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-f563ca4f-0f32-41ca-a37e-24cf987c967c,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-2ea473c5-f142-47c0-9c1b-e5f57f166c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841384988-172.17.0.5-1599368602650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-3bdc68d6-c3ef-476e-9a1e-64e9a760861c,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-aee25176-9236-443b-93d0-516ee497bede,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-77e39167-70ec-4804-af3f-f44b8dab6e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-9dfc2c51-f149-4858-b6cc-b292053f935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-7476817d-00fb-4095-8d1b-ec2075157ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-9c66707b-1eee-493d-b380-538a99b411f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-f563ca4f-0f32-41ca-a37e-24cf987c967c,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-2ea473c5-f142-47c0-9c1b-e5f57f166c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5537
