reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459893096-172.17.0.10-1599304411241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-86fb7c83-4318-40d1-b34a-07b9f001f405,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-200a99bf-2d1b-475f-85f4-31e0691318a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-00a07067-eb5c-4992-9b90-cb80ab44924c,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-6427886a-7813-4ff3-a6de-4c50b5227d33,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-5439e8e0-22d5-42cb-9a32-a3209e5ea7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-f1ac8e6f-9bec-48a8-9fa8-38d64bd2adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-3462b7f6-bd7b-4b92-8895-16c26bd17916,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1d3f1ac4-4cb7-4a9b-81aa-673e8943e47c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459893096-172.17.0.10-1599304411241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-86fb7c83-4318-40d1-b34a-07b9f001f405,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-200a99bf-2d1b-475f-85f4-31e0691318a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-00a07067-eb5c-4992-9b90-cb80ab44924c,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-6427886a-7813-4ff3-a6de-4c50b5227d33,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-5439e8e0-22d5-42cb-9a32-a3209e5ea7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-f1ac8e6f-9bec-48a8-9fa8-38d64bd2adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-3462b7f6-bd7b-4b92-8895-16c26bd17916,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1d3f1ac4-4cb7-4a9b-81aa-673e8943e47c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826311422-172.17.0.10-1599304484210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-1a499566-a146-4905-87a8-e21178f12ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-037b3aed-97ac-4215-b21c-b37742c7d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-83db1d16-c7fd-40b6-a61b-aaa8e9a13e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-e95bb340-c571-4c6b-9252-3beb89ec9579,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-a6c03318-83cd-461d-9c35-09b0b979c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-32a4b8d1-ba43-4498-813c-5114ba151560,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-63d0384d-0c77-48ff-8dcf-7d5cd955aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-1b0b2a15-0e83-4679-af62-c39f70c9f1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826311422-172.17.0.10-1599304484210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-1a499566-a146-4905-87a8-e21178f12ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-037b3aed-97ac-4215-b21c-b37742c7d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-83db1d16-c7fd-40b6-a61b-aaa8e9a13e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-e95bb340-c571-4c6b-9252-3beb89ec9579,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-a6c03318-83cd-461d-9c35-09b0b979c1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-32a4b8d1-ba43-4498-813c-5114ba151560,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-63d0384d-0c77-48ff-8dcf-7d5cd955aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-1b0b2a15-0e83-4679-af62-c39f70c9f1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461728848-172.17.0.10-1599304517403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38892,DS-61d79873-a5e7-4a6b-b1f9-3ea2709ca61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-b40db2ed-6abc-43f9-9940-4a4ac5b6abca,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-72cb1b7c-0c03-44c7-939e-632e645ea4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-2def6c69-95e3-481c-b148-2193cfb2fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-9f499e07-b6cf-4321-8e63-ed2ef129f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-78988869-c97a-401e-af5c-d21790641006,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-c35afaf3-a2e8-4f5c-bfb5-1965ae9544e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-6d5ebb4e-0fcb-4810-a36f-79b796f10469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461728848-172.17.0.10-1599304517403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38892,DS-61d79873-a5e7-4a6b-b1f9-3ea2709ca61c,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-b40db2ed-6abc-43f9-9940-4a4ac5b6abca,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-72cb1b7c-0c03-44c7-939e-632e645ea4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-2def6c69-95e3-481c-b148-2193cfb2fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-9f499e07-b6cf-4321-8e63-ed2ef129f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-78988869-c97a-401e-af5c-d21790641006,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-c35afaf3-a2e8-4f5c-bfb5-1965ae9544e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-6d5ebb4e-0fcb-4810-a36f-79b796f10469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67951992-172.17.0.10-1599304620719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-1f3ced8f-0f9c-4b3e-b47d-7f6bf71dd198,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-823f8be4-3cf0-431b-a393-c2c126d484ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-95ed258a-77a1-4c23-a58a-a709bb1d9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-f882b398-171b-4d47-ad37-02e3c82b9778,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-a49bfbb7-b1c7-4500-9c2e-3ad011dcc707,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-410daa7b-6c35-4eb2-a4ca-4252b1f564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-db3840cc-5d1b-4b9c-8027-86a179feeaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-ab18e935-95fc-4d87-bbd1-ba3671b34fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67951992-172.17.0.10-1599304620719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-1f3ced8f-0f9c-4b3e-b47d-7f6bf71dd198,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-823f8be4-3cf0-431b-a393-c2c126d484ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-95ed258a-77a1-4c23-a58a-a709bb1d9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-f882b398-171b-4d47-ad37-02e3c82b9778,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-a49bfbb7-b1c7-4500-9c2e-3ad011dcc707,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-410daa7b-6c35-4eb2-a4ca-4252b1f564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-db3840cc-5d1b-4b9c-8027-86a179feeaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-ab18e935-95fc-4d87-bbd1-ba3671b34fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807617531-172.17.0.10-1599305269503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-d83c9ff0-e143-49ea-9d97-5f812a672862,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7017df9b-48ac-4999-ab76-4f506fb4525a,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-89465a2c-d124-43e5-89d3-fa3138738c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-35854858-b0b6-4374-859a-a97195a2eace,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-29a5fa31-49e2-4965-82e1-f17ce747c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-721b0b36-fd6a-424c-8736-234cf86c5e88,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-83f9e32e-b18f-4770-896f-75baf6122796,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-9fac060b-f9b9-4cc7-82cb-b74414b385c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807617531-172.17.0.10-1599305269503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-d83c9ff0-e143-49ea-9d97-5f812a672862,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7017df9b-48ac-4999-ab76-4f506fb4525a,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-89465a2c-d124-43e5-89d3-fa3138738c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-35854858-b0b6-4374-859a-a97195a2eace,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-29a5fa31-49e2-4965-82e1-f17ce747c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-721b0b36-fd6a-424c-8736-234cf86c5e88,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-83f9e32e-b18f-4770-896f-75baf6122796,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-9fac060b-f9b9-4cc7-82cb-b74414b385c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011630357-172.17.0.10-1599305376110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c75653e9-dc1b-4c74-bab7-172ed53d3a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-c74534e6-d1fe-4f11-a06c-2089c407012e,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-60556fa4-42f3-4e52-95af-84a4fb2b08b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-2860715c-78db-411e-bd2e-8a67f6d0688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-0e8e67e7-720f-488a-959b-f046ad700a85,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-4bdcbfe0-8f6b-4c13-9044-bb916cb4924a,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-c5a7a85d-1cc7-4737-8a3c-8d77e28abb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-b3827e26-1bcd-4ae0-95b0-3d6640ff503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011630357-172.17.0.10-1599305376110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c75653e9-dc1b-4c74-bab7-172ed53d3a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-c74534e6-d1fe-4f11-a06c-2089c407012e,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-60556fa4-42f3-4e52-95af-84a4fb2b08b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-2860715c-78db-411e-bd2e-8a67f6d0688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-0e8e67e7-720f-488a-959b-f046ad700a85,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-4bdcbfe0-8f6b-4c13-9044-bb916cb4924a,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-c5a7a85d-1cc7-4737-8a3c-8d77e28abb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-b3827e26-1bcd-4ae0-95b0-3d6640ff503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509223386-172.17.0.10-1599305563498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-37e26457-6b44-463e-800d-a756e8fefd06,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d25120b7-32d1-412a-a42a-3632d86d5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-2e6d61d9-3ce2-4391-9a38-d0c310e7ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-a60ddb7e-5855-4a0f-93fe-4d6d3ce628b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-6407c59e-34ef-4efc-86eb-2e7b3f20fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-cb4e31c4-a2f6-4ec7-a899-656fb6efae00,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-28825ebd-9dc7-4b2f-986c-7af3460e662d,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-cf4f86cf-14e9-4b3f-b0a2-e40706246584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509223386-172.17.0.10-1599305563498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-37e26457-6b44-463e-800d-a756e8fefd06,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d25120b7-32d1-412a-a42a-3632d86d5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-2e6d61d9-3ce2-4391-9a38-d0c310e7ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-a60ddb7e-5855-4a0f-93fe-4d6d3ce628b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-6407c59e-34ef-4efc-86eb-2e7b3f20fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-cb4e31c4-a2f6-4ec7-a899-656fb6efae00,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-28825ebd-9dc7-4b2f-986c-7af3460e662d,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-cf4f86cf-14e9-4b3f-b0a2-e40706246584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504709085-172.17.0.10-1599305716141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-7a294c02-e1fd-49f3-97f0-d84ed805335a,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-c9a93b18-0d43-4e1c-bb15-66985553e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-2663444a-200f-4927-a57b-7631a6ffced6,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8ab20614-b808-4571-9950-07a232433bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-ca860dd0-0025-4a29-bd56-c38a9cfde702,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-dee0e48c-aff6-4c97-baaa-08e8eb1d4624,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-30370129-8211-4080-bcf8-f15557154ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-929d7aac-fae1-49a8-904a-24cca95c49c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504709085-172.17.0.10-1599305716141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-7a294c02-e1fd-49f3-97f0-d84ed805335a,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-c9a93b18-0d43-4e1c-bb15-66985553e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-2663444a-200f-4927-a57b-7631a6ffced6,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-8ab20614-b808-4571-9950-07a232433bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-ca860dd0-0025-4a29-bd56-c38a9cfde702,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-dee0e48c-aff6-4c97-baaa-08e8eb1d4624,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-30370129-8211-4080-bcf8-f15557154ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-929d7aac-fae1-49a8-904a-24cca95c49c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777549288-172.17.0.10-1599305988731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-44fb40be-a691-45a9-a253-a0c4952f8ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c6cadfe3-56f1-49ec-96c2-122e2357b294,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-35efb991-478a-4785-841e-de4b39851e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4a75a17a-d24b-4160-a855-9e194e92b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-1146321b-4f3d-4f61-a43d-3cf9072aee67,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4a22f6db-f9e6-4aed-ba0a-2afdbfb294e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-f35ed9ce-c5ce-4c25-af89-7d8023b8d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-91b00e7d-572d-406b-b5cc-7020c08b74fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777549288-172.17.0.10-1599305988731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-44fb40be-a691-45a9-a253-a0c4952f8ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c6cadfe3-56f1-49ec-96c2-122e2357b294,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-35efb991-478a-4785-841e-de4b39851e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4a75a17a-d24b-4160-a855-9e194e92b7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-1146321b-4f3d-4f61-a43d-3cf9072aee67,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4a22f6db-f9e6-4aed-ba0a-2afdbfb294e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-f35ed9ce-c5ce-4c25-af89-7d8023b8d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-91b00e7d-572d-406b-b5cc-7020c08b74fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039302464-172.17.0.10-1599306032554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43758,DS-6df5178c-e2ab-4763-83b7-58868b774728,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d474af6f-a539-48bd-a70d-b841f0975ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-712e3af3-ec04-4fd4-b06a-d3ec0a94e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-5d325aa8-8233-4882-8157-5810a327b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-cb3d881a-44fc-41f8-86ff-5bbe15d85b27,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-b51f4985-2b39-40ea-bc1b-feeb646ad288,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-708b9600-96ca-4cba-a19f-fff2f4816ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-34e95a0b-b3f4-4869-a53c-a68fa7b37c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039302464-172.17.0.10-1599306032554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43758,DS-6df5178c-e2ab-4763-83b7-58868b774728,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d474af6f-a539-48bd-a70d-b841f0975ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-712e3af3-ec04-4fd4-b06a-d3ec0a94e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-5d325aa8-8233-4882-8157-5810a327b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-cb3d881a-44fc-41f8-86ff-5bbe15d85b27,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-b51f4985-2b39-40ea-bc1b-feeb646ad288,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-708b9600-96ca-4cba-a19f-fff2f4816ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-34e95a0b-b3f4-4869-a53c-a68fa7b37c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708466037-172.17.0.10-1599306233194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-d1af2ced-9b68-48b6-872e-2f6024fbf68a,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-a004c2a3-0e18-48d4-a10e-0f5d26d3742e,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-160de1ba-a883-4077-9a69-af58c54170d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-75ff3620-670c-4c96-9448-e867d32c8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-142d04e3-51d0-4106-b189-4edf1c6da43f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f33a6d9b-d21d-444d-989e-bf167248a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-1816e341-aa2e-434c-89bf-a2f422e7c63e,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-457cbcab-54cc-43a0-8cd5-8042d5a20d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708466037-172.17.0.10-1599306233194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-d1af2ced-9b68-48b6-872e-2f6024fbf68a,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-a004c2a3-0e18-48d4-a10e-0f5d26d3742e,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-160de1ba-a883-4077-9a69-af58c54170d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-75ff3620-670c-4c96-9448-e867d32c8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-142d04e3-51d0-4106-b189-4edf1c6da43f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f33a6d9b-d21d-444d-989e-bf167248a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-1816e341-aa2e-434c-89bf-a2f422e7c63e,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-457cbcab-54cc-43a0-8cd5-8042d5a20d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149011360-172.17.0.10-1599307198702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38355,DS-4b230878-5e97-45d0-b19e-cfbb389ac526,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6c8e54c6-2848-40e4-88a9-ddaf0c52e449,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-08d8c85d-26fd-4722-aeee-9f3f21a3952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-d0a1de15-d4c0-4870-8918-2ae9fd7e69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-966fc20b-2e20-47c3-8e64-62014444d138,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-f0d94956-9a0c-46f5-b4ab-f96adfab5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-28e9df88-ca97-43c8-99d1-357feccb3d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-cfc394df-f241-4d06-b25d-d42072f40358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149011360-172.17.0.10-1599307198702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38355,DS-4b230878-5e97-45d0-b19e-cfbb389ac526,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6c8e54c6-2848-40e4-88a9-ddaf0c52e449,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-08d8c85d-26fd-4722-aeee-9f3f21a3952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-d0a1de15-d4c0-4870-8918-2ae9fd7e69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-966fc20b-2e20-47c3-8e64-62014444d138,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-f0d94956-9a0c-46f5-b4ab-f96adfab5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-28e9df88-ca97-43c8-99d1-357feccb3d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-cfc394df-f241-4d06-b25d-d42072f40358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110969060-172.17.0.10-1599307459491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-efee1bca-28f0-41cc-b0d7-fa9163e9f2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-6e41f182-6d71-4856-a5a2-fd840b61e911,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-8286b48f-9c2a-4a05-835e-a816919005aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-dbed0527-fa1b-435e-a167-9d90dc7f3c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2393cffa-d2bb-4a76-8d57-74e614eefec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-737f5ffb-1165-4b7e-9e65-7c64fb8a41f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-402ea5f2-a4a4-4074-b3c7-466f3e0ab26e,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-2b27b4ba-5570-4035-9c91-3ddd453efba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110969060-172.17.0.10-1599307459491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-efee1bca-28f0-41cc-b0d7-fa9163e9f2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-6e41f182-6d71-4856-a5a2-fd840b61e911,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-8286b48f-9c2a-4a05-835e-a816919005aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-dbed0527-fa1b-435e-a167-9d90dc7f3c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2393cffa-d2bb-4a76-8d57-74e614eefec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-737f5ffb-1165-4b7e-9e65-7c64fb8a41f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-402ea5f2-a4a4-4074-b3c7-466f3e0ab26e,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-2b27b4ba-5570-4035-9c91-3ddd453efba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388715638-172.17.0.10-1599307961177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-ccd4e4d5-4f2f-4748-9249-c6a90ad4bb52,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-713b01ce-45ff-4154-890f-6849de791773,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-91dd9815-afdd-44d1-b0db-9620b61f20db,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-e52fe4bc-30a3-45fd-937b-67cff71f2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-ace3403f-1308-4b6e-bd2e-6d7977c095ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-d5a3da4b-97e5-41f9-9004-5602a7e0098e,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-fa591ba4-9bd9-4420-bbf7-1638d1ec1289,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c1a641c0-2ff3-429d-af9f-6ce3ec7e5572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388715638-172.17.0.10-1599307961177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-ccd4e4d5-4f2f-4748-9249-c6a90ad4bb52,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-713b01ce-45ff-4154-890f-6849de791773,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-91dd9815-afdd-44d1-b0db-9620b61f20db,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-e52fe4bc-30a3-45fd-937b-67cff71f2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-ace3403f-1308-4b6e-bd2e-6d7977c095ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-d5a3da4b-97e5-41f9-9004-5602a7e0098e,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-fa591ba4-9bd9-4420-bbf7-1638d1ec1289,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c1a641c0-2ff3-429d-af9f-6ce3ec7e5572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766882382-172.17.0.10-1599307998644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-706cc2f3-906e-47ae-b844-95935389d5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-531a62c0-7445-42c7-9754-831596ce8587,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-4b88597f-e25a-4309-a39a-0f244091a5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-fbc2c972-62d6-425e-98c3-d79fb7c08eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-eb6e7726-9dd2-4616-b3f7-2f29fe1957ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-db7e60a0-41cf-4359-9b04-149eaa719fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-6acb7a35-c62b-4556-8a54-12e3645e9479,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-e591f47d-4ece-4491-8fda-536ba3218ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766882382-172.17.0.10-1599307998644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-706cc2f3-906e-47ae-b844-95935389d5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-531a62c0-7445-42c7-9754-831596ce8587,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-4b88597f-e25a-4309-a39a-0f244091a5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-fbc2c972-62d6-425e-98c3-d79fb7c08eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-eb6e7726-9dd2-4616-b3f7-2f29fe1957ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-db7e60a0-41cf-4359-9b04-149eaa719fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-6acb7a35-c62b-4556-8a54-12e3645e9479,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-e591f47d-4ece-4491-8fda-536ba3218ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337161873-172.17.0.10-1599308067340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-c63e0829-77c7-4e47-93e2-f9b16833b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-3f19af01-18ce-44b2-b518-3c6d6a3d2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-c43b6dab-ea14-4a38-95e5-8433150644b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-106cc13d-a9e4-4c2c-a867-ba0f565dfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-4dc44cbf-bdc6-47b1-ac9a-ed93fffa50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-e6c373bd-d24c-45d2-9f4a-a80624f0f268,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d3ae6922-7cd4-4090-a672-8ca71d81a302,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-cecd5796-9b5f-4017-a3a2-509bd420e409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337161873-172.17.0.10-1599308067340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-c63e0829-77c7-4e47-93e2-f9b16833b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-3f19af01-18ce-44b2-b518-3c6d6a3d2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-c43b6dab-ea14-4a38-95e5-8433150644b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-106cc13d-a9e4-4c2c-a867-ba0f565dfdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-4dc44cbf-bdc6-47b1-ac9a-ed93fffa50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-e6c373bd-d24c-45d2-9f4a-a80624f0f268,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d3ae6922-7cd4-4090-a672-8ca71d81a302,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-cecd5796-9b5f-4017-a3a2-509bd420e409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488708722-172.17.0.10-1599308175076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-b62dded7-7362-45f7-b5e9-f80d8264bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-7bad56eb-b659-4159-8b1a-e64dee00523c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-15308482-a82e-4940-8382-e2fb00c16561,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-f7093ab4-4fcb-4ef3-a39b-60ef918037aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-277812a0-f805-4254-8089-f71c4ee4d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-95caa337-23ab-4ff5-871e-2a75c00c44dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-d329c782-da89-4a09-b021-bfb8cd459842,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6298c821-3b6d-4c68-95a7-63f4a1c9c34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488708722-172.17.0.10-1599308175076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-b62dded7-7362-45f7-b5e9-f80d8264bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-7bad56eb-b659-4159-8b1a-e64dee00523c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-15308482-a82e-4940-8382-e2fb00c16561,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-f7093ab4-4fcb-4ef3-a39b-60ef918037aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-277812a0-f805-4254-8089-f71c4ee4d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-95caa337-23ab-4ff5-871e-2a75c00c44dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-d329c782-da89-4a09-b021-bfb8cd459842,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6298c821-3b6d-4c68-95a7-63f4a1c9c34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133026044-172.17.0.10-1599308478260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-ecd3ca08-a82e-4437-ab17-2502e7e11861,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-2e516118-49a8-4c0d-bc42-2d863b50bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-9e7ff359-42dd-47a8-9641-5ab02b24551e,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-3231bf71-eb7e-43af-b92e-bb7893bc34dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-99ef1d41-e228-4831-a470-ead378173883,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0410507a-a63b-4177-8916-c6684d66a197,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-b47d0ba2-a337-4b31-b3ad-67477ac57255,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-18463fa6-2af6-479e-b93b-6bcdda77abe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133026044-172.17.0.10-1599308478260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-ecd3ca08-a82e-4437-ab17-2502e7e11861,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-2e516118-49a8-4c0d-bc42-2d863b50bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-9e7ff359-42dd-47a8-9641-5ab02b24551e,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-3231bf71-eb7e-43af-b92e-bb7893bc34dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-99ef1d41-e228-4831-a470-ead378173883,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0410507a-a63b-4177-8916-c6684d66a197,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-b47d0ba2-a337-4b31-b3ad-67477ac57255,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-18463fa6-2af6-479e-b93b-6bcdda77abe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506685355-172.17.0.10-1599308525505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-313733b2-86f7-41b6-bcc8-2c9251e6cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-c1e9ff05-b857-4765-b75c-71a46b4ff8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-231b096f-26ac-4398-91cc-8d5068ee01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-364305c2-6ee7-4324-87f5-e188f4cb85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-7e8a956b-5beb-4852-b61c-a2ecac97a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-db0e7b0d-4d80-4aad-9672-a8f475e0bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-96798b5a-cec8-4c07-8c9b-59878f25e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5b204b91-5e9c-424f-8515-ed3429d1a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506685355-172.17.0.10-1599308525505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-313733b2-86f7-41b6-bcc8-2c9251e6cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-c1e9ff05-b857-4765-b75c-71a46b4ff8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-231b096f-26ac-4398-91cc-8d5068ee01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-364305c2-6ee7-4324-87f5-e188f4cb85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-7e8a956b-5beb-4852-b61c-a2ecac97a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-db0e7b0d-4d80-4aad-9672-a8f475e0bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-96798b5a-cec8-4c07-8c9b-59878f25e9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5b204b91-5e9c-424f-8515-ed3429d1a425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5463
