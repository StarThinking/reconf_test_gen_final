reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246452184-172.17.0.14-1599314379881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-72bf719d-c618-4a05-b413-1bad5d01df62,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-646058c7-3ba2-41f9-9d1c-6a02d2ba7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-24f500c5-0386-40bf-ba9a-d2d4e4545cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0e4481bf-08c1-406d-b4e7-d5a6890b3434,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-36118943-929d-4109-a5ab-f7faaba2bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-42749aba-96c9-41ba-a667-ddf24f1660ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-23051130-fc4e-4a69-87e6-93fc25c0d896,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d118c4b3-a488-4ce5-bf1f-ceb93a8a4a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246452184-172.17.0.14-1599314379881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-72bf719d-c618-4a05-b413-1bad5d01df62,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-646058c7-3ba2-41f9-9d1c-6a02d2ba7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-24f500c5-0386-40bf-ba9a-d2d4e4545cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0e4481bf-08c1-406d-b4e7-d5a6890b3434,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-36118943-929d-4109-a5ab-f7faaba2bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-42749aba-96c9-41ba-a667-ddf24f1660ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-23051130-fc4e-4a69-87e6-93fc25c0d896,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d118c4b3-a488-4ce5-bf1f-ceb93a8a4a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233995142-172.17.0.14-1599314619593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-d112de31-c477-44c2-a5a7-35b9a294ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-795c1762-9f5a-4db8-9e6e-e10b536cac47,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-65835ce8-d343-4b24-afb1-1e9f1998ef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-f254bb74-050a-48af-a500-b3933c666d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-201a3384-fcf4-47a8-b89b-1c37c35239fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7286a193-c309-47b2-9c70-fd4f21949029,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-af1a492f-78b6-4b1c-9324-70d91edc7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-8951c36d-819b-4e0f-84e0-ca824916c605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233995142-172.17.0.14-1599314619593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-d112de31-c477-44c2-a5a7-35b9a294ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-795c1762-9f5a-4db8-9e6e-e10b536cac47,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-65835ce8-d343-4b24-afb1-1e9f1998ef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-f254bb74-050a-48af-a500-b3933c666d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-201a3384-fcf4-47a8-b89b-1c37c35239fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-7286a193-c309-47b2-9c70-fd4f21949029,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-af1a492f-78b6-4b1c-9324-70d91edc7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-8951c36d-819b-4e0f-84e0-ca824916c605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314192292-172.17.0.14-1599314830267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-5eeb0159-81ea-4bc0-8ed0-938c929b9a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-714d030b-baa7-4287-b9f3-da5693917515,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-f362b10b-bc6b-4b04-84af-8771c62285c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-53a8ca67-bc17-4c69-97e8-f410577ab71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-ecad34cc-5564-4478-a8ac-61541a1d2423,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b193e90-f31b-457f-9967-48637285f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-8bf3d139-b9c7-46b7-bf8d-dada8032f689,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-a66e072b-62b7-48c2-8769-1aebb62bda87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314192292-172.17.0.14-1599314830267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-5eeb0159-81ea-4bc0-8ed0-938c929b9a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-714d030b-baa7-4287-b9f3-da5693917515,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-f362b10b-bc6b-4b04-84af-8771c62285c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-53a8ca67-bc17-4c69-97e8-f410577ab71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-ecad34cc-5564-4478-a8ac-61541a1d2423,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b193e90-f31b-457f-9967-48637285f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-8bf3d139-b9c7-46b7-bf8d-dada8032f689,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-a66e072b-62b7-48c2-8769-1aebb62bda87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285420689-172.17.0.14-1599315261665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-67ee9778-a980-4670-aca2-0094a7fd20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e2c05859-6b26-4e4c-a4cb-abc4af4f6150,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-04b17fca-967a-4e9a-90cf-578bd42ec8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-51c17739-d22c-41e7-8992-370797a4b2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-33b3a1fe-3b22-48b8-9b71-c17a37ccf12f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-313cc599-9d65-4797-821a-b111fea44a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-2d4d04bf-9263-4018-b1dc-6c097aafdee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-377cb091-95c9-4b3a-8534-b1677e6e91b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285420689-172.17.0.14-1599315261665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-67ee9778-a980-4670-aca2-0094a7fd20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e2c05859-6b26-4e4c-a4cb-abc4af4f6150,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-04b17fca-967a-4e9a-90cf-578bd42ec8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-51c17739-d22c-41e7-8992-370797a4b2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-33b3a1fe-3b22-48b8-9b71-c17a37ccf12f,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-313cc599-9d65-4797-821a-b111fea44a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-2d4d04bf-9263-4018-b1dc-6c097aafdee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-377cb091-95c9-4b3a-8534-b1677e6e91b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153757726-172.17.0.14-1599315330068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-15eb0822-7d25-456a-93eb-8de9873460a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-67047685-0d33-4f45-b416-dc016594d102,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-2895a18e-325c-478f-8a45-c21232e00599,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-0a8136c4-c79b-4052-abf2-cf87fff41b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-6cf04e39-05c3-4735-911e-804e0b559492,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-006dd658-1111-4947-8978-9caa3d1e060e,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-93607a03-2fc3-46cb-b228-b16b8b673e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-e880ea0c-b7e7-4287-a3cc-3d7fafbe4e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153757726-172.17.0.14-1599315330068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-15eb0822-7d25-456a-93eb-8de9873460a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-67047685-0d33-4f45-b416-dc016594d102,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-2895a18e-325c-478f-8a45-c21232e00599,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-0a8136c4-c79b-4052-abf2-cf87fff41b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-6cf04e39-05c3-4735-911e-804e0b559492,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-006dd658-1111-4947-8978-9caa3d1e060e,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-93607a03-2fc3-46cb-b228-b16b8b673e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-e880ea0c-b7e7-4287-a3cc-3d7fafbe4e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232816053-172.17.0.14-1599315371038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-f08d1c77-f9bd-4c8e-b42a-09ef35ebd87e,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-a1908075-0635-4989-a9f8-2dd2f3b7f969,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-ac1cd8fe-9eaf-4442-bced-f294eb1dac58,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6e59b150-4e41-4656-8066-e4f2d67971ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-7de5923e-0891-47d9-a828-210aa444a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-07c7a5a6-f334-49c5-acdd-ef3130237155,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-0af4680c-6965-4c64-af54-7f03437f80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-3a58c071-7738-4cd0-bf16-2793c21add65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232816053-172.17.0.14-1599315371038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-f08d1c77-f9bd-4c8e-b42a-09ef35ebd87e,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-a1908075-0635-4989-a9f8-2dd2f3b7f969,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-ac1cd8fe-9eaf-4442-bced-f294eb1dac58,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6e59b150-4e41-4656-8066-e4f2d67971ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-7de5923e-0891-47d9-a828-210aa444a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-07c7a5a6-f334-49c5-acdd-ef3130237155,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-0af4680c-6965-4c64-af54-7f03437f80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-3a58c071-7738-4cd0-bf16-2793c21add65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797286414-172.17.0.14-1599315406854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43987,DS-2d1f217e-f6ee-4e8e-8a1e-78c7bdba27d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-98e1fc16-6e72-4de5-ad0a-8db14674514a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-37076500-7b10-4d04-bd33-56e6a384c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-5aeb347f-bb34-4c29-a386-7b1c0dee50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-96ab0841-6927-4411-8bdf-2e7ec3e69d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-385b426d-aea2-46b4-9940-9cfae2274338,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-eda3d5e8-5816-4397-b1e5-e5f41ccb6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-f9523515-39c7-4c68-9c46-ce2417a5b82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797286414-172.17.0.14-1599315406854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43987,DS-2d1f217e-f6ee-4e8e-8a1e-78c7bdba27d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-98e1fc16-6e72-4de5-ad0a-8db14674514a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-37076500-7b10-4d04-bd33-56e6a384c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-5aeb347f-bb34-4c29-a386-7b1c0dee50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-96ab0841-6927-4411-8bdf-2e7ec3e69d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-385b426d-aea2-46b4-9940-9cfae2274338,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-eda3d5e8-5816-4397-b1e5-e5f41ccb6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-f9523515-39c7-4c68-9c46-ce2417a5b82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283506075-172.17.0.14-1599315550154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-f028b1b4-86d9-4334-a04b-66a0e5019fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d40996b1-84ed-4a68-9a34-188eff76b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-c835038e-c746-4ca3-89ac-0a68e6b31674,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-ad67bfcd-083f-4944-be6b-b15af731999e,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-58610add-6279-49ee-9d82-8296976e0472,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-9c00f677-2eec-45c7-a44d-62924c54e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-7179bd41-4b87-4132-a0d1-e000eaccd6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-abaa6bee-e9fd-4a79-867c-d8f6381a01bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283506075-172.17.0.14-1599315550154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-f028b1b4-86d9-4334-a04b-66a0e5019fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d40996b1-84ed-4a68-9a34-188eff76b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-c835038e-c746-4ca3-89ac-0a68e6b31674,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-ad67bfcd-083f-4944-be6b-b15af731999e,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-58610add-6279-49ee-9d82-8296976e0472,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-9c00f677-2eec-45c7-a44d-62924c54e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-7179bd41-4b87-4132-a0d1-e000eaccd6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-abaa6bee-e9fd-4a79-867c-d8f6381a01bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303179843-172.17.0.14-1599316279397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-7e09a405-da8c-40f1-8bd8-a61f84ab6911,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-6046f2b9-cfd6-4c0d-8230-00b153c9ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6354c299-a07f-4009-8b1b-ea6028aa7bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-defd40e3-2b37-4477-b3db-bab03cfff907,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-dab07401-b2be-4930-8383-02557a1d1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-60c47542-75ef-4786-98d9-819bdd1bf791,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-4e9e3c3e-137a-45e0-b9a2-8502a97cf634,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-e1fa3a2b-1ca7-43c3-a16c-b3466d7dae35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303179843-172.17.0.14-1599316279397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-7e09a405-da8c-40f1-8bd8-a61f84ab6911,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-6046f2b9-cfd6-4c0d-8230-00b153c9ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-6354c299-a07f-4009-8b1b-ea6028aa7bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-defd40e3-2b37-4477-b3db-bab03cfff907,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-dab07401-b2be-4930-8383-02557a1d1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-60c47542-75ef-4786-98d9-819bdd1bf791,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-4e9e3c3e-137a-45e0-b9a2-8502a97cf634,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-e1fa3a2b-1ca7-43c3-a16c-b3466d7dae35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101096028-172.17.0.14-1599316415233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-eb916d30-5009-4648-bd49-01a3e3e5cf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-bb289d4f-dabf-4e7b-bd30-64cda80eb5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-31f677b6-faed-4dd8-a182-5d999b10680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-14b140f1-3efa-49ee-a41d-d3c97a248bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-a3255b86-fc90-47fa-a966-18465fc9c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-ca255bee-c41a-4096-aedb-9f48ec6dcde1,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-d68e908e-3f9f-458c-9a93-ce006338cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-faaee069-993f-4f4a-b885-36a37693c9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101096028-172.17.0.14-1599316415233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-eb916d30-5009-4648-bd49-01a3e3e5cf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-bb289d4f-dabf-4e7b-bd30-64cda80eb5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-31f677b6-faed-4dd8-a182-5d999b10680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-14b140f1-3efa-49ee-a41d-d3c97a248bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-a3255b86-fc90-47fa-a966-18465fc9c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-ca255bee-c41a-4096-aedb-9f48ec6dcde1,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-d68e908e-3f9f-458c-9a93-ce006338cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-faaee069-993f-4f4a-b885-36a37693c9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542003483-172.17.0.14-1599316599665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-bfbc171c-59aa-4775-82d9-c224167d9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-0047459c-cda4-4abb-ab71-385777f12387,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-dc7cb9c0-6e03-41c5-a5ba-b84abae72522,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-db031a62-f1e8-47e0-bb8b-9151e1c88017,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-29e092d5-5e56-4a60-8de8-ce4933722a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-0c15c22d-4f29-41dc-81e4-42d6db25e3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-89934de1-56f2-48fb-b3dd-4d5893e32beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-27b55f34-0331-4f82-ac03-123379773ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542003483-172.17.0.14-1599316599665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-bfbc171c-59aa-4775-82d9-c224167d9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-0047459c-cda4-4abb-ab71-385777f12387,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-dc7cb9c0-6e03-41c5-a5ba-b84abae72522,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-db031a62-f1e8-47e0-bb8b-9151e1c88017,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-29e092d5-5e56-4a60-8de8-ce4933722a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-0c15c22d-4f29-41dc-81e4-42d6db25e3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-89934de1-56f2-48fb-b3dd-4d5893e32beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-27b55f34-0331-4f82-ac03-123379773ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883864758-172.17.0.14-1599316836350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-90b65f4d-490f-4ca3-906b-116d107c7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-8373215d-5171-4ffa-8abc-cbdd91736364,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-11d85cad-366a-44a0-901d-edfa0485bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-790debe0-67e7-4950-8b22-e8e9bd81b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3f778639-48fd-4379-ba73-12b09f65dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-f19dcb2d-1bb0-4262-8f94-401f4fa36661,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-fa98eb8d-ca9c-441f-a377-3acb0a6cb8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-ae914bbf-c0d4-4cbf-87d5-90bfdcbb0439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883864758-172.17.0.14-1599316836350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-90b65f4d-490f-4ca3-906b-116d107c7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-8373215d-5171-4ffa-8abc-cbdd91736364,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-11d85cad-366a-44a0-901d-edfa0485bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-790debe0-67e7-4950-8b22-e8e9bd81b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3f778639-48fd-4379-ba73-12b09f65dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-f19dcb2d-1bb0-4262-8f94-401f4fa36661,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-fa98eb8d-ca9c-441f-a377-3acb0a6cb8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-ae914bbf-c0d4-4cbf-87d5-90bfdcbb0439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117797941-172.17.0.14-1599316918728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-44c94fb7-660f-4dce-bfd8-7ca3d4d507b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-8b8eb5b0-d442-4dd3-80dc-2fbf605e8955,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-02793425-2997-4975-b5f5-2b9af87b30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-42d47e3d-0c03-4b00-a702-d10a85f0c540,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-69621046-e5bb-402d-b627-7073ab116d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1f20ef6c-04c5-4ad7-b5a3-375c7d648c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-b7fc602b-fc8d-4c8b-89f9-e63fe46930bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-897753d1-75ab-4ecf-94ca-7401b0f77e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117797941-172.17.0.14-1599316918728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-44c94fb7-660f-4dce-bfd8-7ca3d4d507b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-8b8eb5b0-d442-4dd3-80dc-2fbf605e8955,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-02793425-2997-4975-b5f5-2b9af87b30a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-42d47e3d-0c03-4b00-a702-d10a85f0c540,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-69621046-e5bb-402d-b627-7073ab116d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1f20ef6c-04c5-4ad7-b5a3-375c7d648c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-b7fc602b-fc8d-4c8b-89f9-e63fe46930bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-897753d1-75ab-4ecf-94ca-7401b0f77e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387187008-172.17.0.14-1599317099899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-4e328dfe-ef3d-4325-a97d-d238005ecace,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-5009273b-00f2-4990-b624-bd8b8af4de11,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-61f0d80d-0d71-4135-b087-c37eb6f277eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-76fa42a1-1129-4bd8-8fb0-d2d34a5b121d,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-c83c6b7d-0bd0-41c7-9dec-06453ee712ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d4ba9d98-9ed8-459c-a204-c7a38abd71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-4707caa5-dd83-40fb-986d-8d9b3efb99a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-9406aff7-0ae7-4e94-b3fb-55520e7ef5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387187008-172.17.0.14-1599317099899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-4e328dfe-ef3d-4325-a97d-d238005ecace,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-5009273b-00f2-4990-b624-bd8b8af4de11,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-61f0d80d-0d71-4135-b087-c37eb6f277eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-76fa42a1-1129-4bd8-8fb0-d2d34a5b121d,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-c83c6b7d-0bd0-41c7-9dec-06453ee712ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d4ba9d98-9ed8-459c-a204-c7a38abd71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-4707caa5-dd83-40fb-986d-8d9b3efb99a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-9406aff7-0ae7-4e94-b3fb-55520e7ef5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303317404-172.17.0.14-1599317532070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-65d1bceb-ff73-49c1-bfbc-766f2dce70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-573b1390-dcdd-4f76-a49f-f847612580a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-18ad597b-66d9-47ed-99a1-91d0c1eb62ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-686b9bba-e503-48fc-a219-4f728c46558e,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-79e00cc5-e5ae-4105-bc18-6581e0f503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-21751299-3b87-496b-8f82-3583c0faac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-14eba57b-8a5e-400c-8d13-565307390766,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-bcf20dba-1de2-4f94-8bdc-3a82f50122fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303317404-172.17.0.14-1599317532070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-65d1bceb-ff73-49c1-bfbc-766f2dce70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-573b1390-dcdd-4f76-a49f-f847612580a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-18ad597b-66d9-47ed-99a1-91d0c1eb62ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-686b9bba-e503-48fc-a219-4f728c46558e,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-79e00cc5-e5ae-4105-bc18-6581e0f503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-21751299-3b87-496b-8f82-3583c0faac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-14eba57b-8a5e-400c-8d13-565307390766,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-bcf20dba-1de2-4f94-8bdc-3a82f50122fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843566691-172.17.0.14-1599317643352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-30351fe8-97f4-44ad-8166-a7c5bebea841,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-b675e509-97ec-4159-bbef-c1c87c3d889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-d7905c6a-afaa-4cbd-afd8-13f58a3b5aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-bf859571-6649-4497-b122-a32967a7323c,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e19d6995-603e-4146-b180-04f5c03c151e,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-5078fd7d-5772-400e-a54f-f4dcaf0ac39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-7ebde618-14d7-43e3-956e-bcd42e00cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-73ae0a0c-7dfd-4587-8731-b0c283c3cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843566691-172.17.0.14-1599317643352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-30351fe8-97f4-44ad-8166-a7c5bebea841,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-b675e509-97ec-4159-bbef-c1c87c3d889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-d7905c6a-afaa-4cbd-afd8-13f58a3b5aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-bf859571-6649-4497-b122-a32967a7323c,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e19d6995-603e-4146-b180-04f5c03c151e,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-5078fd7d-5772-400e-a54f-f4dcaf0ac39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-7ebde618-14d7-43e3-956e-bcd42e00cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-73ae0a0c-7dfd-4587-8731-b0c283c3cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455380777-172.17.0.14-1599317672544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38927,DS-d46239a9-1d7c-49e2-9eaa-2355b093e193,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-2a7ba857-327d-4088-8dc1-bef8c57f28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-45c76a24-7647-46f0-8415-1151c970f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-f0377cc5-df57-464e-8d7a-cce8cfb96a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-eb5fc104-9f32-4052-a93a-75371cfe7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-3dafe247-97e5-4e31-a94a-5b779b490bee,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-8ef21a84-bf30-4772-8e91-1db8095d6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-dd68f163-1164-481c-bc86-1dacc1bc430f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455380777-172.17.0.14-1599317672544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38927,DS-d46239a9-1d7c-49e2-9eaa-2355b093e193,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-2a7ba857-327d-4088-8dc1-bef8c57f28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-45c76a24-7647-46f0-8415-1151c970f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-f0377cc5-df57-464e-8d7a-cce8cfb96a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-eb5fc104-9f32-4052-a93a-75371cfe7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-3dafe247-97e5-4e31-a94a-5b779b490bee,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-8ef21a84-bf30-4772-8e91-1db8095d6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-dd68f163-1164-481c-bc86-1dacc1bc430f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401113738-172.17.0.14-1599317821768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-4ff02ea3-7ff8-4450-9841-4c3e00a50375,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-008d8bbb-fa43-4ea3-a791-dbe946fe3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-c8966566-2d19-4824-9771-d7f22fe2a764,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-67285638-6141-4b59-b932-433355ea9083,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e5d39071-90e6-4c42-bff7-d9e405dbf268,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-9f18d90a-5e9e-4028-9023-48c871f207f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6002079b-13db-4f0f-855a-3304111c8d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-4b4bc4a9-3435-4432-8e9a-120a9a5cca83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401113738-172.17.0.14-1599317821768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-4ff02ea3-7ff8-4450-9841-4c3e00a50375,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-008d8bbb-fa43-4ea3-a791-dbe946fe3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-c8966566-2d19-4824-9771-d7f22fe2a764,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-67285638-6141-4b59-b932-433355ea9083,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e5d39071-90e6-4c42-bff7-d9e405dbf268,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-9f18d90a-5e9e-4028-9023-48c871f207f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6002079b-13db-4f0f-855a-3304111c8d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-4b4bc4a9-3435-4432-8e9a-120a9a5cca83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100046051-172.17.0.14-1599317893967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-301c6ad0-2d67-4946-a5a2-1c95e093f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-6acd784b-6c26-4780-9708-65055b32b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-5493aa18-a7ea-4158-9ae8-f6e7184faf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-f3b1a37e-77a8-449e-90e5-a533fe96cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-9ba71286-71dc-4738-b92d-b7b00a8d233f,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-f6d2ddc1-59e6-4449-b3cd-afd951229d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-599806f5-078c-4851-8c1d-13ac675af227,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-d31cd94f-5d33-46d7-ad55-bb28b9573d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100046051-172.17.0.14-1599317893967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39959,DS-301c6ad0-2d67-4946-a5a2-1c95e093f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-6acd784b-6c26-4780-9708-65055b32b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-5493aa18-a7ea-4158-9ae8-f6e7184faf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-f3b1a37e-77a8-449e-90e5-a533fe96cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-9ba71286-71dc-4738-b92d-b7b00a8d233f,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-f6d2ddc1-59e6-4449-b3cd-afd951229d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-599806f5-078c-4851-8c1d-13ac675af227,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-d31cd94f-5d33-46d7-ad55-bb28b9573d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995288459-172.17.0.14-1599318061003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-3de1624c-aec3-49ab-bea0-ae6e94bbcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-f159cf0f-01ec-4665-9936-29024ecae51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b1130bc5-a2df-4024-8b65-4fe81dcc9418,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-5e66837f-d091-4164-8603-7385352d8cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-5feef603-4c13-4174-8a31-e80e10d24436,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-236027b7-3026-414a-abe3-4873fbf264db,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-6cb83d65-10d5-41d2-bf3a-c6033873b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-1b3a0263-8a38-4170-b7f2-f772e1286032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995288459-172.17.0.14-1599318061003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-3de1624c-aec3-49ab-bea0-ae6e94bbcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-f159cf0f-01ec-4665-9936-29024ecae51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b1130bc5-a2df-4024-8b65-4fe81dcc9418,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-5e66837f-d091-4164-8603-7385352d8cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-5feef603-4c13-4174-8a31-e80e10d24436,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-236027b7-3026-414a-abe3-4873fbf264db,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-6cb83d65-10d5-41d2-bf3a-c6033873b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-1b3a0263-8a38-4170-b7f2-f772e1286032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143466892-172.17.0.14-1599318823838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-0f002813-7067-48cc-99bf-12eb131aa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-72cb5a96-355b-40b9-b052-73fec77e144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-75eedaad-4aaf-443c-8087-88c27f2f8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-0c48d351-557d-4029-b182-48a275820266,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-42e6bc53-9e54-4b93-abc0-0afe8e92553b,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-52c76745-27ab-496b-8d7c-a69b809d9e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-ff8de774-cc05-4251-b969-24ff0edd1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-be19ca1f-9ad3-422a-9a18-1287cd14ee2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143466892-172.17.0.14-1599318823838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-0f002813-7067-48cc-99bf-12eb131aa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-72cb5a96-355b-40b9-b052-73fec77e144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-75eedaad-4aaf-443c-8087-88c27f2f8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-0c48d351-557d-4029-b182-48a275820266,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-42e6bc53-9e54-4b93-abc0-0afe8e92553b,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-52c76745-27ab-496b-8d7c-a69b809d9e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-ff8de774-cc05-4251-b969-24ff0edd1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-be19ca1f-9ad3-422a-9a18-1287cd14ee2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460818830-172.17.0.14-1599318863567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-d9e344c4-9ea2-43ab-b558-c6a2c8862145,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-ab5e6012-e060-44b8-8d20-e4ee49bbb9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-cca80577-ff78-48c0-865c-dc92b8d57ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9151e813-e17d-49cc-ac36-727a7630ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-910addc6-be74-4c55-b4a4-a8da739c80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-9226cf18-e007-4641-b840-58d2dbb9150a,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-516eda68-edba-40c5-a2d9-b0d3d2ea7775,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-ea815265-affc-492f-be9c-8a7eaf9027b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460818830-172.17.0.14-1599318863567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-d9e344c4-9ea2-43ab-b558-c6a2c8862145,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-ab5e6012-e060-44b8-8d20-e4ee49bbb9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-cca80577-ff78-48c0-865c-dc92b8d57ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9151e813-e17d-49cc-ac36-727a7630ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-910addc6-be74-4c55-b4a4-a8da739c80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-9226cf18-e007-4641-b840-58d2dbb9150a,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-516eda68-edba-40c5-a2d9-b0d3d2ea7775,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-ea815265-affc-492f-be9c-8a7eaf9027b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5335
