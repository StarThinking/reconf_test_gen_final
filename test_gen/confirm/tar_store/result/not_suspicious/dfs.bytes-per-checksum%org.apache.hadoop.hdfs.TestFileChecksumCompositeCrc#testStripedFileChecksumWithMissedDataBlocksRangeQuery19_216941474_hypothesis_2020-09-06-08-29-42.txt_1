reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262726648-172.17.0.5-1599381545224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-c8d578d6-8f76-4814-b3cc-06874bb329a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-569576e8-b7ee-4568-85c3-8b1dbdf8e632,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-d1eacace-32a1-44d7-aa9a-eba79ea7d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-eda29015-f615-42f5-a255-238b7f37b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-af253b60-d636-49cc-9ddc-6530256931cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-467d2f41-9573-40ae-9f05-0ed6e8e97750,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f59388f1-e720-498f-bbec-87efe42f5d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-03804a58-010e-45db-ba79-992f14ab084d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262726648-172.17.0.5-1599381545224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-c8d578d6-8f76-4814-b3cc-06874bb329a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-569576e8-b7ee-4568-85c3-8b1dbdf8e632,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-d1eacace-32a1-44d7-aa9a-eba79ea7d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-eda29015-f615-42f5-a255-238b7f37b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-af253b60-d636-49cc-9ddc-6530256931cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-467d2f41-9573-40ae-9f05-0ed6e8e97750,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f59388f1-e720-498f-bbec-87efe42f5d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-03804a58-010e-45db-ba79-992f14ab084d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195078728-172.17.0.5-1599381667581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-f7484728-319d-41ba-94b9-339b8aedd2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5045c298-8e48-4528-baa0-6afeb99571f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ed0fc4ce-1848-4441-bbe1-ac9e74992166,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-40e9415a-17a0-4f81-bbf3-aa2b50b0f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-fd49ad67-67aa-4efb-bb36-ed741e2532ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-76d23d2e-b7aa-4d35-a7c5-1aaeb60fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-dca4b404-219e-4545-beef-45f4df5d2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-46d137e9-117a-41e6-b885-f0e5ab94d7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195078728-172.17.0.5-1599381667581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-f7484728-319d-41ba-94b9-339b8aedd2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5045c298-8e48-4528-baa0-6afeb99571f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ed0fc4ce-1848-4441-bbe1-ac9e74992166,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-40e9415a-17a0-4f81-bbf3-aa2b50b0f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-fd49ad67-67aa-4efb-bb36-ed741e2532ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-76d23d2e-b7aa-4d35-a7c5-1aaeb60fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-dca4b404-219e-4545-beef-45f4df5d2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-46d137e9-117a-41e6-b885-f0e5ab94d7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244527790-172.17.0.5-1599382503195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-01ff2b03-b631-4235-9c87-4974dfd850c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9297a69b-448b-4241-b76b-2fbf35fb0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-e01641ca-0230-491a-94cf-b452fa1d8626,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-a70c396c-c4c3-4835-93ca-3e701f2be4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-47666c80-67e9-4a94-8b46-515286b955da,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-029cad96-d4a1-454f-af54-23ef4ccd72a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-6486a3b7-3fe4-47e7-9bee-214a6450521b,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-8616e659-fcdb-461f-91f1-89b173c62e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244527790-172.17.0.5-1599382503195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-01ff2b03-b631-4235-9c87-4974dfd850c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9297a69b-448b-4241-b76b-2fbf35fb0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-e01641ca-0230-491a-94cf-b452fa1d8626,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-a70c396c-c4c3-4835-93ca-3e701f2be4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-47666c80-67e9-4a94-8b46-515286b955da,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-029cad96-d4a1-454f-af54-23ef4ccd72a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-6486a3b7-3fe4-47e7-9bee-214a6450521b,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-8616e659-fcdb-461f-91f1-89b173c62e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174806938-172.17.0.5-1599382708956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-20c17f20-ce89-41a8-a789-90adf698f588,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-e6f11b5c-8f04-4ec5-89a2-408fb87b4521,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-a9d244c8-47ca-4aef-96b8-0e39299c3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-1f25232c-4c8d-49c2-8f8a-a475442aa3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-7780e897-8f89-4dd7-82e5-71b1cedebd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-1a5d0969-3970-494f-96b7-a5588b6533c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-34882035-2665-4ecb-aafe-ec1df279cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-70d1634b-cf52-4948-bdd7-1ae6d48491fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174806938-172.17.0.5-1599382708956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-20c17f20-ce89-41a8-a789-90adf698f588,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-e6f11b5c-8f04-4ec5-89a2-408fb87b4521,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-a9d244c8-47ca-4aef-96b8-0e39299c3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-1f25232c-4c8d-49c2-8f8a-a475442aa3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-7780e897-8f89-4dd7-82e5-71b1cedebd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-1a5d0969-3970-494f-96b7-a5588b6533c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-34882035-2665-4ecb-aafe-ec1df279cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-70d1634b-cf52-4948-bdd7-1ae6d48491fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485493611-172.17.0.5-1599382988762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-d9913e1d-4b35-464c-8960-d5c9f096a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-849496a3-0e41-47f7-8fb0-679338c9dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-1e1a9dee-cf73-4e90-8353-93e957f8c19b,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-56f064c8-cbc9-4064-b25e-053f9d58c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f8bfbe0d-8cff-4cf4-b061-aac3e5e6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-36d88ad7-8234-470a-930e-b11c06b14736,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9a8ac3aa-f5cd-445a-ac74-02fec57d5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-febea679-45e6-4017-b292-fe183636c9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485493611-172.17.0.5-1599382988762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-d9913e1d-4b35-464c-8960-d5c9f096a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-849496a3-0e41-47f7-8fb0-679338c9dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-1e1a9dee-cf73-4e90-8353-93e957f8c19b,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-56f064c8-cbc9-4064-b25e-053f9d58c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f8bfbe0d-8cff-4cf4-b061-aac3e5e6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-36d88ad7-8234-470a-930e-b11c06b14736,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-9a8ac3aa-f5cd-445a-ac74-02fec57d5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-febea679-45e6-4017-b292-fe183636c9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119781847-172.17.0.5-1599383856824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-edc8e0f5-f55f-44c9-a440-399c1c0e9d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-ee171b3a-8b3c-4d33-97a0-ecba55f06421,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-7ac71ad3-9f7c-43af-945b-bd60571709e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-f58d7dd5-3b47-4b6f-ab47-cac483527d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c35c82d4-5595-4ac4-aca6-931c8fc1e376,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-2e5e0618-af07-438c-9733-6da4697be21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-14a24088-4713-4e32-b98c-1f85ba0f2387,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-2a381a96-75e5-45e2-a4ef-063199de0d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119781847-172.17.0.5-1599383856824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36388,DS-edc8e0f5-f55f-44c9-a440-399c1c0e9d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-ee171b3a-8b3c-4d33-97a0-ecba55f06421,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-7ac71ad3-9f7c-43af-945b-bd60571709e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-f58d7dd5-3b47-4b6f-ab47-cac483527d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c35c82d4-5595-4ac4-aca6-931c8fc1e376,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-2e5e0618-af07-438c-9733-6da4697be21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-14a24088-4713-4e32-b98c-1f85ba0f2387,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-2a381a96-75e5-45e2-a4ef-063199de0d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022261064-172.17.0.5-1599384019001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-a7d75818-3809-461f-989a-33cc26f7a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-df007d50-67d6-423e-9596-d5899e74dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-731e345b-124f-4918-b8f0-2670938166a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-2c300aa5-96db-4698-ab20-df98dfbdfda0,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-ca0af9a5-11c5-42fd-ac36-8ad7151505ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-b2d483e6-2e43-4d94-9c80-5db604f317c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-3b06ba95-128a-46e1-9d12-b6cd73a8c075,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-9d480489-3421-48e2-8372-0535d1a3399d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022261064-172.17.0.5-1599384019001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-a7d75818-3809-461f-989a-33cc26f7a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-df007d50-67d6-423e-9596-d5899e74dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-731e345b-124f-4918-b8f0-2670938166a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-2c300aa5-96db-4698-ab20-df98dfbdfda0,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-ca0af9a5-11c5-42fd-ac36-8ad7151505ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-b2d483e6-2e43-4d94-9c80-5db604f317c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-3b06ba95-128a-46e1-9d12-b6cd73a8c075,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-9d480489-3421-48e2-8372-0535d1a3399d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483880126-172.17.0.5-1599384681467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-69286aed-a84d-4f41-8075-bbfc9049f4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-44133448-5cc3-4dd3-b9f9-5d3c80f82d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-82b63941-bf7f-43bf-85ae-4186052b082c,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-7554540e-5801-499f-817f-7b52d83361b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3d826492-673a-4294-b0dc-fe25bb237f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-a58c721d-a33b-49ed-931a-a115b11e22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-e7b31b58-0b82-4fa5-bcc3-05abe33a6873,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-4232b57a-180a-41cf-9a3a-eb2a03250698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483880126-172.17.0.5-1599384681467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-69286aed-a84d-4f41-8075-bbfc9049f4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-44133448-5cc3-4dd3-b9f9-5d3c80f82d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-82b63941-bf7f-43bf-85ae-4186052b082c,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-7554540e-5801-499f-817f-7b52d83361b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3d826492-673a-4294-b0dc-fe25bb237f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-a58c721d-a33b-49ed-931a-a115b11e22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-e7b31b58-0b82-4fa5-bcc3-05abe33a6873,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-4232b57a-180a-41cf-9a3a-eb2a03250698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238591484-172.17.0.5-1599384783080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-da8b157d-6b36-4f52-8a99-ea683e4071e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-9c60bd8e-8267-423f-b678-586a2fd91f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-e650e644-508e-4615-ac7b-66ac996e53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-38294d91-e313-4542-b192-f7e9b3f05e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-9bcfdd8e-0c3a-4556-830d-cb26baa15544,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-0311cf5d-5e4e-44b1-92b5-e3044a2f9369,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-01089bfa-6441-4853-aca6-0e4e8d4751b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a9ed3794-9d6e-452e-8de6-d0fceae97946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238591484-172.17.0.5-1599384783080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34374,DS-da8b157d-6b36-4f52-8a99-ea683e4071e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-9c60bd8e-8267-423f-b678-586a2fd91f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-e650e644-508e-4615-ac7b-66ac996e53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-38294d91-e313-4542-b192-f7e9b3f05e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-9bcfdd8e-0c3a-4556-830d-cb26baa15544,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-0311cf5d-5e4e-44b1-92b5-e3044a2f9369,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-01089bfa-6441-4853-aca6-0e4e8d4751b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a9ed3794-9d6e-452e-8de6-d0fceae97946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180084061-172.17.0.5-1599385251201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-3815f46e-ac1c-425a-a1ae-28207aa49ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-ef8ea3b1-0007-4ee7-8dd3-e7bb24c4bd29,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-eb08266f-233f-4f4e-9b2e-68ad5e98a096,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-2f76f9bc-3d60-41d9-ac73-593fc96f1093,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-a4b78f00-40c4-4c90-a20e-2c36ddc03bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7978197c-e7c6-4703-b5d2-f94252fc1015,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-f0fb6858-43e4-44e8-97f5-993b6fb2cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-30ae2d91-0ae3-4a5d-bd40-07bd7c54563f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180084061-172.17.0.5-1599385251201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-3815f46e-ac1c-425a-a1ae-28207aa49ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-ef8ea3b1-0007-4ee7-8dd3-e7bb24c4bd29,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-eb08266f-233f-4f4e-9b2e-68ad5e98a096,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-2f76f9bc-3d60-41d9-ac73-593fc96f1093,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-a4b78f00-40c4-4c90-a20e-2c36ddc03bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7978197c-e7c6-4703-b5d2-f94252fc1015,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-f0fb6858-43e4-44e8-97f5-993b6fb2cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-30ae2d91-0ae3-4a5d-bd40-07bd7c54563f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212119554-172.17.0.5-1599385424793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-a66945f2-a926-4800-ab52-328d648dbe11,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-9d434fe5-ecdf-45d5-8778-d75b51ce8160,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-211684c2-55ea-43e7-a51d-345904ed69ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-2b6ea033-fdb9-4645-88d6-7aba1629d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d60e5629-1804-4792-ad76-f76aa12fd957,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-164d1770-eb59-4185-9944-30d4d5b285ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-0f2e92da-7836-425a-a3a4-8667b3da926d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-9aef19c6-2357-4eec-88c3-3970129fa7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212119554-172.17.0.5-1599385424793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-a66945f2-a926-4800-ab52-328d648dbe11,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-9d434fe5-ecdf-45d5-8778-d75b51ce8160,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-211684c2-55ea-43e7-a51d-345904ed69ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-2b6ea033-fdb9-4645-88d6-7aba1629d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d60e5629-1804-4792-ad76-f76aa12fd957,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-164d1770-eb59-4185-9944-30d4d5b285ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-0f2e92da-7836-425a-a3a4-8667b3da926d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-9aef19c6-2357-4eec-88c3-3970129fa7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972244110-172.17.0.5-1599386327347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-d5918843-16b3-4f4e-b61d-5d7d3bbcc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-93687c4f-90cd-499c-b839-9635704472e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-964a430f-1d40-4b41-88b0-942ba2673c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-82943ec7-3de7-4459-80dd-feb3a44fdb24,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-3cd082c5-708b-4fa3-b0c5-f4e1f420198e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-015f6c71-d8b9-4b0b-b0c3-a070d5dbf03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d94eabba-9489-4867-83a5-0836c0ccc8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d1258c09-b0cd-4a2a-a315-0b1b36948992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972244110-172.17.0.5-1599386327347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-d5918843-16b3-4f4e-b61d-5d7d3bbcc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-93687c4f-90cd-499c-b839-9635704472e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-964a430f-1d40-4b41-88b0-942ba2673c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-82943ec7-3de7-4459-80dd-feb3a44fdb24,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-3cd082c5-708b-4fa3-b0c5-f4e1f420198e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-015f6c71-d8b9-4b0b-b0c3-a070d5dbf03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d94eabba-9489-4867-83a5-0836c0ccc8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d1258c09-b0cd-4a2a-a315-0b1b36948992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391522574-172.17.0.5-1599386358081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-439ede3e-9e1e-4b36-b32b-6f9fbb51d271,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-843e2a8b-c198-4ee9-956a-5a5b9c0d24de,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-be4444bd-0f3d-42b5-b369-22ab5bf174ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-d2da65c1-8878-4588-a85e-062534908b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-a315d11c-7ce9-4bc6-adb8-9d0194415e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6228aeee-c52c-4f3c-b4b8-5daa48cd999e,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e364794d-8a79-4592-be52-29d7f77aaea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-c2c0f792-6650-4f2e-b67c-2041d2e91c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391522574-172.17.0.5-1599386358081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-439ede3e-9e1e-4b36-b32b-6f9fbb51d271,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-843e2a8b-c198-4ee9-956a-5a5b9c0d24de,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-be4444bd-0f3d-42b5-b369-22ab5bf174ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-d2da65c1-8878-4588-a85e-062534908b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-a315d11c-7ce9-4bc6-adb8-9d0194415e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6228aeee-c52c-4f3c-b4b8-5daa48cd999e,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e364794d-8a79-4592-be52-29d7f77aaea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-c2c0f792-6650-4f2e-b67c-2041d2e91c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5498
