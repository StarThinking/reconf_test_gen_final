reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109175608-172.17.0.8-1599306561985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-1541eb52-5499-45d5-b27d-399ecdd1431c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-2785d72a-22d8-442a-aaa4-deb004e8984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-39d35417-24d5-4da8-be11-ab0830675309,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a7cd1c35-8bb2-4653-a074-1ea644c70367,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-48cf9a34-7e8a-4821-8138-aac0ee96c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-19164906-dc2b-4480-93aa-94d924b31101,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-3e6b6398-4573-4bb4-8c49-17976fd18a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-86d76d71-285b-47b6-ab2b-22ac42b3d5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109175608-172.17.0.8-1599306561985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-1541eb52-5499-45d5-b27d-399ecdd1431c,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-2785d72a-22d8-442a-aaa4-deb004e8984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-39d35417-24d5-4da8-be11-ab0830675309,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a7cd1c35-8bb2-4653-a074-1ea644c70367,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-48cf9a34-7e8a-4821-8138-aac0ee96c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-19164906-dc2b-4480-93aa-94d924b31101,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-3e6b6398-4573-4bb4-8c49-17976fd18a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-86d76d71-285b-47b6-ab2b-22ac42b3d5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537135516-172.17.0.8-1599306595609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-d51b32d1-9dc1-44d1-b3ac-f98f7e6222d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-3b670e29-cfec-4daa-9270-89587922616f,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-37f214cd-e8b2-462c-8f1a-b7687a38126b,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-7c41ec55-3cef-48ed-b9c3-231fe41605fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-4f22c33b-7f15-40f5-a38e-5857ba288cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-4f7f6004-5d89-467a-83f9-586c6fe822a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-443e1349-51e9-4df3-9c8a-24271c082433,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-cb7b72bc-6784-4ee1-977a-bc8b2bedcb4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537135516-172.17.0.8-1599306595609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-d51b32d1-9dc1-44d1-b3ac-f98f7e6222d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-3b670e29-cfec-4daa-9270-89587922616f,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-37f214cd-e8b2-462c-8f1a-b7687a38126b,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-7c41ec55-3cef-48ed-b9c3-231fe41605fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-4f22c33b-7f15-40f5-a38e-5857ba288cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-4f7f6004-5d89-467a-83f9-586c6fe822a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-443e1349-51e9-4df3-9c8a-24271c082433,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-cb7b72bc-6784-4ee1-977a-bc8b2bedcb4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686340750-172.17.0.8-1599306880314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-5cf5a514-b2fb-4085-8ac4-ccbfbbf21706,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8ff1580a-79e2-4c16-ab7f-0bb713d9c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-9f4c2d0b-7958-4287-b8b3-1749ba18f599,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-16acd72d-5d77-4c83-8fe4-3ef3c7ab01a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b37c52eb-ca17-4f05-8531-90f6d7d136b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-9eafff62-fa45-47d9-a96d-9c71fa089394,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9b1c4123-a836-4151-a731-29ba1fa4a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-01086557-5ece-4c29-b8d4-bb9f8b18ab31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686340750-172.17.0.8-1599306880314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-5cf5a514-b2fb-4085-8ac4-ccbfbbf21706,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-8ff1580a-79e2-4c16-ab7f-0bb713d9c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-9f4c2d0b-7958-4287-b8b3-1749ba18f599,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-16acd72d-5d77-4c83-8fe4-3ef3c7ab01a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b37c52eb-ca17-4f05-8531-90f6d7d136b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-9eafff62-fa45-47d9-a96d-9c71fa089394,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-9b1c4123-a836-4151-a731-29ba1fa4a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-01086557-5ece-4c29-b8d4-bb9f8b18ab31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225658572-172.17.0.8-1599307157554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-c5a58176-9cef-44b1-b906-da785093496c,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-ea982cf4-8bd2-44d2-bdd2-4e7ba666c7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-f770921b-5a2c-4fc7-b517-80be581f57ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-130c302f-8310-438f-b8d5-cd39c5a9d686,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-42356faf-3163-48a5-bd9c-a2bc0ff86d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-763ab7b1-962c-4470-8103-cd106a9a881b,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6fb84571-7f29-4d59-a695-64a88c6a713e,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-949f69cf-143c-44a1-bf4c-f6d46beb41b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225658572-172.17.0.8-1599307157554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-c5a58176-9cef-44b1-b906-da785093496c,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-ea982cf4-8bd2-44d2-bdd2-4e7ba666c7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-f770921b-5a2c-4fc7-b517-80be581f57ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-130c302f-8310-438f-b8d5-cd39c5a9d686,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-42356faf-3163-48a5-bd9c-a2bc0ff86d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-763ab7b1-962c-4470-8103-cd106a9a881b,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-6fb84571-7f29-4d59-a695-64a88c6a713e,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-949f69cf-143c-44a1-bf4c-f6d46beb41b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248361573-172.17.0.8-1599307505415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-cf9557f0-f9ef-4de8-a228-4bcef9665705,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6de3b3b3-ff65-4feb-8a6b-aa3acf60e881,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-2227e4eb-7ea2-42d8-897a-ed1fca699f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-1f00eacf-5419-40f9-aaf1-f9ad7b7c62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2aef6668-2526-4286-8933-2bec6868d601,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-a90b7eaa-6cc3-4df8-8b8f-a73825c71245,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-92cd75ba-b6e7-4452-b1cc-7b6f269fdc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-2aa80b89-6aea-4dff-8e7f-365cdec44401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248361573-172.17.0.8-1599307505415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37911,DS-cf9557f0-f9ef-4de8-a228-4bcef9665705,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6de3b3b3-ff65-4feb-8a6b-aa3acf60e881,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-2227e4eb-7ea2-42d8-897a-ed1fca699f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-1f00eacf-5419-40f9-aaf1-f9ad7b7c62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2aef6668-2526-4286-8933-2bec6868d601,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-a90b7eaa-6cc3-4df8-8b8f-a73825c71245,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-92cd75ba-b6e7-4452-b1cc-7b6f269fdc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-2aa80b89-6aea-4dff-8e7f-365cdec44401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105754151-172.17.0.8-1599308073826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-d23f96f8-1458-473c-980c-244086347078,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-888a48af-0d2d-4078-863c-d6baa793cf78,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-3d36f6fe-4e32-4c7f-b0f5-c83b006f7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-8aa01bb3-7a8f-476d-a2eb-ca6f51cba3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-425c5f57-36ab-47ab-be76-88b0938cfb17,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-111e3270-116f-41a1-af71-2a0130b85bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-63b2fac8-eb8e-4365-87eb-8e533643829e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-b2e7a214-71f6-4a1e-b7f5-fd7c771e16ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105754151-172.17.0.8-1599308073826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39147,DS-d23f96f8-1458-473c-980c-244086347078,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-888a48af-0d2d-4078-863c-d6baa793cf78,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-3d36f6fe-4e32-4c7f-b0f5-c83b006f7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-8aa01bb3-7a8f-476d-a2eb-ca6f51cba3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-425c5f57-36ab-47ab-be76-88b0938cfb17,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-111e3270-116f-41a1-af71-2a0130b85bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-63b2fac8-eb8e-4365-87eb-8e533643829e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-b2e7a214-71f6-4a1e-b7f5-fd7c771e16ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585534159-172.17.0.8-1599308364391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-87fad46c-3ccb-433a-b6d2-be4769470f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-d4e13939-8b19-484a-8ebd-893d78e9982e,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-0d48ae75-345d-4cea-a08f-3fef75d8550b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-52eb6b6f-777c-416c-a612-2ca72a0318d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-fb26e673-30e8-4933-bfdc-056b3f49e220,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a8d8ed98-0b0b-4701-8759-9da9a21de6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-1b32e463-2ff5-4cc8-9a61-e316e8ebe2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-2e4229c4-d83c-4113-b466-f7aa37dbc3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585534159-172.17.0.8-1599308364391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-87fad46c-3ccb-433a-b6d2-be4769470f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-d4e13939-8b19-484a-8ebd-893d78e9982e,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-0d48ae75-345d-4cea-a08f-3fef75d8550b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-52eb6b6f-777c-416c-a612-2ca72a0318d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-fb26e673-30e8-4933-bfdc-056b3f49e220,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a8d8ed98-0b0b-4701-8759-9da9a21de6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-1b32e463-2ff5-4cc8-9a61-e316e8ebe2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-2e4229c4-d83c-4113-b466-f7aa37dbc3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748133344-172.17.0.8-1599308809344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-2bbe3649-ba96-4bd8-831f-a33204faf9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-c40720b3-695e-499e-9f65-c8610256844c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-4aa2f095-40b0-4c1f-a019-e3343cf6e045,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ec6626a7-b16e-4d28-822b-6fa82684b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-4e1879d4-59e2-4748-a009-73fb12030831,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-b33b3713-2ed9-422b-bbb8-879d49fb7697,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-adb196cb-132f-437b-98dc-0a94a245b2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-8d170a18-12a3-46db-8ece-b0f3d7810e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748133344-172.17.0.8-1599308809344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-2bbe3649-ba96-4bd8-831f-a33204faf9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-c40720b3-695e-499e-9f65-c8610256844c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-4aa2f095-40b0-4c1f-a019-e3343cf6e045,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ec6626a7-b16e-4d28-822b-6fa82684b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-4e1879d4-59e2-4748-a009-73fb12030831,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-b33b3713-2ed9-422b-bbb8-879d49fb7697,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-adb196cb-132f-437b-98dc-0a94a245b2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-8d170a18-12a3-46db-8ece-b0f3d7810e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094483348-172.17.0.8-1599309091304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-69b1d460-5891-4c37-878e-a793f0991509,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-401501ec-a9ec-4fc7-80f7-efe1173d8e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-29bbf4c9-d7d2-4459-b6bb-764621268ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-aca3112b-801c-439f-8905-1b44c2c83968,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-931cc619-acb1-4a1a-9123-a7eee8e29c07,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a78b4f4e-449b-4dbb-aa6b-a72f0531114c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f5297587-2274-45e3-8444-b038067d8500,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e58335fe-fbe0-400a-b63a-139611cdae7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094483348-172.17.0.8-1599309091304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-69b1d460-5891-4c37-878e-a793f0991509,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-401501ec-a9ec-4fc7-80f7-efe1173d8e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-29bbf4c9-d7d2-4459-b6bb-764621268ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-aca3112b-801c-439f-8905-1b44c2c83968,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-931cc619-acb1-4a1a-9123-a7eee8e29c07,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a78b4f4e-449b-4dbb-aa6b-a72f0531114c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f5297587-2274-45e3-8444-b038067d8500,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e58335fe-fbe0-400a-b63a-139611cdae7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989670698-172.17.0.8-1599309165164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-1e73b541-cd2a-42cf-ba5c-0e76bd408f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-60675b04-32ff-430c-8886-863f72604e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-315901ad-1b91-42f9-8c21-8f3a8cfb542d,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-29220e05-ffef-4d51-ac5c-d978457d4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-840c2cb9-5bd9-40aa-8cab-55c93c7a4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-2e33f31d-0a88-4ee0-8d81-c5259df9983c,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-9d91158d-d6e0-48bd-aa77-69fcb5fcd5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-df71034a-2b9a-4f2e-89f7-8559a066898a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989670698-172.17.0.8-1599309165164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-1e73b541-cd2a-42cf-ba5c-0e76bd408f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-60675b04-32ff-430c-8886-863f72604e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-315901ad-1b91-42f9-8c21-8f3a8cfb542d,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-29220e05-ffef-4d51-ac5c-d978457d4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-840c2cb9-5bd9-40aa-8cab-55c93c7a4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-2e33f31d-0a88-4ee0-8d81-c5259df9983c,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-9d91158d-d6e0-48bd-aa77-69fcb5fcd5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-df71034a-2b9a-4f2e-89f7-8559a066898a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668529209-172.17.0.8-1599310094634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-5dc81cf7-0f89-4cd2-8823-4e851c26b75c,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-4f0ec6ea-15bf-4a5c-a2bd-7af901fdaf05,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4e0367c7-f4b1-44cc-b5e3-64ae7d8d82c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-2a5b5ba7-343b-4ca7-abdd-c36c709f90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-507c24e4-9565-4275-944e-83612c9af479,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-4648a2d9-cc77-407a-be8d-b591499a6456,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3c7e6a3b-590b-490b-bd99-7c27c84a2ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1789ca91-8a53-4360-8bc1-8de4c859a9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668529209-172.17.0.8-1599310094634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-5dc81cf7-0f89-4cd2-8823-4e851c26b75c,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-4f0ec6ea-15bf-4a5c-a2bd-7af901fdaf05,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4e0367c7-f4b1-44cc-b5e3-64ae7d8d82c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-2a5b5ba7-343b-4ca7-abdd-c36c709f90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-507c24e4-9565-4275-944e-83612c9af479,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-4648a2d9-cc77-407a-be8d-b591499a6456,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3c7e6a3b-590b-490b-bd99-7c27c84a2ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-1789ca91-8a53-4360-8bc1-8de4c859a9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820709441-172.17.0.8-1599310164048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-a727c3bf-2b7a-46e8-ab43-bd2b9c22e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-dcd09971-0f3a-45b7-aa0c-80ae65b8338c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-2f6d94e0-5daa-4333-9282-59c2bd52a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-e9faffd8-53a9-4486-b528-65b43b457792,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fe5a2bad-b23d-4bcd-813d-87e1bc65698d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2ce55547-7c2f-4084-8b54-9467dd03930f,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3c87ff7b-babe-40ab-9cd1-0a49a1c3c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-1ebc0d79-11c1-4ac2-84b5-4053b06cf6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820709441-172.17.0.8-1599310164048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-a727c3bf-2b7a-46e8-ab43-bd2b9c22e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-dcd09971-0f3a-45b7-aa0c-80ae65b8338c,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-2f6d94e0-5daa-4333-9282-59c2bd52a9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-e9faffd8-53a9-4486-b528-65b43b457792,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fe5a2bad-b23d-4bcd-813d-87e1bc65698d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2ce55547-7c2f-4084-8b54-9467dd03930f,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3c87ff7b-babe-40ab-9cd1-0a49a1c3c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-1ebc0d79-11c1-4ac2-84b5-4053b06cf6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347417143-172.17.0.8-1599310472413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-de26127e-f599-4856-afb5-d85093d389f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-ca293aea-72c0-422b-b957-5ead217cc89f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-2bcceae1-8512-46b3-8af0-c36e40af798d,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-d220c222-5cf5-4b64-bbc6-e141bb2f0d70,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-cc12d290-058c-48e2-a5ac-53b3aaffa737,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-5be09c1d-0c4d-44d3-8b32-0cc02bb2e229,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-b5b18eef-d788-48d2-98eb-e7151bfae212,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-ec0a6940-2d90-4e96-afc7-5bb927e2d3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347417143-172.17.0.8-1599310472413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-de26127e-f599-4856-afb5-d85093d389f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-ca293aea-72c0-422b-b957-5ead217cc89f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-2bcceae1-8512-46b3-8af0-c36e40af798d,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-d220c222-5cf5-4b64-bbc6-e141bb2f0d70,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-cc12d290-058c-48e2-a5ac-53b3aaffa737,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-5be09c1d-0c4d-44d3-8b32-0cc02bb2e229,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-b5b18eef-d788-48d2-98eb-e7151bfae212,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-ec0a6940-2d90-4e96-afc7-5bb927e2d3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074342309-172.17.0.8-1599310939010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-125724f0-891e-4fd8-ad0f-192029e1c231,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ed63e3bd-a8cd-449e-b41b-eeb51ca34f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-74d1fb9d-5893-419c-9aaf-61e8ef3edd24,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-41300e5e-d94c-4fba-9f72-74624df957d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-67ec8fcc-3086-4109-a2e0-20c47c85368d,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-88675134-2c60-40bc-864f-c7e1af4d5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-f4b46d44-30d3-4a3f-98c0-cc467887792e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-8f982255-dc62-4a5c-bf27-0c88cffe0c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074342309-172.17.0.8-1599310939010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-125724f0-891e-4fd8-ad0f-192029e1c231,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ed63e3bd-a8cd-449e-b41b-eeb51ca34f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-74d1fb9d-5893-419c-9aaf-61e8ef3edd24,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-41300e5e-d94c-4fba-9f72-74624df957d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-67ec8fcc-3086-4109-a2e0-20c47c85368d,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-88675134-2c60-40bc-864f-c7e1af4d5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-f4b46d44-30d3-4a3f-98c0-cc467887792e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-8f982255-dc62-4a5c-bf27-0c88cffe0c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970130029-172.17.0.8-1599310976683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-f518b368-fdef-408b-84e7-9fa226149484,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-be0e2406-aef7-4744-8182-5cafede6c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-f2aeeff3-b92e-4d08-acbc-87d4682c71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-53257e1b-fb1d-4b3f-8cfa-d6da0e5cc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-aa0581c4-9ebd-47f9-9d3b-57e41f14430b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-0b562cf0-1765-473c-a6bd-edd8951bf5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-53b62489-692f-425c-aae8-de0a495fe24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-dda5cf2b-7c68-412b-a590-9b8bb2bdc81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970130029-172.17.0.8-1599310976683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-f518b368-fdef-408b-84e7-9fa226149484,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-be0e2406-aef7-4744-8182-5cafede6c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-f2aeeff3-b92e-4d08-acbc-87d4682c71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-53257e1b-fb1d-4b3f-8cfa-d6da0e5cc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-aa0581c4-9ebd-47f9-9d3b-57e41f14430b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-0b562cf0-1765-473c-a6bd-edd8951bf5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-53b62489-692f-425c-aae8-de0a495fe24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-dda5cf2b-7c68-412b-a590-9b8bb2bdc81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5268
