reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609616398-172.17.0.19-1599309656378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33310,DS-6031d88e-29e0-45b5-a3aa-591c47521689,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ccfc392f-5d87-4683-b1f1-833f64de0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-386b3ac5-238c-4a09-92e0-3a48949e4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-359e6139-c64b-40a7-abcd-f5e2f9fbb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-b4ca8085-f734-4cfe-a6ad-217f3a6b473e,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-92fa781c-f56a-4087-985e-56a80bfca6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-fc0728d6-4dc4-4d83-8881-85dbdb7fe139,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-8a8e7f6d-bd58-4c8e-9e50-9b5c3605b339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609616398-172.17.0.19-1599309656378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33310,DS-6031d88e-29e0-45b5-a3aa-591c47521689,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ccfc392f-5d87-4683-b1f1-833f64de0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-386b3ac5-238c-4a09-92e0-3a48949e4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-359e6139-c64b-40a7-abcd-f5e2f9fbb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-b4ca8085-f734-4cfe-a6ad-217f3a6b473e,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-92fa781c-f56a-4087-985e-56a80bfca6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-fc0728d6-4dc4-4d83-8881-85dbdb7fe139,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-8a8e7f6d-bd58-4c8e-9e50-9b5c3605b339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669650554-172.17.0.19-1599309726390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-de1ceaca-795c-4ca4-bfb3-1260a2c2f624,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-d0487cdb-b0af-4b71-8f70-0ecbeac4b419,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-671fa259-515f-439e-9b5b-a352a01adeae,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-8049ee0e-3fed-4444-afa3-55178e4edff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7072c861-59c8-466f-a1d2-5191d415fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-17bda81f-e5dc-4ad6-8618-52bb13a1d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-82b27438-3689-4c33-8ec1-94574534f204,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-bd650fa7-3351-495b-942b-db0f519c44d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669650554-172.17.0.19-1599309726390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-de1ceaca-795c-4ca4-bfb3-1260a2c2f624,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-d0487cdb-b0af-4b71-8f70-0ecbeac4b419,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-671fa259-515f-439e-9b5b-a352a01adeae,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-8049ee0e-3fed-4444-afa3-55178e4edff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7072c861-59c8-466f-a1d2-5191d415fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-17bda81f-e5dc-4ad6-8618-52bb13a1d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-82b27438-3689-4c33-8ec1-94574534f204,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-bd650fa7-3351-495b-942b-db0f519c44d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091989770-172.17.0.19-1599310192474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-93c2f0d8-b8bd-43a3-a412-6338cd5737ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-7a5c201e-ed93-4ad2-90e8-17f336d69ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-3e18fffb-0100-461a-8603-d73d45fa82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2c4bd001-9fc1-4f82-8cbd-e4d6495802c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-f2efdb50-c43f-4638-9ceb-54f81cc51515,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-7b6b2dcb-aec6-44e2-a99c-65a8befd230f,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-c6f9b480-aeab-49e3-950b-47f25cfc4482,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c5527e39-b4f6-4517-b1c1-f14014121999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091989770-172.17.0.19-1599310192474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-93c2f0d8-b8bd-43a3-a412-6338cd5737ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-7a5c201e-ed93-4ad2-90e8-17f336d69ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-3e18fffb-0100-461a-8603-d73d45fa82ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2c4bd001-9fc1-4f82-8cbd-e4d6495802c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-f2efdb50-c43f-4638-9ceb-54f81cc51515,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-7b6b2dcb-aec6-44e2-a99c-65a8befd230f,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-c6f9b480-aeab-49e3-950b-47f25cfc4482,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c5527e39-b4f6-4517-b1c1-f14014121999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810422711-172.17.0.19-1599310272986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-ea8c8ce5-bb93-4a88-a807-20bc5bb26e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-0f2c9d83-5fda-45d0-b590-e4fa96814b31,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-e79df65e-4de9-4cc9-a08a-5b46d3f2394e,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-cd8534cb-3936-445d-b2ee-bd21f33a41b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-bac0320a-d940-40b7-9216-0eb54626a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-607a58da-1854-4367-8c00-5202d2995b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-2a5cac4f-df91-409c-9366-ea9c60f3aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-af667716-c4a0-49bf-8027-899e9b687871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810422711-172.17.0.19-1599310272986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-ea8c8ce5-bb93-4a88-a807-20bc5bb26e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-0f2c9d83-5fda-45d0-b590-e4fa96814b31,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-e79df65e-4de9-4cc9-a08a-5b46d3f2394e,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-cd8534cb-3936-445d-b2ee-bd21f33a41b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-bac0320a-d940-40b7-9216-0eb54626a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-607a58da-1854-4367-8c00-5202d2995b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-2a5cac4f-df91-409c-9366-ea9c60f3aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-af667716-c4a0-49bf-8027-899e9b687871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564196207-172.17.0.19-1599310345464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-8adc46b1-dfde-47f6-a596-4c932c90fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9176f7e6-7a05-4dc2-8f75-f610b19201ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-9dcab147-fee2-48d9-a9d8-ac8c67e8c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-7ed231b9-6ae6-49b0-b954-ba0c0c2c35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-dc1f0225-54e3-48f8-97d8-40830f30831d,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-d3d6b56e-4495-4e86-b6ee-120bcafc940a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-ac694376-e9a4-4296-9429-b5faf5712ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-9cdddbe7-fde4-405b-810a-dd80f3fe36df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564196207-172.17.0.19-1599310345464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-8adc46b1-dfde-47f6-a596-4c932c90fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9176f7e6-7a05-4dc2-8f75-f610b19201ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-9dcab147-fee2-48d9-a9d8-ac8c67e8c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-7ed231b9-6ae6-49b0-b954-ba0c0c2c35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-dc1f0225-54e3-48f8-97d8-40830f30831d,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-d3d6b56e-4495-4e86-b6ee-120bcafc940a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-ac694376-e9a4-4296-9429-b5faf5712ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-9cdddbe7-fde4-405b-810a-dd80f3fe36df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462366258-172.17.0.19-1599310602169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-213654cd-2b9a-4f76-8433-b1962a4356cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-66b928fa-c6e4-43f1-8f15-31da7a00370c,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-b0400c2e-b982-4037-b302-87f8e87d7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-6ce0854e-4385-4e32-8efc-c8ad2ddae1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-821852fa-7dae-4103-92de-3cc70997e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-47537c81-28c9-490c-aab0-1e3e9e9ae649,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-e2e05bda-19ae-4cd6-a97e-54656b063648,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-a96253aa-9074-4385-805a-0c9f2b41c4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462366258-172.17.0.19-1599310602169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-213654cd-2b9a-4f76-8433-b1962a4356cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-66b928fa-c6e4-43f1-8f15-31da7a00370c,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-b0400c2e-b982-4037-b302-87f8e87d7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-6ce0854e-4385-4e32-8efc-c8ad2ddae1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-821852fa-7dae-4103-92de-3cc70997e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-47537c81-28c9-490c-aab0-1e3e9e9ae649,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-e2e05bda-19ae-4cd6-a97e-54656b063648,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-a96253aa-9074-4385-805a-0c9f2b41c4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570109631-172.17.0.19-1599310638170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-57aff103-f220-4fa7-bb6e-c3e70e7d2c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-17c596a2-ac6a-4271-8277-ae65f6030932,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c9af31a7-f029-421d-b2f4-5ea8f1fd82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-1ebce389-6922-44f8-af63-a4680199ae64,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-b738d435-c38c-4dd9-963d-c3021ef4f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-ac691338-29a5-4a6c-88fd-56bac96d0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-8cdb05a9-579c-4546-bf51-338160a30846,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-f1520164-18be-4ac5-9297-dde0101febaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570109631-172.17.0.19-1599310638170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-57aff103-f220-4fa7-bb6e-c3e70e7d2c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-17c596a2-ac6a-4271-8277-ae65f6030932,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c9af31a7-f029-421d-b2f4-5ea8f1fd82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-1ebce389-6922-44f8-af63-a4680199ae64,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-b738d435-c38c-4dd9-963d-c3021ef4f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-ac691338-29a5-4a6c-88fd-56bac96d0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-8cdb05a9-579c-4546-bf51-338160a30846,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-f1520164-18be-4ac5-9297-dde0101febaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440928319-172.17.0.19-1599310705965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-9ddca45e-4660-47b4-91d4-c03983bef501,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4987fbb2-bb16-40b8-8bf5-360024d25087,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-550fbc13-db93-4ab9-9e44-964d74206a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-b8f9c4d5-4d83-4d1d-80cf-dd49225ffc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-eafe3515-eb79-4bda-a571-51fed6acaad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4943a40b-1836-4d0c-9ba5-cf3b4dc7c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-5b8da85f-f158-4a2e-944e-08003e3fb896,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-3865e02d-cfe7-4bd9-99f0-e212d11ec241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440928319-172.17.0.19-1599310705965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-9ddca45e-4660-47b4-91d4-c03983bef501,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4987fbb2-bb16-40b8-8bf5-360024d25087,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-550fbc13-db93-4ab9-9e44-964d74206a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-b8f9c4d5-4d83-4d1d-80cf-dd49225ffc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-eafe3515-eb79-4bda-a571-51fed6acaad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-4943a40b-1836-4d0c-9ba5-cf3b4dc7c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-5b8da85f-f158-4a2e-944e-08003e3fb896,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-3865e02d-cfe7-4bd9-99f0-e212d11ec241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965436030-172.17.0.19-1599310873100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43253,DS-82b997c9-df9f-44c0-b78c-dd1ada3143d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-98699d17-58e3-4dd4-8ba4-3fad11a48776,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-f1fc84df-fa0e-4bb0-8ae4-0c645b994b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-50aa6752-2e4f-45d0-b74a-dd7cee29df10,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-33f9d0f3-3d10-40ff-bc6f-0485b410b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-7887191a-911f-48bd-95f7-4e569c9bfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-0075838a-f392-48ea-9804-a85530d27a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-1c7445fc-a35e-471c-990e-263b4e954e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965436030-172.17.0.19-1599310873100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43253,DS-82b997c9-df9f-44c0-b78c-dd1ada3143d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-98699d17-58e3-4dd4-8ba4-3fad11a48776,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-f1fc84df-fa0e-4bb0-8ae4-0c645b994b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-50aa6752-2e4f-45d0-b74a-dd7cee29df10,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-33f9d0f3-3d10-40ff-bc6f-0485b410b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-7887191a-911f-48bd-95f7-4e569c9bfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-0075838a-f392-48ea-9804-a85530d27a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-1c7445fc-a35e-471c-990e-263b4e954e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58575358-172.17.0.19-1599310909455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-68fbbb8b-695b-4ae7-b13a-c66505dccdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e139b6e2-bbf1-4f14-ad4e-b94535dd3141,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-587d9dd0-d495-4435-8b1f-375cccf70b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-46ac7adf-a447-45a7-94bd-f68ec3a7eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-b858f3c3-46ea-4d32-8d0b-fe1ee898ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-c55b63a5-b614-4299-9127-82976f7154cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-70151d44-ccfe-4ed9-bc02-564cf449c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-25550eb4-cf16-465d-9d7f-2ac0b5df198b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58575358-172.17.0.19-1599310909455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-68fbbb8b-695b-4ae7-b13a-c66505dccdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e139b6e2-bbf1-4f14-ad4e-b94535dd3141,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-587d9dd0-d495-4435-8b1f-375cccf70b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-46ac7adf-a447-45a7-94bd-f68ec3a7eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-b858f3c3-46ea-4d32-8d0b-fe1ee898ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-c55b63a5-b614-4299-9127-82976f7154cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-70151d44-ccfe-4ed9-bc02-564cf449c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-25550eb4-cf16-465d-9d7f-2ac0b5df198b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309265990-172.17.0.19-1599311324475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-b718e4ff-dfe7-4d36-a5f3-35039e4a6326,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-05d89250-2a02-43bd-a53d-6b2333e45e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-ca621087-1cb2-43be-a994-982d56a7b78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-9773f88f-1f59-43e4-9b52-e45c91d9747a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-e23d27dc-de9a-496a-8676-5c7f50cb5168,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f0f6c748-bd1a-4b32-a527-852bed33040c,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-391e189e-e5e2-4957-90a6-ba2b8d33ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c4338d06-02fa-4488-9ade-f1421bbce454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309265990-172.17.0.19-1599311324475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-b718e4ff-dfe7-4d36-a5f3-35039e4a6326,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-05d89250-2a02-43bd-a53d-6b2333e45e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-ca621087-1cb2-43be-a994-982d56a7b78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-9773f88f-1f59-43e4-9b52-e45c91d9747a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-e23d27dc-de9a-496a-8676-5c7f50cb5168,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f0f6c748-bd1a-4b32-a527-852bed33040c,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-391e189e-e5e2-4957-90a6-ba2b8d33ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c4338d06-02fa-4488-9ade-f1421bbce454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396578323-172.17.0.19-1599311358574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2816c888-cfcf-48e4-b9ce-3a9da9cb3631,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-98c90542-7879-4ea9-b297-f9c1139c561f,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-e9d5e3d8-f302-408c-b903-4db3b279b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e33782bc-266a-475a-b9f2-228ab7759ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-cb4ee15a-513f-4a6e-ac01-dedae96e94d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-4a02774b-9661-4542-85bc-a59a012914c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-c31e3178-5869-41a0-8d8e-9b623a905eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-662619ee-6ee4-449b-b27d-d08a935e55c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396578323-172.17.0.19-1599311358574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-2816c888-cfcf-48e4-b9ce-3a9da9cb3631,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-98c90542-7879-4ea9-b297-f9c1139c561f,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-e9d5e3d8-f302-408c-b903-4db3b279b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e33782bc-266a-475a-b9f2-228ab7759ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-cb4ee15a-513f-4a6e-ac01-dedae96e94d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-4a02774b-9661-4542-85bc-a59a012914c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-c31e3178-5869-41a0-8d8e-9b623a905eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-662619ee-6ee4-449b-b27d-d08a935e55c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729470058-172.17.0.19-1599311509128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-625ab6b8-7ef4-4883-9abc-785234405665,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-e46878dc-e3dc-453b-9ad6-528b6dc9f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-531bb4a9-6e29-44de-9814-b04ac4730299,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-03dded4a-3076-420a-b4a3-0352349fec36,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-2cab453f-27c9-44df-815c-b36b3b76a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-828ed99e-7fdc-4b6c-9a89-0c09bbebbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-8f590521-1c12-44b8-a367-a4437dddbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-f25c41b8-fe5a-4b2c-90ae-4809e125d89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729470058-172.17.0.19-1599311509128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-625ab6b8-7ef4-4883-9abc-785234405665,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-e46878dc-e3dc-453b-9ad6-528b6dc9f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-531bb4a9-6e29-44de-9814-b04ac4730299,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-03dded4a-3076-420a-b4a3-0352349fec36,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-2cab453f-27c9-44df-815c-b36b3b76a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-828ed99e-7fdc-4b6c-9a89-0c09bbebbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-8f590521-1c12-44b8-a367-a4437dddbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-f25c41b8-fe5a-4b2c-90ae-4809e125d89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334648049-172.17.0.19-1599311640443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-ad262220-d8b3-4b71-b6cd-2b833647e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-a3196015-64c7-4f4a-97ec-130d1532ec52,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-87341313-e9c5-4dd5-b858-688dce2e13aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-79a180a0-dd37-49f1-b338-5c7fb740ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-20e31097-69ce-40a7-a738-23fcb8723644,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-bc4895f6-bf16-4262-b2de-d781025ba72e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-704c0d72-a2df-47e2-b367-4714c165cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-9c2e000b-da55-4397-9b18-cf390d57bf83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334648049-172.17.0.19-1599311640443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-ad262220-d8b3-4b71-b6cd-2b833647e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-a3196015-64c7-4f4a-97ec-130d1532ec52,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-87341313-e9c5-4dd5-b858-688dce2e13aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-79a180a0-dd37-49f1-b338-5c7fb740ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-20e31097-69ce-40a7-a738-23fcb8723644,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-bc4895f6-bf16-4262-b2de-d781025ba72e,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-704c0d72-a2df-47e2-b367-4714c165cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-9c2e000b-da55-4397-9b18-cf390d57bf83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877740827-172.17.0.19-1599311682052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37308,DS-b2dcefa0-ba9c-4066-8e63-2530c26ebd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-787cc2b5-f449-4350-80e6-8ba6861f7f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-7b661d0f-c8f8-4693-b888-b89c72775961,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-b3e6d1f5-aa7a-408b-88e7-687700a9781d,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b3c606fb-19ca-45a6-aaab-a39324bbaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-abbb7d3a-025e-4ea1-b859-4fb0986553d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-39fb732a-26d5-40be-a638-da88c5a3e679,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-21af43ce-3e9a-4d00-88ab-ef1840f20afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877740827-172.17.0.19-1599311682052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37308,DS-b2dcefa0-ba9c-4066-8e63-2530c26ebd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-787cc2b5-f449-4350-80e6-8ba6861f7f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-7b661d0f-c8f8-4693-b888-b89c72775961,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-b3e6d1f5-aa7a-408b-88e7-687700a9781d,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b3c606fb-19ca-45a6-aaab-a39324bbaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-abbb7d3a-025e-4ea1-b859-4fb0986553d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-39fb732a-26d5-40be-a638-da88c5a3e679,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-21af43ce-3e9a-4d00-88ab-ef1840f20afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688415889-172.17.0.19-1599311846742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-e8af48cf-77ff-4e11-81ba-f3f6a7d011fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-bf6ac4a0-0e1c-4287-9506-8140634ce555,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-f13b39a1-e7bb-4c6b-8a09-1b25219fc323,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-aa417222-ee56-4414-9159-b18980b50516,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-9a41020a-d9a1-49ac-8247-14ab6b8677d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-b70a2fd0-a011-432a-8d47-cd4c0afac885,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-893bbf55-4537-4212-8611-3e26dee9c332,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-d9341c81-6ec4-42de-95aa-09e5e55e601b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688415889-172.17.0.19-1599311846742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-e8af48cf-77ff-4e11-81ba-f3f6a7d011fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-bf6ac4a0-0e1c-4287-9506-8140634ce555,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-f13b39a1-e7bb-4c6b-8a09-1b25219fc323,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-aa417222-ee56-4414-9159-b18980b50516,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-9a41020a-d9a1-49ac-8247-14ab6b8677d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-b70a2fd0-a011-432a-8d47-cd4c0afac885,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-893bbf55-4537-4212-8611-3e26dee9c332,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-d9341c81-6ec4-42de-95aa-09e5e55e601b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560959637-172.17.0.19-1599312841018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-0ef06b63-09f2-423f-ab5f-4185c3f1d664,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-6e4436d7-2652-4ef3-acab-fff2dfaccc27,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6b03ce26-b2fd-4bbf-9882-4f5e8aefe6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-adcffbc7-b237-45ee-9519-37f7f29f040d,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-42ac1fce-7ba4-4bd5-80b4-4c002eab49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-039a6fa1-d081-4149-b7b0-1f510cd90051,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-55088492-3371-46c1-b0e5-59a79c6ad9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-84005dd2-3b84-495a-861d-a3534149351a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560959637-172.17.0.19-1599312841018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-0ef06b63-09f2-423f-ab5f-4185c3f1d664,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-6e4436d7-2652-4ef3-acab-fff2dfaccc27,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6b03ce26-b2fd-4bbf-9882-4f5e8aefe6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-adcffbc7-b237-45ee-9519-37f7f29f040d,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-42ac1fce-7ba4-4bd5-80b4-4c002eab49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-039a6fa1-d081-4149-b7b0-1f510cd90051,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-55088492-3371-46c1-b0e5-59a79c6ad9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-84005dd2-3b84-495a-861d-a3534149351a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211364007-172.17.0.19-1599312916470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-76149899-2c84-42a4-beb2-c6b631d6491a,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-49320a1e-ef60-4161-ac99-b33306f27f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-2d3b3671-c47b-4e95-aa8a-59469583a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-e442095a-7eb2-4a12-8e60-e85f11f3770a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-28f9ebeb-8a2d-492e-867a-dc720a60edad,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-90aa1162-25fa-49bc-b45b-ea19dd3cf4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-4c164f5c-885c-4004-ac89-9240874a898d,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-9ab35c9d-7d39-468d-b076-547ef14e35cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211364007-172.17.0.19-1599312916470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-76149899-2c84-42a4-beb2-c6b631d6491a,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-49320a1e-ef60-4161-ac99-b33306f27f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-2d3b3671-c47b-4e95-aa8a-59469583a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-e442095a-7eb2-4a12-8e60-e85f11f3770a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-28f9ebeb-8a2d-492e-867a-dc720a60edad,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-90aa1162-25fa-49bc-b45b-ea19dd3cf4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-4c164f5c-885c-4004-ac89-9240874a898d,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-9ab35c9d-7d39-468d-b076-547ef14e35cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215105558-172.17.0.19-1599313017041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-599b1813-cc43-40bd-9b1b-fb2f3b2ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-21cc847c-1347-4b97-807c-c1cdf164f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-ff94ab7e-b32b-4a07-aaf4-0e07030749a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-fc3a970d-bcfd-4d19-84c4-8ddf6378d869,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-57517d08-796a-4b16-b82c-da9537671dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-de97f1bf-6b70-43da-8d74-9e5ef2fbfcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-021b8526-1ddb-4821-8006-d974e299e343,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-17c13ae3-c221-4a64-a882-9f4f2a0b9b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215105558-172.17.0.19-1599313017041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-599b1813-cc43-40bd-9b1b-fb2f3b2ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-21cc847c-1347-4b97-807c-c1cdf164f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-ff94ab7e-b32b-4a07-aaf4-0e07030749a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-fc3a970d-bcfd-4d19-84c4-8ddf6378d869,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-57517d08-796a-4b16-b82c-da9537671dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-de97f1bf-6b70-43da-8d74-9e5ef2fbfcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-021b8526-1ddb-4821-8006-d974e299e343,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-17c13ae3-c221-4a64-a882-9f4f2a0b9b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770222819-172.17.0.19-1599313937577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-9ec3aa48-609c-4425-84f7-202e81fcdf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-96447289-4919-4f7d-9c70-c5b10f557bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-264227ec-0a83-45fc-a5b7-2322c72b739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-278a824b-7388-4d23-96f3-5f4356923d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-17431617-0904-4477-a814-42d68e6314ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-851076bb-1fb8-4171-8dac-3f66bbfd374d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-6ce3386b-6572-4593-bfd7-6a048dd89ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-bf6dbff4-6c2e-46a1-bac4-3a472e280bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770222819-172.17.0.19-1599313937577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-9ec3aa48-609c-4425-84f7-202e81fcdf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-96447289-4919-4f7d-9c70-c5b10f557bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-264227ec-0a83-45fc-a5b7-2322c72b739e,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-278a824b-7388-4d23-96f3-5f4356923d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-17431617-0904-4477-a814-42d68e6314ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-851076bb-1fb8-4171-8dac-3f66bbfd374d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-6ce3386b-6572-4593-bfd7-6a048dd89ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-bf6dbff4-6c2e-46a1-bac4-3a472e280bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18603041-172.17.0.19-1599314267336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-fb02b350-184e-4614-8043-cb8626e53fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-62c140ea-a56b-472e-b50f-fc07fe710521,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-3337a429-1067-41df-aa52-78f4d703dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-ddb306e1-17ad-4369-bb87-c98769168a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-9f3fd403-a41e-42a7-a1a6-c91466ab3223,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-eee00269-7777-4714-8286-a0d838b8a049,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-1833d9d4-da3d-4b02-b6d9-e3d23d8ab9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-5769fe72-7e30-46a1-bf3c-5e68fe30ca6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18603041-172.17.0.19-1599314267336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-fb02b350-184e-4614-8043-cb8626e53fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-62c140ea-a56b-472e-b50f-fc07fe710521,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-3337a429-1067-41df-aa52-78f4d703dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-ddb306e1-17ad-4369-bb87-c98769168a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-9f3fd403-a41e-42a7-a1a6-c91466ab3223,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-eee00269-7777-4714-8286-a0d838b8a049,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-1833d9d4-da3d-4b02-b6d9-e3d23d8ab9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-5769fe72-7e30-46a1-bf3c-5e68fe30ca6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496915255-172.17.0.19-1599314381887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45660,DS-6a3ed369-b57d-44fc-af17-b86ba7399a90,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-4f8fd387-657a-4714-ab74-19ae0fcff4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5df38225-a9c2-4db7-b718-0e4fcc2915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-f48b4141-c883-4253-afcf-597e2b198a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-300d2c10-d766-46ee-b01e-1a870452ed39,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-1e499ac2-ed5b-4876-81d2-e7c851467a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-e3b3859b-fd85-458d-96ce-5f25ff1b6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7218418c-cbaf-4edb-a71a-267b885f597b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496915255-172.17.0.19-1599314381887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45660,DS-6a3ed369-b57d-44fc-af17-b86ba7399a90,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-4f8fd387-657a-4714-ab74-19ae0fcff4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5df38225-a9c2-4db7-b718-0e4fcc2915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-f48b4141-c883-4253-afcf-597e2b198a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-300d2c10-d766-46ee-b01e-1a870452ed39,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-1e499ac2-ed5b-4876-81d2-e7c851467a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-e3b3859b-fd85-458d-96ce-5f25ff1b6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-7218418c-cbaf-4edb-a71a-267b885f597b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5283
