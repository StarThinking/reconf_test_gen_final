reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340791125-172.17.0.3-1599367315865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-7c4bdad8-c633-4554-ba09-a524c5ebc1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-45f8047a-34e4-4996-a560-dd84fe70fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-f14dbeeb-45bf-4a6c-9c64-8914f2b62e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-1b2bf767-fc24-455a-95c0-451d1c190b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-4a692af2-3765-4200-a94f-1cea0a7c4787,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7fda8d34-14d3-4421-95d8-a397911c0e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-d000044f-6fe7-4f3f-bcb3-90eb2671e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-05e12fcb-9a4a-4bbc-b6b7-57026c2eded2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340791125-172.17.0.3-1599367315865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-7c4bdad8-c633-4554-ba09-a524c5ebc1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-45f8047a-34e4-4996-a560-dd84fe70fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-f14dbeeb-45bf-4a6c-9c64-8914f2b62e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-1b2bf767-fc24-455a-95c0-451d1c190b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-4a692af2-3765-4200-a94f-1cea0a7c4787,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7fda8d34-14d3-4421-95d8-a397911c0e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-d000044f-6fe7-4f3f-bcb3-90eb2671e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-05e12fcb-9a4a-4bbc-b6b7-57026c2eded2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535104039-172.17.0.3-1599367599092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-4785d3e5-df16-4dc7-b4e3-554e708e287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-a50e2942-ceab-4a42-bb1c-1f0d2ee8f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5a763f15-b00f-490c-ab29-dc2c03a7d341,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2b982265-7ce0-4cc7-a4ce-cd30f1d1d835,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-58cb36da-f3f7-4d9a-8365-6af88e83e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-8349e109-bf29-4506-904d-0ba9240ae95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-bee332a6-5f65-46f0-8063-489a416445f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-73fe6040-60b0-4b88-b9c1-50ab769fab01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535104039-172.17.0.3-1599367599092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-4785d3e5-df16-4dc7-b4e3-554e708e287e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-a50e2942-ceab-4a42-bb1c-1f0d2ee8f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5a763f15-b00f-490c-ab29-dc2c03a7d341,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2b982265-7ce0-4cc7-a4ce-cd30f1d1d835,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-58cb36da-f3f7-4d9a-8365-6af88e83e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-8349e109-bf29-4506-904d-0ba9240ae95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-bee332a6-5f65-46f0-8063-489a416445f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-73fe6040-60b0-4b88-b9c1-50ab769fab01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721636394-172.17.0.3-1599367727662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46120,DS-9367a8f6-8a31-4b88-9274-d104f5f9b321,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-dea2eea0-5773-4e0b-85a1-b6b045af43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-605cab1c-b2fe-4866-a791-e2425a96de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-9915910f-0141-43d8-99d3-3635cbae287f,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-426f701e-9025-4b04-8a7a-525d6b9d1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-506f34a0-32af-4c1d-8505-41b5dafc0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-f670d45e-3682-4d6e-b09b-c7ad6a673458,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-fd40265b-d145-43be-ab1c-955f70989890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721636394-172.17.0.3-1599367727662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46120,DS-9367a8f6-8a31-4b88-9274-d104f5f9b321,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-dea2eea0-5773-4e0b-85a1-b6b045af43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-605cab1c-b2fe-4866-a791-e2425a96de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-9915910f-0141-43d8-99d3-3635cbae287f,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-426f701e-9025-4b04-8a7a-525d6b9d1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-506f34a0-32af-4c1d-8505-41b5dafc0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-f670d45e-3682-4d6e-b09b-c7ad6a673458,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-fd40265b-d145-43be-ab1c-955f70989890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980990164-172.17.0.3-1599367880170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-199bb335-e8f8-4f79-8ad7-294ec1824dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-44cac428-4aa7-4349-9eb2-d2c265c98d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-6c301366-d15c-4046-989e-1213147219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-1922a695-14f9-47db-8bb9-d5cad0520b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-4a2fadd1-b4b4-4708-ae8e-c42b4884bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-8f1cac43-d1f1-4ca3-8355-e5a4e4851196,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-1b7071d0-5b40-4854-a4bd-19cd075f2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-3c67ea87-38e4-4380-93e9-31d7d94614e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980990164-172.17.0.3-1599367880170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-199bb335-e8f8-4f79-8ad7-294ec1824dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-44cac428-4aa7-4349-9eb2-d2c265c98d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-6c301366-d15c-4046-989e-1213147219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-1922a695-14f9-47db-8bb9-d5cad0520b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-4a2fadd1-b4b4-4708-ae8e-c42b4884bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-8f1cac43-d1f1-4ca3-8355-e5a4e4851196,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-1b7071d0-5b40-4854-a4bd-19cd075f2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-3c67ea87-38e4-4380-93e9-31d7d94614e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453336757-172.17.0.3-1599368185357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-6a26c6e0-3a97-4514-972f-f12d413deb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-fce2578c-14c0-43d6-8711-17e712a35641,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-3c828f5e-364f-4e38-b0d5-c64ec80e1402,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-e4f35322-094d-42c2-bb21-5a5a1fa4f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2d667a10-176b-45dd-929f-79f531740b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-5cdb36c5-e5e6-449d-8eca-0909458bec88,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-a0d83e5e-fb8c-4159-ba8f-755da5f5ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-3605a2e9-e8c5-47aa-b8ea-540c876b6552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453336757-172.17.0.3-1599368185357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-6a26c6e0-3a97-4514-972f-f12d413deb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-fce2578c-14c0-43d6-8711-17e712a35641,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-3c828f5e-364f-4e38-b0d5-c64ec80e1402,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-e4f35322-094d-42c2-bb21-5a5a1fa4f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2d667a10-176b-45dd-929f-79f531740b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-5cdb36c5-e5e6-449d-8eca-0909458bec88,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-a0d83e5e-fb8c-4159-ba8f-755da5f5ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-3605a2e9-e8c5-47aa-b8ea-540c876b6552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766185685-172.17.0.3-1599368476049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-7ce05a75-14d8-4742-b57e-13279ff07599,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-93d26094-2dbd-4fc2-8150-c3aeaac8e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-61b5c3e6-8710-4716-af33-d392229f7b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-81cc4bc6-ac3b-4d8e-9a21-20b3d692c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-37ebb35a-38d2-4538-9adb-1c09a285745f,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6e7c2dca-de6e-4611-b29a-79529d74a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-1b57d9a3-7b12-4911-9aca-0546dbcd348b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-f11514af-bfc8-4b15-97ab-7c30278dd1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766185685-172.17.0.3-1599368476049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-7ce05a75-14d8-4742-b57e-13279ff07599,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-93d26094-2dbd-4fc2-8150-c3aeaac8e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-61b5c3e6-8710-4716-af33-d392229f7b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-81cc4bc6-ac3b-4d8e-9a21-20b3d692c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-37ebb35a-38d2-4538-9adb-1c09a285745f,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6e7c2dca-de6e-4611-b29a-79529d74a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-1b57d9a3-7b12-4911-9aca-0546dbcd348b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-f11514af-bfc8-4b15-97ab-7c30278dd1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908407897-172.17.0.3-1599368613245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-8c439827-7927-4418-867d-bb8ab4aefa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-196e3125-c273-447f-b8ec-980ac58570de,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-7be7200f-a865-4932-81c2-f2d28a9133e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-76fcc75f-73cd-4d4c-a778-948ab50c427c,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-a36e6b05-2889-43bd-8a0c-f3cf586420dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d5d7d0c1-6148-4a0d-bf0e-3a499777f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-3be7b3fd-aba5-4e70-a08d-96bd5e6a2468,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-a71b0305-b087-4a9d-93f8-44b5e92eb7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908407897-172.17.0.3-1599368613245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-8c439827-7927-4418-867d-bb8ab4aefa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-196e3125-c273-447f-b8ec-980ac58570de,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-7be7200f-a865-4932-81c2-f2d28a9133e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-76fcc75f-73cd-4d4c-a778-948ab50c427c,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-a36e6b05-2889-43bd-8a0c-f3cf586420dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d5d7d0c1-6148-4a0d-bf0e-3a499777f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-3be7b3fd-aba5-4e70-a08d-96bd5e6a2468,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-a71b0305-b087-4a9d-93f8-44b5e92eb7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41670542-172.17.0.3-1599368996861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-d7acbb10-fc3c-4011-aede-59d7107f1b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-020dd18e-6bef-4574-9b96-14ef6a724caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-d64426b4-21ab-4d40-bcb5-5c03b77be0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-c3da7431-8a6d-43f2-98a2-7f3e78791ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-3048406a-ed22-42e5-8763-b1510a8514c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-63c91fd2-95b6-4ef9-8345-f4e57e61012e,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3648f029-9a95-4e72-ba50-5f923f4a0250,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-ce1f9d4f-5bdc-4511-a313-76d8c6810149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41670542-172.17.0.3-1599368996861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-d7acbb10-fc3c-4011-aede-59d7107f1b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-020dd18e-6bef-4574-9b96-14ef6a724caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-d64426b4-21ab-4d40-bcb5-5c03b77be0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-c3da7431-8a6d-43f2-98a2-7f3e78791ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-3048406a-ed22-42e5-8763-b1510a8514c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-63c91fd2-95b6-4ef9-8345-f4e57e61012e,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3648f029-9a95-4e72-ba50-5f923f4a0250,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-ce1f9d4f-5bdc-4511-a313-76d8c6810149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105785839-172.17.0.3-1599369749097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-9250ac5e-3341-4bde-bb73-0a155b1856be,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-e48127e2-c6a1-4e98-b982-9965472ab460,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-c7a2edbe-039d-4aea-a497-e7c2fe2ee2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-d6a9cc59-b834-4765-b8cc-84b1f538b332,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4022732d-04e5-4e6e-8070-9e8affee20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-580c40b2-3c18-45dc-bd44-8f6684c7f8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b92f56a9-da61-4dd4-aadc-89df0c82f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9e438b04-a92c-4947-bf76-c73e13c45d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105785839-172.17.0.3-1599369749097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-9250ac5e-3341-4bde-bb73-0a155b1856be,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-e48127e2-c6a1-4e98-b982-9965472ab460,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-c7a2edbe-039d-4aea-a497-e7c2fe2ee2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-d6a9cc59-b834-4765-b8cc-84b1f538b332,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4022732d-04e5-4e6e-8070-9e8affee20bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-580c40b2-3c18-45dc-bd44-8f6684c7f8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b92f56a9-da61-4dd4-aadc-89df0c82f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-9e438b04-a92c-4947-bf76-c73e13c45d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984662403-172.17.0.3-1599369940398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-b0a9a321-e88b-4a2d-8cc1-2e8eab767756,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-2a3141c0-81b0-4258-aa28-188863651a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-6a320eaf-0135-42d6-a1f0-e22c20f962ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-e67d03f9-076f-4849-9355-970202738c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-175606cc-5f21-4e3e-aaab-bb07dbe1a410,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0b2552a7-c606-44bc-9783-56ecbc85542b,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-69b11df4-18c8-4f27-b5e8-e6c554e19840,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-3ec45398-535e-4171-9ff8-d9a0865c542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984662403-172.17.0.3-1599369940398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-b0a9a321-e88b-4a2d-8cc1-2e8eab767756,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-2a3141c0-81b0-4258-aa28-188863651a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-6a320eaf-0135-42d6-a1f0-e22c20f962ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-e67d03f9-076f-4849-9355-970202738c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-175606cc-5f21-4e3e-aaab-bb07dbe1a410,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0b2552a7-c606-44bc-9783-56ecbc85542b,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-69b11df4-18c8-4f27-b5e8-e6c554e19840,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-3ec45398-535e-4171-9ff8-d9a0865c542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985041547-172.17.0.3-1599370292271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-f6fd3c71-3eab-4684-9327-d3bc589f8244,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-ddabf106-9ecf-40fa-8efb-a35f47545123,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5efd6d15-181b-463a-9124-d0ac3acdf142,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-0ebfd2df-58e0-49c2-8671-b9fd832078eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-278d516f-a4ad-46dc-a092-4b80b57fd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-ed4c782d-40c0-48e0-8db2-01d73fa94e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-0c885eed-3c81-4a0e-ad65-b17ff8334bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-3a2a52cb-a4b3-41c4-a61b-76274aaaa4d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985041547-172.17.0.3-1599370292271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-f6fd3c71-3eab-4684-9327-d3bc589f8244,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-ddabf106-9ecf-40fa-8efb-a35f47545123,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5efd6d15-181b-463a-9124-d0ac3acdf142,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-0ebfd2df-58e0-49c2-8671-b9fd832078eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-278d516f-a4ad-46dc-a092-4b80b57fd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-ed4c782d-40c0-48e0-8db2-01d73fa94e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-0c885eed-3c81-4a0e-ad65-b17ff8334bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-3a2a52cb-a4b3-41c4-a61b-76274aaaa4d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316349588-172.17.0.3-1599370330931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-1f7ab5dd-02cf-4c37-bd35-46bc97c4f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-5a0d8f09-6d56-4ee2-8b3f-4b672f8b265f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-73371e84-08d3-4cd2-9d8e-42538e31d010,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-6419e4ef-3639-491b-9c23-af056e17f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-82f6e88f-25f6-4186-82a5-8ca46bb91ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-3cb44d80-abf9-4311-8831-2cd1127876e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-2932862b-d6c1-42e4-9d74-375efe460d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-71270932-3b4b-40d6-b73d-3b96eaa88630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316349588-172.17.0.3-1599370330931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-1f7ab5dd-02cf-4c37-bd35-46bc97c4f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-5a0d8f09-6d56-4ee2-8b3f-4b672f8b265f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-73371e84-08d3-4cd2-9d8e-42538e31d010,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-6419e4ef-3639-491b-9c23-af056e17f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-82f6e88f-25f6-4186-82a5-8ca46bb91ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-3cb44d80-abf9-4311-8831-2cd1127876e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-2932862b-d6c1-42e4-9d74-375efe460d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-71270932-3b4b-40d6-b73d-3b96eaa88630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229018654-172.17.0.3-1599370402493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-65d1027b-dbbc-4e16-92ca-e2014c217c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-6c0ecf0e-6fa6-44c8-a981-750727c66283,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c526f9cf-b928-4ec0-b43a-ea7c0d9af9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-ce419038-e557-4f4b-bb26-e2a256ca1848,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-33373fc1-e679-4b1c-9920-e071e57af589,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-b43b02ec-fa90-42e9-95b5-62579eb9c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f36ac9ec-780d-4ff1-b79b-071ce7cd3982,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-4b55847f-5b1c-40aa-8d3e-76c0cf45186b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229018654-172.17.0.3-1599370402493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-65d1027b-dbbc-4e16-92ca-e2014c217c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-6c0ecf0e-6fa6-44c8-a981-750727c66283,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c526f9cf-b928-4ec0-b43a-ea7c0d9af9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-ce419038-e557-4f4b-bb26-e2a256ca1848,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-33373fc1-e679-4b1c-9920-e071e57af589,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-b43b02ec-fa90-42e9-95b5-62579eb9c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f36ac9ec-780d-4ff1-b79b-071ce7cd3982,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-4b55847f-5b1c-40aa-8d3e-76c0cf45186b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739114573-172.17.0.3-1599371293451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-932d6515-1721-4772-b3b2-6fc3cca7c542,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cf7b14e6-db5e-4f3a-8965-097982fd7d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-9a1ad04b-d48c-44b4-b3b3-5db8dd82a722,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2b49410c-703b-4703-83c2-092c7e893ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-b593911c-142a-40fa-9926-9867d2b762d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-9da620c7-9f33-4a19-9ad2-5cfbcd57e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-5ebcfea1-ab17-49de-9daa-ec43749d12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-0e059e16-7e71-45fd-8251-bcd1c13c2eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739114573-172.17.0.3-1599371293451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-932d6515-1721-4772-b3b2-6fc3cca7c542,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cf7b14e6-db5e-4f3a-8965-097982fd7d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-9a1ad04b-d48c-44b4-b3b3-5db8dd82a722,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2b49410c-703b-4703-83c2-092c7e893ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-b593911c-142a-40fa-9926-9867d2b762d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-9da620c7-9f33-4a19-9ad2-5cfbcd57e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-5ebcfea1-ab17-49de-9daa-ec43749d12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-0e059e16-7e71-45fd-8251-bcd1c13c2eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440051604-172.17.0.3-1599371450857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36269,DS-36fff4b8-9e69-4b5e-b440-6459aff31f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-6cbb890c-4d95-42a4-90af-f7cd9b61d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-6c35300f-db41-4bac-b23b-6a2d1805a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-557605d9-6443-4ac1-bc6c-d63d3b6fd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-727f2d93-2706-4f0d-ad68-d87212f69d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-027e6d66-174b-419a-a6fe-6a3b73c4ddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-17980fc1-33e1-4a74-9a55-e63e308c08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-52c7c8ae-f148-46a3-a567-bb39ed148e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440051604-172.17.0.3-1599371450857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36269,DS-36fff4b8-9e69-4b5e-b440-6459aff31f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-6cbb890c-4d95-42a4-90af-f7cd9b61d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-6c35300f-db41-4bac-b23b-6a2d1805a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-557605d9-6443-4ac1-bc6c-d63d3b6fd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-727f2d93-2706-4f0d-ad68-d87212f69d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-027e6d66-174b-419a-a6fe-6a3b73c4ddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-17980fc1-33e1-4a74-9a55-e63e308c08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-52c7c8ae-f148-46a3-a567-bb39ed148e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128963635-172.17.0.3-1599371486114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-b89c9eb0-5d8e-4fb7-a42f-0b8851dd3346,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-18e66355-6ddd-4455-94d5-d2987640f96d,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-af2efca3-675d-4f53-bb68-9e3a689bb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-bd2506c3-d451-400f-9dd3-f011cd7aeaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-8a2a8bc7-c7bc-4e56-af91-ddc3f9cda8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-08f96c8e-e93e-43af-bccf-997b6e3a2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-29a96f9e-5293-454d-ad0f-a5961cce896d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-97106eab-8e24-4ace-bd56-97b4b60e7b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128963635-172.17.0.3-1599371486114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-b89c9eb0-5d8e-4fb7-a42f-0b8851dd3346,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-18e66355-6ddd-4455-94d5-d2987640f96d,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-af2efca3-675d-4f53-bb68-9e3a689bb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-bd2506c3-d451-400f-9dd3-f011cd7aeaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-8a2a8bc7-c7bc-4e56-af91-ddc3f9cda8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-08f96c8e-e93e-43af-bccf-997b6e3a2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-29a96f9e-5293-454d-ad0f-a5961cce896d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-97106eab-8e24-4ace-bd56-97b4b60e7b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499130029-172.17.0.3-1599371521873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-cdb4861f-2127-4cf1-af2a-1fd666b3ebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-5d557433-4f39-4fbd-b821-42d8797d5388,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d9eefbfb-7963-42ff-a711-a33e5ab85b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa8f2ff2-2a1a-4d9f-a2be-503f21d24390,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-c6c793e0-bbe9-42f7-b117-0088e3d6743d,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-bcbef460-f0c1-4dcd-9a1e-91b4be23adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0c318c8d-85b0-4cf8-93ad-27d281838b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-6e42d7a3-e600-486e-9e9d-64376b00da2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499130029-172.17.0.3-1599371521873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-cdb4861f-2127-4cf1-af2a-1fd666b3ebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-5d557433-4f39-4fbd-b821-42d8797d5388,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d9eefbfb-7963-42ff-a711-a33e5ab85b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa8f2ff2-2a1a-4d9f-a2be-503f21d24390,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-c6c793e0-bbe9-42f7-b117-0088e3d6743d,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-bcbef460-f0c1-4dcd-9a1e-91b4be23adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0c318c8d-85b0-4cf8-93ad-27d281838b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-6e42d7a3-e600-486e-9e9d-64376b00da2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689192108-172.17.0.3-1599371665224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-527fd70c-cc92-4f69-a880-9f3fe2be020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-c4113f09-2340-40f4-8855-b5de5c1c8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-81785c2f-56e1-4b54-a556-1a410ddd8860,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-5a278e7b-9f0d-499b-8a33-4c9c6e01374b,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-384338c1-5f5e-45a2-82cd-651930d177f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-990b8c02-b22f-4167-a53c-39051f64cad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d00066b0-52cb-419e-91f1-4fa691b59181,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-f676ce8d-5230-47fe-9d84-3bebd89db08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689192108-172.17.0.3-1599371665224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-527fd70c-cc92-4f69-a880-9f3fe2be020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-c4113f09-2340-40f4-8855-b5de5c1c8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-81785c2f-56e1-4b54-a556-1a410ddd8860,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-5a278e7b-9f0d-499b-8a33-4c9c6e01374b,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-384338c1-5f5e-45a2-82cd-651930d177f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-990b8c02-b22f-4167-a53c-39051f64cad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-d00066b0-52cb-419e-91f1-4fa691b59181,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-f676ce8d-5230-47fe-9d84-3bebd89db08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852501753-172.17.0.3-1599372078461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33196,DS-542b4d75-7114-4c51-b99f-b7fcfe35150a,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-e17b7bda-8633-4acf-b703-50ec59e48ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-ca6057c7-2dc0-4756-9c11-bb8768fb522b,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-551cca06-7400-4b05-9193-286817aa1795,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-12a6f459-fa88-4dd3-973e-523dd14884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f139b069-c724-41de-aebc-bce0b8a6a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-878d76b0-aa9c-42ef-bf84-5df1b4a7127c,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-878f746a-d969-4f24-a22a-dcc57e934a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852501753-172.17.0.3-1599372078461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33196,DS-542b4d75-7114-4c51-b99f-b7fcfe35150a,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-e17b7bda-8633-4acf-b703-50ec59e48ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-ca6057c7-2dc0-4756-9c11-bb8768fb522b,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-551cca06-7400-4b05-9193-286817aa1795,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-12a6f459-fa88-4dd3-973e-523dd14884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f139b069-c724-41de-aebc-bce0b8a6a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-878d76b0-aa9c-42ef-bf84-5df1b4a7127c,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-878f746a-d969-4f24-a22a-dcc57e934a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5365
