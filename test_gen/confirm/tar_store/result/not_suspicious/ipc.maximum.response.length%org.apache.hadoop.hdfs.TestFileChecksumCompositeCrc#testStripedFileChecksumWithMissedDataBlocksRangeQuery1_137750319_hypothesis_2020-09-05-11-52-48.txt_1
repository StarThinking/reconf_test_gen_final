reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376521168-172.17.0.10-1599306869009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-cbd333e3-315b-4354-814d-5c68e0ef1232,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-e5bb55f2-36f6-4571-a366-140c657e2121,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-501c182a-1dab-42bd-a454-db65ee37317c,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-e7936281-b0cf-4b24-8f08-2185d2415c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-3de6e508-5e42-402c-aca8-bc5628976505,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d5fd406a-5e68-47b3-a007-ab800c101f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-f81f2af2-4bae-4758-8273-7cf5ae6faa42,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-1700a099-b6c8-4efa-a156-7add1c4a82ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376521168-172.17.0.10-1599306869009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-cbd333e3-315b-4354-814d-5c68e0ef1232,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-e5bb55f2-36f6-4571-a366-140c657e2121,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-501c182a-1dab-42bd-a454-db65ee37317c,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-e7936281-b0cf-4b24-8f08-2185d2415c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-3de6e508-5e42-402c-aca8-bc5628976505,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-d5fd406a-5e68-47b3-a007-ab800c101f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-f81f2af2-4bae-4758-8273-7cf5ae6faa42,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-1700a099-b6c8-4efa-a156-7add1c4a82ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991866045-172.17.0.10-1599306908599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-59e7e112-f57f-4c71-aa44-9f4585a28ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-582c6b5c-8a8e-4aa7-a1cb-337d366930de,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-8d98a7f3-2a62-4581-828c-8ff18d520044,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-b69b3fec-77ce-47ae-aaf6-6fe5b40c87c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-0aca295e-d35f-40c2-835a-e9a821e8b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5bdd3752-4d5f-4577-b92d-ac23e6b4a8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-a101e903-4741-4c68-9e6c-9915ac3d3d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-1b3e87c6-1aed-4ba1-9aaa-a8f415ade7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991866045-172.17.0.10-1599306908599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-59e7e112-f57f-4c71-aa44-9f4585a28ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-582c6b5c-8a8e-4aa7-a1cb-337d366930de,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-8d98a7f3-2a62-4581-828c-8ff18d520044,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-b69b3fec-77ce-47ae-aaf6-6fe5b40c87c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-0aca295e-d35f-40c2-835a-e9a821e8b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5bdd3752-4d5f-4577-b92d-ac23e6b4a8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-a101e903-4741-4c68-9e6c-9915ac3d3d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-1b3e87c6-1aed-4ba1-9aaa-a8f415ade7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22638374-172.17.0.10-1599307039515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42999,DS-625684c1-b963-4f1a-bfe9-5f31a1e97650,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-7a83fb28-1009-40f4-8a13-eab50d51bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-095452ec-9b5a-4d29-be09-47c487b39263,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-49764c87-91ca-4c3e-85e3-0fab4f7e9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-e6b12334-bb65-403e-be14-c021a620a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-f2603b59-8f39-4fd5-b6a6-d49492c1c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-d6a71bbb-5443-4749-b7ff-0ceb639cea23,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-8c120b05-b7a7-4e79-b568-0d8ffa46a850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22638374-172.17.0.10-1599307039515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42999,DS-625684c1-b963-4f1a-bfe9-5f31a1e97650,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-7a83fb28-1009-40f4-8a13-eab50d51bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-095452ec-9b5a-4d29-be09-47c487b39263,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-49764c87-91ca-4c3e-85e3-0fab4f7e9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-e6b12334-bb65-403e-be14-c021a620a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-f2603b59-8f39-4fd5-b6a6-d49492c1c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-d6a71bbb-5443-4749-b7ff-0ceb639cea23,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-8c120b05-b7a7-4e79-b568-0d8ffa46a850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375735639-172.17.0.10-1599307188800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-d9c1fd90-f68a-41a1-b43b-33d01bbfc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-953657df-09d5-417b-bd96-08f512995b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-20ae4b96-a333-49c7-8b87-9329c1804201,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-68a97e30-2750-43ad-a913-2403b75dcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-e9f8eb90-32a0-4d8b-98c1-4a4896a43da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-69a5bb11-932c-48f1-8b81-e6ecc6ee14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-7073b4d5-7a88-4e9c-aea7-b383651b7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-54b0d53c-12e2-412b-923d-a3f769054b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375735639-172.17.0.10-1599307188800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38750,DS-d9c1fd90-f68a-41a1-b43b-33d01bbfc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-953657df-09d5-417b-bd96-08f512995b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-20ae4b96-a333-49c7-8b87-9329c1804201,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-68a97e30-2750-43ad-a913-2403b75dcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-e9f8eb90-32a0-4d8b-98c1-4a4896a43da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-69a5bb11-932c-48f1-8b81-e6ecc6ee14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-7073b4d5-7a88-4e9c-aea7-b383651b7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-54b0d53c-12e2-412b-923d-a3f769054b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221224139-172.17.0.10-1599307659850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41291,DS-92317882-08fc-4fdb-ad60-ac5eb82a6735,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3867f2b7-cd65-49ef-b55a-08cc3c37393b,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-212fec75-0b15-4f16-9061-1e85fc3ecb96,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-0873e16f-65b9-45b4-a21b-0fe82a00a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b3ee9c5c-6595-4a2b-b21d-d5302d9e604d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-47cd783a-e23a-4491-98a7-a745dced7606,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-665fc705-de55-407a-b2ea-3e147855d624,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-8e00c82f-11f7-4af9-a01a-361645ea7a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221224139-172.17.0.10-1599307659850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41291,DS-92317882-08fc-4fdb-ad60-ac5eb82a6735,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3867f2b7-cd65-49ef-b55a-08cc3c37393b,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-212fec75-0b15-4f16-9061-1e85fc3ecb96,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-0873e16f-65b9-45b4-a21b-0fe82a00a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b3ee9c5c-6595-4a2b-b21d-d5302d9e604d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-47cd783a-e23a-4491-98a7-a745dced7606,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-665fc705-de55-407a-b2ea-3e147855d624,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-8e00c82f-11f7-4af9-a01a-361645ea7a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951776701-172.17.0.10-1599307726882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-81b4a9b9-313c-4c8f-bd39-5b3677ee86f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-19821149-5ade-4bc4-9aee-84bd9a36abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-a248583a-3d59-4d6e-9743-06d2c3fad77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-bdbfb48b-23e3-48c8-b02c-e8d98550eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-26bda095-ddb7-4022-9eda-ea22bffccaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-ddb97bad-a980-425c-b528-89af539b8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-50162025-dba6-49b7-9718-8092fc21266c,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-41c62efa-bf5b-4e24-8399-399b340040d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951776701-172.17.0.10-1599307726882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-81b4a9b9-313c-4c8f-bd39-5b3677ee86f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-19821149-5ade-4bc4-9aee-84bd9a36abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-a248583a-3d59-4d6e-9743-06d2c3fad77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-bdbfb48b-23e3-48c8-b02c-e8d98550eacc,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-26bda095-ddb7-4022-9eda-ea22bffccaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-ddb97bad-a980-425c-b528-89af539b8b22,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-50162025-dba6-49b7-9718-8092fc21266c,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-41c62efa-bf5b-4e24-8399-399b340040d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21155163-172.17.0.10-1599308054913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-699c2921-cbb0-4fcb-a6ae-3b8bcd171331,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-1e736f54-4ba1-4335-80e7-d678e46d9f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-cf98063e-da1f-4712-99ba-368e0d2627b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-2a5bd90d-a168-4dc3-9ebf-2b12ab7a070d,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-c4f329c4-6b7c-4673-b781-61a703647123,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-e42b1fa6-3edc-4da3-85c1-f45fdbea9658,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-64033b2f-a750-475e-a279-696abca44a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-698839a0-b91f-4055-a1a6-cde8c8b26c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21155163-172.17.0.10-1599308054913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-699c2921-cbb0-4fcb-a6ae-3b8bcd171331,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-1e736f54-4ba1-4335-80e7-d678e46d9f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-cf98063e-da1f-4712-99ba-368e0d2627b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-2a5bd90d-a168-4dc3-9ebf-2b12ab7a070d,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-c4f329c4-6b7c-4673-b781-61a703647123,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-e42b1fa6-3edc-4da3-85c1-f45fdbea9658,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-64033b2f-a750-475e-a279-696abca44a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-698839a0-b91f-4055-a1a6-cde8c8b26c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332456753-172.17.0.10-1599308313724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-362510e5-06e7-4fd6-a0f8-448ea987cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-81178099-6288-44bf-912a-df82b4f8d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3ac0f1ac-b8a4-4d66-9c54-675bff333c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-442b464c-6e25-4f63-a8c9-1d9c1991c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-98fd96d8-fec9-4837-9d8b-f56a682a8cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-f4a98596-388c-4e19-bd82-8d7cd7f0fe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-2be24036-68cc-4716-86c6-921a35856a75,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-5b0907cd-f59b-4aec-929d-6a030b7ee9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332456753-172.17.0.10-1599308313724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-362510e5-06e7-4fd6-a0f8-448ea987cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-81178099-6288-44bf-912a-df82b4f8d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3ac0f1ac-b8a4-4d66-9c54-675bff333c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-442b464c-6e25-4f63-a8c9-1d9c1991c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-98fd96d8-fec9-4837-9d8b-f56a682a8cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-f4a98596-388c-4e19-bd82-8d7cd7f0fe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-2be24036-68cc-4716-86c6-921a35856a75,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-5b0907cd-f59b-4aec-929d-6a030b7ee9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959574634-172.17.0.10-1599309387719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43556,DS-add96d02-1dc6-4cc5-a270-142ea8b948b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-43a2aee4-6b35-43a4-976a-8fed8a963457,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-6af2c3a1-e375-459b-aae5-f3bc1ad82ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-621c3290-8371-46d8-98a6-bd5a374948a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-8f56d1d5-49b7-409f-9b73-d05c64a5558d,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-f72ed167-6ca2-4e2d-9a94-4c48a0dd8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-08ef70a6-7f53-465b-9b3e-2149c63b4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-f49d5204-d546-4ce2-aebe-fc37db19bdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959574634-172.17.0.10-1599309387719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43556,DS-add96d02-1dc6-4cc5-a270-142ea8b948b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-43a2aee4-6b35-43a4-976a-8fed8a963457,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-6af2c3a1-e375-459b-aae5-f3bc1ad82ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-621c3290-8371-46d8-98a6-bd5a374948a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-8f56d1d5-49b7-409f-9b73-d05c64a5558d,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-f72ed167-6ca2-4e2d-9a94-4c48a0dd8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-08ef70a6-7f53-465b-9b3e-2149c63b4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-f49d5204-d546-4ce2-aebe-fc37db19bdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105911610-172.17.0.10-1599309940093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-95a14fa7-305a-4a86-904a-46a4846e72f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-3cf1cc96-315b-4d11-948c-64cf76d8797f,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-6a1e947f-e1f7-4b88-9e6f-864f50a8f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-c46f730a-9d35-45ce-afc3-f456e3ed04b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f0fa8c7d-28e1-46ba-b0b0-d755f7918669,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-a61f3044-4589-4e5c-87cf-90b317415f41,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-5bb1922b-ab4b-4c01-8592-21ca584c599b,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-14bb8fff-b8ea-47ad-99fc-c6cdf4f39968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105911610-172.17.0.10-1599309940093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-95a14fa7-305a-4a86-904a-46a4846e72f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-3cf1cc96-315b-4d11-948c-64cf76d8797f,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-6a1e947f-e1f7-4b88-9e6f-864f50a8f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-c46f730a-9d35-45ce-afc3-f456e3ed04b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f0fa8c7d-28e1-46ba-b0b0-d755f7918669,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-a61f3044-4589-4e5c-87cf-90b317415f41,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-5bb1922b-ab4b-4c01-8592-21ca584c599b,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-14bb8fff-b8ea-47ad-99fc-c6cdf4f39968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731093118-172.17.0.10-1599309976471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42574,DS-55546c00-b82c-4187-b12f-67196b8f17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-d23617a6-7f87-4f63-9966-211bdb148a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-9bbfbe70-ef70-4de4-be5b-6d7413f76916,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-26e8c330-9379-42a2-aa69-db39b78f4ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-4a61e479-803c-4f58-9eec-82ad95339e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-f3c1b7c7-e0d8-40fd-bffe-88c64b661782,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-7a7c7829-9f21-4541-a700-619e4e9f1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-6a42f7a8-6b81-4c50-ab15-c4260ca96ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731093118-172.17.0.10-1599309976471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42574,DS-55546c00-b82c-4187-b12f-67196b8f17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-d23617a6-7f87-4f63-9966-211bdb148a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-9bbfbe70-ef70-4de4-be5b-6d7413f76916,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-26e8c330-9379-42a2-aa69-db39b78f4ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-4a61e479-803c-4f58-9eec-82ad95339e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-f3c1b7c7-e0d8-40fd-bffe-88c64b661782,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-7a7c7829-9f21-4541-a700-619e4e9f1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-6a42f7a8-6b81-4c50-ab15-c4260ca96ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004608030-172.17.0.10-1599310340587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-894c108c-b97c-4c72-9ef4-881fb8e378e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b2f558fc-abdf-4000-b39b-788157b62724,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-4a932609-fac6-405b-a30e-63e6714921f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0b4f3674-4dd0-47ab-b474-9815d49e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-2861d10b-be22-4174-90c6-762dbf36d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-cc784eb1-33fb-4176-b54f-305c18123f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f6a3caed-bceb-452e-8864-8f9242a8b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-af6beecc-657c-4d41-8ff1-800404c43907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004608030-172.17.0.10-1599310340587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-894c108c-b97c-4c72-9ef4-881fb8e378e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b2f558fc-abdf-4000-b39b-788157b62724,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-4a932609-fac6-405b-a30e-63e6714921f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0b4f3674-4dd0-47ab-b474-9815d49e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-2861d10b-be22-4174-90c6-762dbf36d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-cc784eb1-33fb-4176-b54f-305c18123f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-f6a3caed-bceb-452e-8864-8f9242a8b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-af6beecc-657c-4d41-8ff1-800404c43907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364190659-172.17.0.10-1599310586132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-5e1a3e79-08c4-45bd-b81b-00f0b791929d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-4a4ab82c-e236-4185-847b-d44970953c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-d5a61ecd-6998-4c24-906a-85a95dfa8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b3106724-6374-4827-98cd-17f3c2d9fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-4e99dbd0-ae0b-4332-a28e-c5c6b71ca3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-abe0a44a-c564-4754-a284-ecd0a78bc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-42f6f6f3-7476-49ec-ad52-215f11580bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-42459285-9629-4f05-aa50-4902ac927551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364190659-172.17.0.10-1599310586132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-5e1a3e79-08c4-45bd-b81b-00f0b791929d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-4a4ab82c-e236-4185-847b-d44970953c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-d5a61ecd-6998-4c24-906a-85a95dfa8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b3106724-6374-4827-98cd-17f3c2d9fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-4e99dbd0-ae0b-4332-a28e-c5c6b71ca3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-abe0a44a-c564-4754-a284-ecd0a78bc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-42f6f6f3-7476-49ec-ad52-215f11580bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-42459285-9629-4f05-aa50-4902ac927551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042277586-172.17.0.10-1599310694236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-34a827ef-8deb-4d15-9c7e-600bc54df8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-501c5305-b213-4b98-9e13-cab52fb3d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-6849129e-96b4-4294-aa3f-ca2e7849f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-9597b7a0-9476-49c7-aba8-9c6ac5596058,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-d4f4af96-b02e-456c-be5b-217a8af87af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-cdbb0627-1c29-44e0-b3bb-dce98e7bf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-50aacaf9-0df2-439d-98f8-0a52a8254348,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-e868e465-d39e-41d1-93de-708125bd5d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042277586-172.17.0.10-1599310694236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-34a827ef-8deb-4d15-9c7e-600bc54df8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-501c5305-b213-4b98-9e13-cab52fb3d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-6849129e-96b4-4294-aa3f-ca2e7849f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-9597b7a0-9476-49c7-aba8-9c6ac5596058,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-d4f4af96-b02e-456c-be5b-217a8af87af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-cdbb0627-1c29-44e0-b3bb-dce98e7bf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-50aacaf9-0df2-439d-98f8-0a52a8254348,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-e868e465-d39e-41d1-93de-708125bd5d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868827254-172.17.0.10-1599310809268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-b778545f-3b53-4267-8c0c-0332d500e063,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-3ebcece9-a51e-4380-8986-dd26f5c69031,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-4f603b21-ba0f-4ede-b592-25aad5649d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ee948306-7cbb-4070-b181-a97f09f1ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-be6ed4fa-abe8-4074-b4d5-f320e45ffa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-255f8586-ed54-4298-8951-05952375773f,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8687c499-33aa-4b30-83c9-4ec0aa7d2dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-99897581-75e4-4815-a2e5-b7b5400083b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868827254-172.17.0.10-1599310809268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-b778545f-3b53-4267-8c0c-0332d500e063,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-3ebcece9-a51e-4380-8986-dd26f5c69031,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-4f603b21-ba0f-4ede-b592-25aad5649d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ee948306-7cbb-4070-b181-a97f09f1ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-be6ed4fa-abe8-4074-b4d5-f320e45ffa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-255f8586-ed54-4298-8951-05952375773f,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8687c499-33aa-4b30-83c9-4ec0aa7d2dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-99897581-75e4-4815-a2e5-b7b5400083b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088760901-172.17.0.10-1599311243922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-3495424c-62f7-43a0-8c6e-15c1e653e452,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-7597dbc3-8857-49ae-bfe6-a74abaadf24e,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-7e32eeeb-3185-4123-93e2-12ee87b5df45,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-f05cbc2c-f095-4b39-96a9-adb925ce1714,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-8124b581-af23-4977-ac19-d7fdaf4ef118,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-1d67f76d-bf5b-4568-a93d-daa45696ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-032d0332-19cc-4a4b-898a-8a038680bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-865da6b4-e6f7-4060-b245-7c6be0a28faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088760901-172.17.0.10-1599311243922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-3495424c-62f7-43a0-8c6e-15c1e653e452,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-7597dbc3-8857-49ae-bfe6-a74abaadf24e,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-7e32eeeb-3185-4123-93e2-12ee87b5df45,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-f05cbc2c-f095-4b39-96a9-adb925ce1714,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-8124b581-af23-4977-ac19-d7fdaf4ef118,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-1d67f76d-bf5b-4568-a93d-daa45696ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-032d0332-19cc-4a4b-898a-8a038680bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-865da6b4-e6f7-4060-b245-7c6be0a28faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5869
