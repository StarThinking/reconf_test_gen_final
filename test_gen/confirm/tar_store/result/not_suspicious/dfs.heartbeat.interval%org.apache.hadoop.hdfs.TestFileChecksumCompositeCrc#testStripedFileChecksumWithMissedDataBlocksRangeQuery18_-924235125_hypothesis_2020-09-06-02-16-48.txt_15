reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426479627-172.17.0.17-1599359211785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-c4ef17e7-8e24-4a34-9124-c0c17b6da585,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-431f78e2-5a8d-4d7f-81d0-e83407954912,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bc594728-d72d-43d1-b7da-225930a3e6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-18963da0-ea31-48ca-9c2c-957e6dc7ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-e82eb39c-6a76-41e3-bd46-b3f8a43640a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-736d0b94-214f-4cb8-94e1-0932dbacb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-d326e87f-5b64-4c0a-aba0-2acad3ec167f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-330163b2-c419-436f-93b7-80ee3e25db82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426479627-172.17.0.17-1599359211785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-c4ef17e7-8e24-4a34-9124-c0c17b6da585,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-431f78e2-5a8d-4d7f-81d0-e83407954912,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bc594728-d72d-43d1-b7da-225930a3e6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-18963da0-ea31-48ca-9c2c-957e6dc7ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-e82eb39c-6a76-41e3-bd46-b3f8a43640a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-736d0b94-214f-4cb8-94e1-0932dbacb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-d326e87f-5b64-4c0a-aba0-2acad3ec167f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-330163b2-c419-436f-93b7-80ee3e25db82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020173687-172.17.0.17-1599359317527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39454,DS-2b2dcdca-7319-46a1-9b1d-83efe1c4c19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-950fba9f-a4e7-4e69-b954-699a7dcc52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-dafa54dd-cd2e-45bb-b0bc-4d86f1c5182b,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-41fe755c-0a77-45e9-9964-53ba64a79880,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a48f5cc7-c098-4df5-adaf-bec976a4bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-1d8e5e87-d47e-4ab9-9146-88fb266eef24,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-db07bfc7-f5e1-4cef-a432-0f9d69027520,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-47105923-5614-45a1-bb93-a6cc35f4569c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020173687-172.17.0.17-1599359317527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39454,DS-2b2dcdca-7319-46a1-9b1d-83efe1c4c19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-950fba9f-a4e7-4e69-b954-699a7dcc52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-dafa54dd-cd2e-45bb-b0bc-4d86f1c5182b,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-41fe755c-0a77-45e9-9964-53ba64a79880,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a48f5cc7-c098-4df5-adaf-bec976a4bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-1d8e5e87-d47e-4ab9-9146-88fb266eef24,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-db07bfc7-f5e1-4cef-a432-0f9d69027520,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-47105923-5614-45a1-bb93-a6cc35f4569c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342110260-172.17.0.17-1599359568196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39559,DS-155623e5-000d-4a99-90cc-f7d633728723,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-b85e6fcf-b115-4180-a1b1-f111867402d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-bb034474-a258-463c-8498-a8c65a36a077,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-66f91d7a-a8b8-469a-8040-790fc294e986,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-b8971518-0ccf-4908-8f1f-7ffc1e43f623,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-22480292-5eba-4d1a-b2b3-190c004b03c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a6fa5c9c-af94-47d9-a208-1c22e70a32b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-6f8d1e23-6ebe-45fb-b796-607320df1be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342110260-172.17.0.17-1599359568196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39559,DS-155623e5-000d-4a99-90cc-f7d633728723,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-b85e6fcf-b115-4180-a1b1-f111867402d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-bb034474-a258-463c-8498-a8c65a36a077,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-66f91d7a-a8b8-469a-8040-790fc294e986,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-b8971518-0ccf-4908-8f1f-7ffc1e43f623,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-22480292-5eba-4d1a-b2b3-190c004b03c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a6fa5c9c-af94-47d9-a208-1c22e70a32b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-6f8d1e23-6ebe-45fb-b796-607320df1be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712133909-172.17.0.17-1599359845433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-021e9cd5-ab02-4491-89ba-cf0b8b6b0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-fe7e1bf0-ca96-421f-833d-5b5afca2ee26,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-9bf08c51-bb12-46c4-aba4-7aa4961a605e,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-207d239a-2cdf-42c7-a767-657a484b7060,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dfa47aeb-bedf-4b51-8d6e-da19eb5de3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-d2ed0199-d5db-4f7e-9a97-cdcdb0ec0ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-b8f73832-b6c5-4509-a470-34413925e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-a9377d4c-9480-465e-ba99-2bf0be1f7e73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712133909-172.17.0.17-1599359845433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-021e9cd5-ab02-4491-89ba-cf0b8b6b0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-fe7e1bf0-ca96-421f-833d-5b5afca2ee26,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-9bf08c51-bb12-46c4-aba4-7aa4961a605e,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-207d239a-2cdf-42c7-a767-657a484b7060,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dfa47aeb-bedf-4b51-8d6e-da19eb5de3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-d2ed0199-d5db-4f7e-9a97-cdcdb0ec0ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-b8f73832-b6c5-4509-a470-34413925e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-a9377d4c-9480-465e-ba99-2bf0be1f7e73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829920776-172.17.0.17-1599360436523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-2f3fed75-726f-48ea-971e-83e48c86efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-320988eb-8470-4142-bc58-56c7709ccd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-81f4e274-72f8-4d4b-a737-5af348a417f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-61aefc42-069d-4ea1-98b7-04de4f84e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-1efc8a98-1ce8-49f5-9f89-a21f38e6b411,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-ce3e1288-229d-44fb-aa1d-8426c13ce28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-75c779ed-fff2-41d6-85d5-18d4421f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-f2c3d8a7-069c-4abb-9eb3-f6d6680240b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829920776-172.17.0.17-1599360436523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-2f3fed75-726f-48ea-971e-83e48c86efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-320988eb-8470-4142-bc58-56c7709ccd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-81f4e274-72f8-4d4b-a737-5af348a417f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-61aefc42-069d-4ea1-98b7-04de4f84e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-1efc8a98-1ce8-49f5-9f89-a21f38e6b411,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-ce3e1288-229d-44fb-aa1d-8426c13ce28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-75c779ed-fff2-41d6-85d5-18d4421f36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-f2c3d8a7-069c-4abb-9eb3-f6d6680240b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858518894-172.17.0.17-1599360806507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-059e949d-487b-4a9c-a406-9dcef7f730e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-df7b961e-adcc-413f-abe1-cc17191762f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0286b578-258c-40c9-8423-ac9239a6524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-74f1afd5-47a2-41ee-95e0-12542348724f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-e3f12a0f-721a-454f-9369-d35245a8af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a419536a-d959-41e2-a68f-8012f6804744,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-5012da49-1035-47a4-9de7-31d9c258bf40,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-8502d4d1-34dc-41f2-a7db-e3b047e2a8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858518894-172.17.0.17-1599360806507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-059e949d-487b-4a9c-a406-9dcef7f730e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-df7b961e-adcc-413f-abe1-cc17191762f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0286b578-258c-40c9-8423-ac9239a6524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-74f1afd5-47a2-41ee-95e0-12542348724f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-e3f12a0f-721a-454f-9369-d35245a8af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a419536a-d959-41e2-a68f-8012f6804744,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-5012da49-1035-47a4-9de7-31d9c258bf40,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-8502d4d1-34dc-41f2-a7db-e3b047e2a8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659255728-172.17.0.17-1599360912779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-7ba8d423-79f0-4e9e-b1a8-9d2867150c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-35da5eff-b0e3-4c12-b04b-974fb0edf326,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-6a5bbcb8-5399-43e5-b007-ad2cec9ba29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-1dbe4562-b5e3-40ef-a641-b6cff1480caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-a951f0c7-16e2-4518-b477-b32e4a2e30fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-a73bf551-1ad2-40c0-b325-87a028faaa40,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d6012c5f-81e2-414b-8009-f87e61f8f177,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-2da95b4f-473a-4bc4-8252-f308ec2a318f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659255728-172.17.0.17-1599360912779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-7ba8d423-79f0-4e9e-b1a8-9d2867150c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-35da5eff-b0e3-4c12-b04b-974fb0edf326,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-6a5bbcb8-5399-43e5-b007-ad2cec9ba29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-1dbe4562-b5e3-40ef-a641-b6cff1480caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-a951f0c7-16e2-4518-b477-b32e4a2e30fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-a73bf551-1ad2-40c0-b325-87a028faaa40,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d6012c5f-81e2-414b-8009-f87e61f8f177,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-2da95b4f-473a-4bc4-8252-f308ec2a318f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221431115-172.17.0.17-1599360965463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-a72237a0-555c-4b48-9d5e-ef2d66bb01f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-edc5e91e-9e6b-4e88-827e-daf018d12631,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-187a8947-b6e2-4d0d-a65e-1d47494769ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-44e3f2f3-a764-4203-b071-ef16a82df13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-5b760b77-203a-444b-b494-3c57ae060cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-6e2d21bc-7b2b-494e-83fd-df96701b6859,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-5493f5bc-d8ba-4eca-9a08-d71f0c10b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-1a6f7fd5-4dc8-42b2-b24e-357d76dfcb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221431115-172.17.0.17-1599360965463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-a72237a0-555c-4b48-9d5e-ef2d66bb01f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-edc5e91e-9e6b-4e88-827e-daf018d12631,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-187a8947-b6e2-4d0d-a65e-1d47494769ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-44e3f2f3-a764-4203-b071-ef16a82df13c,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-5b760b77-203a-444b-b494-3c57ae060cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-6e2d21bc-7b2b-494e-83fd-df96701b6859,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-5493f5bc-d8ba-4eca-9a08-d71f0c10b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-1a6f7fd5-4dc8-42b2-b24e-357d76dfcb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611627135-172.17.0.17-1599361615871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-f431d755-d6dc-460d-a1d0-c28de079a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-c12792ff-6662-4827-a6cc-9ce3ac5bf27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-9b0f85d9-a039-4226-b612-0f3beb1b2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-28d0bbe1-8227-42a7-bfbc-0f2877c6e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-cd163641-cdb0-4b4e-9cd9-4e42eb925aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-136bf75b-95eb-4a02-9f4c-645975541df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-055b57d4-1a06-44a0-bb96-041a1a79fc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-1aa7dda2-c3a4-4103-a6aa-b4c360ab083e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611627135-172.17.0.17-1599361615871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-f431d755-d6dc-460d-a1d0-c28de079a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-c12792ff-6662-4827-a6cc-9ce3ac5bf27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-9b0f85d9-a039-4226-b612-0f3beb1b2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-28d0bbe1-8227-42a7-bfbc-0f2877c6e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-cd163641-cdb0-4b4e-9cd9-4e42eb925aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-136bf75b-95eb-4a02-9f4c-645975541df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-055b57d4-1a06-44a0-bb96-041a1a79fc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-1aa7dda2-c3a4-4103-a6aa-b4c360ab083e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910966105-172.17.0.17-1599362031590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-b73e26ce-dc2d-4aa3-8f19-57f15bd976ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-84115dac-6383-4cf9-94b7-5b02dffbe1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-fa0a833a-7057-44fd-8f7e-c5a520d1604f,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-c8e10756-dd97-49f9-a8ad-c70146d741b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ed0fb663-c40a-4fe5-b23f-89b6c4eeb5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-219d0b8d-c367-4f2b-92ab-795c9aababed,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-c43fc29b-6a45-4974-9271-04a245f31c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-ade0f09f-7e0b-4db5-9e78-e5f65ad85cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910966105-172.17.0.17-1599362031590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-b73e26ce-dc2d-4aa3-8f19-57f15bd976ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-84115dac-6383-4cf9-94b7-5b02dffbe1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-fa0a833a-7057-44fd-8f7e-c5a520d1604f,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-c8e10756-dd97-49f9-a8ad-c70146d741b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ed0fb663-c40a-4fe5-b23f-89b6c4eeb5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-219d0b8d-c367-4f2b-92ab-795c9aababed,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-c43fc29b-6a45-4974-9271-04a245f31c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-ade0f09f-7e0b-4db5-9e78-e5f65ad85cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572819530-172.17.0.17-1599362060905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-dc7d0d9e-772b-46cf-8f60-c8a303f55f78,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-958e28b7-94a2-4d25-92e8-6ce4d93f2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-4ee9c8b2-9d37-498c-ac05-473b99e5263f,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-cbc34277-50b9-420b-9888-3298b4e27c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-883f3525-0093-4780-84f9-a6e150e4e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-1bb7a5cb-ceb5-49e1-9e64-708873292ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-bee0e841-4871-491b-b0be-6e97a18fd061,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c2488d78-b859-4b5b-b1cd-7e061e5d15d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572819530-172.17.0.17-1599362060905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-dc7d0d9e-772b-46cf-8f60-c8a303f55f78,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-958e28b7-94a2-4d25-92e8-6ce4d93f2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-4ee9c8b2-9d37-498c-ac05-473b99e5263f,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-cbc34277-50b9-420b-9888-3298b4e27c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-883f3525-0093-4780-84f9-a6e150e4e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-1bb7a5cb-ceb5-49e1-9e64-708873292ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-bee0e841-4871-491b-b0be-6e97a18fd061,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c2488d78-b859-4b5b-b1cd-7e061e5d15d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668730229-172.17.0.17-1599362253163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-8b432b6f-a05a-4059-ac70-5353ac61ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-12161eb0-6b1b-403d-9ff9-43909f271ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-f7e375d9-9410-4c20-a8c4-5fffecea0053,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-dd079778-84c0-465b-ae74-2f675545f519,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-09d002ef-6dab-4c4b-9f79-c959aa6337db,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b12b38c7-a5e5-403f-8159-2396dfa047af,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-44a67d34-60c0-40ac-907d-5573244b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-c3ae11e1-bda3-4897-ba64-faad92439c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668730229-172.17.0.17-1599362253163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-8b432b6f-a05a-4059-ac70-5353ac61ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-12161eb0-6b1b-403d-9ff9-43909f271ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-f7e375d9-9410-4c20-a8c4-5fffecea0053,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-dd079778-84c0-465b-ae74-2f675545f519,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-09d002ef-6dab-4c4b-9f79-c959aa6337db,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b12b38c7-a5e5-403f-8159-2396dfa047af,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-44a67d34-60c0-40ac-907d-5573244b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-c3ae11e1-bda3-4897-ba64-faad92439c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990997455-172.17.0.17-1599362446003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-83dfff68-8922-467d-b804-6c8faaeacc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-0830e2aa-9cee-4fdd-ba2f-92f627d5c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-db694f35-b58e-46e2-a893-52aff42545f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-98089281-e0cb-4dc3-97e8-eed70168a654,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-e9f6bda1-943c-4ea2-821f-0b42cf9d74e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-34fa4c96-e13a-4563-86d2-7e0d91a01149,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-288341b8-579d-4c34-abba-0a420b0b259d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-10bd2105-79f4-4acd-9219-f995277dfb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990997455-172.17.0.17-1599362446003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-83dfff68-8922-467d-b804-6c8faaeacc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-0830e2aa-9cee-4fdd-ba2f-92f627d5c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-db694f35-b58e-46e2-a893-52aff42545f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-98089281-e0cb-4dc3-97e8-eed70168a654,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-e9f6bda1-943c-4ea2-821f-0b42cf9d74e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-34fa4c96-e13a-4563-86d2-7e0d91a01149,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-288341b8-579d-4c34-abba-0a420b0b259d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-10bd2105-79f4-4acd-9219-f995277dfb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4212
