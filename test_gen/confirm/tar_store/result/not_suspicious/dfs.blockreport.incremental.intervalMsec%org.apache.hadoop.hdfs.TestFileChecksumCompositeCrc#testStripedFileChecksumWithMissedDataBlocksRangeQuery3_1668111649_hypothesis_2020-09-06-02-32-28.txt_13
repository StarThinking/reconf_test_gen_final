reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84755021-172.17.0.19-1599359560548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-d2bb8fd5-f12e-4f9c-9a48-8c444a0d82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-b717b105-9af5-45c9-a934-c237a3f5a241,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-572b85a3-c3a2-4fcc-b840-b3471b100366,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-39be0b0e-930b-4852-bddf-ed878f7e4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-ef44669a-803f-4ff9-bcc5-8748a8a24c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7fa3de76-5b9a-4f2e-ae74-e2ca86d4720f,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-51361019-f517-4635-8e66-b65e9050827e,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-5890ea3c-3fce-44e7-acc8-9b7a7b1807f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84755021-172.17.0.19-1599359560548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-d2bb8fd5-f12e-4f9c-9a48-8c444a0d82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-b717b105-9af5-45c9-a934-c237a3f5a241,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-572b85a3-c3a2-4fcc-b840-b3471b100366,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-39be0b0e-930b-4852-bddf-ed878f7e4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-ef44669a-803f-4ff9-bcc5-8748a8a24c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7fa3de76-5b9a-4f2e-ae74-e2ca86d4720f,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-51361019-f517-4635-8e66-b65e9050827e,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-5890ea3c-3fce-44e7-acc8-9b7a7b1807f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793568064-172.17.0.19-1599359774429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-d9fbb8d0-c280-4035-abd3-725dc1edb927,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-5270c627-1b0a-42bc-a6b3-d7de0ce4b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-b9aa56f3-cc39-4bd7-b1b3-134b9f0d0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-6dc29d8a-56cc-4422-9419-25918ceedcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-9bf147b5-16b3-4c1a-9c7f-72240f341092,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-4d48ad84-6fef-47c1-8aad-a90e30faca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-cebf99a1-54d7-42d2-8a1d-8fe898f984df,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-186ac40a-9fe7-421f-8901-cf8aa92b79e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793568064-172.17.0.19-1599359774429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-d9fbb8d0-c280-4035-abd3-725dc1edb927,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-5270c627-1b0a-42bc-a6b3-d7de0ce4b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-b9aa56f3-cc39-4bd7-b1b3-134b9f0d0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-6dc29d8a-56cc-4422-9419-25918ceedcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-9bf147b5-16b3-4c1a-9c7f-72240f341092,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-4d48ad84-6fef-47c1-8aad-a90e30faca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-cebf99a1-54d7-42d2-8a1d-8fe898f984df,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-186ac40a-9fe7-421f-8901-cf8aa92b79e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506408955-172.17.0.19-1599360007967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-0d1acfcb-bcfa-4e18-be1c-f24cbcb0129d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-070a25ee-22a4-48cb-a8b3-fe2d4d3798c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f6eeef9e-e1e5-49d0-a593-fb062680eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-419637bf-df9a-4423-8ab0-c0d04dbcf9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-b7338372-81c5-493e-821c-88d8aa9a88a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c83e8cdb-af04-457c-b62d-7c78aea9a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-9d5b4786-141d-4de1-9870-8eb79e79c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-89b205f2-5be8-4f57-803a-e840cb04089e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506408955-172.17.0.19-1599360007967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-0d1acfcb-bcfa-4e18-be1c-f24cbcb0129d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-070a25ee-22a4-48cb-a8b3-fe2d4d3798c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f6eeef9e-e1e5-49d0-a593-fb062680eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-419637bf-df9a-4423-8ab0-c0d04dbcf9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-b7338372-81c5-493e-821c-88d8aa9a88a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c83e8cdb-af04-457c-b62d-7c78aea9a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-9d5b4786-141d-4de1-9870-8eb79e79c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-89b205f2-5be8-4f57-803a-e840cb04089e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739704725-172.17.0.19-1599360080766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-d98860a0-f86e-4103-93c7-eb0c82637094,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-9d66ff0d-91e6-439c-aa08-a124f63c18df,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-6ea5867f-7329-4edc-b974-5d7fff62605e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-48129bc1-4225-4a81-a82d-ec6cedbddd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-1b2f910d-4618-4538-8828-a303691d16fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-b1706b6e-0222-4069-a9cc-c02c50cf16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-c2e0fa34-c020-4bae-9bcf-877e1b105113,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-e46acf9e-f9e8-440c-bd33-ebe68b1a70f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739704725-172.17.0.19-1599360080766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-d98860a0-f86e-4103-93c7-eb0c82637094,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-9d66ff0d-91e6-439c-aa08-a124f63c18df,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-6ea5867f-7329-4edc-b974-5d7fff62605e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-48129bc1-4225-4a81-a82d-ec6cedbddd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-1b2f910d-4618-4538-8828-a303691d16fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-b1706b6e-0222-4069-a9cc-c02c50cf16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-c2e0fa34-c020-4bae-9bcf-877e1b105113,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-e46acf9e-f9e8-440c-bd33-ebe68b1a70f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905285101-172.17.0.19-1599360351213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-68a1d375-d094-4a2c-896e-27b77b19dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-79f8b602-9564-467b-9321-718fa3cdf560,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-deccc678-75a8-4e16-a64e-f7e24946289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-882986c9-250c-4d0f-b767-0ff1470ac1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6a9fef9c-94f0-4925-831a-b0699cc450a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-8e62beb1-4b8c-466c-8c10-f4db0409b742,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-51e749e5-4288-4425-b88b-c9f7b8a8735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-515457c5-fc77-44bf-805c-504094f527e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905285101-172.17.0.19-1599360351213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-68a1d375-d094-4a2c-896e-27b77b19dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-79f8b602-9564-467b-9321-718fa3cdf560,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-deccc678-75a8-4e16-a64e-f7e24946289b,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-882986c9-250c-4d0f-b767-0ff1470ac1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6a9fef9c-94f0-4925-831a-b0699cc450a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-8e62beb1-4b8c-466c-8c10-f4db0409b742,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-51e749e5-4288-4425-b88b-c9f7b8a8735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-515457c5-fc77-44bf-805c-504094f527e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681671895-172.17.0.19-1599360494910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-38047265-4d7e-43da-a345-f6cb6bbfda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-c19dbcf0-97a2-4d95-bbf5-301f263fb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-2362f1c5-ae0c-4094-8274-bf68416a94fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-af863384-310f-4c97-9ee0-323ea9305510,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-4c254f04-7d9c-4982-a170-e74f93d0cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-daf88ad8-94df-4e67-b88c-ad1b3b1e7848,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a1d78912-46fd-40e8-9fcb-1efb7c6e7998,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-79ee940c-e432-4bf3-87b7-c8bd7e11a9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681671895-172.17.0.19-1599360494910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-38047265-4d7e-43da-a345-f6cb6bbfda0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-c19dbcf0-97a2-4d95-bbf5-301f263fb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-2362f1c5-ae0c-4094-8274-bf68416a94fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-af863384-310f-4c97-9ee0-323ea9305510,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-4c254f04-7d9c-4982-a170-e74f93d0cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-daf88ad8-94df-4e67-b88c-ad1b3b1e7848,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a1d78912-46fd-40e8-9fcb-1efb7c6e7998,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-79ee940c-e432-4bf3-87b7-c8bd7e11a9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174484015-172.17.0.19-1599360837310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-4213d52b-e94c-4078-9877-f3b8d18710ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-83157004-8b89-423c-8773-e4a96394e140,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-20e0c00b-d87c-4a54-a728-31eade5de794,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-8121e649-82e6-4646-bf57-786c3c2d323e,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-772db3b2-cb56-424e-9a43-d216cc620a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-e6db32a9-7906-4b51-88bb-ea18af3a8764,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-ffa84087-e4a7-4a86-aacf-91e55ca2676f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-67f84bf4-8991-472e-981d-7f63f458f909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174484015-172.17.0.19-1599360837310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-4213d52b-e94c-4078-9877-f3b8d18710ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-83157004-8b89-423c-8773-e4a96394e140,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-20e0c00b-d87c-4a54-a728-31eade5de794,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-8121e649-82e6-4646-bf57-786c3c2d323e,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-772db3b2-cb56-424e-9a43-d216cc620a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-e6db32a9-7906-4b51-88bb-ea18af3a8764,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-ffa84087-e4a7-4a86-aacf-91e55ca2676f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-67f84bf4-8991-472e-981d-7f63f458f909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452539005-172.17.0.19-1599360894505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-bb5b79e0-d14b-4f54-95c5-b68bd725d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-ef3d6ed0-fdc8-40da-b453-6cf399f6b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-bb4dae24-5512-49fb-9974-68252d7cab53,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8c08f08e-7c7c-4d25-8c38-2ffef7d63079,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-541a8134-0e4b-496c-ba8c-24c3354c9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-340e3a70-156b-4f2f-a375-cef059bcd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-e361f4e2-0f8d-4fec-8fe6-8dcd76ef5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-6da59196-97f6-4ab5-aa03-db872c29856b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452539005-172.17.0.19-1599360894505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-bb5b79e0-d14b-4f54-95c5-b68bd725d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-ef3d6ed0-fdc8-40da-b453-6cf399f6b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-bb4dae24-5512-49fb-9974-68252d7cab53,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8c08f08e-7c7c-4d25-8c38-2ffef7d63079,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-541a8134-0e4b-496c-ba8c-24c3354c9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-340e3a70-156b-4f2f-a375-cef059bcd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-e361f4e2-0f8d-4fec-8fe6-8dcd76ef5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-6da59196-97f6-4ab5-aa03-db872c29856b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042128928-172.17.0.19-1599361913237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-10d279d4-4fa3-4f04-a1ce-4dd365f9e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-aa77c7dc-b725-46bc-9472-2995a7f683af,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-e4294fa6-2c46-46fb-ba12-8d2a307e3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-8182f47a-6704-48b1-ae90-95b12960e683,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-d7ea5a53-7c9e-4951-b475-d2c4442bbe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-e0e2f325-7e76-412d-910c-6629ad086bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-472505b4-1a1c-4814-a25d-37d06b74595c,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-18815aac-3340-4229-b05b-5994beb3b5e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042128928-172.17.0.19-1599361913237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-10d279d4-4fa3-4f04-a1ce-4dd365f9e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-aa77c7dc-b725-46bc-9472-2995a7f683af,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-e4294fa6-2c46-46fb-ba12-8d2a307e3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-8182f47a-6704-48b1-ae90-95b12960e683,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-d7ea5a53-7c9e-4951-b475-d2c4442bbe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-e0e2f325-7e76-412d-910c-6629ad086bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-472505b4-1a1c-4814-a25d-37d06b74595c,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-18815aac-3340-4229-b05b-5994beb3b5e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293796262-172.17.0.19-1599361949939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-c6434f23-8e0f-4533-bc24-15934ea61404,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-34d82748-fbb3-4c0e-850e-4ad599f1a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-47704dab-e889-4c83-9a46-9be1a78c3ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-dc27a70c-ba67-478a-b19d-9a3ce38e6345,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-be8671a7-9108-4dff-9110-115e39333f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-f6ee617e-6aea-4d6e-b812-8e7c465d3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-dd6a0cb3-046e-474f-885e-fdeb625ba59d,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-a3704a46-a112-4be6-aacb-17b5627d654d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293796262-172.17.0.19-1599361949939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44797,DS-c6434f23-8e0f-4533-bc24-15934ea61404,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-34d82748-fbb3-4c0e-850e-4ad599f1a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-47704dab-e889-4c83-9a46-9be1a78c3ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-dc27a70c-ba67-478a-b19d-9a3ce38e6345,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-be8671a7-9108-4dff-9110-115e39333f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-f6ee617e-6aea-4d6e-b812-8e7c465d3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-dd6a0cb3-046e-474f-885e-fdeb625ba59d,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-a3704a46-a112-4be6-aacb-17b5627d654d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802274740-172.17.0.19-1599363543806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-8376e94d-7c58-4db7-bde7-10689bc741fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-1dbd988b-4d03-4d8f-b689-07f770b20188,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-4e195dba-613f-488a-b2e0-a62db65cc9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-d19bb9df-c4d7-4b69-8d16-22c8e238d937,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-9b8a6a58-9eb0-4df6-baa9-34fb5e0cc841,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-684cdea8-3956-49bf-98d0-cbc140083dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-64c46b10-ec74-49fc-8fbd-b54db4a43fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-ba9c64c0-f70e-46ca-9413-61f9d9f03da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802274740-172.17.0.19-1599363543806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-8376e94d-7c58-4db7-bde7-10689bc741fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-1dbd988b-4d03-4d8f-b689-07f770b20188,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-4e195dba-613f-488a-b2e0-a62db65cc9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-d19bb9df-c4d7-4b69-8d16-22c8e238d937,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-9b8a6a58-9eb0-4df6-baa9-34fb5e0cc841,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-684cdea8-3956-49bf-98d0-cbc140083dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-64c46b10-ec74-49fc-8fbd-b54db4a43fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-ba9c64c0-f70e-46ca-9413-61f9d9f03da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178541333-172.17.0.19-1599363897148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-e211335f-3271-4cdb-9b90-1fdd5895a808,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-b9c06cd2-dc35-4898-ae5e-7173b69aaf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-10cd50bc-8186-45a9-bdb1-b0865183daea,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-967c450d-bca4-4c29-a0ab-b1e0b2f3cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-bb58b8e5-3b71-4364-8161-f27d8c66141a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-a746987c-0416-452a-9f8f-9ebeb6ac123b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-47fa372a-11f7-454c-9444-2f9233495a60,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-48df9927-f9c5-4081-bb8f-a5a714b6ad6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178541333-172.17.0.19-1599363897148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-e211335f-3271-4cdb-9b90-1fdd5895a808,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-b9c06cd2-dc35-4898-ae5e-7173b69aaf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-10cd50bc-8186-45a9-bdb1-b0865183daea,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-967c450d-bca4-4c29-a0ab-b1e0b2f3cd77,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-bb58b8e5-3b71-4364-8161-f27d8c66141a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-a746987c-0416-452a-9f8f-9ebeb6ac123b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-47fa372a-11f7-454c-9444-2f9233495a60,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-48df9927-f9c5-4081-bb8f-a5a714b6ad6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636682740-172.17.0.19-1599364056822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-b507283a-5d78-4558-a3dd-4c2d33722b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-543dcb28-6b6e-490e-9bc0-6bb396d8b761,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-91ce6614-8cd4-415c-b833-4c8d9b8583eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-23a44dc7-61a2-4100-9a49-3963f37bab23,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-4cc9eabf-a422-4da1-bd19-973cbeb13a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0a27bf24-a74d-4b39-bbdf-ddaa53b22dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-d9752fb0-f76e-42aa-b759-dc1e96d00059,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-d8e4498a-9337-43ae-a11c-a3d4849f221f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636682740-172.17.0.19-1599364056822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-b507283a-5d78-4558-a3dd-4c2d33722b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-543dcb28-6b6e-490e-9bc0-6bb396d8b761,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-91ce6614-8cd4-415c-b833-4c8d9b8583eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-23a44dc7-61a2-4100-9a49-3963f37bab23,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-4cc9eabf-a422-4da1-bd19-973cbeb13a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0a27bf24-a74d-4b39-bbdf-ddaa53b22dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-d9752fb0-f76e-42aa-b759-dc1e96d00059,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-d8e4498a-9337-43ae-a11c-a3d4849f221f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421892646-172.17.0.19-1599364093605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-d36cd2bb-f6c2-4dc0-a4f7-71852c57de78,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-1d0a20d3-879e-4541-b284-0af35fad362e,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-919161f7-411a-49db-88ab-b45d258178a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-0d19c7e5-61fa-4db2-af6e-cdd3d7359b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-d509b0b5-48f8-4f03-ae0e-7400607cc3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-2d304d29-9803-41d7-b5a3-bf135407a9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-493925a2-2d9a-41d9-b2ba-13ffaaef1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-380ba283-cd29-4496-92e5-71b0e8cca538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421892646-172.17.0.19-1599364093605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-d36cd2bb-f6c2-4dc0-a4f7-71852c57de78,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-1d0a20d3-879e-4541-b284-0af35fad362e,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-919161f7-411a-49db-88ab-b45d258178a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-0d19c7e5-61fa-4db2-af6e-cdd3d7359b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-d509b0b5-48f8-4f03-ae0e-7400607cc3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-2d304d29-9803-41d7-b5a3-bf135407a9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-493925a2-2d9a-41d9-b2ba-13ffaaef1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-380ba283-cd29-4496-92e5-71b0e8cca538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5040
