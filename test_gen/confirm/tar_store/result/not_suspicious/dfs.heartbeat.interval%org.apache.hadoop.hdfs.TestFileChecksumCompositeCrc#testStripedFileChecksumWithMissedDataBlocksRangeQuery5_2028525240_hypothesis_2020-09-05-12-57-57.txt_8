reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252470038-172.17.0.12-1599310692562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-9c03a184-0b0b-4e26-aee7-26e164e7032d,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-c338be33-0b19-4de1-adc9-5a9b6bd08e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-0d988bd4-d772-4736-b33a-228482eec49c,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-444d05c3-14f1-4a45-8b03-33b45283815c,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-c4b5bd11-4202-4abf-9029-c5aed2182b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-b60cc4e5-b63c-49f6-9556-1b16e31665cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-db1ea9df-c938-4ff8-a148-77b091294e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-cbf2d38a-f5ee-4bcc-8854-e3476d4e2aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252470038-172.17.0.12-1599310692562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-9c03a184-0b0b-4e26-aee7-26e164e7032d,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-c338be33-0b19-4de1-adc9-5a9b6bd08e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-0d988bd4-d772-4736-b33a-228482eec49c,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-444d05c3-14f1-4a45-8b03-33b45283815c,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-c4b5bd11-4202-4abf-9029-c5aed2182b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-b60cc4e5-b63c-49f6-9556-1b16e31665cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-db1ea9df-c938-4ff8-a148-77b091294e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-cbf2d38a-f5ee-4bcc-8854-e3476d4e2aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018536680-172.17.0.12-1599311243249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42291,DS-3ecd447e-70be-4e5f-bb75-371c4ac16d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-eb3dcb3a-1206-41d8-a55f-f1d9b2e5693d,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-a01b1914-22e4-4775-9bd2-02ec13725f12,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-851a8f6d-b7a6-4665-859e-2c47cd292026,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-63f86e7a-0e44-4b1f-bbb2-0593877d907c,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-850ab197-fab2-40d3-8dc5-a54740586fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-3bff394e-c26a-45ea-9be7-9027362876ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-f53fd56d-3afd-4c4a-90bd-8380cdcf41d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018536680-172.17.0.12-1599311243249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42291,DS-3ecd447e-70be-4e5f-bb75-371c4ac16d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-eb3dcb3a-1206-41d8-a55f-f1d9b2e5693d,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-a01b1914-22e4-4775-9bd2-02ec13725f12,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-851a8f6d-b7a6-4665-859e-2c47cd292026,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-63f86e7a-0e44-4b1f-bbb2-0593877d907c,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-850ab197-fab2-40d3-8dc5-a54740586fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-3bff394e-c26a-45ea-9be7-9027362876ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-f53fd56d-3afd-4c4a-90bd-8380cdcf41d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81262039-172.17.0.12-1599311505771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-cde23cd1-bfbd-45c2-957c-47694a6c6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-64b2d7eb-046a-4280-9b16-b981db0aef76,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f6816590-17a4-467f-8180-fe41ca76b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-fd81d826-93d7-4236-877e-d1d1cd8ac592,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-409d5ccb-4c21-4322-b815-87269b907c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-d8af658d-fde0-420a-ad32-af0678e82b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-1a33fbd0-3b8c-44f5-bb2f-4b4b3c8b4783,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-26bb3da5-0d1c-4136-a0a9-0a6e2925887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81262039-172.17.0.12-1599311505771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45089,DS-cde23cd1-bfbd-45c2-957c-47694a6c6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-64b2d7eb-046a-4280-9b16-b981db0aef76,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f6816590-17a4-467f-8180-fe41ca76b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-fd81d826-93d7-4236-877e-d1d1cd8ac592,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-409d5ccb-4c21-4322-b815-87269b907c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-d8af658d-fde0-420a-ad32-af0678e82b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-1a33fbd0-3b8c-44f5-bb2f-4b4b3c8b4783,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-26bb3da5-0d1c-4136-a0a9-0a6e2925887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567051295-172.17.0.12-1599311686169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-ec0bfdd6-b3bc-4080-ae3d-bb61f39c5ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-0938165f-bca2-4855-8cdf-e8294d78bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-c5c6599b-8da2-4b26-8173-f996bf49393b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-1f3d3725-649b-478e-b834-35c8a9ce0cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c19557fb-1b6a-4957-88da-3261aae2ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-a1cb3dc0-bbec-4648-a434-442a9b1cd5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a4c576e8-7913-4d94-99e8-116f1afa5bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-ec2dba67-5cca-4082-b302-eaa5c702a5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567051295-172.17.0.12-1599311686169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-ec0bfdd6-b3bc-4080-ae3d-bb61f39c5ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-0938165f-bca2-4855-8cdf-e8294d78bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-c5c6599b-8da2-4b26-8173-f996bf49393b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-1f3d3725-649b-478e-b834-35c8a9ce0cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c19557fb-1b6a-4957-88da-3261aae2ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-a1cb3dc0-bbec-4648-a434-442a9b1cd5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a4c576e8-7913-4d94-99e8-116f1afa5bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-ec2dba67-5cca-4082-b302-eaa5c702a5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644312201-172.17.0.12-1599311899041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-229eec4a-b057-43b5-aa7c-fcc5e66e8275,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-14181806-3e5f-43bf-9756-e6509abfb8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-cb38f9d5-cc6d-42fd-98f0-da0816d9b304,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-cec85ead-1a49-4515-bc72-45add83fb498,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8e85af32-3cb9-4eee-9cbd-3a4918756a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ac8177c6-b203-486d-b977-f34bf8d362c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-90fa5715-dee3-467c-a99b-02fc9822d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-14ca7ff1-1988-485f-ac27-ea0811809a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644312201-172.17.0.12-1599311899041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-229eec4a-b057-43b5-aa7c-fcc5e66e8275,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-14181806-3e5f-43bf-9756-e6509abfb8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-cb38f9d5-cc6d-42fd-98f0-da0816d9b304,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-cec85ead-1a49-4515-bc72-45add83fb498,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8e85af32-3cb9-4eee-9cbd-3a4918756a64,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-ac8177c6-b203-486d-b977-f34bf8d362c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-90fa5715-dee3-467c-a99b-02fc9822d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-14ca7ff1-1988-485f-ac27-ea0811809a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876298011-172.17.0.12-1599312151513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-1da476d7-7319-4144-a031-7ce7ecb579c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-4cd9b0d8-b6b9-4ddd-be62-c4ebc8f8239e,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-7f2ca3ec-25da-4993-ba81-c60011d1fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-7ea63056-97b7-4cf0-8559-655e19667ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f86298f5-4901-4240-aa72-927686aa6a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-5a7f0573-ffbf-4b9f-9c1c-3942d5a15e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-caf8a45d-a12b-476e-835a-9cd5df48edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-ec741998-c680-405c-8d47-980f348c3ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876298011-172.17.0.12-1599312151513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-1da476d7-7319-4144-a031-7ce7ecb579c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-4cd9b0d8-b6b9-4ddd-be62-c4ebc8f8239e,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-7f2ca3ec-25da-4993-ba81-c60011d1fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-7ea63056-97b7-4cf0-8559-655e19667ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-f86298f5-4901-4240-aa72-927686aa6a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-5a7f0573-ffbf-4b9f-9c1c-3942d5a15e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-caf8a45d-a12b-476e-835a-9cd5df48edc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-ec741998-c680-405c-8d47-980f348c3ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434929884-172.17.0.12-1599313206340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-2d6e54b7-2579-4748-80d4-cf9deb0fd426,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-7c05619a-44e4-459b-bc16-3b2769e9d5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e296f7ac-9020-4c6e-b903-3a74572cdd10,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-901beca1-30f1-4564-91ef-e341e14f414e,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-2148e07a-5d45-4476-b812-1d9b08d2ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b07b8865-9f23-406f-a401-2d2f9514c781,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-8f830afe-c3b8-4c91-935e-d620843437d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-d073ef4d-7d83-40f5-82ee-42c171adc7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434929884-172.17.0.12-1599313206340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-2d6e54b7-2579-4748-80d4-cf9deb0fd426,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-7c05619a-44e4-459b-bc16-3b2769e9d5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e296f7ac-9020-4c6e-b903-3a74572cdd10,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-901beca1-30f1-4564-91ef-e341e14f414e,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-2148e07a-5d45-4476-b812-1d9b08d2ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b07b8865-9f23-406f-a401-2d2f9514c781,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-8f830afe-c3b8-4c91-935e-d620843437d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-d073ef4d-7d83-40f5-82ee-42c171adc7c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151154270-172.17.0.12-1599313388615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-d2583060-89c5-4716-b561-5f9188e39a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-858a9543-a4ea-466a-b114-6da7445cb649,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-be5957df-e741-44de-8e77-8691ee1051d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-a56d8829-c67a-4e33-9d20-6fa2075a8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-5292fc3c-4a7a-46b0-9317-84e24cb8f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b8b302ca-15df-485c-9144-d47a2fded0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-9c6878d2-d62f-42a5-a05a-ac5de6ac8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-675b79f6-a72d-469b-b389-94a97e2ff8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151154270-172.17.0.12-1599313388615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-d2583060-89c5-4716-b561-5f9188e39a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-858a9543-a4ea-466a-b114-6da7445cb649,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-be5957df-e741-44de-8e77-8691ee1051d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-a56d8829-c67a-4e33-9d20-6fa2075a8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-5292fc3c-4a7a-46b0-9317-84e24cb8f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b8b302ca-15df-485c-9144-d47a2fded0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-9c6878d2-d62f-42a5-a05a-ac5de6ac8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-675b79f6-a72d-469b-b389-94a97e2ff8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627271126-172.17.0.12-1599313451117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40690,DS-d1454d7c-9da5-46ee-84e4-65515e7fe3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-9bd8430d-f1c6-4dce-ab00-74838e2268b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-2850b795-1ed5-4a6f-adab-fc1644a5dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-07c2dc0a-a955-4598-9d7a-b329fe43b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-d15a3b88-3349-40b8-aba5-465a514cb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-0ed39bab-f1c8-4bb9-b689-e3048eb8fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1754716e-66fb-4f29-a3c6-1f003527192b,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-006eac9c-91e5-431e-866e-dc98259d6ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627271126-172.17.0.12-1599313451117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40690,DS-d1454d7c-9da5-46ee-84e4-65515e7fe3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-9bd8430d-f1c6-4dce-ab00-74838e2268b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-2850b795-1ed5-4a6f-adab-fc1644a5dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-07c2dc0a-a955-4598-9d7a-b329fe43b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-d15a3b88-3349-40b8-aba5-465a514cb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-0ed39bab-f1c8-4bb9-b689-e3048eb8fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1754716e-66fb-4f29-a3c6-1f003527192b,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-006eac9c-91e5-431e-866e-dc98259d6ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446301750-172.17.0.12-1599313514915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-62ac43b8-67a1-4b44-bdf2-de8aac9d20c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-7fbd2574-8bb0-4b0e-814e-e57ab6079e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-feee1282-a0b9-4e04-bc94-6fca4e600546,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-2ce132b1-a48d-48cd-b9ac-2982272a8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-26860ea9-72b6-47b2-a95a-36ea4f5970c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-522c9aed-40c8-455d-9881-6631ed057f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-e710f451-0db2-4f59-a0be-4f3537d1dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-34b43650-db2a-4404-a570-a98b5a0e1d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446301750-172.17.0.12-1599313514915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-62ac43b8-67a1-4b44-bdf2-de8aac9d20c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-7fbd2574-8bb0-4b0e-814e-e57ab6079e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-feee1282-a0b9-4e04-bc94-6fca4e600546,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-2ce132b1-a48d-48cd-b9ac-2982272a8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-26860ea9-72b6-47b2-a95a-36ea4f5970c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-522c9aed-40c8-455d-9881-6631ed057f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-e710f451-0db2-4f59-a0be-4f3537d1dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-34b43650-db2a-4404-a570-a98b5a0e1d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616324660-172.17.0.12-1599314269830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-c22571e7-66ab-4ae9-a7b8-bfff0271405e,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7a4afdb1-7b56-406d-8a22-b7962ee70542,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-26ebc422-7a31-43ea-acbb-960617ee61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-632d3092-1476-4c76-85bd-33e02cf56139,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-48b00233-c907-432a-a334-0692448f2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-db802e85-80da-44c8-9cd8-2e19ae578e02,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-3ebeaf47-cd73-4e23-b471-0dbcaafdd73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-e40c2ef2-6a6e-48e9-8649-0846e845d064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616324660-172.17.0.12-1599314269830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-c22571e7-66ab-4ae9-a7b8-bfff0271405e,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-7a4afdb1-7b56-406d-8a22-b7962ee70542,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-26ebc422-7a31-43ea-acbb-960617ee61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-632d3092-1476-4c76-85bd-33e02cf56139,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-48b00233-c907-432a-a334-0692448f2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-db802e85-80da-44c8-9cd8-2e19ae578e02,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-3ebeaf47-cd73-4e23-b471-0dbcaafdd73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-e40c2ef2-6a6e-48e9-8649-0846e845d064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910383976-172.17.0.12-1599314344504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-b989476d-92fc-4528-8a70-8528357e1879,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-af9e05c9-5a30-4ad5-92ff-c0143b8afce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1e8abdbb-a534-45ba-bbea-9b7f808f6415,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-3a97f03b-2e47-40e6-a34c-c1472af3cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-da7d6fab-d9a1-423f-baea-214bf1f8823d,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-ec7e08fe-592b-459d-8dfc-b063979b9ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-36adbf20-1e95-4dc6-811c-76c42077af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-2719b981-a531-4fda-adc2-b59d8fc5d191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910383976-172.17.0.12-1599314344504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34003,DS-b989476d-92fc-4528-8a70-8528357e1879,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-af9e05c9-5a30-4ad5-92ff-c0143b8afce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1e8abdbb-a534-45ba-bbea-9b7f808f6415,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-3a97f03b-2e47-40e6-a34c-c1472af3cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-da7d6fab-d9a1-423f-baea-214bf1f8823d,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-ec7e08fe-592b-459d-8dfc-b063979b9ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-36adbf20-1e95-4dc6-811c-76c42077af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-2719b981-a531-4fda-adc2-b59d8fc5d191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675703935-172.17.0.12-1599314711856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-b78025dc-6292-485c-a190-87f64a5ca4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-ef993972-be4b-4930-9cf5-be3537af3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-370bf1d6-e7ea-464f-bccc-73c4736961cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-974f6c65-2690-412f-8f23-b8992cf70518,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-9795c43b-c72f-4e93-944b-30cbcd0a2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-631d890f-fcd7-4e9b-a3b5-0386e53dc59e,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-5f599d96-0078-4f19-a150-dfbc4f052351,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-c07cd94e-fa93-4ac2-8e85-cc17e36c1559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675703935-172.17.0.12-1599314711856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-b78025dc-6292-485c-a190-87f64a5ca4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-ef993972-be4b-4930-9cf5-be3537af3e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-370bf1d6-e7ea-464f-bccc-73c4736961cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-974f6c65-2690-412f-8f23-b8992cf70518,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-9795c43b-c72f-4e93-944b-30cbcd0a2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-631d890f-fcd7-4e9b-a3b5-0386e53dc59e,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-5f599d96-0078-4f19-a150-dfbc4f052351,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-c07cd94e-fa93-4ac2-8e85-cc17e36c1559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526018811-172.17.0.12-1599314901628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-c7818352-8900-4764-b2b4-e831bad4babc,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-797862d2-5212-457c-a22b-25f56ccc76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5cdad00f-9764-48b0-b7ac-a30de7be65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-64777976-4f05-49aa-97a7-8ab5de23fb68,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-cf52c5a4-c5ea-46de-a7aa-98fb50daab98,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-6d3872a6-06dc-48d8-9ec3-3235a325d0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-760ddd0e-153b-4b67-ba4a-bfcae5144479,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-9cf2d904-0f0d-4e3b-afc0-5ddbf138eb52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526018811-172.17.0.12-1599314901628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-c7818352-8900-4764-b2b4-e831bad4babc,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-797862d2-5212-457c-a22b-25f56ccc76c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5cdad00f-9764-48b0-b7ac-a30de7be65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-64777976-4f05-49aa-97a7-8ab5de23fb68,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-cf52c5a4-c5ea-46de-a7aa-98fb50daab98,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-6d3872a6-06dc-48d8-9ec3-3235a325d0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-760ddd0e-153b-4b67-ba4a-bfcae5144479,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-9cf2d904-0f0d-4e3b-afc0-5ddbf138eb52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476101571-172.17.0.12-1599315344584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-411b4ffe-d375-4c54-9d21-ff75736cbbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2240b6af-a14e-4c3a-9bc9-d28a8014f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-f255b692-1a2c-4d7c-84c3-376eb68ed113,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-b49e0b54-1c61-4d96-8f51-aeb5d6676be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-6ac76525-bf13-4285-91cb-09a1feb843a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-d7a8bc93-5aae-432a-825c-aa5a8aa1ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-526be5d6-6a53-498b-addb-8d618e00f980,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-45533d35-aaeb-405f-be33-3f2f668c2bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476101571-172.17.0.12-1599315344584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-411b4ffe-d375-4c54-9d21-ff75736cbbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2240b6af-a14e-4c3a-9bc9-d28a8014f89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-f255b692-1a2c-4d7c-84c3-376eb68ed113,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-b49e0b54-1c61-4d96-8f51-aeb5d6676be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-6ac76525-bf13-4285-91cb-09a1feb843a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-d7a8bc93-5aae-432a-825c-aa5a8aa1ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-526be5d6-6a53-498b-addb-8d618e00f980,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-45533d35-aaeb-405f-be33-3f2f668c2bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855946002-172.17.0.12-1599315823665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-8ecd2eda-ae58-4489-8eec-d7b33f062d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-55901f9f-f755-48ca-8bd2-6544a52ccf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-3a08a488-5162-4f3c-b74f-a58f7ba4c123,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-47709cb4-d0eb-4e5e-83bc-b57412ac365e,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-6a44be07-4b2d-4da1-9a46-1a8e6731ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-637da599-8ac7-41d6-bdb3-fe2491fcb690,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-5ea016e4-4bfd-40ad-bb1b-82d44bf912a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-159a4abb-e83a-4404-877e-6f2325027281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855946002-172.17.0.12-1599315823665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-8ecd2eda-ae58-4489-8eec-d7b33f062d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-55901f9f-f755-48ca-8bd2-6544a52ccf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-3a08a488-5162-4f3c-b74f-a58f7ba4c123,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-47709cb4-d0eb-4e5e-83bc-b57412ac365e,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-6a44be07-4b2d-4da1-9a46-1a8e6731ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-637da599-8ac7-41d6-bdb3-fe2491fcb690,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-5ea016e4-4bfd-40ad-bb1b-82d44bf912a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-159a4abb-e83a-4404-877e-6f2325027281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5497
