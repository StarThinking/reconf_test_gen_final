reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372919181-172.17.0.2-1599342237446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-897f4064-1a7b-45e1-89e3-b4de09784ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-81adc103-f2e0-4da4-94fd-c898ed796bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c47c8d9b-a858-4519-9ae2-c0f21b2cde90,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b98021e0-2e23-451b-a392-af3d1cb582e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-16ec7cc4-98b1-4a46-94d3-22e861e9cdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-6379e81c-5c8d-4951-b843-0e5b998d2ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-113641f3-933b-42a7-8c18-fc5ae3ce55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2a97126b-4153-49f9-97c9-b4478888a8a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372919181-172.17.0.2-1599342237446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-897f4064-1a7b-45e1-89e3-b4de09784ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-81adc103-f2e0-4da4-94fd-c898ed796bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c47c8d9b-a858-4519-9ae2-c0f21b2cde90,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b98021e0-2e23-451b-a392-af3d1cb582e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-16ec7cc4-98b1-4a46-94d3-22e861e9cdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-6379e81c-5c8d-4951-b843-0e5b998d2ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-113641f3-933b-42a7-8c18-fc5ae3ce55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2a97126b-4153-49f9-97c9-b4478888a8a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246572996-172.17.0.2-1599342276735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-f556eb85-8259-465b-bffa-536d5711c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-78c85f10-e36a-4704-bb30-7357e342695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-5b3d6804-5793-435e-8265-fe4edab905d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-f745bba0-511e-4212-8639-187691fe1caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-b1728788-3ce0-40eb-9ba0-4ba96a8518bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-8a0c06e9-6057-4678-beec-9d54ae336d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-7f189a02-27bc-4199-b68e-12a85894977a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-56d2e944-3c20-45b1-907f-fbc5a61238ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246572996-172.17.0.2-1599342276735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-f556eb85-8259-465b-bffa-536d5711c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-78c85f10-e36a-4704-bb30-7357e342695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-5b3d6804-5793-435e-8265-fe4edab905d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-f745bba0-511e-4212-8639-187691fe1caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-b1728788-3ce0-40eb-9ba0-4ba96a8518bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-8a0c06e9-6057-4678-beec-9d54ae336d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-7f189a02-27bc-4199-b68e-12a85894977a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-56d2e944-3c20-45b1-907f-fbc5a61238ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768574264-172.17.0.2-1599342311695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-87984e8e-ec49-4075-9788-f6a41b26b507,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-33413a3b-db01-4336-aa0d-2dc1d58dcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-9b09d853-6ccf-412a-aebd-07ac0ccdac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-77ff36f5-198a-436a-a12f-36cd3807233b,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-d91e357d-bb97-4e58-a97d-bc56ee736af7,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-dbd41015-38a1-4a50-b996-eb615583e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-6e6b8f7e-333b-4923-b387-c54b9b87e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-a0d66b42-06f3-4c51-88d7-a8a5a8beba3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768574264-172.17.0.2-1599342311695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36165,DS-87984e8e-ec49-4075-9788-f6a41b26b507,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-33413a3b-db01-4336-aa0d-2dc1d58dcf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-9b09d853-6ccf-412a-aebd-07ac0ccdac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-77ff36f5-198a-436a-a12f-36cd3807233b,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-d91e357d-bb97-4e58-a97d-bc56ee736af7,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-dbd41015-38a1-4a50-b996-eb615583e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-6e6b8f7e-333b-4923-b387-c54b9b87e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-a0d66b42-06f3-4c51-88d7-a8a5a8beba3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937843808-172.17.0.2-1599342469003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-e1f368f9-688f-4891-9e20-35e3e2f67b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-4ed998cd-d6f8-4577-ba06-b6f8ca5b2637,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-de8470f8-86ce-4451-8490-db9d31035cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-6042ca19-243e-44b3-8031-9f5c9b783d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-51b3bd00-c922-4624-88bb-1bb8777f62f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-bdb08004-4cbb-486c-aa90-d5366a00645c,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-149034fb-ec93-4443-a015-7b3739671321,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-ef3ebc02-9b44-406e-b5c0-be9366c3c900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937843808-172.17.0.2-1599342469003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32900,DS-e1f368f9-688f-4891-9e20-35e3e2f67b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-4ed998cd-d6f8-4577-ba06-b6f8ca5b2637,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-de8470f8-86ce-4451-8490-db9d31035cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-6042ca19-243e-44b3-8031-9f5c9b783d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-51b3bd00-c922-4624-88bb-1bb8777f62f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-bdb08004-4cbb-486c-aa90-d5366a00645c,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-149034fb-ec93-4443-a015-7b3739671321,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-ef3ebc02-9b44-406e-b5c0-be9366c3c900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561363937-172.17.0.2-1599342551016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-4548a778-1c56-4c28-a6e6-b8b9d53f7fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-b56eb06d-6111-4c08-855e-f175972d4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-a4e646a4-6022-45d0-aba8-d141259a5b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-576eca84-a024-40cf-9c3a-3437b4ceb70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-5b64a587-562a-438e-ac34-6a3abefb9a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-f5cd3742-8f42-48ec-8455-4ae9933973fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-ccd7db0a-28b6-4e00-8f96-ffefeda569ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-d6537230-cf32-42fd-8e85-015df1829a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561363937-172.17.0.2-1599342551016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-4548a778-1c56-4c28-a6e6-b8b9d53f7fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-b56eb06d-6111-4c08-855e-f175972d4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-a4e646a4-6022-45d0-aba8-d141259a5b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-576eca84-a024-40cf-9c3a-3437b4ceb70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-5b64a587-562a-438e-ac34-6a3abefb9a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-f5cd3742-8f42-48ec-8455-4ae9933973fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-ccd7db0a-28b6-4e00-8f96-ffefeda569ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-d6537230-cf32-42fd-8e85-015df1829a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632399176-172.17.0.2-1599342612960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-772fb6c7-7fb9-4915-988f-269f361035af,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9e5e8773-ba7b-489a-8943-367a189d0933,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-0e2072cf-f08a-4bf5-a0a8-3b5d6a852c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-228f838e-ace5-4f2d-954b-ddabfb4f7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-059bd397-7d51-49c5-aa8b-ec3b1901a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-e8a2cacc-84c0-4826-8167-3a01fa7ab2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-edbed856-8af3-4059-99cf-2eb31fc0df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9fdca8e1-bde0-4bf8-b49c-3f27a8ac2c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632399176-172.17.0.2-1599342612960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-772fb6c7-7fb9-4915-988f-269f361035af,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9e5e8773-ba7b-489a-8943-367a189d0933,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-0e2072cf-f08a-4bf5-a0a8-3b5d6a852c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-228f838e-ace5-4f2d-954b-ddabfb4f7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-059bd397-7d51-49c5-aa8b-ec3b1901a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-e8a2cacc-84c0-4826-8167-3a01fa7ab2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-edbed856-8af3-4059-99cf-2eb31fc0df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9fdca8e1-bde0-4bf8-b49c-3f27a8ac2c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611983230-172.17.0.2-1599342725475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-23169afe-cb6f-4032-a4f6-cab67d47b5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-ef3f3a88-63dd-4021-8152-f57af8cb530d,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-57ffd6c7-f3cc-4885-95ae-89b44e9dd47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-19fd21e4-633f-4b55-9c0c-00ae242bb630,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-ee975451-1827-4d07-b6af-1ccd2e2ae121,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-23f7dfb5-49c7-41c3-9699-f1fb2266590a,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-b7544e68-2739-40b3-9379-c438d6186706,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-8732a235-7d6b-42d2-9a1f-0feb90075179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611983230-172.17.0.2-1599342725475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-23169afe-cb6f-4032-a4f6-cab67d47b5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-ef3f3a88-63dd-4021-8152-f57af8cb530d,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-57ffd6c7-f3cc-4885-95ae-89b44e9dd47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-19fd21e4-633f-4b55-9c0c-00ae242bb630,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-ee975451-1827-4d07-b6af-1ccd2e2ae121,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-23f7dfb5-49c7-41c3-9699-f1fb2266590a,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-b7544e68-2739-40b3-9379-c438d6186706,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-8732a235-7d6b-42d2-9a1f-0feb90075179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883199054-172.17.0.2-1599343116639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-573603e8-a8b5-462a-ad60-0841ac854aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d8341846-00f3-4a31-abf0-11f83be0e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-9429ddb2-a3e4-4e11-b1f0-7f31b8a3102f,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-a82fd003-f55f-4123-8575-d98071cdae57,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-c76f0ddc-a7c7-4267-8d40-1757b4926259,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-db0fa9fe-df85-464d-b6f3-0b575ab837ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-b3d2f2ba-86d3-4912-ad69-4aced2487a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-ed133530-0efc-436b-aacc-3d9e15018207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883199054-172.17.0.2-1599343116639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-573603e8-a8b5-462a-ad60-0841ac854aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d8341846-00f3-4a31-abf0-11f83be0e8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-9429ddb2-a3e4-4e11-b1f0-7f31b8a3102f,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-a82fd003-f55f-4123-8575-d98071cdae57,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-c76f0ddc-a7c7-4267-8d40-1757b4926259,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-db0fa9fe-df85-464d-b6f3-0b575ab837ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-b3d2f2ba-86d3-4912-ad69-4aced2487a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-ed133530-0efc-436b-aacc-3d9e15018207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860970233-172.17.0.2-1599343192385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-f1eb0827-4743-4dc8-9d4f-731ca7d3b726,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-a1de5ffa-b531-4358-9576-1213cf7f2dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-375c40d1-1fde-4fc9-8963-4a0c168f3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-a753571f-0a0b-4f8b-95d5-f4595d6c2cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-24ab469f-e690-4fd0-85c1-0dd1b9f0767e,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-c7404637-79ed-4036-8dc1-5af4b638fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-bba2274e-9548-4fd6-8e8d-c2ebfe673816,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-4b606b47-c74d-4557-b170-03b80d9927cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860970233-172.17.0.2-1599343192385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-f1eb0827-4743-4dc8-9d4f-731ca7d3b726,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-a1de5ffa-b531-4358-9576-1213cf7f2dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-375c40d1-1fde-4fc9-8963-4a0c168f3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-a753571f-0a0b-4f8b-95d5-f4595d6c2cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-24ab469f-e690-4fd0-85c1-0dd1b9f0767e,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-c7404637-79ed-4036-8dc1-5af4b638fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-bba2274e-9548-4fd6-8e8d-c2ebfe673816,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-4b606b47-c74d-4557-b170-03b80d9927cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394376545-172.17.0.2-1599343363343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-3507a552-bfbf-4bea-90bb-d2c530d48626,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-cad8188e-96f2-4b96-916a-fdd59ea255ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-dd91cd58-6747-4c2c-9e02-c3939013ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-83d87270-ef50-4e53-8b15-568d81862be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-3fec223b-52c2-4a66-9b23-1a1209f77115,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-bf78e29a-624c-4158-8735-410cd0990d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-749142c7-9f61-4f0e-ac05-d7cce77e69d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-b8b4a737-e253-4cad-97ce-e6bb4434ec7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394376545-172.17.0.2-1599343363343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-3507a552-bfbf-4bea-90bb-d2c530d48626,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-cad8188e-96f2-4b96-916a-fdd59ea255ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-dd91cd58-6747-4c2c-9e02-c3939013ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-83d87270-ef50-4e53-8b15-568d81862be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-3fec223b-52c2-4a66-9b23-1a1209f77115,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-bf78e29a-624c-4158-8735-410cd0990d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-749142c7-9f61-4f0e-ac05-d7cce77e69d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-b8b4a737-e253-4cad-97ce-e6bb4434ec7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066722457-172.17.0.2-1599343396504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-3ca50dca-893c-4e74-b8ed-4ecf400d0063,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ebe11dea-b807-4b10-a276-13c3aeabb7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-120c027a-70fb-4ad6-a19c-8aa54254a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-7c644062-2866-40c6-a477-edf2f416d492,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-f3ab4352-a787-48a4-85bd-16fdea388d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-8a490fd5-230d-4450-9344-4dab057e4638,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-a8fa3beb-64f5-41bd-8fe4-7def6d6f2977,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-bde77a93-7faf-46ce-95ec-d569b7aa9fdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066722457-172.17.0.2-1599343396504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-3ca50dca-893c-4e74-b8ed-4ecf400d0063,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ebe11dea-b807-4b10-a276-13c3aeabb7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-120c027a-70fb-4ad6-a19c-8aa54254a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-7c644062-2866-40c6-a477-edf2f416d492,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-f3ab4352-a787-48a4-85bd-16fdea388d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-8a490fd5-230d-4450-9344-4dab057e4638,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-a8fa3beb-64f5-41bd-8fe4-7def6d6f2977,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-bde77a93-7faf-46ce-95ec-d569b7aa9fdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166610527-172.17.0.2-1599343581749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35650,DS-1f3d4b6e-6bfe-4f2a-8854-8f912ea1c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-280305b3-dcc0-48a7-a9db-2c098856a118,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-cd2bb906-157e-408a-a2de-52f5f897b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-965c5f74-3359-46d6-9a04-a5ca6658bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-10f857a6-2eb9-43a3-92b8-7b645acad1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-abf20bd4-ebda-44ff-b640-43d49203f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-65987e88-b4d4-47ad-ae8b-1e6dc8c5956b,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b085c898-5d35-4b68-9866-48a5bf086a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166610527-172.17.0.2-1599343581749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35650,DS-1f3d4b6e-6bfe-4f2a-8854-8f912ea1c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-280305b3-dcc0-48a7-a9db-2c098856a118,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-cd2bb906-157e-408a-a2de-52f5f897b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-965c5f74-3359-46d6-9a04-a5ca6658bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-10f857a6-2eb9-43a3-92b8-7b645acad1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-abf20bd4-ebda-44ff-b640-43d49203f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-65987e88-b4d4-47ad-ae8b-1e6dc8c5956b,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b085c898-5d35-4b68-9866-48a5bf086a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922753254-172.17.0.2-1599343616082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-564bb4dd-9be2-463a-95ff-f9a3548d5f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-5fe6f387-7ae3-4931-8064-e6dd412d54fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-ce424e54-3aaf-4bac-a0c7-597fe6f4104a,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-350c1c46-15d9-40e9-a7b4-feefcab0f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-9c84fc2d-c4ad-49a8-a91e-15a81314c5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-b8c19c34-de09-4cfa-a42f-908bd518c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-b66e8950-9436-4f87-a40b-2dd96f56c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2a2518ef-c5e5-4712-8471-fa03242f50d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922753254-172.17.0.2-1599343616082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-564bb4dd-9be2-463a-95ff-f9a3548d5f47,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-5fe6f387-7ae3-4931-8064-e6dd412d54fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-ce424e54-3aaf-4bac-a0c7-597fe6f4104a,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-350c1c46-15d9-40e9-a7b4-feefcab0f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-9c84fc2d-c4ad-49a8-a91e-15a81314c5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-b8c19c34-de09-4cfa-a42f-908bd518c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-b66e8950-9436-4f87-a40b-2dd96f56c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2a2518ef-c5e5-4712-8471-fa03242f50d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773345091-172.17.0.2-1599343651566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-19088da0-4812-4dcd-83a6-e5d55689a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-2b4a79d7-a73a-41e5-a55a-bedbfe2330aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-5444305e-ac6d-4c14-bb8d-326e01a04fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-5249f98c-fb63-4a24-8c9a-3e6b99f4e892,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2f24d9a6-e63f-47ee-8eb0-ed771d8150f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-bc181c69-edcc-4ae1-b512-613f56a12a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-6495756d-b7c5-4cd2-aaf8-28733cd426b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-1cf97999-d911-4f99-9cb4-c9f39c82ab1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773345091-172.17.0.2-1599343651566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-19088da0-4812-4dcd-83a6-e5d55689a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-2b4a79d7-a73a-41e5-a55a-bedbfe2330aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-5444305e-ac6d-4c14-bb8d-326e01a04fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-5249f98c-fb63-4a24-8c9a-3e6b99f4e892,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2f24d9a6-e63f-47ee-8eb0-ed771d8150f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-bc181c69-edcc-4ae1-b512-613f56a12a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-6495756d-b7c5-4cd2-aaf8-28733cd426b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-1cf97999-d911-4f99-9cb4-c9f39c82ab1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236376784-172.17.0.2-1599343759236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33310,DS-6a35ec2e-2708-494d-b14e-5e1079da01b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-22a6eef8-c896-4135-9cf3-f0446dc4a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-f1b803c9-f97a-4b71-a2a0-2ff3616baf50,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-8e5df1ab-c2f2-469f-b253-8b7449d376c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-37e10c03-900a-4e36-b348-c8b8552ed4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-a52d3bf6-5ac5-489a-a2a9-cbb3fa401e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-bc4baf91-0776-48ad-8a9e-e04541084f72,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-ebea76b7-f89e-49f8-930c-b6d6998d0843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236376784-172.17.0.2-1599343759236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33310,DS-6a35ec2e-2708-494d-b14e-5e1079da01b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-22a6eef8-c896-4135-9cf3-f0446dc4a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-f1b803c9-f97a-4b71-a2a0-2ff3616baf50,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-8e5df1ab-c2f2-469f-b253-8b7449d376c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-37e10c03-900a-4e36-b348-c8b8552ed4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-a52d3bf6-5ac5-489a-a2a9-cbb3fa401e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-bc4baf91-0776-48ad-8a9e-e04541084f72,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-ebea76b7-f89e-49f8-930c-b6d6998d0843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385175175-172.17.0.2-1599343946287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-b3d45f99-2322-4201-a932-bcb0142bc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-c02e0e0c-4b97-4e2f-b9b8-48b4906b0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-5c0bde91-ab85-4926-988f-6119c93648f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-f1a24d6f-2c0a-426b-a09e-8cab3458ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-19ac1be2-8f1f-4c7c-aaec-406b731dd244,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-be63b40a-e7ed-402f-9301-15e853a5a018,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-eadc7653-f256-4553-b446-28bb783589dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-365b184b-b1a7-471f-adba-e85dbf7f92a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385175175-172.17.0.2-1599343946287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-b3d45f99-2322-4201-a932-bcb0142bc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-c02e0e0c-4b97-4e2f-b9b8-48b4906b0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-5c0bde91-ab85-4926-988f-6119c93648f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-f1a24d6f-2c0a-426b-a09e-8cab3458ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-19ac1be2-8f1f-4c7c-aaec-406b731dd244,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-be63b40a-e7ed-402f-9301-15e853a5a018,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-eadc7653-f256-4553-b446-28bb783589dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-365b184b-b1a7-471f-adba-e85dbf7f92a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704639176-172.17.0.2-1599343975812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34396,DS-7e670e6f-bf14-439e-9d91-b2e2ade7c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-e0b40f6d-012b-4a7f-9a62-9110cf66c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-fa4bf744-a7f8-48e8-b2ff-c341d29975d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-88c6801a-9d09-44c1-8f2e-1aa05e1aaf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-e47e2aeb-89bd-490f-8257-0a2116a3c619,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-222968ff-8fd7-442e-8d23-d6a9bf2646da,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-cb3750e5-a5ce-4a1e-af78-4501e0be8819,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-5f2272db-202d-4862-8f73-e677ffeacec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704639176-172.17.0.2-1599343975812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34396,DS-7e670e6f-bf14-439e-9d91-b2e2ade7c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-e0b40f6d-012b-4a7f-9a62-9110cf66c4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-fa4bf744-a7f8-48e8-b2ff-c341d29975d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-88c6801a-9d09-44c1-8f2e-1aa05e1aaf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-e47e2aeb-89bd-490f-8257-0a2116a3c619,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-222968ff-8fd7-442e-8d23-d6a9bf2646da,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-cb3750e5-a5ce-4a1e-af78-4501e0be8819,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-5f2272db-202d-4862-8f73-e677ffeacec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648612498-172.17.0.2-1599344143945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33939,DS-e987c203-b019-4363-b573-1f616a3c714c,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-263ffcef-7fe1-4c4b-bd18-076223a5acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-918aab34-8056-457f-b133-5ec454e73803,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-cec4622a-06d7-4315-a6b2-63cec26d80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-4115ac3c-7d6a-49f3-af1f-5ee8e0867f37,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-66d39de9-e0d3-4abf-a0d0-4544c8efcc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-841171c6-17ba-4e38-bbb5-37a5e3ea342c,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-881b12bf-95ed-4116-95c9-245de47a2d81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648612498-172.17.0.2-1599344143945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33939,DS-e987c203-b019-4363-b573-1f616a3c714c,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-263ffcef-7fe1-4c4b-bd18-076223a5acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-918aab34-8056-457f-b133-5ec454e73803,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-cec4622a-06d7-4315-a6b2-63cec26d80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-4115ac3c-7d6a-49f3-af1f-5ee8e0867f37,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-66d39de9-e0d3-4abf-a0d0-4544c8efcc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-841171c6-17ba-4e38-bbb5-37a5e3ea342c,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-881b12bf-95ed-4116-95c9-245de47a2d81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936794987-172.17.0.2-1599344216496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-f983b223-e3a1-4ab6-be7e-ff5e88c418d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-c2ab0618-2a8e-487b-aa0e-6ff9f4aecfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-a6d8e8b4-7742-470e-a0fe-946a2fbf6254,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-09f4360f-a0d5-4d5a-8d1c-4fbd44cab183,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-584826ac-8dcd-46e2-9071-5e0722aa4260,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-c4bae0be-a50b-452d-8009-893b032c8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-b13fb707-b3d3-43e9-b31e-63e9f88b6988,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-9cd7d0e3-9dc4-4191-89dd-204f8bee6c6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936794987-172.17.0.2-1599344216496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-f983b223-e3a1-4ab6-be7e-ff5e88c418d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-c2ab0618-2a8e-487b-aa0e-6ff9f4aecfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-a6d8e8b4-7742-470e-a0fe-946a2fbf6254,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-09f4360f-a0d5-4d5a-8d1c-4fbd44cab183,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-584826ac-8dcd-46e2-9071-5e0722aa4260,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-c4bae0be-a50b-452d-8009-893b032c8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-b13fb707-b3d3-43e9-b31e-63e9f88b6988,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-9cd7d0e3-9dc4-4191-89dd-204f8bee6c6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122463073-172.17.0.2-1599344589989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-8a9f45e6-713b-4ccb-80cd-e22f3985af8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b5c085ed-29aa-42ff-8771-b3c1473853e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3d8f68ea-bac6-4ac5-b3d7-18e51951326b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c70933bb-7916-4527-a120-c148327f960d,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-1833f9fd-79ae-4a86-8512-bf1819ca6504,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-b9fe9f7e-e5c7-4a0b-8e9b-2249758c8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-09f3151b-763c-41e0-861f-62e1ea42e349,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-8d321957-6b36-4534-bfca-3928258d0169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122463073-172.17.0.2-1599344589989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-8a9f45e6-713b-4ccb-80cd-e22f3985af8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b5c085ed-29aa-42ff-8771-b3c1473853e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3d8f68ea-bac6-4ac5-b3d7-18e51951326b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-c70933bb-7916-4527-a120-c148327f960d,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-1833f9fd-79ae-4a86-8512-bf1819ca6504,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-b9fe9f7e-e5c7-4a0b-8e9b-2249758c8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-09f3151b-763c-41e0-861f-62e1ea42e349,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-8d321957-6b36-4534-bfca-3928258d0169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244849682-172.17.0.2-1599344721732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-cbc271a2-3b8d-44f2-bf37-5f9e3892bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9f154313-7fbf-4838-bda2-c38d517f7263,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-8bb23722-5727-43ac-a61a-ceaa99c4dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-9c9e52b4-f07a-4eaf-bf20-dad695ddfa26,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-dd7ecd33-6f84-4dab-b9b2-fef6bd4975f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3b58d382-c467-4565-8dd2-d69fb16a391e,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-6132a0a3-2a11-4a0e-8a8b-65b335ca2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-82aa223d-f3ec-49da-a3e6-266c052e63f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244849682-172.17.0.2-1599344721732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-cbc271a2-3b8d-44f2-bf37-5f9e3892bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9f154313-7fbf-4838-bda2-c38d517f7263,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-8bb23722-5727-43ac-a61a-ceaa99c4dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-9c9e52b4-f07a-4eaf-bf20-dad695ddfa26,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-dd7ecd33-6f84-4dab-b9b2-fef6bd4975f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3b58d382-c467-4565-8dd2-d69fb16a391e,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-6132a0a3-2a11-4a0e-8a8b-65b335ca2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-82aa223d-f3ec-49da-a3e6-266c052e63f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502275838-172.17.0.2-1599344805931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-ee1d9227-b539-4c95-94fb-519353b4a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-7edb4bc6-fe3e-41b5-aecd-c8300bc76e39,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-47ea5e7f-c367-4730-a853-1e02a6fa5384,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-d62415df-8711-4cde-94c4-05a1cd2685a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-00fbc5de-af49-4900-9926-ba3738c7423e,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-919d97ea-5123-4c91-ad8f-b002ebf43c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-acd02a4e-1dad-4a20-b242-5e2d29e5bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-c58a1eca-5c6e-444e-a463-8996ae122732,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502275838-172.17.0.2-1599344805931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-ee1d9227-b539-4c95-94fb-519353b4a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-7edb4bc6-fe3e-41b5-aecd-c8300bc76e39,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-47ea5e7f-c367-4730-a853-1e02a6fa5384,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-d62415df-8711-4cde-94c4-05a1cd2685a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-00fbc5de-af49-4900-9926-ba3738c7423e,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-919d97ea-5123-4c91-ad8f-b002ebf43c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-acd02a4e-1dad-4a20-b242-5e2d29e5bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-c58a1eca-5c6e-444e-a463-8996ae122732,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860353152-172.17.0.2-1599344886406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-0134999e-b3b7-4356-a0b2-57d9d52af5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1a81a04a-6bbb-4fa1-8302-24f398c044ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-45fdbafd-d1f8-4b35-a886-3964e2e7ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-4d7e105b-775b-40b6-8733-4ede0e2bf74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-3bcaa875-f739-44aa-952a-78d7af560464,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6f17d408-bf8a-4185-b47d-397490459aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-bf4e3026-6f7c-46a8-904a-8337aa3eccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-b10a0796-3431-484e-b9f8-f85a652af4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860353152-172.17.0.2-1599344886406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-0134999e-b3b7-4356-a0b2-57d9d52af5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1a81a04a-6bbb-4fa1-8302-24f398c044ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-45fdbafd-d1f8-4b35-a886-3964e2e7ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-4d7e105b-775b-40b6-8733-4ede0e2bf74f,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-3bcaa875-f739-44aa-952a-78d7af560464,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6f17d408-bf8a-4185-b47d-397490459aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-bf4e3026-6f7c-46a8-904a-8337aa3eccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-b10a0796-3431-484e-b9f8-f85a652af4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775387504-172.17.0.2-1599345272942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-28a039f6-aef5-42d6-a180-9632aec610d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b63cf345-024f-4cc9-b59d-34c25632e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-963209b2-36d3-471e-a5ce-0a5130a6e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-facb69c8-81c4-42d8-a92d-0d92b89000f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-a54e6e75-6808-4aa5-a36e-fbc6d411e789,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-27cbe511-d9ae-4b08-b924-536d289aa434,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-ed3fb4ec-6de8-4d62-8798-4d3ee6d72e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-e9d0d52e-07bb-4f94-87a5-f5447d209983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775387504-172.17.0.2-1599345272942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-28a039f6-aef5-42d6-a180-9632aec610d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b63cf345-024f-4cc9-b59d-34c25632e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-963209b2-36d3-471e-a5ce-0a5130a6e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-facb69c8-81c4-42d8-a92d-0d92b89000f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-a54e6e75-6808-4aa5-a36e-fbc6d411e789,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-27cbe511-d9ae-4b08-b924-536d289aa434,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-ed3fb4ec-6de8-4d62-8798-4d3ee6d72e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-e9d0d52e-07bb-4f94-87a5-f5447d209983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905513316-172.17.0.2-1599345320043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34320,DS-d1847138-ba88-441e-b6bb-9801a6b94860,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-80157259-0a38-4ecb-89e7-47a5e5aa5032,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-0f7855ae-5a1e-4661-8c84-cf59bf4dba03,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a64401b1-370d-45ac-aada-4647db005b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-6abeb4a9-b75e-4d33-88b2-3a66c4fa91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-c5c00bfd-027c-4ec3-8623-da753fef25e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-0ab9790a-be4d-4515-a2a5-9d79c2a15a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-e22b0e7c-e936-4295-a35f-7d7149c5bdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905513316-172.17.0.2-1599345320043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34320,DS-d1847138-ba88-441e-b6bb-9801a6b94860,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-80157259-0a38-4ecb-89e7-47a5e5aa5032,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-0f7855ae-5a1e-4661-8c84-cf59bf4dba03,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a64401b1-370d-45ac-aada-4647db005b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-6abeb4a9-b75e-4d33-88b2-3a66c4fa91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-c5c00bfd-027c-4ec3-8623-da753fef25e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-0ab9790a-be4d-4515-a2a5-9d79c2a15a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-e22b0e7c-e936-4295-a35f-7d7149c5bdf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886532793-172.17.0.2-1599345488321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-7846018f-f586-4f29-a476-71c12e68e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-ba50ffb5-9630-4e5f-8dc0-34078cbfc37f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-d316d30d-f2c6-492f-ad63-8bf014e213f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-38de49e8-086a-418d-ae3c-f983940d8c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-31a7097e-f949-4cfd-b00c-7e4ded9ac6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-09b52282-e58e-49b4-99e4-423fb3cc2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-828ab7b2-ed38-42aa-97fb-96114e2db369,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-78c1aa56-0811-4826-abb9-13b7d2abce58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886532793-172.17.0.2-1599345488321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-7846018f-f586-4f29-a476-71c12e68e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-ba50ffb5-9630-4e5f-8dc0-34078cbfc37f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-d316d30d-f2c6-492f-ad63-8bf014e213f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-38de49e8-086a-418d-ae3c-f983940d8c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-31a7097e-f949-4cfd-b00c-7e4ded9ac6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-09b52282-e58e-49b4-99e4-423fb3cc2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-828ab7b2-ed38-42aa-97fb-96114e2db369,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-78c1aa56-0811-4826-abb9-13b7d2abce58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438872001-172.17.0.2-1599345532312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-0aa5ed36-4183-486c-b3da-659b31096348,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c77ca420-7cc9-4e7a-b7a5-3bf2d2e631d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-2a48ab57-b60c-44fd-bd2e-9f0a0f2f1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-b7067de2-d2a2-4764-a84e-685adbfd4dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-5894cf3b-1bfc-4215-85c9-bbd5c1750a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-7868bfe7-2068-4466-8c09-06349ddffe13,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-743e1cba-91a5-4e1f-af84-def0f749e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-d4a3d8f6-9d76-48a5-9ca4-c92f8b01badb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438872001-172.17.0.2-1599345532312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-0aa5ed36-4183-486c-b3da-659b31096348,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c77ca420-7cc9-4e7a-b7a5-3bf2d2e631d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-2a48ab57-b60c-44fd-bd2e-9f0a0f2f1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-b7067de2-d2a2-4764-a84e-685adbfd4dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-5894cf3b-1bfc-4215-85c9-bbd5c1750a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-7868bfe7-2068-4466-8c09-06349ddffe13,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-743e1cba-91a5-4e1f-af84-def0f749e18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-d4a3d8f6-9d76-48a5-9ca4-c92f8b01badb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325808334-172.17.0.2-1599345578389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-60667a17-a221-4854-a1cd-768a44df5eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-0afd9203-d6db-4e77-9b11-fb1aa862da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-07e40555-a661-4a51-a913-87f2889f775f,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-7680bb61-31a8-47b3-9283-1b777d0e235d,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-4f4b9640-ce29-4a68-bb44-06aad010a1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-4006f819-4390-49a5-879f-1cca7387ee61,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7d860ae4-627a-4f77-861b-e61cc9e63ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-4b6a5ee8-1fd2-4031-8f58-25a74005811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325808334-172.17.0.2-1599345578389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-60667a17-a221-4854-a1cd-768a44df5eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-0afd9203-d6db-4e77-9b11-fb1aa862da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-07e40555-a661-4a51-a913-87f2889f775f,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-7680bb61-31a8-47b3-9283-1b777d0e235d,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-4f4b9640-ce29-4a68-bb44-06aad010a1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-4006f819-4390-49a5-879f-1cca7387ee61,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7d860ae4-627a-4f77-861b-e61cc9e63ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-4b6a5ee8-1fd2-4031-8f58-25a74005811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715074636-172.17.0.2-1599345826760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-a7ab2302-6d1d-4f0e-931f-093f2df00208,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-f3a2700d-3f07-4cc4-8651-6f579f6282ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-951df03d-a2ea-40f9-a52a-f8cea21a29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-e7f4c2e2-f16a-47da-9a00-11356a6ca005,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-bbccce02-dc37-458f-9bd6-c6cace283960,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-8e105e32-cf6c-45c4-95d6-c6ded7b5983b,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-28a738ed-1d88-4632-92ce-eac2029c447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-04a4fdbb-b69c-4609-9535-6eb2dc0e23ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715074636-172.17.0.2-1599345826760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-a7ab2302-6d1d-4f0e-931f-093f2df00208,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-f3a2700d-3f07-4cc4-8651-6f579f6282ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-951df03d-a2ea-40f9-a52a-f8cea21a29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-e7f4c2e2-f16a-47da-9a00-11356a6ca005,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-bbccce02-dc37-458f-9bd6-c6cace283960,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-8e105e32-cf6c-45c4-95d6-c6ded7b5983b,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-28a738ed-1d88-4632-92ce-eac2029c447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-04a4fdbb-b69c-4609-9535-6eb2dc0e23ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153292053-172.17.0.2-1599346098858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41985,DS-63a963d2-755b-4ac2-ade0-970b4ff40bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-86fadc26-a714-4b0a-b1c7-52c4458b390e,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-0296a791-d66d-4615-88eb-aec20b82d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-6e8efd59-1ecf-46b8-853d-ebefad434b07,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2508c972-339d-48b6-941a-482067aca1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-a618f9e0-da67-4d0c-9b26-a1f8612cceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-917fb40a-f750-4495-9cbc-f90ec8450e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-5ddb3ea5-0ffa-4814-ac65-e7755c09c57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153292053-172.17.0.2-1599346098858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41985,DS-63a963d2-755b-4ac2-ade0-970b4ff40bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-86fadc26-a714-4b0a-b1c7-52c4458b390e,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-0296a791-d66d-4615-88eb-aec20b82d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-6e8efd59-1ecf-46b8-853d-ebefad434b07,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-2508c972-339d-48b6-941a-482067aca1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-a618f9e0-da67-4d0c-9b26-a1f8612cceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-917fb40a-f750-4495-9cbc-f90ec8450e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-5ddb3ea5-0ffa-4814-ac65-e7755c09c57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749326727-172.17.0.2-1599346327823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-7c3e6abf-8b98-4025-9f11-34bcbef3e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-f6876e39-4c32-41cb-8a05-03ca3fe2a181,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-24bbcd06-2e21-4871-b6ca-89b42cfd7d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-94edd25d-74e7-4d51-95e7-d65371ba2f76,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-f17b5b97-7cdf-4368-9ccc-d358861543a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d8b8eb30-9b6e-4c6a-aa4b-66efc4ac6666,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-73222c4c-11d0-4325-a290-d40ec75d8919,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-96ad6e10-b0f3-4514-9cc7-f7d95c61f3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749326727-172.17.0.2-1599346327823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-7c3e6abf-8b98-4025-9f11-34bcbef3e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-f6876e39-4c32-41cb-8a05-03ca3fe2a181,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-24bbcd06-2e21-4871-b6ca-89b42cfd7d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-94edd25d-74e7-4d51-95e7-d65371ba2f76,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-f17b5b97-7cdf-4368-9ccc-d358861543a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d8b8eb30-9b6e-4c6a-aa4b-66efc4ac6666,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-73222c4c-11d0-4325-a290-d40ec75d8919,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-96ad6e10-b0f3-4514-9cc7-f7d95c61f3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166903122-172.17.0.2-1599346445155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-c4a86916-7813-4c8d-b319-759e300839ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-b4426b36-c174-4076-8f47-541e35fda304,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-64fbeb30-d5f1-4a33-bcc8-d14c5cdf3fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-b637ce15-e6d5-4011-beb8-d82a9009bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-b5a307f5-7373-429f-9a7a-be6ee1352005,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-8c05c7d7-6ff5-429e-ae6c-ac3fed2f66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-bc68de9f-1645-4185-90fc-f86f05b98bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-993488da-8e91-432d-bc24-32a28a12bdd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166903122-172.17.0.2-1599346445155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-c4a86916-7813-4c8d-b319-759e300839ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-b4426b36-c174-4076-8f47-541e35fda304,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-64fbeb30-d5f1-4a33-bcc8-d14c5cdf3fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-b637ce15-e6d5-4011-beb8-d82a9009bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-b5a307f5-7373-429f-9a7a-be6ee1352005,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-8c05c7d7-6ff5-429e-ae6c-ac3fed2f66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-bc68de9f-1645-4185-90fc-f86f05b98bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-993488da-8e91-432d-bc24-32a28a12bdd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520326082-172.17.0.2-1599346584999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-7d10c2c2-4395-47dd-8bfb-4985b9a4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5817aa6a-6557-4a28-b3a6-0d3fae66d962,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-5ac4554f-cbcb-427a-a41f-8e6bf65145ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-577a7aa5-08b3-485e-8b3e-36022e03fb00,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-94a763b0-3bd7-49a7-aca3-d4dbcb14425f,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-2f896ee2-3222-44cd-924c-f41191955ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-9b461f21-8d63-4c4a-87ba-08d36cc2719e,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-943a7969-d746-4709-ae72-2a310b3970d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520326082-172.17.0.2-1599346584999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36863,DS-7d10c2c2-4395-47dd-8bfb-4985b9a4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5817aa6a-6557-4a28-b3a6-0d3fae66d962,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-5ac4554f-cbcb-427a-a41f-8e6bf65145ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-577a7aa5-08b3-485e-8b3e-36022e03fb00,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-94a763b0-3bd7-49a7-aca3-d4dbcb14425f,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-2f896ee2-3222-44cd-924c-f41191955ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-9b461f21-8d63-4c4a-87ba-08d36cc2719e,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-943a7969-d746-4709-ae72-2a310b3970d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397221520-172.17.0.2-1599346957898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36412,DS-b12607ed-50b5-4e16-92c0-2265890ee8df,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-e01f40f9-e140-4373-9940-1d00408bcd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-e950cef5-27ac-40f5-83b7-81d0404d6474,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-42f792fb-d648-4601-a1c2-c30983117788,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-c1210c46-9314-4c2f-aa1e-51a3dbe7000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-28de0850-3894-4294-bc02-ac697235418c,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-bfbc660d-c771-45e3-b695-9a226a737c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-de24e339-27ca-4657-8dd4-301d4e680d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397221520-172.17.0.2-1599346957898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36412,DS-b12607ed-50b5-4e16-92c0-2265890ee8df,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-e01f40f9-e140-4373-9940-1d00408bcd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-e950cef5-27ac-40f5-83b7-81d0404d6474,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-42f792fb-d648-4601-a1c2-c30983117788,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-c1210c46-9314-4c2f-aa1e-51a3dbe7000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-28de0850-3894-4294-bc02-ac697235418c,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-bfbc660d-c771-45e3-b695-9a226a737c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-de24e339-27ca-4657-8dd4-301d4e680d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897110324-172.17.0.2-1599347225746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-71120c41-f854-4b78-98ec-5aed4286436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-9633ec7b-aea2-4056-988d-73ebf625f990,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-935a1fb1-3f32-496c-9df1-b6e9b12d25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-11709c56-dee7-40ed-9982-eb9454c4dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-f4226bfe-7da5-4a9d-b239-e849380a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-4c9fe69c-838a-45bd-9b11-172a9308c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-b0c71aec-4db3-4293-a38d-c3b15f615ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-c950e886-9ab4-4cca-8df0-b744b741eaa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897110324-172.17.0.2-1599347225746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-71120c41-f854-4b78-98ec-5aed4286436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-9633ec7b-aea2-4056-988d-73ebf625f990,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-935a1fb1-3f32-496c-9df1-b6e9b12d25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-11709c56-dee7-40ed-9982-eb9454c4dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-f4226bfe-7da5-4a9d-b239-e849380a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-4c9fe69c-838a-45bd-9b11-172a9308c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-b0c71aec-4db3-4293-a38d-c3b15f615ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-c950e886-9ab4-4cca-8df0-b744b741eaa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092079413-172.17.0.2-1599347388646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34885,DS-15ac93ae-3a8a-4e19-926d-ba155e4465a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-f6576123-a4d2-4e2b-b1cb-2427abe4e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-9048e95b-6724-47e3-b43d-882ef1e6e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-1ff98a80-e6c6-4423-978b-747f59f26842,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-070039a8-919a-452c-a676-ad58218e6063,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-3c6560a5-64c2-4ee9-8b13-5ab4a538699c,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-42a690c0-0658-4bf7-9b1e-e4a957844adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-605a0af0-4166-46ac-8157-ebde7727f433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092079413-172.17.0.2-1599347388646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34885,DS-15ac93ae-3a8a-4e19-926d-ba155e4465a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-f6576123-a4d2-4e2b-b1cb-2427abe4e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-9048e95b-6724-47e3-b43d-882ef1e6e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-1ff98a80-e6c6-4423-978b-747f59f26842,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-070039a8-919a-452c-a676-ad58218e6063,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-3c6560a5-64c2-4ee9-8b13-5ab4a538699c,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-42a690c0-0658-4bf7-9b1e-e4a957844adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-605a0af0-4166-46ac-8157-ebde7727f433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987304644-172.17.0.2-1599347469551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-0eb7ce8a-8031-4eab-82ae-f5bf3f5f4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-ce77f4c4-aae3-434e-a5bf-8bfa0325a284,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ded77609-558e-4309-8ed9-a6b9f1cea12f,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-a08ba4f4-0456-41a7-8ce2-8d10603aa65b,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-9837f3ac-182e-4068-865e-82aa36ac11ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-10e089fa-f7e8-4c4e-92b0-b637d6762945,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-84c89a80-0f1c-4919-99c5-c9c72554aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-40a2b853-ebfe-43ba-90ef-d82a21a22bf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987304644-172.17.0.2-1599347469551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-0eb7ce8a-8031-4eab-82ae-f5bf3f5f4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-ce77f4c4-aae3-434e-a5bf-8bfa0325a284,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ded77609-558e-4309-8ed9-a6b9f1cea12f,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-a08ba4f4-0456-41a7-8ce2-8d10603aa65b,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-9837f3ac-182e-4068-865e-82aa36ac11ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-10e089fa-f7e8-4c4e-92b0-b637d6762945,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-84c89a80-0f1c-4919-99c5-c9c72554aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-40a2b853-ebfe-43ba-90ef-d82a21a22bf3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857369573-172.17.0.2-1599347533203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-018ac678-bbad-4c73-9b80-9ec836f36b13,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-fdd3af2c-50e3-43d9-8907-d969888e31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-8a39498f-4339-4e2a-b486-69110c5f0454,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-1224270c-f44c-4548-8864-5ddb58c7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-b19b1f9c-2c9e-4f4a-b6fa-2edc8708915d,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-c1720362-85f5-444d-b7f6-0adae4a21a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-573f1112-486a-4de3-bf7d-c61cbac6f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-03eca80f-8ca7-4a19-b9d5-b7c5bb70c876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857369573-172.17.0.2-1599347533203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-018ac678-bbad-4c73-9b80-9ec836f36b13,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-fdd3af2c-50e3-43d9-8907-d969888e31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-8a39498f-4339-4e2a-b486-69110c5f0454,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-1224270c-f44c-4548-8864-5ddb58c7d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-b19b1f9c-2c9e-4f4a-b6fa-2edc8708915d,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-c1720362-85f5-444d-b7f6-0adae4a21a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-573f1112-486a-4de3-bf7d-c61cbac6f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-03eca80f-8ca7-4a19-b9d5-b7c5bb70c876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514311294-172.17.0.2-1599347642940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-36f49f56-5fee-407b-834f-9cfb287831d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-32b7d725-0870-4cad-918b-1475eb8197b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-02d995f6-c36c-40f4-bda3-f599373019c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-5888d493-4d95-4e1b-83a7-2c253e983adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-66933eb3-d553-4360-9d07-c802d0556b23,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-4867206b-a992-4898-9f09-33e091a27659,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-60bf1f4a-4be9-4545-9706-d6e3f41ea47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-03aede53-80db-4292-86b6-2441fb1eaef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514311294-172.17.0.2-1599347642940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-36f49f56-5fee-407b-834f-9cfb287831d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-32b7d725-0870-4cad-918b-1475eb8197b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-02d995f6-c36c-40f4-bda3-f599373019c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-5888d493-4d95-4e1b-83a7-2c253e983adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-66933eb3-d553-4360-9d07-c802d0556b23,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-4867206b-a992-4898-9f09-33e091a27659,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-60bf1f4a-4be9-4545-9706-d6e3f41ea47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-03aede53-80db-4292-86b6-2441fb1eaef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 26 out of 50
result: false positive !!!
Total execution time in seconds : 5600
