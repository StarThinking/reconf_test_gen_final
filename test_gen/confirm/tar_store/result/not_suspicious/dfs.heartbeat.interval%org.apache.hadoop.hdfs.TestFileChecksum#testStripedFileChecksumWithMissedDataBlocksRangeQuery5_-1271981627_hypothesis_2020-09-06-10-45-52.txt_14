reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553783673-172.17.0.10-1599389279046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-18977322-5297-42ec-b2f7-7e2bf156ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-0aa8df0d-640b-49a5-b170-d783771039f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-bde9a240-716f-484e-a741-b7929399f5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-f9a07bf2-f950-448b-bb65-4adc8cfc417c,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-25ee7882-0603-494c-9d19-4f4084f172fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-2ccbf8db-c018-4079-926b-6f2dea7c5a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-57b5d076-71ae-4430-bb73-119d65d7d13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-d6520573-fc0c-4cef-b24f-038220914ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553783673-172.17.0.10-1599389279046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-18977322-5297-42ec-b2f7-7e2bf156ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-0aa8df0d-640b-49a5-b170-d783771039f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-bde9a240-716f-484e-a741-b7929399f5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-f9a07bf2-f950-448b-bb65-4adc8cfc417c,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-25ee7882-0603-494c-9d19-4f4084f172fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-2ccbf8db-c018-4079-926b-6f2dea7c5a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-57b5d076-71ae-4430-bb73-119d65d7d13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-d6520573-fc0c-4cef-b24f-038220914ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299458891-172.17.0.10-1599389617829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-569b2647-bf3a-47a0-9f35-92ddd926545a,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-907fa1ab-975e-4f8f-ba7a-dc6f73074b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-3c14cbb8-cc10-4e85-927d-3640182e58e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-787decfc-8718-4184-bc02-544ecf510a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-442f04ab-a03d-4164-a0fc-76df6a1adcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-ca314eed-3e4f-43bd-9fc0-f9deec2f5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-94b2e545-732b-4f87-83f3-7e6a8a9ab2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-2977dd27-2c14-4c2b-98df-c26997a1b8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299458891-172.17.0.10-1599389617829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34428,DS-569b2647-bf3a-47a0-9f35-92ddd926545a,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-907fa1ab-975e-4f8f-ba7a-dc6f73074b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-3c14cbb8-cc10-4e85-927d-3640182e58e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-787decfc-8718-4184-bc02-544ecf510a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-442f04ab-a03d-4164-a0fc-76df6a1adcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-ca314eed-3e4f-43bd-9fc0-f9deec2f5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-94b2e545-732b-4f87-83f3-7e6a8a9ab2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-2977dd27-2c14-4c2b-98df-c26997a1b8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328110352-172.17.0.10-1599390416340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39522,DS-ea355e83-c3dc-445c-8550-2c8d82cede79,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-ba4dd770-5356-471f-a8aa-5ad73ebcea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-78cb7e47-1184-4c20-ad18-824291e1911f,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-d4ad5bce-768a-4961-b1bc-688f1e18db48,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-1c23bc77-2225-4390-809b-a21d7b6fc6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-3aece94f-4a65-41af-af55-e193f458b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-84c661c6-a81e-4298-95d5-93df28576c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-4e176aa2-10ef-49f6-9750-e2127f65914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328110352-172.17.0.10-1599390416340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39522,DS-ea355e83-c3dc-445c-8550-2c8d82cede79,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-ba4dd770-5356-471f-a8aa-5ad73ebcea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-78cb7e47-1184-4c20-ad18-824291e1911f,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-d4ad5bce-768a-4961-b1bc-688f1e18db48,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-1c23bc77-2225-4390-809b-a21d7b6fc6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-3aece94f-4a65-41af-af55-e193f458b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-84c661c6-a81e-4298-95d5-93df28576c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-4e176aa2-10ef-49f6-9750-e2127f65914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948909613-172.17.0.10-1599390531188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-0a38f45f-f574-4682-af91-740d82bfcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-000bd5c6-b176-44ad-9fcf-3bbb6a9a9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-ba3936ca-2584-4ded-91c3-9f673b5b7a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-41704918-4024-4457-b4c4-3b45f6810cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-255dcb95-aa7c-4a52-9f0a-d56e1e7b6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-d0816cf0-5983-4140-a72f-108247ee04d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c64c94cd-9b5e-4060-a4ec-cabf861b7d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-6966f383-ab13-4e8e-bd41-0634b40a37fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948909613-172.17.0.10-1599390531188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-0a38f45f-f574-4682-af91-740d82bfcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-000bd5c6-b176-44ad-9fcf-3bbb6a9a9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-ba3936ca-2584-4ded-91c3-9f673b5b7a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-41704918-4024-4457-b4c4-3b45f6810cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-255dcb95-aa7c-4a52-9f0a-d56e1e7b6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-d0816cf0-5983-4140-a72f-108247ee04d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c64c94cd-9b5e-4060-a4ec-cabf861b7d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-6966f383-ab13-4e8e-bd41-0634b40a37fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271015731-172.17.0.10-1599391195300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-d1b0460b-3d2f-4543-aeff-5c488f81187c,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-9d05fb0e-ec35-4467-95fe-15cacb2f918c,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-21a5e713-993c-4535-a4a8-61d7b65e0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-44a301ef-b84b-4019-b1c3-2be2981333dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-17de22ee-5f1d-46e9-90af-4128494be7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-991ab40e-b42e-406e-b177-dc67fe9f3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-c17ec3cc-f68f-429f-b84b-5e26e02aa93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-cb641e1e-596f-485f-8b79-69f919fc5752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271015731-172.17.0.10-1599391195300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-d1b0460b-3d2f-4543-aeff-5c488f81187c,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-9d05fb0e-ec35-4467-95fe-15cacb2f918c,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-21a5e713-993c-4535-a4a8-61d7b65e0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-44a301ef-b84b-4019-b1c3-2be2981333dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-17de22ee-5f1d-46e9-90af-4128494be7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-991ab40e-b42e-406e-b177-dc67fe9f3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-c17ec3cc-f68f-429f-b84b-5e26e02aa93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-cb641e1e-596f-485f-8b79-69f919fc5752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267329931-172.17.0.10-1599391719115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-22a41a03-13cb-4337-9abb-1bb78e129137,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-832f22e8-89e9-49fe-ac6c-603da792ef91,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-a62b24aa-a9f3-40ac-b34c-3e8cb0a28210,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-9303fb6d-a961-4f1c-ae1e-c2b1c0923a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-29ce22ab-61e5-48b7-bb0d-fa4602232025,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-2bb21c85-153c-4af7-b78d-9662446b8504,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-0e8d4a8d-c31a-4eaf-a852-4d391c05fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-3239879f-ff31-48c6-ae14-b190d2a813f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267329931-172.17.0.10-1599391719115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-22a41a03-13cb-4337-9abb-1bb78e129137,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-832f22e8-89e9-49fe-ac6c-603da792ef91,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-a62b24aa-a9f3-40ac-b34c-3e8cb0a28210,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-9303fb6d-a961-4f1c-ae1e-c2b1c0923a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-29ce22ab-61e5-48b7-bb0d-fa4602232025,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-2bb21c85-153c-4af7-b78d-9662446b8504,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-0e8d4a8d-c31a-4eaf-a852-4d391c05fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-3239879f-ff31-48c6-ae14-b190d2a813f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866223613-172.17.0.10-1599391809384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40341,DS-8bea1bfa-34a5-4ab2-b5eb-788f86e8427a,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-6bb21ef0-a6e8-4649-9076-7a98dd18e595,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-c6ccad38-c32a-4d17-a2b3-c259b5da7f46,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-dba282a9-759d-4146-9c12-767f3207d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-95b7ea48-7c0f-41b7-ab0a-2cf6acfd7f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4579c52d-602c-476a-be48-6e4e94c6352c,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-b867709d-1fbc-42d2-bb3d-93ef00afa7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-14d7b077-8613-4551-8309-406f568150a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866223613-172.17.0.10-1599391809384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40341,DS-8bea1bfa-34a5-4ab2-b5eb-788f86e8427a,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-6bb21ef0-a6e8-4649-9076-7a98dd18e595,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-c6ccad38-c32a-4d17-a2b3-c259b5da7f46,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-dba282a9-759d-4146-9c12-767f3207d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-95b7ea48-7c0f-41b7-ab0a-2cf6acfd7f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4579c52d-602c-476a-be48-6e4e94c6352c,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-b867709d-1fbc-42d2-bb3d-93ef00afa7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-14d7b077-8613-4551-8309-406f568150a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210384055-172.17.0.10-1599391873846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-2752cfdf-4dea-4b6d-afb6-7adcfc4e82c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-4906cc89-c094-4af7-9aab-8445d7db1e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-da93d95a-56d9-40e3-b7f5-daf8d0d70f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-330d0f72-b728-4f23-9c18-4dc310f0c7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-14ee260e-120f-4918-9c85-231f8eaa4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-636e01a1-af25-4971-b5f4-03929af8d486,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-954ab167-1665-4f5a-94b7-f0aba06da3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-b30d4898-7a26-4bcc-8efc-8ac3226c05da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210384055-172.17.0.10-1599391873846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-2752cfdf-4dea-4b6d-afb6-7adcfc4e82c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-4906cc89-c094-4af7-9aab-8445d7db1e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-da93d95a-56d9-40e3-b7f5-daf8d0d70f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-330d0f72-b728-4f23-9c18-4dc310f0c7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-14ee260e-120f-4918-9c85-231f8eaa4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-636e01a1-af25-4971-b5f4-03929af8d486,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-954ab167-1665-4f5a-94b7-f0aba06da3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-b30d4898-7a26-4bcc-8efc-8ac3226c05da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370480638-172.17.0.10-1599392160492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-2c8da58e-0464-4f29-a089-c75165596428,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-42ec5cf4-6715-42ef-b595-2b2f62b1e137,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-6b003eae-0cf5-4c38-9ed0-08b9efee4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a23c5594-9abe-4be9-9815-c1749e973d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-877b78ef-2ccd-4fdc-8c35-63cb9343fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-55465d85-d1a6-4169-baf4-3a73b4cd71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-dc565a00-2c8e-4a3e-b0fa-0ff77c822936,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-b77304c0-6631-4e15-8d22-7ac0f45747ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370480638-172.17.0.10-1599392160492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-2c8da58e-0464-4f29-a089-c75165596428,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-42ec5cf4-6715-42ef-b595-2b2f62b1e137,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-6b003eae-0cf5-4c38-9ed0-08b9efee4e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a23c5594-9abe-4be9-9815-c1749e973d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-877b78ef-2ccd-4fdc-8c35-63cb9343fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-55465d85-d1a6-4169-baf4-3a73b4cd71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-dc565a00-2c8e-4a3e-b0fa-0ff77c822936,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-b77304c0-6631-4e15-8d22-7ac0f45747ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238941501-172.17.0.10-1599392255567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-a75915c8-733f-4de6-8839-903f95c2b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-37d1f29f-0133-4785-8115-454d2f3ed14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-5cef20ab-bf1a-4175-a321-542622972ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-ce9325ce-73c3-4f9d-97af-a43ee516f030,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-791e2b05-a0da-4f87-ac17-d2bea10dc047,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-d6c147fe-12eb-436c-8677-0e66fb2edc08,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f542df92-8448-4a3d-aa3c-94e0cedff680,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7e90daed-e20c-435f-9566-fbc54b7c5d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238941501-172.17.0.10-1599392255567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-a75915c8-733f-4de6-8839-903f95c2b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-37d1f29f-0133-4785-8115-454d2f3ed14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-5cef20ab-bf1a-4175-a321-542622972ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-ce9325ce-73c3-4f9d-97af-a43ee516f030,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-791e2b05-a0da-4f87-ac17-d2bea10dc047,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-d6c147fe-12eb-436c-8677-0e66fb2edc08,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f542df92-8448-4a3d-aa3c-94e0cedff680,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7e90daed-e20c-435f-9566-fbc54b7c5d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811953524-172.17.0.10-1599392283373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-1b3e7cbb-a27a-4419-916e-9967aa304496,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-4f814e16-3070-4c33-a5b4-b90ac7ab82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-11bd7d4c-a20b-4437-9a59-df82f50d9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-c6e1c6a4-a974-464b-9324-43289faaeaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-22a2c287-5c18-4026-9b79-757041740fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-83241446-4706-4e6d-9927-520a11e7059b,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-f3e38109-a8ae-48ed-9535-36f81236de05,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-496deb87-b279-4cad-9c1b-7ecaa57a3ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811953524-172.17.0.10-1599392283373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-1b3e7cbb-a27a-4419-916e-9967aa304496,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-4f814e16-3070-4c33-a5b4-b90ac7ab82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-11bd7d4c-a20b-4437-9a59-df82f50d9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-c6e1c6a4-a974-464b-9324-43289faaeaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-22a2c287-5c18-4026-9b79-757041740fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-83241446-4706-4e6d-9927-520a11e7059b,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-f3e38109-a8ae-48ed-9535-36f81236de05,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-496deb87-b279-4cad-9c1b-7ecaa57a3ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110905907-172.17.0.10-1599392488895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-e72baee0-ab16-4335-b7fd-ec1ec5886bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-c0d8a848-f7e9-4d4a-9a84-86472f3c1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d52b6bdb-28a9-40fb-b473-6e7e9dbbcb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-73b19765-31b8-48e2-b2ed-9a36bac700c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-2c240e7b-ac3c-4d03-bb23-9a25ad915864,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-81f476b1-7bdc-4d22-bcc6-ee856c68f627,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a9d8fc04-addd-4529-88ad-57fc059ef0de,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-bde57749-989f-423b-bc82-7daedb2500db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110905907-172.17.0.10-1599392488895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-e72baee0-ab16-4335-b7fd-ec1ec5886bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-c0d8a848-f7e9-4d4a-9a84-86472f3c1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d52b6bdb-28a9-40fb-b473-6e7e9dbbcb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-73b19765-31b8-48e2-b2ed-9a36bac700c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-2c240e7b-ac3c-4d03-bb23-9a25ad915864,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-81f476b1-7bdc-4d22-bcc6-ee856c68f627,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-a9d8fc04-addd-4529-88ad-57fc059ef0de,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-bde57749-989f-423b-bc82-7daedb2500db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394478111-172.17.0.10-1599392575492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-ae9752f7-b0c0-463a-8be3-8563d1ec6304,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-746a086b-515d-4c96-b7eb-73bbcaec6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5b6da7cf-4965-4497-8b2b-2aa5ed0d61f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-555bac7b-e96f-4426-afa9-f8407e7df96a,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-fcaffcec-e742-4364-821c-f057e6c2e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-1701da06-fb8f-47ff-a61e-103148f2bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-7df844b6-0eb3-43c1-8560-00aa7219bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-745637ab-b0e1-4e65-86d0-206f8d7dbf5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394478111-172.17.0.10-1599392575492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-ae9752f7-b0c0-463a-8be3-8563d1ec6304,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-746a086b-515d-4c96-b7eb-73bbcaec6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5b6da7cf-4965-4497-8b2b-2aa5ed0d61f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-555bac7b-e96f-4426-afa9-f8407e7df96a,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-fcaffcec-e742-4364-821c-f057e6c2e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-1701da06-fb8f-47ff-a61e-103148f2bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-7df844b6-0eb3-43c1-8560-00aa7219bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-745637ab-b0e1-4e65-86d0-206f8d7dbf5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021529610-172.17.0.10-1599393044032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-94a90287-4d66-4959-aca3-20c61f3b56fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-1af0bcdf-1691-4f3d-850c-d257fd429472,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-1fea7015-5f6e-42a1-9429-c47394516f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-2afb8725-00dc-4463-a10a-a08b5b4be15b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-72285aa2-a15a-41a5-a13a-e5509e3178a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a774db54-5b87-427d-803d-db0d92370df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-7e30ace0-4054-4a06-a752-a6e09935c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-73e41a5e-6fa0-44ad-9c28-6c334e1da224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021529610-172.17.0.10-1599393044032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-94a90287-4d66-4959-aca3-20c61f3b56fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-1af0bcdf-1691-4f3d-850c-d257fd429472,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-1fea7015-5f6e-42a1-9429-c47394516f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-2afb8725-00dc-4463-a10a-a08b5b4be15b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-72285aa2-a15a-41a5-a13a-e5509e3178a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a774db54-5b87-427d-803d-db0d92370df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-7e30ace0-4054-4a06-a752-a6e09935c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-73e41a5e-6fa0-44ad-9c28-6c334e1da224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615600459-172.17.0.10-1599393074658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-0eb6dbf5-d499-4b71-9cde-e656c8c9f286,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-98c015a5-d863-41ba-941f-05276743be1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-c809e48b-2bb2-4526-91b5-0440f12fd842,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-71a07d93-7924-4f89-852a-888fac348ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f18a1124-9cd2-43d7-8efa-aec6296f1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-130262ca-7f4b-4a0b-8a75-9649d4a34b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-11e5a4f2-0326-42c7-979e-10e2dd78d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-3ba7e155-614b-4618-89ae-e6f49ad08fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615600459-172.17.0.10-1599393074658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41764,DS-0eb6dbf5-d499-4b71-9cde-e656c8c9f286,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-98c015a5-d863-41ba-941f-05276743be1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-c809e48b-2bb2-4526-91b5-0440f12fd842,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-71a07d93-7924-4f89-852a-888fac348ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f18a1124-9cd2-43d7-8efa-aec6296f1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-130262ca-7f4b-4a0b-8a75-9649d4a34b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-11e5a4f2-0326-42c7-979e-10e2dd78d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-3ba7e155-614b-4618-89ae-e6f49ad08fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958246346-172.17.0.10-1599393242895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-b5124c57-fc67-4219-8a27-05ed495e44af,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-df4d44e2-4a39-4ca1-b6da-7ca683dfcf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-78652cc7-4c3d-452b-8e31-8ffecd05510b,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-8b7254d0-4538-421f-8f34-ba112a6e25b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-7e90d3bb-09d8-42e5-80b2-790d79946d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-7830f00b-96cc-4cc4-b935-cd2b51f0e917,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-50b03305-2d31-450c-9e6d-1e257fc2f688,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-2c4c684b-b71e-41e7-b26e-be003100698b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958246346-172.17.0.10-1599393242895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-b5124c57-fc67-4219-8a27-05ed495e44af,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-df4d44e2-4a39-4ca1-b6da-7ca683dfcf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-78652cc7-4c3d-452b-8e31-8ffecd05510b,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-8b7254d0-4538-421f-8f34-ba112a6e25b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-7e90d3bb-09d8-42e5-80b2-790d79946d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-7830f00b-96cc-4cc4-b935-cd2b51f0e917,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-50b03305-2d31-450c-9e6d-1e257fc2f688,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-2c4c684b-b71e-41e7-b26e-be003100698b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391942595-172.17.0.10-1599393909891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-02d0dcd2-3566-4f1a-b800-fa95914b553a,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-c52b2a8c-f70d-49e8-a167-a04e51e45def,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-7d724ad5-cfc3-44ea-a58d-af82ff4479b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-2176ddfb-d696-4d80-8fab-f75af6ad2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-7c8b4a42-d32c-4b8c-9d25-4b6db0add0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c9e7b3e1-c3e7-4935-a1df-2f8405c4fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-fbc14858-a8c9-450c-9938-07cb4785de60,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e3f843a7-9944-4fcf-b5be-1d4aeec19a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391942595-172.17.0.10-1599393909891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-02d0dcd2-3566-4f1a-b800-fa95914b553a,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-c52b2a8c-f70d-49e8-a167-a04e51e45def,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-7d724ad5-cfc3-44ea-a58d-af82ff4479b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-2176ddfb-d696-4d80-8fab-f75af6ad2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-7c8b4a42-d32c-4b8c-9d25-4b6db0add0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-c9e7b3e1-c3e7-4935-a1df-2f8405c4fc26,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-fbc14858-a8c9-450c-9938-07cb4785de60,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e3f843a7-9944-4fcf-b5be-1d4aeec19a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582161804-172.17.0.10-1599394203941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32834,DS-aefa8c7d-b0e0-4e98-88fb-904a1d1eccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-914f46f6-73ea-44bd-bf31-41c9997f3f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-7177cd6b-f636-4724-a793-33586db436a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-1bfc5a7f-b112-4b93-b9df-6957e0a5ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b4905542-f31a-491f-87a5-c6b99bddbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-aedaa29d-0182-44fa-aa5c-25433ce949f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-1c38cd08-9d34-4b24-85a5-f3df465f2cde,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8ce6b973-24d2-4f0d-9567-b3cbb5cdddc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582161804-172.17.0.10-1599394203941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32834,DS-aefa8c7d-b0e0-4e98-88fb-904a1d1eccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-914f46f6-73ea-44bd-bf31-41c9997f3f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-7177cd6b-f636-4724-a793-33586db436a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-1bfc5a7f-b112-4b93-b9df-6957e0a5ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b4905542-f31a-491f-87a5-c6b99bddbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-aedaa29d-0182-44fa-aa5c-25433ce949f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-1c38cd08-9d34-4b24-85a5-f3df465f2cde,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8ce6b973-24d2-4f0d-9567-b3cbb5cdddc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187886531-172.17.0.10-1599394403370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45568,DS-b00a510c-1524-4c83-b252-aa9c4fddd26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-33c21f06-9644-4bfe-bb31-9d6161c2b576,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-40705c82-a24c-480d-8152-a2b92beaef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-c6b225c2-e6c5-4423-af84-4f470206e2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-b7ee0cdd-acac-47e3-9a0c-9be5ffd973d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-94f851d9-f81f-4849-8c23-359dae8e16a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-77e20439-d13b-4767-8c53-e4aebbc6dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-801a326a-8bf2-419c-b211-d31821ed811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187886531-172.17.0.10-1599394403370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45568,DS-b00a510c-1524-4c83-b252-aa9c4fddd26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-33c21f06-9644-4bfe-bb31-9d6161c2b576,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-40705c82-a24c-480d-8152-a2b92beaef0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-c6b225c2-e6c5-4423-af84-4f470206e2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-b7ee0cdd-acac-47e3-9a0c-9be5ffd973d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-94f851d9-f81f-4849-8c23-359dae8e16a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-77e20439-d13b-4767-8c53-e4aebbc6dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-801a326a-8bf2-419c-b211-d31821ed811b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5353
