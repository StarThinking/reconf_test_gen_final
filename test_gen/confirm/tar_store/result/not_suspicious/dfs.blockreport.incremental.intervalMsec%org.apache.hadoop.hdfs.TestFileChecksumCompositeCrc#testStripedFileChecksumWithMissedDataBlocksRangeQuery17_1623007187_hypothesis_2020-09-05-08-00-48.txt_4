reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52124139-172.17.0.2-1599293171331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38985,DS-ac749da1-0124-4652-b5dc-57a30eeb9c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-aaabe60b-28e7-4ad7-933c-b6198d489a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-822d17cf-94ae-464e-a553-94e244a31a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-81747760-aa97-40c9-bf20-b57081a261ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-95c98a04-766c-4c51-a273-5f5e029712db,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-737da70f-0075-42af-926b-63415a550c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d382b006-c8c7-4798-80a7-f903d003fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-1f70ddd3-afd8-4cf5-816e-c252517d9719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52124139-172.17.0.2-1599293171331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38985,DS-ac749da1-0124-4652-b5dc-57a30eeb9c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-aaabe60b-28e7-4ad7-933c-b6198d489a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-822d17cf-94ae-464e-a553-94e244a31a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-81747760-aa97-40c9-bf20-b57081a261ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-95c98a04-766c-4c51-a273-5f5e029712db,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-737da70f-0075-42af-926b-63415a550c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d382b006-c8c7-4798-80a7-f903d003fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-1f70ddd3-afd8-4cf5-816e-c252517d9719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787239353-172.17.0.2-1599293365619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-2088d235-a69a-4c93-984a-676d9cf87c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-9dfdb726-9cad-4468-8fde-d6cf56bb1338,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-d7a6c6de-cd20-4a32-b7b1-5e174f136bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-ca00760e-0f56-487c-ac65-9dac1b0a7fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-6d637094-5e1e-4281-99fd-59c96a1fefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-404df5a3-bc76-4875-91c3-1cece2ea34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-b3c1bef9-7ec9-4edc-8dd4-49f3afcd0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-c842b88a-0bd9-430a-97bc-199380fde940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787239353-172.17.0.2-1599293365619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-2088d235-a69a-4c93-984a-676d9cf87c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-9dfdb726-9cad-4468-8fde-d6cf56bb1338,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-d7a6c6de-cd20-4a32-b7b1-5e174f136bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-ca00760e-0f56-487c-ac65-9dac1b0a7fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-6d637094-5e1e-4281-99fd-59c96a1fefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-404df5a3-bc76-4875-91c3-1cece2ea34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-b3c1bef9-7ec9-4edc-8dd4-49f3afcd0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-c842b88a-0bd9-430a-97bc-199380fde940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135940976-172.17.0.2-1599293401247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-61c7163b-59da-4dd0-bea3-c4cada2e2417,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-8eb65f84-fc71-4973-8a1f-4d5024ccb34d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1f526351-4f9e-4b3a-b95f-acc16f3be4df,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-a0c7f99c-ada5-4f4a-b33b-3641e66cf925,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-7fa18680-99d1-4618-bb68-39d69c51a71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-d0eca2aa-ab1d-4756-a619-91ef0cc0c685,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d47a0b43-fae3-40e7-90b9-4ea49110905c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-179f57bb-9399-4bbd-b505-6515b561e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135940976-172.17.0.2-1599293401247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-61c7163b-59da-4dd0-bea3-c4cada2e2417,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-8eb65f84-fc71-4973-8a1f-4d5024ccb34d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1f526351-4f9e-4b3a-b95f-acc16f3be4df,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-a0c7f99c-ada5-4f4a-b33b-3641e66cf925,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-7fa18680-99d1-4618-bb68-39d69c51a71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-d0eca2aa-ab1d-4756-a619-91ef0cc0c685,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d47a0b43-fae3-40e7-90b9-4ea49110905c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-179f57bb-9399-4bbd-b505-6515b561e103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367329981-172.17.0.2-1599293598894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-363438d9-09a6-4133-960d-1b7e2117fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-5bbd5cf0-a27c-4ec6-8847-086df1a3be67,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-1efb7a1f-d26f-4355-9791-8b4611a9bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-1c7699ef-aa3e-4e12-a0f7-002e3dc6b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-fc2d4f0c-70c4-433a-87ee-b55038151b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-2bf90587-3fc9-4fd5-8467-322023e76518,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-a2e80570-d526-469e-8643-a7f9eb5f772f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-d5df4dd7-4f41-439e-9359-47468948e2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367329981-172.17.0.2-1599293598894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-363438d9-09a6-4133-960d-1b7e2117fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-5bbd5cf0-a27c-4ec6-8847-086df1a3be67,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-1efb7a1f-d26f-4355-9791-8b4611a9bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-1c7699ef-aa3e-4e12-a0f7-002e3dc6b97c,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-fc2d4f0c-70c4-433a-87ee-b55038151b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-2bf90587-3fc9-4fd5-8467-322023e76518,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-a2e80570-d526-469e-8643-a7f9eb5f772f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-d5df4dd7-4f41-439e-9359-47468948e2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095090298-172.17.0.2-1599293998621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-3c17061c-762c-44fa-a225-5b35f081d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-f2fb5320-6b9a-4615-9af3-24b1ec984feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-5a7c4978-315b-452b-9f12-9b4562ba58db,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-918e3f84-071a-4966-be64-1768ac9b62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-a73962e5-bf43-47a7-9770-caddfa33133e,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-2fae037b-a372-4718-8d11-8fe516142a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-1eee66de-9287-4eb8-967e-abbb65745b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-5d1f26df-550a-4b80-b4d1-32915cdb2f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095090298-172.17.0.2-1599293998621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-3c17061c-762c-44fa-a225-5b35f081d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-f2fb5320-6b9a-4615-9af3-24b1ec984feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-5a7c4978-315b-452b-9f12-9b4562ba58db,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-918e3f84-071a-4966-be64-1768ac9b62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-a73962e5-bf43-47a7-9770-caddfa33133e,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-2fae037b-a372-4718-8d11-8fe516142a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-1eee66de-9287-4eb8-967e-abbb65745b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-5d1f26df-550a-4b80-b4d1-32915cdb2f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482700395-172.17.0.2-1599294724439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-f55bd438-2613-4f41-a7a1-246785262118,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-90a15ee9-f6c4-4f2f-9ba4-0b921e84ad12,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-902426ac-2973-4b11-b5af-6d1c19c79c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-7fde0562-edad-46be-b403-8f6596b78969,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-60e43d2d-3312-4a78-ab8f-df06852009a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-9ff7d403-6062-4f43-8e94-d331153c114f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-6bd6c095-0865-4f80-bd5a-e3e495012449,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-8f0c60d2-b2ae-4c7f-8e99-7cc8ae926b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482700395-172.17.0.2-1599294724439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-f55bd438-2613-4f41-a7a1-246785262118,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-90a15ee9-f6c4-4f2f-9ba4-0b921e84ad12,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-902426ac-2973-4b11-b5af-6d1c19c79c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-7fde0562-edad-46be-b403-8f6596b78969,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-60e43d2d-3312-4a78-ab8f-df06852009a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-9ff7d403-6062-4f43-8e94-d331153c114f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-6bd6c095-0865-4f80-bd5a-e3e495012449,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-8f0c60d2-b2ae-4c7f-8e99-7cc8ae926b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599951252-172.17.0.2-1599294787960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-1a290fda-640e-42f0-a851-7553fe43ecff,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-3650fec3-1ad4-4c6a-aeb3-551b517953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-5b5391d2-d15c-4e59-8a28-80ed71ce00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-5793b066-77ea-4969-b85c-c1724c186de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-21d4b783-7d45-49a5-a10a-edc48f565ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8b6ededc-0423-46bf-8a3a-eb396fdf5104,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-52844a6e-ecda-4f09-871a-844b756583ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-47fe78d5-87d6-44db-b5bf-4ddb9913f76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599951252-172.17.0.2-1599294787960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-1a290fda-640e-42f0-a851-7553fe43ecff,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-3650fec3-1ad4-4c6a-aeb3-551b517953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-5b5391d2-d15c-4e59-8a28-80ed71ce00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-5793b066-77ea-4969-b85c-c1724c186de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-21d4b783-7d45-49a5-a10a-edc48f565ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8b6ededc-0423-46bf-8a3a-eb396fdf5104,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-52844a6e-ecda-4f09-871a-844b756583ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-47fe78d5-87d6-44db-b5bf-4ddb9913f76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910534797-172.17.0.2-1599294892389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-c088492b-ad33-45fe-92be-49d06095f9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e31bfd73-a2e0-4a16-bdc8-253bc4014a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ab24d901-8ef0-49dd-af3e-5864ce5d2479,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-0f86a0a5-a1d7-4891-8bb4-85759f5e6f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-5e8af67b-deff-442e-b2d2-b72bb828c5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ef1acf06-7c94-4e62-8048-96a84ec8db09,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-66a0b97c-157a-479c-a907-27373b75f89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-16b58c7b-f784-49ce-b34d-2a0eb16439fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910534797-172.17.0.2-1599294892389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-c088492b-ad33-45fe-92be-49d06095f9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e31bfd73-a2e0-4a16-bdc8-253bc4014a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ab24d901-8ef0-49dd-af3e-5864ce5d2479,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-0f86a0a5-a1d7-4891-8bb4-85759f5e6f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-5e8af67b-deff-442e-b2d2-b72bb828c5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ef1acf06-7c94-4e62-8048-96a84ec8db09,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-66a0b97c-157a-479c-a907-27373b75f89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-16b58c7b-f784-49ce-b34d-2a0eb16439fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792329496-172.17.0.2-1599295193922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-2a35f1ac-5dce-40b4-ae75-97189a841052,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-1df74ae1-ed0d-4ec4-9b96-be50e3d05fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-ca2db733-06c2-4c27-a814-21c1ec2a8021,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-90375eb4-2cd1-4f47-9319-22f7801ca42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-49068d99-ea8f-43d0-94cd-a245f5e0e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-8dc87dc3-7da1-45a7-8db0-7805652fb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-7d8d673d-0b47-45d3-b314-036eea59a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-d2de1df5-caa9-47fc-a97c-11d7953af090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792329496-172.17.0.2-1599295193922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-2a35f1ac-5dce-40b4-ae75-97189a841052,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-1df74ae1-ed0d-4ec4-9b96-be50e3d05fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-ca2db733-06c2-4c27-a814-21c1ec2a8021,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-90375eb4-2cd1-4f47-9319-22f7801ca42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-49068d99-ea8f-43d0-94cd-a245f5e0e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-8dc87dc3-7da1-45a7-8db0-7805652fb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-7d8d673d-0b47-45d3-b314-036eea59a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-d2de1df5-caa9-47fc-a97c-11d7953af090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433872284-172.17.0.2-1599295345901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-a914286b-3288-45db-b930-050ffcd3a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-aca50127-0abe-4204-a860-12d1dc2e7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-86360231-b280-4bf3-aa53-ec63f0553243,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-1fc1d560-6f5a-4da8-9568-f382c1ec6a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-1e2d0d6e-e5fa-4284-93fd-39f5876ebc01,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-3a2b01a4-9cf7-41c5-98cc-c187a587eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-1bda41ce-233a-4ded-b889-164d13a994c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b5309f7f-1db4-41c8-a161-eba14ffe6242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433872284-172.17.0.2-1599295345901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-a914286b-3288-45db-b930-050ffcd3a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-aca50127-0abe-4204-a860-12d1dc2e7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-86360231-b280-4bf3-aa53-ec63f0553243,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-1fc1d560-6f5a-4da8-9568-f382c1ec6a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-1e2d0d6e-e5fa-4284-93fd-39f5876ebc01,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-3a2b01a4-9cf7-41c5-98cc-c187a587eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-1bda41ce-233a-4ded-b889-164d13a994c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b5309f7f-1db4-41c8-a161-eba14ffe6242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522981952-172.17.0.2-1599295535950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-e1c6d793-01d3-4f5e-9ba3-d48bb44f9e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-1cfbb695-26bf-4b3a-9bc6-96c1d4c966e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-f834852d-ffa7-4b9c-99fd-8eb2e0af392c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-bad6ee47-eb37-4e2e-b458-bef26503fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-5e6f9c1c-5369-4ace-8ce8-f1d0e6f3d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-f9be9726-5153-4dc7-a001-c07d1f52aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-2161bd1a-e69b-4236-8cd5-9bf94de22779,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-27a9ec06-a02a-41d9-a41c-8b145b15f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522981952-172.17.0.2-1599295535950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-e1c6d793-01d3-4f5e-9ba3-d48bb44f9e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-1cfbb695-26bf-4b3a-9bc6-96c1d4c966e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-f834852d-ffa7-4b9c-99fd-8eb2e0af392c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-bad6ee47-eb37-4e2e-b458-bef26503fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-5e6f9c1c-5369-4ace-8ce8-f1d0e6f3d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-f9be9726-5153-4dc7-a001-c07d1f52aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-2161bd1a-e69b-4236-8cd5-9bf94de22779,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-27a9ec06-a02a-41d9-a41c-8b145b15f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716504171-172.17.0.2-1599295612584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-8f562215-4dd2-4f8a-8b51-5f49267c0a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-e2592c00-90d5-4520-941d-fbba8d58629a,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-e92c93c3-7639-48f8-82fb-31318d22b062,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-11b61c13-4d94-498d-9fe6-5e6ce39d3dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-cf73d342-461a-49ad-82a2-3ee34dfdd365,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-ae136771-76f5-45b8-a647-2a4f61bc1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-86f6976c-8f7a-4c50-a918-1d6f564c2037,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d006f3d5-4602-439b-9807-1f74110eb8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716504171-172.17.0.2-1599295612584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-8f562215-4dd2-4f8a-8b51-5f49267c0a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-e2592c00-90d5-4520-941d-fbba8d58629a,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-e92c93c3-7639-48f8-82fb-31318d22b062,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-11b61c13-4d94-498d-9fe6-5e6ce39d3dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-cf73d342-461a-49ad-82a2-3ee34dfdd365,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-ae136771-76f5-45b8-a647-2a4f61bc1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-86f6976c-8f7a-4c50-a918-1d6f564c2037,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d006f3d5-4602-439b-9807-1f74110eb8fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23236406-172.17.0.2-1599295738733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-e0957e11-5d2c-404c-ac18-d7f5fe8a9510,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-903ca591-38d8-4094-b584-c578648e6175,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b78789f2-cb0a-40a5-88cd-e30f9c8f5466,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-ce5e2cc9-4964-4027-b126-f379fc493cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-51ca56af-dc12-419e-8b68-253e0d57be99,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-f1e0940e-a682-48bb-bc29-0669d78637dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-e2a91c4a-5acf-4b26-98cb-ff9fd588c457,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-ed08172f-d006-4408-ab1d-5ea400686c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23236406-172.17.0.2-1599295738733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-e0957e11-5d2c-404c-ac18-d7f5fe8a9510,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-903ca591-38d8-4094-b584-c578648e6175,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b78789f2-cb0a-40a5-88cd-e30f9c8f5466,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-ce5e2cc9-4964-4027-b126-f379fc493cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-51ca56af-dc12-419e-8b68-253e0d57be99,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-f1e0940e-a682-48bb-bc29-0669d78637dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-e2a91c4a-5acf-4b26-98cb-ff9fd588c457,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-ed08172f-d006-4408-ab1d-5ea400686c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904057471-172.17.0.2-1599295987232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37755,DS-59c187f1-9397-444c-9e9c-cdbf1fe8c438,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-07487779-1d21-424c-af02-54ee2238f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-1e06f509-72a8-458d-9415-bfd601b367f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-4dafa15e-512f-44d4-ac1f-de7e7fa44925,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b9ea07bb-5d14-426e-941b-c8547c392c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-b8bb1f02-8f0e-479c-b080-e4d027be6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-8178f948-3350-4426-9a40-404afaa53993,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-a7869454-7a38-44bc-9e78-28519702783e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904057471-172.17.0.2-1599295987232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37755,DS-59c187f1-9397-444c-9e9c-cdbf1fe8c438,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-07487779-1d21-424c-af02-54ee2238f6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-1e06f509-72a8-458d-9415-bfd601b367f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-4dafa15e-512f-44d4-ac1f-de7e7fa44925,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b9ea07bb-5d14-426e-941b-c8547c392c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-b8bb1f02-8f0e-479c-b080-e4d027be6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-8178f948-3350-4426-9a40-404afaa53993,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-a7869454-7a38-44bc-9e78-28519702783e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363549947-172.17.0.2-1599296945729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-a4f24ae3-fe8e-42e6-8021-8c13ef1bca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-5687674e-ebbf-4ff5-b6c3-9de09f8cf9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-53774a4b-855c-4e77-8395-5b79e9b7ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-62aa5ae8-bd94-48b8-af3f-ac835a792c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-9ab6d920-a682-47d7-a3db-6b7b206dddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3535fbb8-d2ba-41dd-b554-179165f6117d,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-449d1923-e2e2-4c07-ba9b-7a955b7dea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9466ef09-0506-481f-9eb2-13b67d1b0596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363549947-172.17.0.2-1599296945729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-a4f24ae3-fe8e-42e6-8021-8c13ef1bca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-5687674e-ebbf-4ff5-b6c3-9de09f8cf9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-53774a4b-855c-4e77-8395-5b79e9b7ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-62aa5ae8-bd94-48b8-af3f-ac835a792c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-9ab6d920-a682-47d7-a3db-6b7b206dddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3535fbb8-d2ba-41dd-b554-179165f6117d,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-449d1923-e2e2-4c07-ba9b-7a955b7dea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9466ef09-0506-481f-9eb2-13b67d1b0596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226363785-172.17.0.2-1599296982719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-c0739393-4daf-4951-bb6f-fb2d70833e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-a5008e46-5cdf-42c4-96d3-f6bf1b95470e,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-834079c1-0759-4379-a4e5-ee5f441aacc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-9073e8db-08dc-40a2-abe4-c5c90cb815cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b044f187-c455-469a-a8ea-0672f12b7636,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3f4f93cc-fba8-4b97-ac85-471df50dff23,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-6138eb9a-fda2-4043-bfe0-68a47e00f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-9e98fd12-498e-4a9c-bd43-7e9865d96eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226363785-172.17.0.2-1599296982719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-c0739393-4daf-4951-bb6f-fb2d70833e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-a5008e46-5cdf-42c4-96d3-f6bf1b95470e,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-834079c1-0759-4379-a4e5-ee5f441aacc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-9073e8db-08dc-40a2-abe4-c5c90cb815cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b044f187-c455-469a-a8ea-0672f12b7636,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3f4f93cc-fba8-4b97-ac85-471df50dff23,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-6138eb9a-fda2-4043-bfe0-68a47e00f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-9e98fd12-498e-4a9c-bd43-7e9865d96eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994193533-172.17.0.2-1599297659666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-e674ac6e-8552-4cdb-a738-c2c0fa0b403e,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-ddadbd4c-ad99-4a43-aa6b-bfecd28cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-7e284058-2526-4899-85c2-9a01c58ea4de,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c25e9ad8-9e08-4e86-846e-3ce3b57946a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-6fd2c97a-a729-4e3f-b0ba-18599ad8dbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-630f5d36-018d-45a0-9a0d-34c61132383c,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-aa39e65d-4914-49ee-9466-54513d12d389,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-85b476f9-c123-453d-90ff-46b7581cddd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994193533-172.17.0.2-1599297659666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-e674ac6e-8552-4cdb-a738-c2c0fa0b403e,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-ddadbd4c-ad99-4a43-aa6b-bfecd28cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-7e284058-2526-4899-85c2-9a01c58ea4de,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c25e9ad8-9e08-4e86-846e-3ce3b57946a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-6fd2c97a-a729-4e3f-b0ba-18599ad8dbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-630f5d36-018d-45a0-9a0d-34c61132383c,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-aa39e65d-4914-49ee-9466-54513d12d389,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-85b476f9-c123-453d-90ff-46b7581cddd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786239060-172.17.0.2-1599298119209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-e1289c91-001b-4935-872f-dba98d43bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-e6ac5fe6-eacb-494a-bc43-3dcdfa6e7fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-4accf29b-d0e1-4985-ad64-d41644e3b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-9aeb4767-e2b5-4651-a7f4-90aa8568a717,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-33a4a667-46b4-4b05-9686-eed53b76c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-a3cfe197-46a6-4c72-a2d0-9a12a638584d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-2d969d21-b438-4c05-9d8e-e0992b3e0271,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-1193f9bf-6395-4239-b5fe-b3351f17f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786239060-172.17.0.2-1599298119209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-e1289c91-001b-4935-872f-dba98d43bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-e6ac5fe6-eacb-494a-bc43-3dcdfa6e7fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-4accf29b-d0e1-4985-ad64-d41644e3b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-9aeb4767-e2b5-4651-a7f4-90aa8568a717,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-33a4a667-46b4-4b05-9686-eed53b76c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-a3cfe197-46a6-4c72-a2d0-9a12a638584d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-2d969d21-b438-4c05-9d8e-e0992b3e0271,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-1193f9bf-6395-4239-b5fe-b3351f17f355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5528
