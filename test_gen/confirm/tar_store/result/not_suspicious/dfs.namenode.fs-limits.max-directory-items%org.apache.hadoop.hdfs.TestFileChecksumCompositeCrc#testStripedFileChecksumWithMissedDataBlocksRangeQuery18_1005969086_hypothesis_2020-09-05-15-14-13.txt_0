reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733625531-172.17.0.10-1599318933162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-21a30060-1a83-4c7e-8871-e66f15feb7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-688049d6-bc75-43c7-919a-359840201d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-90cdec5a-7187-4062-b969-e4088de3ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-9a317285-b561-45a2-9cb8-837283d80268,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ae7809b1-ca39-479f-af2e-81660f192813,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-716a2fe7-1aef-431e-b50a-95de3dbb59ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-f6c4f662-f6a3-466c-805f-fb1a66f13f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-e3bd61da-bfda-409a-8516-26f851513b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733625531-172.17.0.10-1599318933162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-21a30060-1a83-4c7e-8871-e66f15feb7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-688049d6-bc75-43c7-919a-359840201d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-90cdec5a-7187-4062-b969-e4088de3ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-9a317285-b561-45a2-9cb8-837283d80268,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ae7809b1-ca39-479f-af2e-81660f192813,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-716a2fe7-1aef-431e-b50a-95de3dbb59ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-f6c4f662-f6a3-466c-805f-fb1a66f13f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-e3bd61da-bfda-409a-8516-26f851513b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847893444-172.17.0.10-1599319011519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-63a540c0-9bee-48e2-ac2b-9b41a95bf932,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-e28d0ea6-276b-4ecb-8a32-15eb1113de36,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-f65ccb61-34bf-4987-bc21-5dbe4561ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b145690b-3193-4c62-af9c-60c842543141,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-9c2cac06-d931-4ceb-95f6-a65528730db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-eb79fe47-2d5f-4aef-89ba-96cc5476e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-12342f3a-cf78-4c52-8ce2-0ca311a88ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-96fe8603-d24c-4078-aaec-fef81cda78ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847893444-172.17.0.10-1599319011519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-63a540c0-9bee-48e2-ac2b-9b41a95bf932,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-e28d0ea6-276b-4ecb-8a32-15eb1113de36,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-f65ccb61-34bf-4987-bc21-5dbe4561ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b145690b-3193-4c62-af9c-60c842543141,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-9c2cac06-d931-4ceb-95f6-a65528730db8,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-eb79fe47-2d5f-4aef-89ba-96cc5476e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-12342f3a-cf78-4c52-8ce2-0ca311a88ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-96fe8603-d24c-4078-aaec-fef81cda78ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850876813-172.17.0.10-1599319166816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-d4f085e0-9216-43dd-aba2-40c1cd68af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-4aff24bc-3290-41c7-bc3e-96497a802150,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-f1e600da-4180-4f5c-97bb-85a879b413ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e7349874-441d-42a4-ae5a-d28f1f58dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-270d588b-c699-491a-9eec-3c4cc5442cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-46355646-6eda-4d88-aa47-6424ff946c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-618c5911-4cb9-48c9-a55e-bf16fd7d9f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-65cf9005-5b02-4538-a944-01eb2587e4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850876813-172.17.0.10-1599319166816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-d4f085e0-9216-43dd-aba2-40c1cd68af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-4aff24bc-3290-41c7-bc3e-96497a802150,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-f1e600da-4180-4f5c-97bb-85a879b413ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-e7349874-441d-42a4-ae5a-d28f1f58dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-270d588b-c699-491a-9eec-3c4cc5442cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-46355646-6eda-4d88-aa47-6424ff946c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-618c5911-4cb9-48c9-a55e-bf16fd7d9f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-65cf9005-5b02-4538-a944-01eb2587e4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860281718-172.17.0.10-1599319706589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34347,DS-e38fee39-f665-4bbb-b53c-fb1440f89229,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-c4072e92-4d80-4de4-a5df-5b43a16eee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-60f53cf8-dd93-40cf-9299-7da2f0aaf872,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-6ee90fb3-1726-46a1-87ee-3b0f8397f305,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-05f01bca-1afa-46d2-beaf-e918b526badc,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-241fb939-a90e-42ce-8333-b4872875026b,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b009389f-29b3-48e0-84c1-485142d97f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b8c2a09b-5edb-4aeb-86bc-76ad3984e39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860281718-172.17.0.10-1599319706589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34347,DS-e38fee39-f665-4bbb-b53c-fb1440f89229,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-c4072e92-4d80-4de4-a5df-5b43a16eee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-60f53cf8-dd93-40cf-9299-7da2f0aaf872,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-6ee90fb3-1726-46a1-87ee-3b0f8397f305,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-05f01bca-1afa-46d2-beaf-e918b526badc,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-241fb939-a90e-42ce-8333-b4872875026b,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b009389f-29b3-48e0-84c1-485142d97f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b8c2a09b-5edb-4aeb-86bc-76ad3984e39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582730662-172.17.0.10-1599319899388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-249e9b9a-a754-488f-b1c2-4529c3fc9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-be2b576f-d26c-4a5f-a452-54866a81569c,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-a3b639f2-090f-4151-a1cb-98a44e1687cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-8ffe25c1-1168-43bf-9c6a-0a8422353f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-918b54ac-2457-4523-98b9-21c32f5e9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-f06903fe-f78c-4a72-8ab6-cb481603db3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-d5ac4a2e-76da-40e1-ad4d-cb48a618691b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-dbfbaf05-4fcd-4952-9833-f4001e6a395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582730662-172.17.0.10-1599319899388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-249e9b9a-a754-488f-b1c2-4529c3fc9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-be2b576f-d26c-4a5f-a452-54866a81569c,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-a3b639f2-090f-4151-a1cb-98a44e1687cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-8ffe25c1-1168-43bf-9c6a-0a8422353f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-918b54ac-2457-4523-98b9-21c32f5e9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-f06903fe-f78c-4a72-8ab6-cb481603db3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-d5ac4a2e-76da-40e1-ad4d-cb48a618691b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-dbfbaf05-4fcd-4952-9833-f4001e6a395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107291639-172.17.0.10-1599320555915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42003,DS-611dc4d3-d9eb-4838-a4e9-a3fa8677b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-9e11972c-7d35-4a6f-a4cc-63118205ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-8c30a9ae-56cd-418d-a929-f07591880f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-e394a5f7-ab10-4fa2-8fa8-83df25adbd08,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-bfc42056-00cb-4e45-801d-3923eaa9640b,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-1ab520cf-8703-4c1a-a3a3-ddc08b855468,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-c0964f1a-ee1c-4af2-bfe7-1bd2d7f68b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-eda94445-1aee-4553-bc99-341b016a498c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107291639-172.17.0.10-1599320555915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42003,DS-611dc4d3-d9eb-4838-a4e9-a3fa8677b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-9e11972c-7d35-4a6f-a4cc-63118205ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-8c30a9ae-56cd-418d-a929-f07591880f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-e394a5f7-ab10-4fa2-8fa8-83df25adbd08,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-bfc42056-00cb-4e45-801d-3923eaa9640b,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-1ab520cf-8703-4c1a-a3a3-ddc08b855468,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-c0964f1a-ee1c-4af2-bfe7-1bd2d7f68b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-eda94445-1aee-4553-bc99-341b016a498c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740641237-172.17.0.10-1599320635183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40317,DS-0e2332af-6831-41fa-a34b-a381407567eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-7dc84a8a-4219-4f33-b1f7-0d532584749a,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-68d64b2f-386d-45c6-ab95-2fc8274d67af,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-0eea8df2-eb13-447b-98cd-7e4f09eef8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-1413ddd4-3790-499d-9639-91387232f436,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-80866865-9078-4c3f-b7ec-9e43609b0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-37aa6eee-c999-4daf-b52c-5aab2c2160b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-1250aa9d-09b8-4bfb-9706-85296476aa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740641237-172.17.0.10-1599320635183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40317,DS-0e2332af-6831-41fa-a34b-a381407567eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-7dc84a8a-4219-4f33-b1f7-0d532584749a,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-68d64b2f-386d-45c6-ab95-2fc8274d67af,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-0eea8df2-eb13-447b-98cd-7e4f09eef8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-1413ddd4-3790-499d-9639-91387232f436,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-80866865-9078-4c3f-b7ec-9e43609b0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-37aa6eee-c999-4daf-b52c-5aab2c2160b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-1250aa9d-09b8-4bfb-9706-85296476aa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128918645-172.17.0.10-1599320748013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-a2a30e24-10a2-4539-aa81-0b61a35253c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-a00a3239-4376-48fd-8e7b-a7b5a630daf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-909bfeb8-bc35-4324-8be6-66342aa973da,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-1c698b58-d263-4214-bb5c-d31d4aa18129,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-9f628139-616c-4b07-ad6e-51dfa9b84149,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-14a23948-9cbc-48bb-b71c-e94a6ff67d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-8d09a998-7438-46dd-a476-2547144643aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ad3940ba-8245-40e8-a9b1-3c27c8827347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128918645-172.17.0.10-1599320748013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-a2a30e24-10a2-4539-aa81-0b61a35253c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-a00a3239-4376-48fd-8e7b-a7b5a630daf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-909bfeb8-bc35-4324-8be6-66342aa973da,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-1c698b58-d263-4214-bb5c-d31d4aa18129,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-9f628139-616c-4b07-ad6e-51dfa9b84149,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-14a23948-9cbc-48bb-b71c-e94a6ff67d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-8d09a998-7438-46dd-a476-2547144643aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ad3940ba-8245-40e8-a9b1-3c27c8827347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185465923-172.17.0.10-1599321825768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-b6e4b063-9aa8-49e7-8559-62610fbba3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-6b1a2bde-5e53-4910-9c37-4915d968e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-af43bd30-27ae-4b8c-b1c6-f2aeac36f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fb5334b0-d58e-4d86-8320-0558a90967ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1aaa3433-2b39-4f3c-b9c9-bddcb6038f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-d16407f7-11d0-45f1-8623-cc80b0cb00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-038047ed-bda6-4f0d-8f7a-16654508e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-5c0d54e0-86f9-45ff-9691-0ed9c4fa5d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185465923-172.17.0.10-1599321825768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-b6e4b063-9aa8-49e7-8559-62610fbba3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-6b1a2bde-5e53-4910-9c37-4915d968e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-af43bd30-27ae-4b8c-b1c6-f2aeac36f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fb5334b0-d58e-4d86-8320-0558a90967ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1aaa3433-2b39-4f3c-b9c9-bddcb6038f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-d16407f7-11d0-45f1-8623-cc80b0cb00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-038047ed-bda6-4f0d-8f7a-16654508e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-5c0d54e0-86f9-45ff-9691-0ed9c4fa5d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127771828-172.17.0.10-1599321891038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-0ec96897-69f9-4f1b-9136-7d1e3158be60,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b849ac86-2a01-40ea-b7de-af51be4a03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3d1056ca-65c5-4a10-b4e8-786fc6adbb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-627fbd88-a067-4244-a7dd-1372865dc437,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-9fcb8cd8-c711-46b8-8069-d03babdcb368,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-40596ade-a524-4df6-b6bf-faf0a0c7cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-a068376e-72e8-4725-bfac-f030f200a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5d58ba53-46d7-454a-8ba1-8187e918ac44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127771828-172.17.0.10-1599321891038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-0ec96897-69f9-4f1b-9136-7d1e3158be60,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b849ac86-2a01-40ea-b7de-af51be4a03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-3d1056ca-65c5-4a10-b4e8-786fc6adbb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-627fbd88-a067-4244-a7dd-1372865dc437,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-9fcb8cd8-c711-46b8-8069-d03babdcb368,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-40596ade-a524-4df6-b6bf-faf0a0c7cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-a068376e-72e8-4725-bfac-f030f200a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5d58ba53-46d7-454a-8ba1-8187e918ac44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813116425-172.17.0.10-1599322363312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38614,DS-ee1db03b-763d-4d82-997d-d9b43f868f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-154ac7ba-9231-46ae-8138-6619590eb802,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-8c347f55-b352-4abb-bb7b-2d92a5d2a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d11084ed-588d-47f4-8fd9-05ad32b51f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-70b920a9-cec6-4ff9-8a6a-fb88b99fc3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-830fc205-181e-4c4c-a6f6-47bcf123a028,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-92c5570c-2276-47f4-8102-6301e82d2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-571df657-e8c7-4e9e-8e9c-042c727db078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813116425-172.17.0.10-1599322363312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38614,DS-ee1db03b-763d-4d82-997d-d9b43f868f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-154ac7ba-9231-46ae-8138-6619590eb802,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-8c347f55-b352-4abb-bb7b-2d92a5d2a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d11084ed-588d-47f4-8fd9-05ad32b51f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-70b920a9-cec6-4ff9-8a6a-fb88b99fc3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-830fc205-181e-4c4c-a6f6-47bcf123a028,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-92c5570c-2276-47f4-8102-6301e82d2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-571df657-e8c7-4e9e-8e9c-042c727db078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361982825-172.17.0.10-1599322402179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44851,DS-489a5e59-e2fe-45ee-83b1-9fdc857e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-a74b9409-d766-4e4f-baf2-76737980115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-eb6dcdf2-7c98-4b8a-b994-2fb55dcaf241,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-0a0c3621-ccbc-46ef-9410-25b5dc707cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-8c21d964-3ba0-4178-96a0-4ceaec859390,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-2fdef0a7-1480-4f94-a625-1e744a1ee993,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-342b25cb-c732-437c-a407-a13cd1934a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4d90a9d1-3577-4ace-8ca7-15a0f4ce1601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361982825-172.17.0.10-1599322402179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44851,DS-489a5e59-e2fe-45ee-83b1-9fdc857e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-a74b9409-d766-4e4f-baf2-76737980115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-eb6dcdf2-7c98-4b8a-b994-2fb55dcaf241,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-0a0c3621-ccbc-46ef-9410-25b5dc707cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-8c21d964-3ba0-4178-96a0-4ceaec859390,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-2fdef0a7-1480-4f94-a625-1e744a1ee993,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-342b25cb-c732-437c-a407-a13cd1934a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4d90a9d1-3577-4ace-8ca7-15a0f4ce1601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792514219-172.17.0.10-1599322568351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-f435ede9-4d05-46f1-bff9-5cfa3af742b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-392a7123-9f77-4c4e-b677-efc1e45895d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-47ba76ba-f8f1-4a2b-9529-5fb9c518a963,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-c609c50b-af76-4a4f-b789-ac571c8ec222,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-bc1ed031-49fa-4bde-9f07-91d2d281f555,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-ff6cdb66-2634-4b68-a4ea-216685bf32d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-493be000-5fbf-4de0-9860-beb5f4d98f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-61c6f3fb-65dc-4801-9d5d-2f60120f21f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792514219-172.17.0.10-1599322568351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-f435ede9-4d05-46f1-bff9-5cfa3af742b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-392a7123-9f77-4c4e-b677-efc1e45895d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-47ba76ba-f8f1-4a2b-9529-5fb9c518a963,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-c609c50b-af76-4a4f-b789-ac571c8ec222,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-bc1ed031-49fa-4bde-9f07-91d2d281f555,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-ff6cdb66-2634-4b68-a4ea-216685bf32d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-493be000-5fbf-4de0-9860-beb5f4d98f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-61c6f3fb-65dc-4801-9d5d-2f60120f21f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014124640-172.17.0.10-1599322634019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-b9f88ffd-9fd0-4be8-93cc-2a486243d87e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-6207b6aa-7165-4e30-873a-dc2644b3ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-e4e7c82b-2362-48d7-b634-418ac98ea847,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-fe5b9d4c-f510-4759-9768-3b713113cc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-630822b2-0591-478c-8a39-bacd3403d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-07b49cf4-cf85-43a3-a0ad-9dbf5e67e159,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-d1249a16-d6ba-4c8d-99a3-a7d7e38986ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-12127dcb-5bce-4ef9-90fc-58ef60d282c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014124640-172.17.0.10-1599322634019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-b9f88ffd-9fd0-4be8-93cc-2a486243d87e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-6207b6aa-7165-4e30-873a-dc2644b3ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-e4e7c82b-2362-48d7-b634-418ac98ea847,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-fe5b9d4c-f510-4759-9768-3b713113cc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-630822b2-0591-478c-8a39-bacd3403d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-07b49cf4-cf85-43a3-a0ad-9dbf5e67e159,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-d1249a16-d6ba-4c8d-99a3-a7d7e38986ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-12127dcb-5bce-4ef9-90fc-58ef60d282c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753407062-172.17.0.10-1599322669748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-962fc5f2-c662-4777-8d28-0f9dd873b347,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-80e3baa8-4be2-454b-9243-5a6d272f624b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-f7ade4e2-4c72-4cb3-ae9a-164254d74564,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-2bc6ab32-692b-4880-8295-b31793f7baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-d80acd6d-6a26-4d35-bc6a-33e4c053bbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-ad47ee4a-e886-46d2-bd3a-316106d2d408,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b4d8d08f-2c9b-4dc7-9a7d-75196a4b205c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-fa07faa4-0467-4a17-88fa-1ffc214956f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753407062-172.17.0.10-1599322669748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-962fc5f2-c662-4777-8d28-0f9dd873b347,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-80e3baa8-4be2-454b-9243-5a6d272f624b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-f7ade4e2-4c72-4cb3-ae9a-164254d74564,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-2bc6ab32-692b-4880-8295-b31793f7baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-d80acd6d-6a26-4d35-bc6a-33e4c053bbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-ad47ee4a-e886-46d2-bd3a-316106d2d408,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b4d8d08f-2c9b-4dc7-9a7d-75196a4b205c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-fa07faa4-0467-4a17-88fa-1ffc214956f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534526420-172.17.0.10-1599322794109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-cf678142-8d67-45b4-99d4-f99e85e959b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-b5503b1d-443f-41be-a0a8-22f233b025c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ab57e19d-a306-432f-9e24-dd77c2109cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3bc0a246-133d-4f7f-a452-18068e94f2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-31951adb-73c5-4288-8fc1-9bcf17c9d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-9ef07b24-17ec-48a8-93d4-d00531a339b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-b2a8bc5b-3d7d-44f2-abeb-f9031715f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-a4b843f9-b9f3-4e51-b33f-f2e18c27fa9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534526420-172.17.0.10-1599322794109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-cf678142-8d67-45b4-99d4-f99e85e959b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-b5503b1d-443f-41be-a0a8-22f233b025c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ab57e19d-a306-432f-9e24-dd77c2109cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3bc0a246-133d-4f7f-a452-18068e94f2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-31951adb-73c5-4288-8fc1-9bcf17c9d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-9ef07b24-17ec-48a8-93d4-d00531a339b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-b2a8bc5b-3d7d-44f2-abeb-f9031715f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-a4b843f9-b9f3-4e51-b33f-f2e18c27fa9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298678340-172.17.0.10-1599323016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-e45946ee-bc69-41b6-a2c0-3d7ef9d45adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-aba2e1a9-07dd-4e72-8842-01857f3be93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-230d955f-2e04-4420-87b2-6f78e9537ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-aa93978f-fecf-4153-b556-f86ed9b0033e,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ba55f210-32a8-4688-b120-ab81ce9a6697,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f4411a38-8ec7-4338-abfa-c4e998fa0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-64a220be-f339-437c-869b-7023296e386a,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-0c0ea002-3eb2-46bf-8a12-92909185d5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298678340-172.17.0.10-1599323016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46333,DS-e45946ee-bc69-41b6-a2c0-3d7ef9d45adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-aba2e1a9-07dd-4e72-8842-01857f3be93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-230d955f-2e04-4420-87b2-6f78e9537ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-aa93978f-fecf-4153-b556-f86ed9b0033e,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ba55f210-32a8-4688-b120-ab81ce9a6697,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f4411a38-8ec7-4338-abfa-c4e998fa0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-64a220be-f339-437c-869b-7023296e386a,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-0c0ea002-3eb2-46bf-8a12-92909185d5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573272697-172.17.0.10-1599323126329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-9650abe6-2625-43db-9d38-f89c3888d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-bcc8b800-a8cb-45ad-a51f-4e4b1edf6e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c3468f8a-1fb1-4a3b-b00a-6fde48ae684d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-2ee16eb0-1d40-4e9c-8b9a-dfb7bd47c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-42def55d-6cb3-4d9b-8831-b40b0abc1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-831acbf7-22bb-4240-b454-f0338593c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-88bb9dbb-9ec5-4793-9565-e0a256c7c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-1ba7bcce-4f08-4a6f-90c9-5189006bf135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573272697-172.17.0.10-1599323126329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-9650abe6-2625-43db-9d38-f89c3888d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-bcc8b800-a8cb-45ad-a51f-4e4b1edf6e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c3468f8a-1fb1-4a3b-b00a-6fde48ae684d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-2ee16eb0-1d40-4e9c-8b9a-dfb7bd47c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-42def55d-6cb3-4d9b-8831-b40b0abc1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-831acbf7-22bb-4240-b454-f0338593c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-88bb9dbb-9ec5-4793-9565-e0a256c7c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-1ba7bcce-4f08-4a6f-90c9-5189006bf135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5339
