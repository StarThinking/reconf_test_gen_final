reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396263765-172.17.0.5-1599358887680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-e204d0ca-bd17-4c60-ac1c-59db3687c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-9da41e80-203c-475c-8254-05d8a996c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-5c8e7978-ea3b-4473-bcd0-0d1061879631,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-5cde0a64-6b36-4098-835e-73ff3ee2b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-ac3994f4-0852-4d63-af3f-6570cc8a4547,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0ef8f9cb-4bc4-464c-b76c-99f117d9f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-083b01ec-c8ab-4204-9a82-cfdb58a6b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-235707b8-25c8-478d-8334-514c1f8c89f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396263765-172.17.0.5-1599358887680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-e204d0ca-bd17-4c60-ac1c-59db3687c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-9da41e80-203c-475c-8254-05d8a996c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-5c8e7978-ea3b-4473-bcd0-0d1061879631,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-5cde0a64-6b36-4098-835e-73ff3ee2b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-ac3994f4-0852-4d63-af3f-6570cc8a4547,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0ef8f9cb-4bc4-464c-b76c-99f117d9f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-083b01ec-c8ab-4204-9a82-cfdb58a6b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-235707b8-25c8-478d-8334-514c1f8c89f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715980505-172.17.0.5-1599359128381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-88955e67-58be-4053-838b-bed16b9ef5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-ba146adc-fc56-4903-b562-cc6864e3cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-31a9e29f-2b81-4dbf-952c-86567033ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-98714a13-5827-4847-953a-0f6bb96185ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-fbb8faba-167f-4cfb-bbd5-a76f1d796947,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-2e953608-98ae-4b7e-87a1-40d9ed8508d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-0b758bb5-cda0-47ce-9b8b-3286423f51b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-f64de560-38c4-4e50-8bb2-294dff1669c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715980505-172.17.0.5-1599359128381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-88955e67-58be-4053-838b-bed16b9ef5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-ba146adc-fc56-4903-b562-cc6864e3cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-31a9e29f-2b81-4dbf-952c-86567033ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-98714a13-5827-4847-953a-0f6bb96185ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-fbb8faba-167f-4cfb-bbd5-a76f1d796947,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-2e953608-98ae-4b7e-87a1-40d9ed8508d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-0b758bb5-cda0-47ce-9b8b-3286423f51b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-f64de560-38c4-4e50-8bb2-294dff1669c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888931134-172.17.0.5-1599359910379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-8456eadd-05e8-4146-af27-e870a00a8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-09544f71-21d4-4b48-8704-cd45751005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-683b23a5-e01e-42e6-84ab-cd4901f5fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7116e7e9-6224-4650-85ee-3299da9b0902,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-561a6286-a98e-434a-95e4-a01d23def9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-b84cfbd5-d925-47c7-ac5e-717683ea6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-367e195c-14e2-44c5-bdf6-39463168d037,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-12e404c9-4bc5-4392-88e8-15130e80b47d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888931134-172.17.0.5-1599359910379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-8456eadd-05e8-4146-af27-e870a00a8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-09544f71-21d4-4b48-8704-cd45751005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-683b23a5-e01e-42e6-84ab-cd4901f5fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7116e7e9-6224-4650-85ee-3299da9b0902,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-561a6286-a98e-434a-95e4-a01d23def9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-b84cfbd5-d925-47c7-ac5e-717683ea6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-367e195c-14e2-44c5-bdf6-39463168d037,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-12e404c9-4bc5-4392-88e8-15130e80b47d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880725208-172.17.0.5-1599359967558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-9260321d-7084-442f-b46c-29d20d3e2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2da91741-94ec-4b87-a72e-0920ae698b59,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-b1fc0221-900a-44d9-8383-281da13150c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9a829c1d-8b92-4b6e-93ef-883428d9283c,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-af3344de-14cd-4e5c-a1ee-ff77c7b40cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9ad9a810-667b-4ada-804b-e9a4b903e655,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-63d881a4-ae60-40df-9ef0-4c8370f612fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-545c4d26-fded-4730-b650-f8976d45ab7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880725208-172.17.0.5-1599359967558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-9260321d-7084-442f-b46c-29d20d3e2b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2da91741-94ec-4b87-a72e-0920ae698b59,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-b1fc0221-900a-44d9-8383-281da13150c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9a829c1d-8b92-4b6e-93ef-883428d9283c,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-af3344de-14cd-4e5c-a1ee-ff77c7b40cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9ad9a810-667b-4ada-804b-e9a4b903e655,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-63d881a4-ae60-40df-9ef0-4c8370f612fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-545c4d26-fded-4730-b650-f8976d45ab7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963679766-172.17.0.5-1599360386285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44260,DS-7eee3c7f-977b-451d-a598-9a952b79d7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-31e04a78-24da-4a1a-9a75-736c3e7a8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-d0c9b011-7cc2-40d2-af25-75f26f15d350,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-b62efe68-ba39-4ff8-9b81-aac543ed6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-a501df12-bc78-405e-aadf-db67dfdf2c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-bfffbca8-1b37-4af4-8369-95aaedf909d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-0a0f625d-6c8e-4480-9fce-85d55abe8ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-76f84d39-6adb-4c72-b333-6bf0a5b9bee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963679766-172.17.0.5-1599360386285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44260,DS-7eee3c7f-977b-451d-a598-9a952b79d7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-31e04a78-24da-4a1a-9a75-736c3e7a8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-d0c9b011-7cc2-40d2-af25-75f26f15d350,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-b62efe68-ba39-4ff8-9b81-aac543ed6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-a501df12-bc78-405e-aadf-db67dfdf2c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-bfffbca8-1b37-4af4-8369-95aaedf909d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-0a0f625d-6c8e-4480-9fce-85d55abe8ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-76f84d39-6adb-4c72-b333-6bf0a5b9bee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848767023-172.17.0.5-1599360505007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-698740f7-df7c-4beb-9560-7a45e4755ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-b3680ec8-5fc3-4b54-9ed5-bb0be82351a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a5151b5f-b91f-4776-a4cf-daaec35b326a,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-c29684cb-56cc-4b72-860a-9b2e1f8911c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0100ea01-4a65-47cf-b91a-6b85a354c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-02159bc1-3311-486a-98e7-b159bde7717b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-812c8898-c356-4502-8e32-fd3031d6c52d,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e5ff4021-90d4-43d8-b3e6-26e121fdd217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848767023-172.17.0.5-1599360505007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-698740f7-df7c-4beb-9560-7a45e4755ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-b3680ec8-5fc3-4b54-9ed5-bb0be82351a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a5151b5f-b91f-4776-a4cf-daaec35b326a,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-c29684cb-56cc-4b72-860a-9b2e1f8911c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0100ea01-4a65-47cf-b91a-6b85a354c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-02159bc1-3311-486a-98e7-b159bde7717b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-812c8898-c356-4502-8e32-fd3031d6c52d,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e5ff4021-90d4-43d8-b3e6-26e121fdd217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826848199-172.17.0.5-1599360654556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-185eaf71-3794-4758-8c9b-dbac1e0baa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-3789cf3f-12b4-45a9-b039-f596e9f95a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-fa6b943a-3f60-4fa8-9dee-cb382cab6086,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a1ff5195-0864-4b2b-941f-a5d564e38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-04a7276a-1a8e-491d-9644-1402081b6a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-1ed43096-5a25-4adc-870c-2744f0345ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-e200a270-1b7a-4052-887d-612ffd6c27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-55e7d186-2d5b-41d2-ac63-ce2453a48556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826848199-172.17.0.5-1599360654556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-185eaf71-3794-4758-8c9b-dbac1e0baa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-3789cf3f-12b4-45a9-b039-f596e9f95a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-fa6b943a-3f60-4fa8-9dee-cb382cab6086,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a1ff5195-0864-4b2b-941f-a5d564e38c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-04a7276a-1a8e-491d-9644-1402081b6a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-1ed43096-5a25-4adc-870c-2744f0345ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-e200a270-1b7a-4052-887d-612ffd6c27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-55e7d186-2d5b-41d2-ac63-ce2453a48556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913511168-172.17.0.5-1599361024382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45685,DS-559d196b-8cee-4a2e-8ea3-1838e0d02ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-660486f7-29da-40b9-b059-9190cf93f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-68190dcd-c538-4a18-b2be-cc1ec7c06bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-1d77cbb7-0a77-4e51-9156-bddab3a57adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-1800677a-f83d-45fe-8847-fbee40d82f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-08b8a960-044d-41d4-ad7f-d997fb4365d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-5c9010eb-246a-4237-8f46-78b0d5fbb662,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-ebb2bf1e-e028-40d3-8fa9-9c03f642afe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913511168-172.17.0.5-1599361024382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45685,DS-559d196b-8cee-4a2e-8ea3-1838e0d02ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-660486f7-29da-40b9-b059-9190cf93f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-68190dcd-c538-4a18-b2be-cc1ec7c06bda,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-1d77cbb7-0a77-4e51-9156-bddab3a57adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-1800677a-f83d-45fe-8847-fbee40d82f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-08b8a960-044d-41d4-ad7f-d997fb4365d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-5c9010eb-246a-4237-8f46-78b0d5fbb662,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-ebb2bf1e-e028-40d3-8fa9-9c03f642afe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928996992-172.17.0.5-1599361109073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-57e5c1b7-84a3-4ae8-bc2a-a0045934ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-395f1b4d-50e3-434d-8331-4682ed7b273c,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-d4adad48-f564-4974-a21a-38c1f18880f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-d1cc8e39-9d97-424a-9749-a44daf2a73ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-ce3f8125-3349-436c-bfb2-9512abb83bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4899cbd8-c5b9-43a3-816f-8ede84772514,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-44be9cb5-83e1-43a4-9671-43a513b922cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-46a4aa23-66fc-4e34-bc9b-9dfcde1c1de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928996992-172.17.0.5-1599361109073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40609,DS-57e5c1b7-84a3-4ae8-bc2a-a0045934ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-395f1b4d-50e3-434d-8331-4682ed7b273c,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-d4adad48-f564-4974-a21a-38c1f18880f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-d1cc8e39-9d97-424a-9749-a44daf2a73ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-ce3f8125-3349-436c-bfb2-9512abb83bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4899cbd8-c5b9-43a3-816f-8ede84772514,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-44be9cb5-83e1-43a4-9671-43a513b922cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-46a4aa23-66fc-4e34-bc9b-9dfcde1c1de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761360843-172.17.0.5-1599361774313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-fc474ce1-4b74-446f-b739-c5bdd7418dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-995911a0-dc2d-488c-9ac0-23956457942f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-84300b63-7106-4e03-8631-2e024120e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-214ab749-96c8-402d-bc3a-77863d122514,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43cc81cf-bd0d-4bd8-ba4a-c1ca634cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-d84fd548-947b-40a4-9a35-caf16802fb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-783ce068-d181-420c-b8c0-8bc098d8ed41,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-707cd8d9-ec86-4854-ad1a-4e3e41f688cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761360843-172.17.0.5-1599361774313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-fc474ce1-4b74-446f-b739-c5bdd7418dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-995911a0-dc2d-488c-9ac0-23956457942f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-84300b63-7106-4e03-8631-2e024120e8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-214ab749-96c8-402d-bc3a-77863d122514,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43cc81cf-bd0d-4bd8-ba4a-c1ca634cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-d84fd548-947b-40a4-9a35-caf16802fb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-783ce068-d181-420c-b8c0-8bc098d8ed41,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-707cd8d9-ec86-4854-ad1a-4e3e41f688cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533450261-172.17.0.5-1599362335498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42220,DS-39c83e56-9c0f-4b2a-b742-824680899625,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-82e37608-0865-44b8-ad7f-9fd36015642b,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-de85fd8f-e227-4842-bfeb-64c7cff6692c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-2b1224d7-eee6-4256-b443-53373abb0160,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-c1b6e5e7-6284-49f9-82ff-ca60f7f859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-374f7833-51aa-42ea-b41a-53e8f65b48d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-14c19c6f-2890-4cf1-82e6-f362d031c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-d03f855b-ed91-4904-bf04-4e6383eded89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533450261-172.17.0.5-1599362335498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42220,DS-39c83e56-9c0f-4b2a-b742-824680899625,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-82e37608-0865-44b8-ad7f-9fd36015642b,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-de85fd8f-e227-4842-bfeb-64c7cff6692c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-2b1224d7-eee6-4256-b443-53373abb0160,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-c1b6e5e7-6284-49f9-82ff-ca60f7f859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-374f7833-51aa-42ea-b41a-53e8f65b48d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-14c19c6f-2890-4cf1-82e6-f362d031c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-d03f855b-ed91-4904-bf04-4e6383eded89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582580413-172.17.0.5-1599362667154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-e345c368-62f2-40f8-9cae-025d8bea60b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-ffd3cfe9-e4b0-41ae-b336-c9e5532ae520,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0b692d81-ede2-4312-a616-671d052661cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-923f838e-121a-4a09-8e38-80bb9407fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-926b743b-8f3f-4e00-8777-2c06932e92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-87c77af8-f63c-45f0-ba95-0471a410faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d8489133-6302-4c32-ad2e-be642842c374,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-3376e4f5-8549-4461-819a-c5b65915f0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582580413-172.17.0.5-1599362667154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-e345c368-62f2-40f8-9cae-025d8bea60b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-ffd3cfe9-e4b0-41ae-b336-c9e5532ae520,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-0b692d81-ede2-4312-a616-671d052661cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-923f838e-121a-4a09-8e38-80bb9407fb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-926b743b-8f3f-4e00-8777-2c06932e92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-87c77af8-f63c-45f0-ba95-0471a410faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d8489133-6302-4c32-ad2e-be642842c374,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-3376e4f5-8549-4461-819a-c5b65915f0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583948816-172.17.0.5-1599362694325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-88086ccc-824b-451a-a795-064fb92ed595,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-864d7588-7204-4300-b9a7-fa6b93e5c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d6d5b94e-dc3b-4ba2-b7da-c85af4f60bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-96c31348-f807-4027-922c-c9b6673d2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-d8dc1dc2-143c-4018-8782-13a2b8907c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-9496d219-45b9-48ac-ae58-2850c6a03157,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-736767ae-b267-4394-bb6b-0f9c3ee961cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-b4a65fea-db97-4481-bc83-705560c69b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583948816-172.17.0.5-1599362694325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-88086ccc-824b-451a-a795-064fb92ed595,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-864d7588-7204-4300-b9a7-fa6b93e5c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d6d5b94e-dc3b-4ba2-b7da-c85af4f60bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-96c31348-f807-4027-922c-c9b6673d2ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-d8dc1dc2-143c-4018-8782-13a2b8907c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-9496d219-45b9-48ac-ae58-2850c6a03157,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-736767ae-b267-4394-bb6b-0f9c3ee961cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-b4a65fea-db97-4481-bc83-705560c69b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534538621-172.17.0.5-1599362839855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39763,DS-cf1f47de-7797-4363-841c-2b075a33136f,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-841c1049-6c8d-438d-adb6-6cf02cd96dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-25e9f9be-22cc-4dcb-bd5f-5ccf365008e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-9780ec2a-0888-492b-a130-c8c58625bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-ca39b947-e7bb-4661-b6a9-175a9054eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-c83eeac7-f949-408e-9cbf-37f0a1376258,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-0950e4fa-74ce-4ac1-9a4c-d6fcd7ea693d,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-71b41e3c-521a-43bb-9418-c5d8dcc6fc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534538621-172.17.0.5-1599362839855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39763,DS-cf1f47de-7797-4363-841c-2b075a33136f,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-841c1049-6c8d-438d-adb6-6cf02cd96dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-25e9f9be-22cc-4dcb-bd5f-5ccf365008e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-9780ec2a-0888-492b-a130-c8c58625bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-ca39b947-e7bb-4661-b6a9-175a9054eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-c83eeac7-f949-408e-9cbf-37f0a1376258,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-0950e4fa-74ce-4ac1-9a4c-d6fcd7ea693d,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-71b41e3c-521a-43bb-9418-c5d8dcc6fc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4473
