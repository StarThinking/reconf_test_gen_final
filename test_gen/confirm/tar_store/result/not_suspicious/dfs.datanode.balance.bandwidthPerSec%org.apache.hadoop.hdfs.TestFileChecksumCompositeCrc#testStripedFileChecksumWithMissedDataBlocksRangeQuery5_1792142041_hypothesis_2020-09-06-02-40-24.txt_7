reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967299493-172.17.0.21-1599360321503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-b589aeea-1dff-4328-b9fc-3697edd654ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-b221fdbf-c4c2-4b01-a658-25b1a9ca3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-9e00fec7-1102-424f-aef1-7a66981a5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-cf9353cd-b755-43ca-83fd-1122760c4390,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-e5094557-b1bd-45bf-8664-281bb5219192,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-1c593007-941a-440d-aaaf-b16e8a80b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d6437e82-2b77-4aa7-abd9-f50f0d99d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b381c331-a2f5-43ff-9731-7410ba8ac2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967299493-172.17.0.21-1599360321503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-b589aeea-1dff-4328-b9fc-3697edd654ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-b221fdbf-c4c2-4b01-a658-25b1a9ca3c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-9e00fec7-1102-424f-aef1-7a66981a5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-cf9353cd-b755-43ca-83fd-1122760c4390,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-e5094557-b1bd-45bf-8664-281bb5219192,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-1c593007-941a-440d-aaaf-b16e8a80b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d6437e82-2b77-4aa7-abd9-f50f0d99d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b381c331-a2f5-43ff-9731-7410ba8ac2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546674526-172.17.0.21-1599360366336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-23a84e44-8aca-4cb5-bec4-784ade618a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-96550fb4-5c4f-4704-84e4-dccde6b6c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-f85cade0-41b1-40d4-8a93-4f7cf1c108f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-6fcb65ab-8ba1-413a-87dd-2817477f4941,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-92ee1f4c-bd16-4810-9959-2c39667a3d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1a9d000e-b505-4808-9e91-d6181a273f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-1de13a7b-69cd-49e5-811b-2fc9bea6f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-1b06c479-3c83-41a8-bd0e-276a6987e87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546674526-172.17.0.21-1599360366336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-23a84e44-8aca-4cb5-bec4-784ade618a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-96550fb4-5c4f-4704-84e4-dccde6b6c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-f85cade0-41b1-40d4-8a93-4f7cf1c108f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-6fcb65ab-8ba1-413a-87dd-2817477f4941,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-92ee1f4c-bd16-4810-9959-2c39667a3d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-1a9d000e-b505-4808-9e91-d6181a273f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-1de13a7b-69cd-49e5-811b-2fc9bea6f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-1b06c479-3c83-41a8-bd0e-276a6987e87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025409434-172.17.0.21-1599360523338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-4e12a132-6776-4583-8c54-b4c7ec07ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-897ea406-1a0c-4030-8cf2-5b41f3c1cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-83ef2edc-0274-4f18-a568-732aa5491a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-c1724e67-767f-491c-bec8-d6e4e4e5a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-0a0842a9-cfe2-458a-af2c-e204cee2df00,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-0b8dd5f3-0123-4442-976f-7a3c2b481215,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-38238a9b-7b3c-4063-a2f4-61119aab88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-b1c8b14f-dafa-44ca-a7a0-781db10186ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025409434-172.17.0.21-1599360523338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-4e12a132-6776-4583-8c54-b4c7ec07ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-897ea406-1a0c-4030-8cf2-5b41f3c1cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-83ef2edc-0274-4f18-a568-732aa5491a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-c1724e67-767f-491c-bec8-d6e4e4e5a5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-0a0842a9-cfe2-458a-af2c-e204cee2df00,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-0b8dd5f3-0123-4442-976f-7a3c2b481215,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-38238a9b-7b3c-4063-a2f4-61119aab88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-b1c8b14f-dafa-44ca-a7a0-781db10186ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032149456-172.17.0.21-1599360755099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-15f6cdfe-c04f-4e91-a6e1-719112767b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-57c4ea1b-2401-4c3e-be90-1ea8d923984a,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-05497e5e-6b8a-4ae5-9676-96de84fbf5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-ac243398-7c35-44c0-87b4-b63de60414fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-70bd0226-1582-4a3a-955c-fa93c75b0661,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7ee5ce96-b907-4ae1-9b21-43da03ebea46,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-2e6f811c-21f9-40eb-a1c5-142d39ae9bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-0a9447f5-e7d9-49b5-997b-69edfa14ed2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032149456-172.17.0.21-1599360755099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-15f6cdfe-c04f-4e91-a6e1-719112767b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-57c4ea1b-2401-4c3e-be90-1ea8d923984a,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-05497e5e-6b8a-4ae5-9676-96de84fbf5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-ac243398-7c35-44c0-87b4-b63de60414fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-70bd0226-1582-4a3a-955c-fa93c75b0661,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7ee5ce96-b907-4ae1-9b21-43da03ebea46,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-2e6f811c-21f9-40eb-a1c5-142d39ae9bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-0a9447f5-e7d9-49b5-997b-69edfa14ed2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720620331-172.17.0.21-1599361011396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-da4f9c16-2f2c-485c-8e4a-9e348e70d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-98be70af-90a4-4694-aee3-09d3d77593b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-1e79b565-768c-4b3a-ad2f-3e63990b0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-b670de3a-a8d8-477c-8533-3ff793c46056,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-150107c9-b3ff-4dda-bea9-a7ef41164226,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d5a30a8a-5d93-4e89-93ae-59f2513747e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5661827f-30ac-43b1-aaa3-88c2545ccd21,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-2bf9e6ae-3f71-4229-a2bc-c74bc487c039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720620331-172.17.0.21-1599361011396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-da4f9c16-2f2c-485c-8e4a-9e348e70d10c,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-98be70af-90a4-4694-aee3-09d3d77593b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-1e79b565-768c-4b3a-ad2f-3e63990b0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-b670de3a-a8d8-477c-8533-3ff793c46056,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-150107c9-b3ff-4dda-bea9-a7ef41164226,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d5a30a8a-5d93-4e89-93ae-59f2513747e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5661827f-30ac-43b1-aaa3-88c2545ccd21,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-2bf9e6ae-3f71-4229-a2bc-c74bc487c039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866616623-172.17.0.21-1599361044484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-ee14c1fc-a43e-4f45-8f51-ca973282eac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-e1e9dfac-1a19-4d5d-846f-9c57c0cf7864,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-7d87f391-c2a5-4eec-97f9-b6bd397650f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-0b4847e5-2457-4c68-915a-7bcf5109f670,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-bee1fb0c-3045-49bd-8bbf-98ede1ba8680,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-8fcaf7a6-7d86-4e1d-99d8-9cddb45c5769,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-6c4598db-11bd-45e7-b50e-236a6fb495f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-0ddde9da-ef8b-4e50-874d-3a051905bcd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866616623-172.17.0.21-1599361044484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-ee14c1fc-a43e-4f45-8f51-ca973282eac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-e1e9dfac-1a19-4d5d-846f-9c57c0cf7864,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-7d87f391-c2a5-4eec-97f9-b6bd397650f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-0b4847e5-2457-4c68-915a-7bcf5109f670,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-bee1fb0c-3045-49bd-8bbf-98ede1ba8680,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-8fcaf7a6-7d86-4e1d-99d8-9cddb45c5769,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-6c4598db-11bd-45e7-b50e-236a6fb495f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-0ddde9da-ef8b-4e50-874d-3a051905bcd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885600898-172.17.0.21-1599361134474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-96268fb5-6fbe-4cb4-a4cd-244a5f5f0fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e57629f1-326b-40a0-beb2-fef07393025d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-03d659cd-9896-4b29-9280-29ca047ac88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-a005972f-3a24-42ad-945d-ab66772ddb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-6c47858c-993d-4155-b9be-5cf6f88ebb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-89b0e45b-8239-4aac-a5f4-f1ed8b60067f,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-31a9ebd4-2180-456e-a711-041fdd50c730,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-04f09ed8-f8aa-4a80-b8d6-5389db901740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885600898-172.17.0.21-1599361134474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-96268fb5-6fbe-4cb4-a4cd-244a5f5f0fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e57629f1-326b-40a0-beb2-fef07393025d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-03d659cd-9896-4b29-9280-29ca047ac88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-a005972f-3a24-42ad-945d-ab66772ddb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-6c47858c-993d-4155-b9be-5cf6f88ebb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-89b0e45b-8239-4aac-a5f4-f1ed8b60067f,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-31a9ebd4-2180-456e-a711-041fdd50c730,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-04f09ed8-f8aa-4a80-b8d6-5389db901740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633983487-172.17.0.21-1599361622125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-62a04260-a896-4bea-9859-87673efe04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-4705e12e-4f9a-4689-9067-d2cafd032603,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-47de431d-6916-405a-af43-5a159ca3b19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-8dea4d64-950d-4f10-8867-56fe8b4603b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-7c0a16e2-a728-48e0-be7f-2ebbfa83e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-beccea48-a6ea-47d1-a5c4-cc075cb9ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-376aab47-7eb5-41e4-8aca-297415e7d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-4903643f-ecd4-4e65-baf3-e715cf359962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633983487-172.17.0.21-1599361622125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-62a04260-a896-4bea-9859-87673efe04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-4705e12e-4f9a-4689-9067-d2cafd032603,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-47de431d-6916-405a-af43-5a159ca3b19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-8dea4d64-950d-4f10-8867-56fe8b4603b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-7c0a16e2-a728-48e0-be7f-2ebbfa83e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-beccea48-a6ea-47d1-a5c4-cc075cb9ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-376aab47-7eb5-41e4-8aca-297415e7d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-4903643f-ecd4-4e65-baf3-e715cf359962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608195670-172.17.0.21-1599361651426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-2cfcc897-7da8-411e-aeef-b368b056aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-0754f6d9-88e5-4c65-b606-3ed790bc4e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7dc25ab4-e4ca-43fd-b200-52afc7f1ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-8f667c18-0602-4668-974d-0085dfb727c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-d0c85f68-f4aa-46d0-8ccc-3ae1d5d7bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-ef303f7c-f7f0-4bc3-9dfd-0fc11b824feb,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0b6d252a-0571-4489-a0f2-b66bc4d688c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-19c4b82e-e2f9-407d-b32c-15edc0e77428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608195670-172.17.0.21-1599361651426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36213,DS-2cfcc897-7da8-411e-aeef-b368b056aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-0754f6d9-88e5-4c65-b606-3ed790bc4e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7dc25ab4-e4ca-43fd-b200-52afc7f1ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-8f667c18-0602-4668-974d-0085dfb727c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-d0c85f68-f4aa-46d0-8ccc-3ae1d5d7bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-ef303f7c-f7f0-4bc3-9dfd-0fc11b824feb,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0b6d252a-0571-4489-a0f2-b66bc4d688c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-19c4b82e-e2f9-407d-b32c-15edc0e77428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659161438-172.17.0.21-1599361806212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-89fb23d4-0045-426a-8873-8ea93f65b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-efcaaa5f-171a-411f-a7a1-0f8ea4fdbe13,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-bfcc1cef-dfa9-4662-8348-cd14d661784d,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-c018f977-9b3b-400b-8693-5e032443469c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-952fe1e9-2735-400f-9254-b00d2c1e185b,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-0713cb21-0876-4f38-921e-99f5e2233bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-13e736ec-17fd-463f-b246-9dfd7ed29240,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-fb698b36-a178-45c7-85a3-ebbf56cd8038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659161438-172.17.0.21-1599361806212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-89fb23d4-0045-426a-8873-8ea93f65b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-efcaaa5f-171a-411f-a7a1-0f8ea4fdbe13,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-bfcc1cef-dfa9-4662-8348-cd14d661784d,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-c018f977-9b3b-400b-8693-5e032443469c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-952fe1e9-2735-400f-9254-b00d2c1e185b,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-0713cb21-0876-4f38-921e-99f5e2233bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-13e736ec-17fd-463f-b246-9dfd7ed29240,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-fb698b36-a178-45c7-85a3-ebbf56cd8038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897623368-172.17.0.21-1599362625660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-521cfec7-4a25-45db-9422-87cb56d1431e,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f321c664-0c7f-4bd0-8cd7-6485a1674bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-f4edd268-f3fe-478b-815c-f9e7219fcdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-2ecfc8e8-6d2a-4fb9-8a14-b66b5a1ea9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-cabeec6c-9dde-49f1-b1c1-9904eb8940a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-85f0addf-c6fd-4edb-960e-dec77231fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-c23badfa-3aa2-4494-8241-799c4921384f,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-a5ffc9af-f03a-4602-b13a-a6215e2b75c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897623368-172.17.0.21-1599362625660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-521cfec7-4a25-45db-9422-87cb56d1431e,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f321c664-0c7f-4bd0-8cd7-6485a1674bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-f4edd268-f3fe-478b-815c-f9e7219fcdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-2ecfc8e8-6d2a-4fb9-8a14-b66b5a1ea9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-cabeec6c-9dde-49f1-b1c1-9904eb8940a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-85f0addf-c6fd-4edb-960e-dec77231fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-c23badfa-3aa2-4494-8241-799c4921384f,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-a5ffc9af-f03a-4602-b13a-a6215e2b75c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574853889-172.17.0.21-1599362731377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35940,DS-53bf3692-4806-4c97-b7f2-42378a97f19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-3707d585-eb5c-4ada-bdcd-5532e1ead89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-db0e6f19-793e-4ca3-a154-9366c709b229,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-145f08b8-4c54-4ee6-9ad5-cc01c070e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-ceae0295-2f0f-44a3-bad6-1c8e7bd13a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-49661f0c-80bd-46b1-926a-542d02b00104,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-f02b2440-0e3d-47b1-ad20-1ea4acb7b210,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-80b3de4d-4c1d-4b49-8099-d99bde9df46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574853889-172.17.0.21-1599362731377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35940,DS-53bf3692-4806-4c97-b7f2-42378a97f19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-3707d585-eb5c-4ada-bdcd-5532e1ead89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-db0e6f19-793e-4ca3-a154-9366c709b229,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-145f08b8-4c54-4ee6-9ad5-cc01c070e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-ceae0295-2f0f-44a3-bad6-1c8e7bd13a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-49661f0c-80bd-46b1-926a-542d02b00104,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-f02b2440-0e3d-47b1-ad20-1ea4acb7b210,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-80b3de4d-4c1d-4b49-8099-d99bde9df46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747437028-172.17.0.21-1599362930764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-2b8c9740-f257-4b75-a306-544c46df703d,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-fa4778fd-2db4-4484-bb6a-c6629d622c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-7f76d752-3412-4069-bd7a-fec934916e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-1d73edae-f58e-4556-9117-9f7f9ffd36ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-0d9de867-c803-4dbc-a6f0-acfea4287c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d9f4010e-00c6-4443-8ab1-0338659cb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-71b57d46-7d87-4891-9362-eaa42dd0046a,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-89a9babd-b4fe-42b2-b723-d791cca600e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747437028-172.17.0.21-1599362930764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-2b8c9740-f257-4b75-a306-544c46df703d,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-fa4778fd-2db4-4484-bb6a-c6629d622c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-7f76d752-3412-4069-bd7a-fec934916e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-1d73edae-f58e-4556-9117-9f7f9ffd36ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-0d9de867-c803-4dbc-a6f0-acfea4287c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-d9f4010e-00c6-4443-8ab1-0338659cb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-71b57d46-7d87-4891-9362-eaa42dd0046a,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-89a9babd-b4fe-42b2-b723-d791cca600e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626498842-172.17.0.21-1599363096091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-c33b69a7-50c8-4769-a923-80da7af5f0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-fa80487b-05de-4577-a79b-6d0fb9f79208,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-0fea3c6b-0f30-4337-8be9-f9422f12af11,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-9d320f48-05bb-4eb8-a4b5-3deecacf56a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-7d30f57f-47d6-4535-a23b-85db656f6068,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-44ee15cf-61ab-472d-a799-b06767f1ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-501a81ad-06be-4648-90f2-5b7d610588df,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-3fe822bc-013a-45cb-af0b-5c22eb4811e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626498842-172.17.0.21-1599363096091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-c33b69a7-50c8-4769-a923-80da7af5f0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-fa80487b-05de-4577-a79b-6d0fb9f79208,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-0fea3c6b-0f30-4337-8be9-f9422f12af11,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-9d320f48-05bb-4eb8-a4b5-3deecacf56a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-7d30f57f-47d6-4535-a23b-85db656f6068,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-44ee15cf-61ab-472d-a799-b06767f1ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-501a81ad-06be-4648-90f2-5b7d610588df,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-3fe822bc-013a-45cb-af0b-5c22eb4811e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300216677-172.17.0.21-1599363481853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-75a693c9-48f2-4839-bcc8-d074c43059b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-fe27a991-7580-410d-8ff5-915f0ff360e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-7989f85a-34c5-481c-855d-c3b9b0f92cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-c8d46acb-3d26-447a-b509-f9718465f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-d6cc5cbe-b576-4190-bab1-7688c63d3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7af08e45-9f24-4dd3-876f-18e92d8e3baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-84fec8ae-4b5e-4486-84fb-24ae97a6569d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-eb799ed4-0bb8-4f89-95e3-5cacc30ec9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300216677-172.17.0.21-1599363481853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-75a693c9-48f2-4839-bcc8-d074c43059b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-fe27a991-7580-410d-8ff5-915f0ff360e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-7989f85a-34c5-481c-855d-c3b9b0f92cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-c8d46acb-3d26-447a-b509-f9718465f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-d6cc5cbe-b576-4190-bab1-7688c63d3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7af08e45-9f24-4dd3-876f-18e92d8e3baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-84fec8ae-4b5e-4486-84fb-24ae97a6569d,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-eb799ed4-0bb8-4f89-95e3-5cacc30ec9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929905102-172.17.0.21-1599363625004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-579efd1d-685f-492b-acf8-e422b6ee492f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a390374f-6e77-4b86-9d59-2ef323fffe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-297bad00-656a-4bd3-8182-d75f13b0988f,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-151ac9bb-795a-427f-a879-6071fd73f418,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-f3ff77bb-d201-48ef-8d52-26d9db55d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-37860620-7b54-4736-aabf-8703761c160c,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-e337036d-3aca-48ef-88b7-add0721ec166,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-5d334608-5ed2-4fad-bcab-e94541d9376e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929905102-172.17.0.21-1599363625004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-579efd1d-685f-492b-acf8-e422b6ee492f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a390374f-6e77-4b86-9d59-2ef323fffe2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-297bad00-656a-4bd3-8182-d75f13b0988f,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-151ac9bb-795a-427f-a879-6071fd73f418,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-f3ff77bb-d201-48ef-8d52-26d9db55d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-37860620-7b54-4736-aabf-8703761c160c,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-e337036d-3aca-48ef-88b7-add0721ec166,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-5d334608-5ed2-4fad-bcab-e94541d9376e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884486530-172.17.0.21-1599363787058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-13bbf381-0fca-4175-b7a1-2546c06aa35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-7b2fa5a7-41bd-4d45-8ca7-c77b0ddd5050,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-53876734-db00-49d8-bc78-63f246519f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-5c401ad4-1882-48c9-a3e6-dd22f6096313,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-f67f37f0-c307-4976-8bb7-5959dab4ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-c2d447f6-e0c6-4505-9b2b-369587a6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-614f952f-37c1-46ff-8f76-94771bb5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-045ca42d-5350-4b62-9ca8-b0c971f86caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884486530-172.17.0.21-1599363787058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-13bbf381-0fca-4175-b7a1-2546c06aa35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-7b2fa5a7-41bd-4d45-8ca7-c77b0ddd5050,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-53876734-db00-49d8-bc78-63f246519f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-5c401ad4-1882-48c9-a3e6-dd22f6096313,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-f67f37f0-c307-4976-8bb7-5959dab4ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-c2d447f6-e0c6-4505-9b2b-369587a6ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-614f952f-37c1-46ff-8f76-94771bb5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-045ca42d-5350-4b62-9ca8-b0c971f86caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974051490-172.17.0.21-1599363818200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-76dd5968-3a9d-4748-a166-ea639725aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b8956da3-44a4-4788-8d4b-f791fb5556a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-c80711ea-b84b-4974-b513-d58b860c111d,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-a95dc9ac-cdbb-4228-bd7e-728ce9c142d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-f9777daa-cac1-47eb-82c3-d0b87c5072f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-9487b91e-2ce0-425c-a32a-265781ea6bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-2962b9c0-04fb-4331-91cc-2e71ee7a15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-0906c5b7-97ab-493c-9ca8-8c16ee5bac9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974051490-172.17.0.21-1599363818200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-76dd5968-3a9d-4748-a166-ea639725aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b8956da3-44a4-4788-8d4b-f791fb5556a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-c80711ea-b84b-4974-b513-d58b860c111d,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-a95dc9ac-cdbb-4228-bd7e-728ce9c142d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-f9777daa-cac1-47eb-82c3-d0b87c5072f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-9487b91e-2ce0-425c-a32a-265781ea6bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-2962b9c0-04fb-4331-91cc-2e71ee7a15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-0906c5b7-97ab-493c-9ca8-8c16ee5bac9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473276771-172.17.0.21-1599364566454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-7e24ab59-6657-4c55-b517-cc8ee0e0a072,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bdba6c2f-a96f-42c0-9a80-967008e185a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-3e9e9e8c-eb38-4787-bfdb-52a4299e5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-c9573bb9-9a52-4bae-9595-366bf621c141,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-a7095ab4-a108-4866-86d9-35f23f2ee5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9812064-a283-41e5-8726-d1331737ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-3fa24bf4-63fd-4fae-92c4-5095d96156b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-cfd1c8c7-04c1-49a8-b07a-a3152cfd2bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473276771-172.17.0.21-1599364566454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-7e24ab59-6657-4c55-b517-cc8ee0e0a072,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bdba6c2f-a96f-42c0-9a80-967008e185a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-3e9e9e8c-eb38-4787-bfdb-52a4299e5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-c9573bb9-9a52-4bae-9595-366bf621c141,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-a7095ab4-a108-4866-86d9-35f23f2ee5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9812064-a283-41e5-8726-d1331737ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-3fa24bf4-63fd-4fae-92c4-5095d96156b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-cfd1c8c7-04c1-49a8-b07a-a3152cfd2bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306075977-172.17.0.21-1599364639105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-c333eaf9-9269-4cf0-9f6b-bde2c19b9a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-407ef5ca-add7-43ee-bc17-6c2f0f00e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-9553b2e4-cf04-4252-ba38-5cd226c98d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-90d097d6-7f5c-4fb0-be03-ead22a0d0801,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-2220da16-bbce-46eb-a16f-f18d36ac4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-cee3ccaa-e00e-4a37-97e4-71631fa572aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-9d605b94-1e0f-4956-805a-3a9369780e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-53dc4e33-b19b-4070-8f24-9d95066ad01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306075977-172.17.0.21-1599364639105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-c333eaf9-9269-4cf0-9f6b-bde2c19b9a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-407ef5ca-add7-43ee-bc17-6c2f0f00e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-9553b2e4-cf04-4252-ba38-5cd226c98d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-90d097d6-7f5c-4fb0-be03-ead22a0d0801,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-2220da16-bbce-46eb-a16f-f18d36ac4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-cee3ccaa-e00e-4a37-97e4-71631fa572aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-9d605b94-1e0f-4956-805a-3a9369780e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-53dc4e33-b19b-4070-8f24-9d95066ad01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201214661-172.17.0.21-1599364843132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-23628be7-c575-486d-a3c6-519110f6d44a,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-71f24c13-d961-41f1-848a-e13df02bd831,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-2c39acc7-be1f-445f-a142-e9f7c488539d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-cb8f6896-eb1e-4838-b9b9-e6ab2fd104a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-0ee4d59f-168e-42ff-b3c8-52d1945a6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-4fb0ce68-d982-47ea-a12f-e79062eadd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-7f9a7066-98a2-4fc5-b28a-a19ffa00d61f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-5774e88d-b112-49fe-be7f-9d5b6a707866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201214661-172.17.0.21-1599364843132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-23628be7-c575-486d-a3c6-519110f6d44a,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-71f24c13-d961-41f1-848a-e13df02bd831,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-2c39acc7-be1f-445f-a142-e9f7c488539d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-cb8f6896-eb1e-4838-b9b9-e6ab2fd104a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-0ee4d59f-168e-42ff-b3c8-52d1945a6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-4fb0ce68-d982-47ea-a12f-e79062eadd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-7f9a7066-98a2-4fc5-b28a-a19ffa00d61f,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-5774e88d-b112-49fe-be7f-9d5b6a707866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4938
