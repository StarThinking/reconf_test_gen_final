reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683955995-172.17.0.16-1599339782453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-447fac17-833b-4dba-9497-b1fcb5edfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-fe395e60-5dbd-4be5-9062-bfed0bdb5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-a34ff543-aa42-4f27-9b9c-6c16768de7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-66217b18-9ad9-45d3-a4b5-64a5a0fc426a,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-459af10d-7a0c-4638-abc6-01ff317804b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-f9828027-3a59-4f93-9958-e077ba5654b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-c4063fe1-d672-42b6-b0d1-ecdd2c45aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-1a30e335-45dc-46ef-886b-075ff7b28a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683955995-172.17.0.16-1599339782453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-447fac17-833b-4dba-9497-b1fcb5edfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-fe395e60-5dbd-4be5-9062-bfed0bdb5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-a34ff543-aa42-4f27-9b9c-6c16768de7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-66217b18-9ad9-45d3-a4b5-64a5a0fc426a,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-459af10d-7a0c-4638-abc6-01ff317804b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-f9828027-3a59-4f93-9958-e077ba5654b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-c4063fe1-d672-42b6-b0d1-ecdd2c45aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-1a30e335-45dc-46ef-886b-075ff7b28a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490072812-172.17.0.16-1599340519089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-e7cff6c9-f4c1-41f1-9b21-56d6c6aeea74,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-8ee5898a-5944-4173-a943-c8a4579f4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-408ddbdf-faeb-459b-baf6-1fcd18eba600,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-11db408a-d57d-434e-a6ba-9da215cb2958,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-86ff4649-db63-4a4f-9bf3-5b49a11523f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-015c4734-85bc-4479-8e93-5df17a167737,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-3b5d2069-70d1-4ccf-9e8b-f1bfc6e9aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-a3ec1212-d673-48c5-9326-f4a33e107730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490072812-172.17.0.16-1599340519089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-e7cff6c9-f4c1-41f1-9b21-56d6c6aeea74,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-8ee5898a-5944-4173-a943-c8a4579f4f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-408ddbdf-faeb-459b-baf6-1fcd18eba600,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-11db408a-d57d-434e-a6ba-9da215cb2958,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-86ff4649-db63-4a4f-9bf3-5b49a11523f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-015c4734-85bc-4479-8e93-5df17a167737,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-3b5d2069-70d1-4ccf-9e8b-f1bfc6e9aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-a3ec1212-d673-48c5-9326-f4a33e107730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13149910-172.17.0.16-1599341028990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-8dcc5672-476b-4d4d-91b4-76e50e85c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-b0768f39-00cb-421c-9fb6-934e1884be86,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-12a0b58c-22f6-4fb4-9d10-457a8706c966,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-67c6f1c4-cc1b-4e17-a7a4-453d3ea2eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-db8d6dde-2df0-4e01-9b0b-4a4fd94fd115,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-9cb45b55-3d9c-47d5-8b02-ebebbfa0d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-6663789b-5a2f-4324-a8c9-e2dc055fcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-ee06845b-8fe2-4f66-963a-5448b3c1f9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13149910-172.17.0.16-1599341028990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-8dcc5672-476b-4d4d-91b4-76e50e85c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-b0768f39-00cb-421c-9fb6-934e1884be86,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-12a0b58c-22f6-4fb4-9d10-457a8706c966,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-67c6f1c4-cc1b-4e17-a7a4-453d3ea2eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-db8d6dde-2df0-4e01-9b0b-4a4fd94fd115,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-9cb45b55-3d9c-47d5-8b02-ebebbfa0d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-6663789b-5a2f-4324-a8c9-e2dc055fcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-ee06845b-8fe2-4f66-963a-5448b3c1f9ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83904839-172.17.0.16-1599341065485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-213d4e63-0f3a-4cf9-8a43-82d3a6bff628,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-4807bda2-b15f-4cb6-b894-037283a259a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-daf54fd8-ef64-4a1d-81e4-e7c6eb4b4162,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-bb67edbd-7271-4114-9e60-749ba5493a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-76eae535-d577-480c-8e62-6115ba2dcb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-628092d6-7c8e-4216-80be-f5e18f76c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-50d541a0-5910-459b-8b2a-e89190d6c135,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-a07ca291-4dc1-4cbb-8e64-9e6a04ebf023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83904839-172.17.0.16-1599341065485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-213d4e63-0f3a-4cf9-8a43-82d3a6bff628,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-4807bda2-b15f-4cb6-b894-037283a259a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-daf54fd8-ef64-4a1d-81e4-e7c6eb4b4162,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-bb67edbd-7271-4114-9e60-749ba5493a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-76eae535-d577-480c-8e62-6115ba2dcb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-628092d6-7c8e-4216-80be-f5e18f76c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-50d541a0-5910-459b-8b2a-e89190d6c135,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-a07ca291-4dc1-4cbb-8e64-9e6a04ebf023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353627182-172.17.0.16-1599342692813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-d7b54e23-7e66-4a5f-8cfc-9fc59aa410cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-d7741515-7de2-41e5-aef0-7309deb1bf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-cd53d96d-b9c0-4f44-a733-757e9c95a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-8cef2964-4a61-43fb-9485-e9c889d9cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-2b7bc27c-a3c7-4326-ad34-d03e6c270cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-bc20fdc2-cfca-422d-a6fd-dc424bc71855,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-28299e35-430f-469c-9997-2d971ab5de32,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-637e1ae9-440c-465a-9db1-1eeef698cb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353627182-172.17.0.16-1599342692813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-d7b54e23-7e66-4a5f-8cfc-9fc59aa410cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-d7741515-7de2-41e5-aef0-7309deb1bf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-cd53d96d-b9c0-4f44-a733-757e9c95a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-8cef2964-4a61-43fb-9485-e9c889d9cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-2b7bc27c-a3c7-4326-ad34-d03e6c270cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-bc20fdc2-cfca-422d-a6fd-dc424bc71855,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-28299e35-430f-469c-9997-2d971ab5de32,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-637e1ae9-440c-465a-9db1-1eeef698cb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118653914-172.17.0.16-1599342733979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-888759aa-d767-466b-bfb7-a2a452f8b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-c938897f-18c6-4e4a-b4d3-e347b7fbb728,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-fe89ca22-9cdc-4f4a-85b2-43eb0904b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-a5711e33-5f0b-4885-8ee9-064a8988a423,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-342b4e54-5289-4fa1-96dd-c18993fcdda9,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-b3ea71f6-1803-44d8-af5c-cb83b8c28363,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-0d70f8ec-6202-46ed-b56d-01a93d0982e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-c11fe96f-f38e-40a2-aa8d-d7ac718b7db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118653914-172.17.0.16-1599342733979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-888759aa-d767-466b-bfb7-a2a452f8b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-c938897f-18c6-4e4a-b4d3-e347b7fbb728,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-fe89ca22-9cdc-4f4a-85b2-43eb0904b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-a5711e33-5f0b-4885-8ee9-064a8988a423,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-342b4e54-5289-4fa1-96dd-c18993fcdda9,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-b3ea71f6-1803-44d8-af5c-cb83b8c28363,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-0d70f8ec-6202-46ed-b56d-01a93d0982e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-c11fe96f-f38e-40a2-aa8d-d7ac718b7db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495590999-172.17.0.16-1599343610243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-8f56a7d9-82fc-4b96-9903-689ae86fc604,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-39148f9f-491e-44f4-bd93-dfd676cbed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-294f4144-1ad1-45c4-ad8b-1528662d5307,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-f17fd9f4-7a89-4eee-9726-5511441cdfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5c046257-2b36-43f4-921f-1297c01c2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c4872e26-d734-4864-912a-f4be0be82058,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-e745b226-90ed-402b-9400-9364a4cd18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-4c092b6c-17bb-41c4-9bf0-6dbc369c0b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495590999-172.17.0.16-1599343610243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-8f56a7d9-82fc-4b96-9903-689ae86fc604,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-39148f9f-491e-44f4-bd93-dfd676cbed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-294f4144-1ad1-45c4-ad8b-1528662d5307,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-f17fd9f4-7a89-4eee-9726-5511441cdfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5c046257-2b36-43f4-921f-1297c01c2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c4872e26-d734-4864-912a-f4be0be82058,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-e745b226-90ed-402b-9400-9364a4cd18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-4c092b6c-17bb-41c4-9bf0-6dbc369c0b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163256117-172.17.0.16-1599343786186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-cbcd25ac-83d0-48c8-b467-4265b98f7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-767bae38-cb58-4076-8eac-1c8028a56bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1918c395-a501-4c42-abe3-1623377b69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-50cb3637-3bf9-4e8e-b6e1-e7c41a1c48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4ce4cfc9-a0dc-4e64-9a9f-0b6757305ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-8a6f5d0c-089d-4b6f-8b07-8f8f833e9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-7f3da25d-d75e-4062-a4eb-23bcec0cc028,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-64836e71-ae59-4408-a6fc-871779c732de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163256117-172.17.0.16-1599343786186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-cbcd25ac-83d0-48c8-b467-4265b98f7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-767bae38-cb58-4076-8eac-1c8028a56bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1918c395-a501-4c42-abe3-1623377b69b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-50cb3637-3bf9-4e8e-b6e1-e7c41a1c48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4ce4cfc9-a0dc-4e64-9a9f-0b6757305ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-8a6f5d0c-089d-4b6f-8b07-8f8f833e9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-7f3da25d-d75e-4062-a4eb-23bcec0cc028,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-64836e71-ae59-4408-a6fc-871779c732de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529453431-172.17.0.16-1599343857807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-b94a9f9e-fdf8-4b93-b70b-d408c9137198,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-0808890f-4227-41dd-b1b4-6292f108ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-719dd396-e548-4a29-bfe7-d97bcdd5b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-8c59939f-4650-47fb-baf6-464874ae3177,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2c92fd43-9df5-4a72-b398-9c95ec379c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-f8a3a9b3-1741-40bd-8b32-fff5062e5845,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-97732d7f-ed7a-4ca9-89b1-f37fd13af580,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-3d63ce50-78ea-42fb-b801-dee3576f18ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529453431-172.17.0.16-1599343857807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-b94a9f9e-fdf8-4b93-b70b-d408c9137198,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-0808890f-4227-41dd-b1b4-6292f108ecbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-719dd396-e548-4a29-bfe7-d97bcdd5b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-8c59939f-4650-47fb-baf6-464874ae3177,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-2c92fd43-9df5-4a72-b398-9c95ec379c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-f8a3a9b3-1741-40bd-8b32-fff5062e5845,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-97732d7f-ed7a-4ca9-89b1-f37fd13af580,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-3d63ce50-78ea-42fb-b801-dee3576f18ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138531323-172.17.0.16-1599343888292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-02ac3444-3e23-4db0-83d8-d07dd705c5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-39b302e3-7d99-4fc2-a3dc-27f927a9d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-52c5d004-d418-4b85-952c-f49d91b962b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-a0155684-b7fe-4d5b-9aed-0210c293ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-04dbda64-43ce-41ed-b05e-c14fad5589dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-532b1bcb-be5e-4621-9be0-644c4a1370ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-18f1ace8-60af-4b30-8b46-7c85abe14f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-d732e50d-1656-47d4-8c8f-eed6181f6963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138531323-172.17.0.16-1599343888292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-02ac3444-3e23-4db0-83d8-d07dd705c5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-39b302e3-7d99-4fc2-a3dc-27f927a9d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-52c5d004-d418-4b85-952c-f49d91b962b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-a0155684-b7fe-4d5b-9aed-0210c293ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-04dbda64-43ce-41ed-b05e-c14fad5589dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-532b1bcb-be5e-4621-9be0-644c4a1370ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-18f1ace8-60af-4b30-8b46-7c85abe14f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-d732e50d-1656-47d4-8c8f-eed6181f6963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72767178-172.17.0.16-1599344133319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-8c10f604-7084-45ba-a9cd-c128b3c05d99,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-ef384af6-3e0e-400f-bcfc-2cfb2f67e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-d23d2c89-baf6-4271-ad87-5ce39dd0be95,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-f028263e-6a70-482f-86b9-a88e7bcc2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-f9257a7f-85b9-4776-a163-861483262430,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-baed2c2d-40ea-4b23-99ef-405ec0c2c669,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c4dd20e5-4f35-4639-b66f-50cfa69bfa84,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d9e46b85-496a-4804-accd-936cc68fe384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72767178-172.17.0.16-1599344133319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-8c10f604-7084-45ba-a9cd-c128b3c05d99,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-ef384af6-3e0e-400f-bcfc-2cfb2f67e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-d23d2c89-baf6-4271-ad87-5ce39dd0be95,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-f028263e-6a70-482f-86b9-a88e7bcc2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-f9257a7f-85b9-4776-a163-861483262430,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-baed2c2d-40ea-4b23-99ef-405ec0c2c669,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c4dd20e5-4f35-4639-b66f-50cfa69bfa84,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-d9e46b85-496a-4804-accd-936cc68fe384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4906
