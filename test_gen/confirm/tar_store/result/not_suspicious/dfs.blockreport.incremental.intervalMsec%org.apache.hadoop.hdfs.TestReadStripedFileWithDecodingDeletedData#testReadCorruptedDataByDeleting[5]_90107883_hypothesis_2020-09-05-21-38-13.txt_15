reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1820453935-172.17.0.18-1599343181794:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-32b86a81-1f04-4f63-aace-29f47a7b6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-727174d5-3068-4cba-b562-817b16e2175e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-70384375-91b9-4b9b-ac37-f35baa6fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-01109c03-b8a9-4aca-a21d-65bca606042d,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d03597a4-334c-482a-993d-b139443d3d08,DISK]]; indices=[1, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1820453935-172.17.0.18-1599343181794:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-3d57f8f8-c7d7-422f-9727-246156b9f584,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-32b86a81-1f04-4f63-aace-29f47a7b6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-727174d5-3068-4cba-b562-817b16e2175e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-70384375-91b9-4b9b-ac37-f35baa6fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-01109c03-b8a9-4aca-a21d-65bca606042d,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d03597a4-334c-482a-993d-b139443d3d08,DISK]]; indices=[0, 1, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1820453935-172.17.0.18-1599343181794:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-32b86a81-1f04-4f63-aace-29f47a7b6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-727174d5-3068-4cba-b562-817b16e2175e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-70384375-91b9-4b9b-ac37-f35baa6fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-01109c03-b8a9-4aca-a21d-65bca606042d,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d03597a4-334c-482a-993d-b139443d3d08,DISK]]; indices=[1, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1820453935-172.17.0.18-1599343181794:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-3d57f8f8-c7d7-422f-9727-246156b9f584,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-32b86a81-1f04-4f63-aace-29f47a7b6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-727174d5-3068-4cba-b562-817b16e2175e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-70384375-91b9-4b9b-ac37-f35baa6fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-01109c03-b8a9-4aca-a21d-65bca606042d,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-d03597a4-334c-482a-993d-b139443d3d08,DISK]]; indices=[0, 1, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1141491804-172.17.0.18-1599343911654:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-0a9ebefc-a01f-4484-89fd-995dc00cea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6c1a6f87-0f14-4999-abcd-6d89dac67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-0f6d93b9-2893-492b-862c-3c08e94480d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-f4e8755a-ddba-4a9e-8d5e-a70b4787ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-24697e2f-cd17-41c0-bb0c-70853b2b2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ea7852d1-efc6-4a2c-a70f-29c0ae252f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bdb7e13e-cc7c-47f0-9c1b-cfcf2c7512ef,DISK]]; indices=[0, 1, 2, 3, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1141491804-172.17.0.18-1599343911654:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-0a9ebefc-a01f-4484-89fd-995dc00cea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6c1a6f87-0f14-4999-abcd-6d89dac67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-0f6d93b9-2893-492b-862c-3c08e94480d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-f4e8755a-ddba-4a9e-8d5e-a70b4787ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-24697e2f-cd17-41c0-bb0c-70853b2b2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ea7852d1-efc6-4a2c-a70f-29c0ae252f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bdb7e13e-cc7c-47f0-9c1b-cfcf2c7512ef,DISK]]; indices=[0, 1, 2, 3, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1141491804-172.17.0.18-1599343911654:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-0a9ebefc-a01f-4484-89fd-995dc00cea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6c1a6f87-0f14-4999-abcd-6d89dac67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-0f6d93b9-2893-492b-862c-3c08e94480d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-f4e8755a-ddba-4a9e-8d5e-a70b4787ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-24697e2f-cd17-41c0-bb0c-70853b2b2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ea7852d1-efc6-4a2c-a70f-29c0ae252f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bdb7e13e-cc7c-47f0-9c1b-cfcf2c7512ef,DISK]]; indices=[0, 1, 2, 3, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1141491804-172.17.0.18-1599343911654:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-0a9ebefc-a01f-4484-89fd-995dc00cea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-6c1a6f87-0f14-4999-abcd-6d89dac67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-0f6d93b9-2893-492b-862c-3c08e94480d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-f4e8755a-ddba-4a9e-8d5e-a70b4787ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-24697e2f-cd17-41c0-bb0c-70853b2b2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ea7852d1-efc6-4a2c-a70f-29c0ae252f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bdb7e13e-cc7c-47f0-9c1b-cfcf2c7512ef,DISK]]; indices=[0, 1, 2, 3, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1770035152-172.17.0.18-1599344301596:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-4dfc2151-79d2-43dd-8a38-00cdbeddda63,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3988b00c-1498-4a3b-ac6d-f9ee55b76944,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d42e8053-8ffd-4b57-9764-29f1a9b9a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1dbefed9-3b7b-4f6d-b4f9-14c76b5c788e,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b8b7719f-9b78-4141-bac7-6c116fbf1e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f675f343-5834-4d96-aa08-8bb481f9e86b,DISK]]; indices=[0, 1, 3, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1770035152-172.17.0.18-1599344301596:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-4dfc2151-79d2-43dd-8a38-00cdbeddda63,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3988b00c-1498-4a3b-ac6d-f9ee55b76944,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d42e8053-8ffd-4b57-9764-29f1a9b9a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1dbefed9-3b7b-4f6d-b4f9-14c76b5c788e,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b8b7719f-9b78-4141-bac7-6c116fbf1e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f675f343-5834-4d96-aa08-8bb481f9e86b,DISK]]; indices=[0, 1, 3, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1770035152-172.17.0.18-1599344301596:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-4dfc2151-79d2-43dd-8a38-00cdbeddda63,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3988b00c-1498-4a3b-ac6d-f9ee55b76944,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d42e8053-8ffd-4b57-9764-29f1a9b9a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1dbefed9-3b7b-4f6d-b4f9-14c76b5c788e,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b8b7719f-9b78-4141-bac7-6c116fbf1e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f675f343-5834-4d96-aa08-8bb481f9e86b,DISK]]; indices=[0, 1, 3, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1770035152-172.17.0.18-1599344301596:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-4dfc2151-79d2-43dd-8a38-00cdbeddda63,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3988b00c-1498-4a3b-ac6d-f9ee55b76944,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d42e8053-8ffd-4b57-9764-29f1a9b9a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-1dbefed9-3b7b-4f6d-b4f9-14c76b5c788e,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b8b7719f-9b78-4141-bac7-6c116fbf1e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f675f343-5834-4d96-aa08-8bb481f9e86b,DISK]]; indices=[0, 1, 3, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1623611557-172.17.0.18-1599344686067:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-087f7279-46e6-4025-b2c2-20ccef19d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-7a20e103-ff76-496d-b571-1d4fcaae0101,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ca3cf0a2-e91b-4047-93f4-935310482b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6cedfaf1-1e4f-4741-b9dc-05341e7418ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-e4cb7067-d27c-4de9-a607-f0832b08325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9d76d251-9646-4cad-8e71-43ce28aa8376,DISK]]; indices=[1, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1623611557-172.17.0.18-1599344686067:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-087f7279-46e6-4025-b2c2-20ccef19d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-7a20e103-ff76-496d-b571-1d4fcaae0101,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ca3cf0a2-e91b-4047-93f4-935310482b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6cedfaf1-1e4f-4741-b9dc-05341e7418ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-e4cb7067-d27c-4de9-a607-f0832b08325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9d76d251-9646-4cad-8e71-43ce28aa8376,DISK]]; indices=[1, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1623611557-172.17.0.18-1599344686067:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-087f7279-46e6-4025-b2c2-20ccef19d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-7a20e103-ff76-496d-b571-1d4fcaae0101,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ca3cf0a2-e91b-4047-93f4-935310482b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6cedfaf1-1e4f-4741-b9dc-05341e7418ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-e4cb7067-d27c-4de9-a607-f0832b08325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9d76d251-9646-4cad-8e71-43ce28aa8376,DISK]]; indices=[1, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1623611557-172.17.0.18-1599344686067:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-087f7279-46e6-4025-b2c2-20ccef19d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-7a20e103-ff76-496d-b571-1d4fcaae0101,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-ca3cf0a2-e91b-4047-93f4-935310482b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6cedfaf1-1e4f-4741-b9dc-05341e7418ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-e4cb7067-d27c-4de9-a607-f0832b08325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9d76d251-9646-4cad-8e71-43ce28aa8376,DISK]]; indices=[1, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1702408738-172.17.0.18-1599345238251:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-40b16dc3-a62a-4beb-ad9f-5c6c8f4b44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-979d1531-c616-4a6b-b496-1ab9e2eded4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-aff4be01-3364-4715-bc17-dd1e49d3bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-a54f7683-2a38-4ecb-9334-794d139433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-906f9012-279d-4a0d-a969-c2f47b66856e,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-eaada12c-aeca-4b44-94f8-72b55005f126,DISK]]; indices=[0, 1, 2, 3, 4, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1702408738-172.17.0.18-1599345238251:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-40b16dc3-a62a-4beb-ad9f-5c6c8f4b44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-979d1531-c616-4a6b-b496-1ab9e2eded4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-aff4be01-3364-4715-bc17-dd1e49d3bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-a54f7683-2a38-4ecb-9334-794d139433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-906f9012-279d-4a0d-a969-c2f47b66856e,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-eaada12c-aeca-4b44-94f8-72b55005f126,DISK]]; indices=[0, 1, 2, 3, 4, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1702408738-172.17.0.18-1599345238251:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-40b16dc3-a62a-4beb-ad9f-5c6c8f4b44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-979d1531-c616-4a6b-b496-1ab9e2eded4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-aff4be01-3364-4715-bc17-dd1e49d3bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-a54f7683-2a38-4ecb-9334-794d139433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-906f9012-279d-4a0d-a969-c2f47b66856e,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-eaada12c-aeca-4b44-94f8-72b55005f126,DISK]]; indices=[0, 1, 2, 3, 4, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1702408738-172.17.0.18-1599345238251:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-40b16dc3-a62a-4beb-ad9f-5c6c8f4b44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-979d1531-c616-4a6b-b496-1ab9e2eded4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-aff4be01-3364-4715-bc17-dd1e49d3bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-a54f7683-2a38-4ecb-9334-794d139433d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-906f9012-279d-4a0d-a969-c2f47b66856e,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-eaada12c-aeca-4b44-94f8-72b55005f126,DISK]]; indices=[0, 1, 2, 3, 4, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1889527408-172.17.0.18-1599345546127:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f93f322d-85f0-40b9-94b4-7ab8aafca82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-e82ce5e4-df19-40a5-898d-4cf56508d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-16ec5ea4-b359-4e62-9127-d0d9003cbd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbc8a8c2-b908-4c24-b085-3da9f5efc80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-75ebdb43-8f49-4087-ba59-64045dc3e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-d8c860f8-4fc9-4e39-9518-8368937b6057,DISK]]; indices=[1, 4, 5, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1889527408-172.17.0.18-1599345546127:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f93f322d-85f0-40b9-94b4-7ab8aafca82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-e82ce5e4-df19-40a5-898d-4cf56508d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-16ec5ea4-b359-4e62-9127-d0d9003cbd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbc8a8c2-b908-4c24-b085-3da9f5efc80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-75ebdb43-8f49-4087-ba59-64045dc3e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-d8c860f8-4fc9-4e39-9518-8368937b6057,DISK]]; indices=[1, 4, 5, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1889527408-172.17.0.18-1599345546127:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f93f322d-85f0-40b9-94b4-7ab8aafca82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-e82ce5e4-df19-40a5-898d-4cf56508d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-16ec5ea4-b359-4e62-9127-d0d9003cbd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbc8a8c2-b908-4c24-b085-3da9f5efc80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-75ebdb43-8f49-4087-ba59-64045dc3e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-d8c860f8-4fc9-4e39-9518-8368937b6057,DISK]]; indices=[1, 4, 5, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1889527408-172.17.0.18-1599345546127:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f93f322d-85f0-40b9-94b4-7ab8aafca82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-e82ce5e4-df19-40a5-898d-4cf56508d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-16ec5ea4-b359-4e62-9127-d0d9003cbd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-fbc8a8c2-b908-4c24-b085-3da9f5efc80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-75ebdb43-8f49-4087-ba59-64045dc3e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-d8c860f8-4fc9-4e39-9518-8368937b6057,DISK]]; indices=[1, 4, 5, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-361039849-172.17.0.18-1599346295974:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-5a023f9d-3094-45f9-b2f5-e2fb33a43a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1fe912f9-8e62-45f6-a428-c48fe611d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-15b2da36-e05a-42ac-89c2-b56c55f13f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-de1dc644-68a1-4600-ab20-dc6a7f7c0989,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-18f7acb4-2efc-4dbc-8881-e7c497838580,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-2fba3a3e-bde7-426a-a4b4-b9cb6f261bed,DISK]]; indices=[0, 1, 2, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-361039849-172.17.0.18-1599346295974:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-5a023f9d-3094-45f9-b2f5-e2fb33a43a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1fe912f9-8e62-45f6-a428-c48fe611d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-15b2da36-e05a-42ac-89c2-b56c55f13f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-de1dc644-68a1-4600-ab20-dc6a7f7c0989,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-18f7acb4-2efc-4dbc-8881-e7c497838580,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-2fba3a3e-bde7-426a-a4b4-b9cb6f261bed,DISK]]; indices=[0, 1, 2, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-361039849-172.17.0.18-1599346295974:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-5a023f9d-3094-45f9-b2f5-e2fb33a43a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1fe912f9-8e62-45f6-a428-c48fe611d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-15b2da36-e05a-42ac-89c2-b56c55f13f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-de1dc644-68a1-4600-ab20-dc6a7f7c0989,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-18f7acb4-2efc-4dbc-8881-e7c497838580,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-2fba3a3e-bde7-426a-a4b4-b9cb6f261bed,DISK]]; indices=[0, 1, 2, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-361039849-172.17.0.18-1599346295974:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37974,DS-5a023f9d-3094-45f9-b2f5-e2fb33a43a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1fe912f9-8e62-45f6-a428-c48fe611d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-15b2da36-e05a-42ac-89c2-b56c55f13f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-de1dc644-68a1-4600-ab20-dc6a7f7c0989,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-18f7acb4-2efc-4dbc-8881-e7c497838580,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-2fba3a3e-bde7-426a-a4b4-b9cb6f261bed,DISK]]; indices=[0, 1, 2, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-54075362-172.17.0.18-1599346915611:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-7995a837-b3a5-4e02-b00f-e035abe7385c,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-d9aa9a82-fbc4-450b-ba3e-13740d182d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-48d37525-c145-461b-96e0-39f0641e6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dc576ece-ca5b-454c-aecd-9fda18ca1dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b9ab5c63-4ad1-41a7-9c36-c4109f3c40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-14a26101-4490-414c-aa6d-7aaa4239f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a06a0808-71af-4640-b78e-7552b496c99c,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-54075362-172.17.0.18-1599346915611:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-7995a837-b3a5-4e02-b00f-e035abe7385c,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-d9aa9a82-fbc4-450b-ba3e-13740d182d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-48d37525-c145-461b-96e0-39f0641e6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dc576ece-ca5b-454c-aecd-9fda18ca1dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b9ab5c63-4ad1-41a7-9c36-c4109f3c40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-14a26101-4490-414c-aa6d-7aaa4239f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a06a0808-71af-4640-b78e-7552b496c99c,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-54075362-172.17.0.18-1599346915611:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-7995a837-b3a5-4e02-b00f-e035abe7385c,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-d9aa9a82-fbc4-450b-ba3e-13740d182d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-48d37525-c145-461b-96e0-39f0641e6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dc576ece-ca5b-454c-aecd-9fda18ca1dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b9ab5c63-4ad1-41a7-9c36-c4109f3c40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-14a26101-4490-414c-aa6d-7aaa4239f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a06a0808-71af-4640-b78e-7552b496c99c,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-54075362-172.17.0.18-1599346915611:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-7995a837-b3a5-4e02-b00f-e035abe7385c,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-d9aa9a82-fbc4-450b-ba3e-13740d182d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-48d37525-c145-461b-96e0-39f0641e6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-dc576ece-ca5b-454c-aecd-9fda18ca1dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-b9ab5c63-4ad1-41a7-9c36-c4109f3c40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-14a26101-4490-414c-aa6d-7aaa4239f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-a06a0808-71af-4640-b78e-7552b496c99c,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1330984102-172.17.0.18-1599347015913:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-a839f997-6f71-409f-8971-0faadf39396c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-8e77aff5-f43f-4f71-a40c-3aab67b0aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bb18bb71-4d2c-474c-a9ad-c95b5cefaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ee8ffe71-a2f6-4f41-9a7f-83679cc5b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-34cb575a-78ce-4d5e-b0a1-55ee943b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-75906e25-99c2-4435-95ba-d857372d88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-8c1a4525-a8c4-42ab-af9c-947a1c2c1335,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-dfa2269e-e82f-41e6-9480-6036fe84d08d,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1330984102-172.17.0.18-1599347015913:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-a839f997-6f71-409f-8971-0faadf39396c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-8e77aff5-f43f-4f71-a40c-3aab67b0aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bb18bb71-4d2c-474c-a9ad-c95b5cefaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ee8ffe71-a2f6-4f41-9a7f-83679cc5b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-34cb575a-78ce-4d5e-b0a1-55ee943b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-75906e25-99c2-4435-95ba-d857372d88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-8c1a4525-a8c4-42ab-af9c-947a1c2c1335,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-dfa2269e-e82f-41e6-9480-6036fe84d08d,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1330984102-172.17.0.18-1599347015913:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-a839f997-6f71-409f-8971-0faadf39396c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-8e77aff5-f43f-4f71-a40c-3aab67b0aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bb18bb71-4d2c-474c-a9ad-c95b5cefaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ee8ffe71-a2f6-4f41-9a7f-83679cc5b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-34cb575a-78ce-4d5e-b0a1-55ee943b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-75906e25-99c2-4435-95ba-d857372d88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-8c1a4525-a8c4-42ab-af9c-947a1c2c1335,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-dfa2269e-e82f-41e6-9480-6036fe84d08d,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1330984102-172.17.0.18-1599347015913:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-a839f997-6f71-409f-8971-0faadf39396c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-8e77aff5-f43f-4f71-a40c-3aab67b0aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bb18bb71-4d2c-474c-a9ad-c95b5cefaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ee8ffe71-a2f6-4f41-9a7f-83679cc5b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-34cb575a-78ce-4d5e-b0a1-55ee943b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-75906e25-99c2-4435-95ba-d857372d88e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-8c1a4525-a8c4-42ab-af9c-947a1c2c1335,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-dfa2269e-e82f-41e6-9480-6036fe84d08d,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1099808524-172.17.0.18-1599347172906:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-1cc814fe-d5bf-47a1-88c0-34cd4643b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-5e582a3c-4cb1-4e24-a845-2af374a1c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fdebacb2-b21f-4b9f-82d2-21368c3ef5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-48d9e2cb-ee4c-48f2-b0a6-aae05338b608,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d3df79c7-4569-4572-9d1c-f943e602fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-8010d56a-bddc-4777-aae5-7855718d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-70bbe5ce-e460-45ed-9294-53b583c56e2a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1099808524-172.17.0.18-1599347172906:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-1cc814fe-d5bf-47a1-88c0-34cd4643b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-5e582a3c-4cb1-4e24-a845-2af374a1c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fdebacb2-b21f-4b9f-82d2-21368c3ef5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-48d9e2cb-ee4c-48f2-b0a6-aae05338b608,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d3df79c7-4569-4572-9d1c-f943e602fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-8010d56a-bddc-4777-aae5-7855718d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-70bbe5ce-e460-45ed-9294-53b583c56e2a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1099808524-172.17.0.18-1599347172906:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-1cc814fe-d5bf-47a1-88c0-34cd4643b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-5e582a3c-4cb1-4e24-a845-2af374a1c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fdebacb2-b21f-4b9f-82d2-21368c3ef5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-48d9e2cb-ee4c-48f2-b0a6-aae05338b608,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d3df79c7-4569-4572-9d1c-f943e602fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-8010d56a-bddc-4777-aae5-7855718d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-70bbe5ce-e460-45ed-9294-53b583c56e2a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1099808524-172.17.0.18-1599347172906:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-1cc814fe-d5bf-47a1-88c0-34cd4643b9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-5e582a3c-4cb1-4e24-a845-2af374a1c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-fdebacb2-b21f-4b9f-82d2-21368c3ef5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-48d9e2cb-ee4c-48f2-b0a6-aae05338b608,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d3df79c7-4569-4572-9d1c-f943e602fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-8010d56a-bddc-4777-aae5-7855718d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-70bbe5ce-e460-45ed-9294-53b583c56e2a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1117606542-172.17.0.18-1599347782862:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-8b3ca204-c95d-4b00-8b5e-b527435d06ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-e18bf347-aa78-4ae8-9391-a400113e8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-be43fd4a-7f69-4285-8074-0f18dd5642a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f80d0eed-c8eb-40b5-933c-a2e505691de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-7659caaf-0343-4752-a589-0ee716c890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d6d01315-a298-4150-b632-6c35ad15a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ea25b1ae-fc4f-4c28-9eb0-30f7a345951a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1117606542-172.17.0.18-1599347782862:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-2f97552b-3dc3-4104-97f9-9af816646b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-8b3ca204-c95d-4b00-8b5e-b527435d06ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-e18bf347-aa78-4ae8-9391-a400113e8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-be43fd4a-7f69-4285-8074-0f18dd5642a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f80d0eed-c8eb-40b5-933c-a2e505691de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-7659caaf-0343-4752-a589-0ee716c890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d6d01315-a298-4150-b632-6c35ad15a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ea25b1ae-fc4f-4c28-9eb0-30f7a345951a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1117606542-172.17.0.18-1599347782862:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-8b3ca204-c95d-4b00-8b5e-b527435d06ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-e18bf347-aa78-4ae8-9391-a400113e8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-be43fd4a-7f69-4285-8074-0f18dd5642a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f80d0eed-c8eb-40b5-933c-a2e505691de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-7659caaf-0343-4752-a589-0ee716c890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d6d01315-a298-4150-b632-6c35ad15a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ea25b1ae-fc4f-4c28-9eb0-30f7a345951a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-1117606542-172.17.0.18-1599347782862:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-2f97552b-3dc3-4104-97f9-9af816646b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-8b3ca204-c95d-4b00-8b5e-b527435d06ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-e18bf347-aa78-4ae8-9391-a400113e8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-be43fd4a-7f69-4285-8074-0f18dd5642a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f80d0eed-c8eb-40b5-933c-a2e505691de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-7659caaf-0343-4752-a589-0ee716c890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d6d01315-a298-4150-b632-6c35ad15a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ea25b1ae-fc4f-4c28-9eb0-30f7a345951a,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-323365277-172.17.0.18-1599348247704:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-06b86f0f-2eec-490a-9239-f9bef3292e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e87451f5-3991-44c2-9d89-182e6ea70f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-2c89d30a-010e-4dbc-96f1-942659813410,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b7848133-9628-42f0-bb4b-376b03f60362,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-bfe29654-9650-4b73-aa07-d95fecaa9783,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-48169990-cd77-4e4f-9960-ced98eacb6a0,DISK]]; indices=[1, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-323365277-172.17.0.18-1599348247704:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-06b86f0f-2eec-490a-9239-f9bef3292e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e87451f5-3991-44c2-9d89-182e6ea70f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-2c89d30a-010e-4dbc-96f1-942659813410,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b7848133-9628-42f0-bb4b-376b03f60362,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-bfe29654-9650-4b73-aa07-d95fecaa9783,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-48169990-cd77-4e4f-9960-ced98eacb6a0,DISK]]; indices=[1, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-323365277-172.17.0.18-1599348247704:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-06b86f0f-2eec-490a-9239-f9bef3292e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e87451f5-3991-44c2-9d89-182e6ea70f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-2c89d30a-010e-4dbc-96f1-942659813410,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b7848133-9628-42f0-bb4b-376b03f60362,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-bfe29654-9650-4b73-aa07-d95fecaa9783,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-48169990-cd77-4e4f-9960-ced98eacb6a0,DISK]]; indices=[1, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-323365277-172.17.0.18-1599348247704:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-06b86f0f-2eec-490a-9239-f9bef3292e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e87451f5-3991-44c2-9d89-182e6ea70f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-2c89d30a-010e-4dbc-96f1-942659813410,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-b7848133-9628-42f0-bb4b-376b03f60362,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-bfe29654-9650-4b73-aa07-d95fecaa9783,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-48169990-cd77-4e4f-9960-ced98eacb6a0,DISK]]; indices=[1, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-291879877-172.17.0.18-1599349291017:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-558d4b52-7333-4316-9014-665b4d5ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-21588145-55ed-4f80-9715-1289605e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1f258e96-a8f0-41cd-9db2-5551538a3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-fff81b88-221e-442f-a842-ef23d48b828c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-53daa1e9-5ee1-45cc-9b7e-511a45be1079,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-646df17b-4830-47fc-bac9-c9031507aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9fadfd79-86f8-42d6-ae9e-1ac6daa73ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a42932c9-ebac-4ea1-b2d5-f5daad1b87b8,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-291879877-172.17.0.18-1599349291017:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-558d4b52-7333-4316-9014-665b4d5ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-21588145-55ed-4f80-9715-1289605e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1f258e96-a8f0-41cd-9db2-5551538a3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-fff81b88-221e-442f-a842-ef23d48b828c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-53daa1e9-5ee1-45cc-9b7e-511a45be1079,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-646df17b-4830-47fc-bac9-c9031507aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9fadfd79-86f8-42d6-ae9e-1ac6daa73ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a42932c9-ebac-4ea1-b2d5-f5daad1b87b8,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-291879877-172.17.0.18-1599349291017:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-558d4b52-7333-4316-9014-665b4d5ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-21588145-55ed-4f80-9715-1289605e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1f258e96-a8f0-41cd-9db2-5551538a3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-fff81b88-221e-442f-a842-ef23d48b828c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-53daa1e9-5ee1-45cc-9b7e-511a45be1079,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-646df17b-4830-47fc-bac9-c9031507aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9fadfd79-86f8-42d6-ae9e-1ac6daa73ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a42932c9-ebac-4ea1-b2d5-f5daad1b87b8,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-291879877-172.17.0.18-1599349291017:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-558d4b52-7333-4316-9014-665b4d5ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-21588145-55ed-4f80-9715-1289605e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-1f258e96-a8f0-41cd-9db2-5551538a3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-fff81b88-221e-442f-a842-ef23d48b828c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-53daa1e9-5ee1-45cc-9b7e-511a45be1079,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-646df17b-4830-47fc-bac9-c9031507aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9fadfd79-86f8-42d6-ae9e-1ac6daa73ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a42932c9-ebac-4ea1-b2d5-f5daad1b87b8,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-458628249-172.17.0.18-1599350521962:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-11705c3d-8e50-4d23-b4f0-fa376f953cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5adec58a-abc0-4de1-aca7-4536033bb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-bf1ff848-42bb-4ce4-a86e-a359e6dfba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-a7c58b46-b3c1-40a2-8b00-86575a0f335d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9fab16e5-e906-4987-b3c2-e641f070a381,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-6ea9f553-6ddb-4806-9770-68e78091910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-ee2da5b1-17fe-49d6-9950-52f039b959e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-7931ea9d-35c6-49bc-ae11-87451da75657,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-458628249-172.17.0.18-1599350521962:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-11705c3d-8e50-4d23-b4f0-fa376f953cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5adec58a-abc0-4de1-aca7-4536033bb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-bf1ff848-42bb-4ce4-a86e-a359e6dfba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-a7c58b46-b3c1-40a2-8b00-86575a0f335d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9fab16e5-e906-4987-b3c2-e641f070a381,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-6ea9f553-6ddb-4806-9770-68e78091910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-ee2da5b1-17fe-49d6-9950-52f039b959e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-7931ea9d-35c6-49bc-ae11-87451da75657,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-458628249-172.17.0.18-1599350521962:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-11705c3d-8e50-4d23-b4f0-fa376f953cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5adec58a-abc0-4de1-aca7-4536033bb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-bf1ff848-42bb-4ce4-a86e-a359e6dfba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-a7c58b46-b3c1-40a2-8b00-86575a0f335d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9fab16e5-e906-4987-b3c2-e641f070a381,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-6ea9f553-6ddb-4806-9770-68e78091910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-ee2da5b1-17fe-49d6-9950-52f039b959e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-7931ea9d-35c6-49bc-ae11-87451da75657,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-458628249-172.17.0.18-1599350521962:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-11705c3d-8e50-4d23-b4f0-fa376f953cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5adec58a-abc0-4de1-aca7-4536033bb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-bf1ff848-42bb-4ce4-a86e-a359e6dfba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-a7c58b46-b3c1-40a2-8b00-86575a0f335d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-9fab16e5-e906-4987-b3c2-e641f070a381,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-6ea9f553-6ddb-4806-9770-68e78091910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-ee2da5b1-17fe-49d6-9950-52f039b959e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-7931ea9d-35c6-49bc-ae11-87451da75657,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 8978
