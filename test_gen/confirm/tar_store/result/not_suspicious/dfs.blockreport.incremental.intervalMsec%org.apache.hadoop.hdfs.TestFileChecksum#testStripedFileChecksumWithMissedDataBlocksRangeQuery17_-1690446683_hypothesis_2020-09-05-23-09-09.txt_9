reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075618947-172.17.0.21-1599347486753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-3b0ea922-4f03-4e0e-9904-3c4b71d23c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-64789c56-c9cc-4a3a-9869-2e2258db0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-e5ff6f5c-c0a4-4652-9750-9dcb9cc5ed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-04f79834-c4b0-4c9d-b9a4-55e6019d631a,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-1b4aa6d6-7a3b-4a3d-9d7f-3fbaa9095422,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-3bfa9b57-59ea-4f9a-a382-f5acd15992ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-3375e75d-463e-4f86-a23a-bcc3a4d35ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-111bbb1d-3783-4529-a131-0fbd9dcf96f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075618947-172.17.0.21-1599347486753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-3b0ea922-4f03-4e0e-9904-3c4b71d23c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-64789c56-c9cc-4a3a-9869-2e2258db0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-e5ff6f5c-c0a4-4652-9750-9dcb9cc5ed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-04f79834-c4b0-4c9d-b9a4-55e6019d631a,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-1b4aa6d6-7a3b-4a3d-9d7f-3fbaa9095422,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-3bfa9b57-59ea-4f9a-a382-f5acd15992ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-3375e75d-463e-4f86-a23a-bcc3a4d35ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-111bbb1d-3783-4529-a131-0fbd9dcf96f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220860247-172.17.0.21-1599347729364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43628,DS-2a341a57-abde-43f8-b0f0-8d7adf22058d,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-90573c3c-93f2-495f-8469-0e7b63b0576e,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-9c2b0dc6-f329-4fcf-b62e-dc9277dc2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-fdbfc498-e440-4f7a-9622-5820b626be45,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-89753f61-dea5-4868-b2fd-cac431398af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-87d91deb-8141-4ff6-9dd3-51d23b59822b,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-d5733d64-845a-4d5d-bee9-ce534c52f265,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-dbc55aca-2953-401a-bd90-ae0d8c66bb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220860247-172.17.0.21-1599347729364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43628,DS-2a341a57-abde-43f8-b0f0-8d7adf22058d,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-90573c3c-93f2-495f-8469-0e7b63b0576e,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-9c2b0dc6-f329-4fcf-b62e-dc9277dc2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-fdbfc498-e440-4f7a-9622-5820b626be45,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-89753f61-dea5-4868-b2fd-cac431398af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-87d91deb-8141-4ff6-9dd3-51d23b59822b,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-d5733d64-845a-4d5d-bee9-ce534c52f265,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-dbc55aca-2953-401a-bd90-ae0d8c66bb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428718290-172.17.0.21-1599348170699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-ac2d99b7-7048-4d70-8f11-cdbc588ca058,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-7e86f9f8-e59f-407f-a573-150e97dd5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85fa12e8-b978-4b35-a80e-72c061431e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-4bec5c41-75f7-41ed-b037-c408067836dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-d6b5f4b7-de5e-4019-9abe-530482a4925b,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-cd2b9bb2-3355-48b7-8587-b0651f343cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-63be3c54-1d58-48f2-b42a-65464bef905f,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-648e34d6-cccd-4f68-841a-243b6117d80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428718290-172.17.0.21-1599348170699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-ac2d99b7-7048-4d70-8f11-cdbc588ca058,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-7e86f9f8-e59f-407f-a573-150e97dd5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85fa12e8-b978-4b35-a80e-72c061431e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-4bec5c41-75f7-41ed-b037-c408067836dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-d6b5f4b7-de5e-4019-9abe-530482a4925b,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-cd2b9bb2-3355-48b7-8587-b0651f343cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-63be3c54-1d58-48f2-b42a-65464bef905f,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-648e34d6-cccd-4f68-841a-243b6117d80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785308828-172.17.0.21-1599348712580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-4ee42f08-8121-469e-aa38-4c2baf6d80c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-6e350d35-9ee2-4fb0-b3d3-5bc4f6b4a651,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-34d0a23c-c2fe-425d-89ca-5dab90614d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-8ad356ec-4306-470b-93ba-ff593db0d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-09ffd8ae-bd24-4b6d-adfd-0a51bc2549b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e72ac81a-7580-4cae-beb8-cd147cd46d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-070639a4-583d-46a2-9c44-f54d362145dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-eb7774d8-8693-44ca-8d3e-0295ee9e6ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785308828-172.17.0.21-1599348712580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-4ee42f08-8121-469e-aa38-4c2baf6d80c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-6e350d35-9ee2-4fb0-b3d3-5bc4f6b4a651,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-34d0a23c-c2fe-425d-89ca-5dab90614d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-8ad356ec-4306-470b-93ba-ff593db0d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-09ffd8ae-bd24-4b6d-adfd-0a51bc2549b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e72ac81a-7580-4cae-beb8-cd147cd46d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-070639a4-583d-46a2-9c44-f54d362145dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-eb7774d8-8693-44ca-8d3e-0295ee9e6ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205171588-172.17.0.21-1599349357475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-54cdc362-3085-418d-aad1-4b97fdf6b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-5a5dc6a7-bc1a-4fba-b9e5-f2dc3051006a,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f6bf457a-af74-45ef-b9b2-4364e31e1bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-abe05092-5604-4802-a6b0-baf5e0ed2869,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-5558da12-5024-4662-b982-204d10c6d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-04504284-2282-494c-8c44-29c35db62a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ce6ac8ea-45fd-45c4-9b6c-41fb05a64424,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e65d6919-26d1-4969-8722-79809195ea27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205171588-172.17.0.21-1599349357475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45777,DS-54cdc362-3085-418d-aad1-4b97fdf6b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-5a5dc6a7-bc1a-4fba-b9e5-f2dc3051006a,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f6bf457a-af74-45ef-b9b2-4364e31e1bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-abe05092-5604-4802-a6b0-baf5e0ed2869,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-5558da12-5024-4662-b982-204d10c6d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-04504284-2282-494c-8c44-29c35db62a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ce6ac8ea-45fd-45c4-9b6c-41fb05a64424,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e65d6919-26d1-4969-8722-79809195ea27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942270047-172.17.0.21-1599349941955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39388,DS-eb1b73f9-1f61-440e-90ea-bbea3d284368,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-c2bb389f-df60-457c-a8d8-c5212c8a84b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-28209cb8-2b63-4266-8125-1c5fe50bbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-618199e9-13a7-405b-9a92-50075ba4976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-4f70ed0b-99c2-4484-9821-c82a385fd1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5231a32a-6c25-412d-86fc-166994dff5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-badc5bea-4d9f-4e1e-9b16-f642abcbd181,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-ae1acb61-9e5a-4488-8c85-bb22374c878b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942270047-172.17.0.21-1599349941955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39388,DS-eb1b73f9-1f61-440e-90ea-bbea3d284368,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-c2bb389f-df60-457c-a8d8-c5212c8a84b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-28209cb8-2b63-4266-8125-1c5fe50bbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-618199e9-13a7-405b-9a92-50075ba4976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-4f70ed0b-99c2-4484-9821-c82a385fd1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5231a32a-6c25-412d-86fc-166994dff5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-badc5bea-4d9f-4e1e-9b16-f642abcbd181,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-ae1acb61-9e5a-4488-8c85-bb22374c878b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008168768-172.17.0.21-1599350269729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-a36c4da1-f634-4cc8-87ca-d93fd101df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-f303d213-47d9-4e96-9b7f-2522e2be15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-c361400f-5d96-449c-9c3c-306c1315b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-be63d0be-ca57-4f52-b584-2747de315a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b5e4e670-6ccd-49e0-bde8-2cd9aa6dad50,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-4b8d7a29-7214-4da0-be25-e3625e9a5775,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-483dbced-23a1-4291-a9e2-400b83e3fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-61db5527-f7ec-42af-a0a8-66dc4fc826ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008168768-172.17.0.21-1599350269729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-a36c4da1-f634-4cc8-87ca-d93fd101df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-f303d213-47d9-4e96-9b7f-2522e2be15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-c361400f-5d96-449c-9c3c-306c1315b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-be63d0be-ca57-4f52-b584-2747de315a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b5e4e670-6ccd-49e0-bde8-2cd9aa6dad50,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-4b8d7a29-7214-4da0-be25-e3625e9a5775,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-483dbced-23a1-4291-a9e2-400b83e3fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-61db5527-f7ec-42af-a0a8-66dc4fc826ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043785557-172.17.0.21-1599350437329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-078dd72f-9ed0-43a5-ae3f-f14bd8f7c594,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-ed87ad5e-7362-464e-afe5-667b8d152885,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-d48c2f75-25bb-47fd-b64a-339f0f2b2f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-98c853f2-28ce-4695-b4b7-f6b7b8bd08cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-b105729b-b8ac-40a9-8df2-378d85eddc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3c967de-256c-4848-bda0-85e1b83137f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-575113ee-81d8-4443-87aa-f15be8679dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-df1f30a0-e4f4-4359-aa78-b45a90eeea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043785557-172.17.0.21-1599350437329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41632,DS-078dd72f-9ed0-43a5-ae3f-f14bd8f7c594,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-ed87ad5e-7362-464e-afe5-667b8d152885,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-d48c2f75-25bb-47fd-b64a-339f0f2b2f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-98c853f2-28ce-4695-b4b7-f6b7b8bd08cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-b105729b-b8ac-40a9-8df2-378d85eddc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3c967de-256c-4848-bda0-85e1b83137f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-575113ee-81d8-4443-87aa-f15be8679dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-df1f30a0-e4f4-4359-aa78-b45a90eeea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270508960-172.17.0.21-1599350481787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-3b063fd6-2e22-43e5-b3bd-f059b3e1e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-11b9b24a-fef8-4510-80fe-08138244fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-0e810ee4-0485-477b-aae8-88fe31e28852,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-75e8441f-13e4-4e04-997a-c28d928f1dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-f47df198-aa62-4784-84b4-544d25012604,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-8fb300c8-f759-4b7f-a83e-04c8d7709e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2cbe0ed7-4e3e-4298-b7bd-7a822b917d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-5f68693d-0068-4384-b4d7-df851e541b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270508960-172.17.0.21-1599350481787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-3b063fd6-2e22-43e5-b3bd-f059b3e1e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-11b9b24a-fef8-4510-80fe-08138244fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-0e810ee4-0485-477b-aae8-88fe31e28852,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-75e8441f-13e4-4e04-997a-c28d928f1dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-f47df198-aa62-4784-84b4-544d25012604,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-8fb300c8-f759-4b7f-a83e-04c8d7709e60,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-2cbe0ed7-4e3e-4298-b7bd-7a822b917d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-5f68693d-0068-4384-b4d7-df851e541b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36126415-172.17.0.21-1599350603659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-b3130f06-039e-45f2-894d-18395fbf46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-98683a50-9324-467e-837e-aa2c8d7e8863,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-95a0eb77-5f52-4155-8927-4ab2e766ed61,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-c7bff10d-3141-4dcb-9ad2-fa78d452a637,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-8b31b696-101b-4308-b8fb-12bff5fb4590,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-17533db0-a20c-4b33-ad77-b31514c71ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-296235f3-c928-42e4-90e1-e422e2ec8a79,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-e664ec9d-a69b-4ab6-8957-8e697a380262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36126415-172.17.0.21-1599350603659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-b3130f06-039e-45f2-894d-18395fbf46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-98683a50-9324-467e-837e-aa2c8d7e8863,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-95a0eb77-5f52-4155-8927-4ab2e766ed61,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-c7bff10d-3141-4dcb-9ad2-fa78d452a637,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-8b31b696-101b-4308-b8fb-12bff5fb4590,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-17533db0-a20c-4b33-ad77-b31514c71ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-296235f3-c928-42e4-90e1-e422e2ec8a79,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-e664ec9d-a69b-4ab6-8957-8e697a380262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515354903-172.17.0.21-1599350802131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-ba60b71f-582c-42ce-9b75-48b86bde87a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-689ec2ef-5a06-4d7b-b24c-27753767f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-ab37c255-a2f5-4e3c-b8cc-f6df1074c116,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-1817d92d-ff1e-48ac-991f-98d0d4b72ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9a272ee0-9611-4c38-9181-ffb0733c4984,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-1d5060ef-42c5-4d02-a96e-94bd97b8dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2f28cc4a-5118-4f23-8e38-e2935f134c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-b53adffd-a0d7-493a-80a3-01681465a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515354903-172.17.0.21-1599350802131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-ba60b71f-582c-42ce-9b75-48b86bde87a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-689ec2ef-5a06-4d7b-b24c-27753767f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-ab37c255-a2f5-4e3c-b8cc-f6df1074c116,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-1817d92d-ff1e-48ac-991f-98d0d4b72ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9a272ee0-9611-4c38-9181-ffb0733c4984,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-1d5060ef-42c5-4d02-a96e-94bd97b8dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2f28cc4a-5118-4f23-8e38-e2935f134c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-b53adffd-a0d7-493a-80a3-01681465a115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356139046-172.17.0.21-1599350874997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-48d27266-544f-4151-ad95-f016d2b2ef97,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-43e368af-8a47-4c50-a8cc-f33089abdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-aeeda981-a8ae-472b-9de5-6d5223cbe93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-bf8ba98b-e7bb-472c-87b9-78909bdca7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c9360091-06df-46a3-aaee-ec1e4b73a608,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-cc7e3c21-43e1-4e33-9e20-0260cc45a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-71c73aba-4b3e-4c6e-8cb9-3c227b6f5584,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-882ba22e-1098-493a-bbda-2a641bedd3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356139046-172.17.0.21-1599350874997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-48d27266-544f-4151-ad95-f016d2b2ef97,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-43e368af-8a47-4c50-a8cc-f33089abdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-aeeda981-a8ae-472b-9de5-6d5223cbe93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-bf8ba98b-e7bb-472c-87b9-78909bdca7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c9360091-06df-46a3-aaee-ec1e4b73a608,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-cc7e3c21-43e1-4e33-9e20-0260cc45a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-71c73aba-4b3e-4c6e-8cb9-3c227b6f5584,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-882ba22e-1098-493a-bbda-2a641bedd3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767820008-172.17.0.21-1599351098392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-a8593393-7f63-4898-9195-1c82a7cf1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-d062a458-d075-41ca-8ab6-497f8c1bdb50,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-565502e8-e507-4271-9808-c6f4eed74886,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-cf2f0352-6461-4c68-90cf-684cd609fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-f09faf4e-8a3b-4eaf-b4c1-cde25c7661f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-d563352a-e351-4dce-8382-c5fd536327e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-3286a46e-d7f7-464d-91b1-79a90282798c,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-060f6ba8-5715-42ae-953a-87a589ef342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767820008-172.17.0.21-1599351098392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-a8593393-7f63-4898-9195-1c82a7cf1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-d062a458-d075-41ca-8ab6-497f8c1bdb50,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-565502e8-e507-4271-9808-c6f4eed74886,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-cf2f0352-6461-4c68-90cf-684cd609fd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-f09faf4e-8a3b-4eaf-b4c1-cde25c7661f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-d563352a-e351-4dce-8382-c5fd536327e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-3286a46e-d7f7-464d-91b1-79a90282798c,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-060f6ba8-5715-42ae-953a-87a589ef342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556040037-172.17.0.21-1599351236553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-db7aa091-3b85-4c33-9a1b-4bb39bdd9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-ce3417dd-6283-4547-abe5-bde372a4df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-e4ce3c78-88fc-48fc-b58c-56c345ad08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-97ba8a77-28eb-4669-92ed-2d1e9d56966c,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-bc72a0d9-2bc4-4559-a657-892a7b00c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-ceca5ade-7853-4450-933d-b119f405b817,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ab386754-a4ce-4e79-b96f-b7dc8cb3eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f6e11cf5-7e4d-45a5-8f30-c426660c2685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556040037-172.17.0.21-1599351236553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-db7aa091-3b85-4c33-9a1b-4bb39bdd9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-ce3417dd-6283-4547-abe5-bde372a4df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-e4ce3c78-88fc-48fc-b58c-56c345ad08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-97ba8a77-28eb-4669-92ed-2d1e9d56966c,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-bc72a0d9-2bc4-4559-a657-892a7b00c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-ceca5ade-7853-4450-933d-b119f405b817,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ab386754-a4ce-4e79-b96f-b7dc8cb3eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f6e11cf5-7e4d-45a5-8f30-c426660c2685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767835865-172.17.0.21-1599351485999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-81b728a6-2316-4263-833d-b651e020291f,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-45c1fc40-6ace-4b17-997e-03f15088bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-1c0549cf-2f45-45c6-85a0-8d89d1ee4f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-5a99ca2f-7eb6-4d82-864a-d0af7c21b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-45026d5f-34f8-4887-9e5f-2b17299a80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-5944da91-5e50-441a-9aaa-cb07fdaba505,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-2def8db4-f88f-43ce-86fd-2c169dfbf2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-813b8962-a9f5-47e2-ac12-a4eb68f7fc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767835865-172.17.0.21-1599351485999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-81b728a6-2316-4263-833d-b651e020291f,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-45c1fc40-6ace-4b17-997e-03f15088bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-1c0549cf-2f45-45c6-85a0-8d89d1ee4f59,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-5a99ca2f-7eb6-4d82-864a-d0af7c21b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-45026d5f-34f8-4887-9e5f-2b17299a80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-5944da91-5e50-441a-9aaa-cb07fdaba505,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-2def8db4-f88f-43ce-86fd-2c169dfbf2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-813b8962-a9f5-47e2-ac12-a4eb68f7fc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785044995-172.17.0.21-1599351744830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36576,DS-a1482e97-fc3b-4993-9aba-9f22f61742b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-404bddf9-e569-4294-86e1-3c05d96238cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-0bd71749-9c19-4e27-ac2c-8b4a11fb1513,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-4d710fe9-b13e-4c79-80b5-b4cdb925c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-145b9452-332f-4e27-a1a3-c366f7281c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-d1be8bc8-67d0-4ddb-9dda-63a4eaac03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-7e05c9d9-7ae6-49dc-b549-4d765d5ee8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-0a10e17c-02e7-4ad2-bc2b-fe1ef5d6d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785044995-172.17.0.21-1599351744830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36576,DS-a1482e97-fc3b-4993-9aba-9f22f61742b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-404bddf9-e569-4294-86e1-3c05d96238cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-0bd71749-9c19-4e27-ac2c-8b4a11fb1513,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-4d710fe9-b13e-4c79-80b5-b4cdb925c06c,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-145b9452-332f-4e27-a1a3-c366f7281c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-d1be8bc8-67d0-4ddb-9dda-63a4eaac03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-7e05c9d9-7ae6-49dc-b549-4d765d5ee8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-0a10e17c-02e7-4ad2-bc2b-fe1ef5d6d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104968478-172.17.0.21-1599351959858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33394,DS-a9bda10c-918e-41ca-883b-ae850f8d5842,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-426d8f98-cf30-4939-917b-68874b73e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-7352718a-cd91-45c6-a074-241aae23f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-43f69183-7eff-4875-8644-6c554b7c99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-535c79ed-922c-4874-890e-1c811b3baa15,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b3700fa8-831f-4af5-ad4a-102fe75c601b,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-16425856-81ad-41b2-83ed-de3dcf3612c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-44dff44c-3d41-4e41-9799-e651d846a48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104968478-172.17.0.21-1599351959858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33394,DS-a9bda10c-918e-41ca-883b-ae850f8d5842,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-426d8f98-cf30-4939-917b-68874b73e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-7352718a-cd91-45c6-a074-241aae23f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-43f69183-7eff-4875-8644-6c554b7c99f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-535c79ed-922c-4874-890e-1c811b3baa15,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b3700fa8-831f-4af5-ad4a-102fe75c601b,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-16425856-81ad-41b2-83ed-de3dcf3612c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-44dff44c-3d41-4e41-9799-e651d846a48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869630633-172.17.0.21-1599352004318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-9e1203a4-0065-42bc-9b38-556baa954cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-c34d01db-fd2c-40ce-a210-dabae75ef76d,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-7bb4fe22-821d-466a-840c-febaf33649e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-acbe65c4-f005-4832-97aa-7bea79d7b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-92e14d77-e891-41dd-a918-391aadedfd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-17360910-fae3-40dc-b0c1-52687d10110a,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-ab7b1b72-7c21-42f0-88e1-e307f2730385,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-622a0202-f82f-41b3-a0fd-cf669f758ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869630633-172.17.0.21-1599352004318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-9e1203a4-0065-42bc-9b38-556baa954cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-c34d01db-fd2c-40ce-a210-dabae75ef76d,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-7bb4fe22-821d-466a-840c-febaf33649e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-acbe65c4-f005-4832-97aa-7bea79d7b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-92e14d77-e891-41dd-a918-391aadedfd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-17360910-fae3-40dc-b0c1-52687d10110a,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-ab7b1b72-7c21-42f0-88e1-e307f2730385,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-622a0202-f82f-41b3-a0fd-cf669f758ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864855980-172.17.0.21-1599352149868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-6433d91a-bb2e-4763-8f17-61688895070a,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-052e6e81-ccee-4fc1-b9e8-13ea281837b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-c8bd2997-9e1c-4cf5-b8e4-b329f4a46774,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-14d0716e-0e68-4743-87bf-b9de06ebf4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-56ac6eeb-fe2f-4499-a6f8-72cec83f7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-9eb2b08f-70ae-42ca-8183-907d05148484,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-5e3392da-faa7-42b7-9ab6-17e6f3a5a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-ecde73ff-7554-4857-9971-a47a1fa05edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864855980-172.17.0.21-1599352149868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-6433d91a-bb2e-4763-8f17-61688895070a,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-052e6e81-ccee-4fc1-b9e8-13ea281837b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-c8bd2997-9e1c-4cf5-b8e4-b329f4a46774,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-14d0716e-0e68-4743-87bf-b9de06ebf4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-56ac6eeb-fe2f-4499-a6f8-72cec83f7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-9eb2b08f-70ae-42ca-8183-907d05148484,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-5e3392da-faa7-42b7-9ab6-17e6f3a5a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-ecde73ff-7554-4857-9971-a47a1fa05edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831147968-172.17.0.21-1599352493220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-2f956d54-664f-42a4-8014-582b36689ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-58f9c3fa-0743-4bc0-bc00-42ba83a0d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9d714ca8-c10d-4fdf-a486-0fbf2a2cf548,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c882225b-4896-442f-875b-8cfd272e37fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5bbd188b-eed8-41f6-93b1-6ac8b35ccca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-96a6277a-e15f-4c82-961c-f920e00c0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-44b8af99-fa25-4461-88e5-96ff4c8dc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-2a05b0ee-864a-4c83-adbc-ec015c91711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831147968-172.17.0.21-1599352493220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-2f956d54-664f-42a4-8014-582b36689ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-58f9c3fa-0743-4bc0-bc00-42ba83a0d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9d714ca8-c10d-4fdf-a486-0fbf2a2cf548,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c882225b-4896-442f-875b-8cfd272e37fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-5bbd188b-eed8-41f6-93b1-6ac8b35ccca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-96a6277a-e15f-4c82-961c-f920e00c0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-44b8af99-fa25-4461-88e5-96ff4c8dc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-2a05b0ee-864a-4c83-adbc-ec015c91711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668605023-172.17.0.21-1599352671720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-1cc95168-3bd9-425a-bdca-36db1e7b2c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-a544e78c-defe-49ca-a168-e4b024589ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-c6ac7afb-1c55-4ae2-ae95-3e23d96b3994,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-6350015f-3572-4672-85fe-2a59052f3492,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-18bf8082-920f-47fb-b4e8-33582ec0ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-53c4525e-8a71-44c2-bea5-6fb6d280d824,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-589fd3d6-ea52-4a53-ac9a-f1dab30799b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-afcaacf6-ec0f-4045-aa06-b1cadeb9e02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668605023-172.17.0.21-1599352671720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-1cc95168-3bd9-425a-bdca-36db1e7b2c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-a544e78c-defe-49ca-a168-e4b024589ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-c6ac7afb-1c55-4ae2-ae95-3e23d96b3994,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-6350015f-3572-4672-85fe-2a59052f3492,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-18bf8082-920f-47fb-b4e8-33582ec0ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-53c4525e-8a71-44c2-bea5-6fb6d280d824,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-589fd3d6-ea52-4a53-ac9a-f1dab30799b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-afcaacf6-ec0f-4045-aa06-b1cadeb9e02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319597776-172.17.0.21-1599352869312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-b00fe7c2-4848-4ee3-a2db-1397e5c7c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-e91a103b-f504-4b48-9af7-389df27d291b,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-b38bc529-ae97-4397-a865-fcab342cb977,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-110b9887-9a4a-4ce1-8abd-4ba539724b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-4acce842-6097-4cec-b15c-94436a8ac183,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-740d0cad-eb9e-4da0-bdcc-aaa72a0d9678,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-95fedf71-b175-4005-a26d-18da49488dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-2b687469-75ae-4145-9a53-347699761575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319597776-172.17.0.21-1599352869312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-b00fe7c2-4848-4ee3-a2db-1397e5c7c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-e91a103b-f504-4b48-9af7-389df27d291b,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-b38bc529-ae97-4397-a865-fcab342cb977,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-110b9887-9a4a-4ce1-8abd-4ba539724b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-4acce842-6097-4cec-b15c-94436a8ac183,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-740d0cad-eb9e-4da0-bdcc-aaa72a0d9678,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-95fedf71-b175-4005-a26d-18da49488dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-2b687469-75ae-4145-9a53-347699761575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5612
