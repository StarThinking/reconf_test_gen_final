reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180268331-172.17.0.14-1599348859463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-5a7f83ef-8edc-499a-969b-21481366575d,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-428d0e34-f753-49a6-a7b7-024c60ea5f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-3f2c59a9-ae19-4501-bf4b-ea3a1c121f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-7eb51ef1-7de0-46f8-bf48-7896f579a369,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-4a88b796-82bf-422c-81e3-3436a45847f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-d8f827eb-6061-4d92-bb7c-4e5354945a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4c9eb2cc-1426-4f7b-b1a3-cbbb61fe7269,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-f8ac2afd-f651-489a-83d0-d8ca809cac35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180268331-172.17.0.14-1599348859463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-5a7f83ef-8edc-499a-969b-21481366575d,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-428d0e34-f753-49a6-a7b7-024c60ea5f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-3f2c59a9-ae19-4501-bf4b-ea3a1c121f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-7eb51ef1-7de0-46f8-bf48-7896f579a369,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-4a88b796-82bf-422c-81e3-3436a45847f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-d8f827eb-6061-4d92-bb7c-4e5354945a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4c9eb2cc-1426-4f7b-b1a3-cbbb61fe7269,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-f8ac2afd-f651-489a-83d0-d8ca809cac35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753322530-172.17.0.14-1599349036164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-d7af9db0-53df-439b-8ce9-923bc43dd57d,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-4c76f011-519e-445a-bc71-8cec1df1ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-73e20785-af6f-4eef-8ef7-8ede39743e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-0587c5b8-c6b6-42e6-9b05-6fe200d9f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-aa13e634-69d3-4f60-aef4-2318de33ad06,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-908dbcc7-8df1-48c0-b3b9-de66c8444865,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-b70a52a9-7ccd-4f1f-85ae-ec3ab919b885,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-ad019542-4266-446d-a93f-de8ce4c81365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753322530-172.17.0.14-1599349036164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-d7af9db0-53df-439b-8ce9-923bc43dd57d,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-4c76f011-519e-445a-bc71-8cec1df1ac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-73e20785-af6f-4eef-8ef7-8ede39743e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-0587c5b8-c6b6-42e6-9b05-6fe200d9f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-aa13e634-69d3-4f60-aef4-2318de33ad06,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-908dbcc7-8df1-48c0-b3b9-de66c8444865,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-b70a52a9-7ccd-4f1f-85ae-ec3ab919b885,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-ad019542-4266-446d-a93f-de8ce4c81365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823100743-172.17.0.14-1599349337733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-46a7f976-cb9a-4636-b44a-573c7d0c3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-28a8ee9c-bfde-4f4c-8a5a-e4e59f87fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-26ace17b-ab9d-43c4-99f4-ac27076bf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4acfaff3-5b2f-443b-9500-975a4760df62,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-a75f2bd6-ef25-4064-88e3-ce347952612a,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-956009b4-fc18-485b-acaf-597ea4a89de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-be110548-a656-4936-b0c8-a659ff174e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-3a7dddf7-ee08-45ee-ad03-ac59822d3ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823100743-172.17.0.14-1599349337733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-46a7f976-cb9a-4636-b44a-573c7d0c3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-28a8ee9c-bfde-4f4c-8a5a-e4e59f87fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-26ace17b-ab9d-43c4-99f4-ac27076bf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4acfaff3-5b2f-443b-9500-975a4760df62,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-a75f2bd6-ef25-4064-88e3-ce347952612a,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-956009b4-fc18-485b-acaf-597ea4a89de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-be110548-a656-4936-b0c8-a659ff174e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-3a7dddf7-ee08-45ee-ad03-ac59822d3ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102515734-172.17.0.14-1599349506343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41504,DS-6e935455-d06b-465b-b62c-80c5a85df13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-9a04f588-0b5b-4030-b06b-364095bffd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-ef376b11-0b3c-4579-96ba-7dcb2a600ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-57102f15-654f-4ba4-8d65-8675a6185dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d1ca9fab-de4e-41f5-9593-f2786c445c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-0c87cd94-c3c5-4dc3-a9aa-990e00aa6cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-4dc29758-f1b2-4bba-97ca-58205990b900,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-bd20ffa7-8b65-4c23-b711-815c42288d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102515734-172.17.0.14-1599349506343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41504,DS-6e935455-d06b-465b-b62c-80c5a85df13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-9a04f588-0b5b-4030-b06b-364095bffd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-ef376b11-0b3c-4579-96ba-7dcb2a600ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-57102f15-654f-4ba4-8d65-8675a6185dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d1ca9fab-de4e-41f5-9593-f2786c445c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-0c87cd94-c3c5-4dc3-a9aa-990e00aa6cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-4dc29758-f1b2-4bba-97ca-58205990b900,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-bd20ffa7-8b65-4c23-b711-815c42288d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094036064-172.17.0.14-1599349868833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33006,DS-1a8c5ab1-c254-4833-8e87-a65d625bb99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-49143f33-fa23-4c4d-af0a-143374964232,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-512657c8-9df0-4b9a-8d28-f8714de7b973,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-2602900f-9ec2-47da-8e6b-e5398a375468,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-8e81ae58-0fea-424f-9cc1-4e0a8a090f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-22b0da3c-204c-46a3-bc60-9012e2679e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-52c3d979-ab8e-4f8e-871b-cdef0f64e538,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-6b9f57e8-7410-4765-8a37-0f918f658137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094036064-172.17.0.14-1599349868833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33006,DS-1a8c5ab1-c254-4833-8e87-a65d625bb99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-49143f33-fa23-4c4d-af0a-143374964232,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-512657c8-9df0-4b9a-8d28-f8714de7b973,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-2602900f-9ec2-47da-8e6b-e5398a375468,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-8e81ae58-0fea-424f-9cc1-4e0a8a090f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-22b0da3c-204c-46a3-bc60-9012e2679e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-52c3d979-ab8e-4f8e-871b-cdef0f64e538,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-6b9f57e8-7410-4765-8a37-0f918f658137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597942861-172.17.0.14-1599350282831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-8f401036-2348-49ec-af0a-408b7fccead7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-cd044991-86e8-42b4-8147-1bc379f24e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-462c1ff8-14b4-48e5-b1f6-4ef06850a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-7cfc7d5f-d767-4c11-ae04-79be502c18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-dc1fa596-5dbe-4437-963c-94e3a35f7cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-a1f40d1e-ce7c-4254-b6fd-23aa53605278,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-be6e37ce-9890-4ef5-99e5-a0331417426d,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-cd68a99f-52ed-4b03-8a68-b40bec04e53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597942861-172.17.0.14-1599350282831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-8f401036-2348-49ec-af0a-408b7fccead7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-cd044991-86e8-42b4-8147-1bc379f24e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-462c1ff8-14b4-48e5-b1f6-4ef06850a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-7cfc7d5f-d767-4c11-ae04-79be502c18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-dc1fa596-5dbe-4437-963c-94e3a35f7cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-a1f40d1e-ce7c-4254-b6fd-23aa53605278,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-be6e37ce-9890-4ef5-99e5-a0331417426d,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-cd68a99f-52ed-4b03-8a68-b40bec04e53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686906516-172.17.0.14-1599350350182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-9b8bf0c0-abbd-4c68-af5f-633054f2f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-88d2dbe3-2d9f-42c5-b950-47b90e08468a,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-1f245e81-280b-4eb9-84b0-ee60ae892854,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-9e5efd47-41aa-4c6e-9568-bdd66baa427b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bf408156-065f-45f8-a48e-056afc16833b,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-348adb43-3152-4b5a-b38d-856697a0b031,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-32d51320-ca59-4dc1-b941-e2dfeabdc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-7df64571-2230-4894-af32-76af55de166e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686906516-172.17.0.14-1599350350182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-9b8bf0c0-abbd-4c68-af5f-633054f2f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-88d2dbe3-2d9f-42c5-b950-47b90e08468a,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-1f245e81-280b-4eb9-84b0-ee60ae892854,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-9e5efd47-41aa-4c6e-9568-bdd66baa427b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bf408156-065f-45f8-a48e-056afc16833b,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-348adb43-3152-4b5a-b38d-856697a0b031,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-32d51320-ca59-4dc1-b941-e2dfeabdc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-7df64571-2230-4894-af32-76af55de166e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184420657-172.17.0.14-1599350685592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-8b47adde-982d-4d87-b901-4b6505554d38,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-981d4b6b-11f8-4de4-8438-e55331ff802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-236835e5-c8fc-4199-8f7c-fa04c9502f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-dcf56407-ef98-488c-898e-ae39d0cfa946,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-23ed08bc-b854-4991-9d2f-3832a6809102,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-aa4420b0-47c1-468c-baac-d3b645dc3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-c7bcdac8-c57b-4806-af00-aec18464ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-4354bae6-62bb-4d6a-9a76-93460fedba63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184420657-172.17.0.14-1599350685592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-8b47adde-982d-4d87-b901-4b6505554d38,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-981d4b6b-11f8-4de4-8438-e55331ff802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-236835e5-c8fc-4199-8f7c-fa04c9502f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-dcf56407-ef98-488c-898e-ae39d0cfa946,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-23ed08bc-b854-4991-9d2f-3832a6809102,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-aa4420b0-47c1-468c-baac-d3b645dc3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-c7bcdac8-c57b-4806-af00-aec18464ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-4354bae6-62bb-4d6a-9a76-93460fedba63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176787468-172.17.0.14-1599351100932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-f9383ae1-7ad0-4d44-b08b-6dd0d2ce5922,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b936b656-9684-4434-9def-b39e815a38b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-715d9b12-e676-4634-be57-0f832700b234,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-586053b8-3a09-48fd-bb70-4c5be0ce6561,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-7d21b5b7-dee0-4134-8d76-9073cd0c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-57b192b8-4ba6-42d8-a013-55523520abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-ee214981-d023-4cb3-8929-3ec6ae6533f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-59a3983a-f0f5-49e2-b75f-235b2a1419d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176787468-172.17.0.14-1599351100932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-f9383ae1-7ad0-4d44-b08b-6dd0d2ce5922,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b936b656-9684-4434-9def-b39e815a38b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-715d9b12-e676-4634-be57-0f832700b234,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-586053b8-3a09-48fd-bb70-4c5be0ce6561,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-7d21b5b7-dee0-4134-8d76-9073cd0c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-57b192b8-4ba6-42d8-a013-55523520abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-ee214981-d023-4cb3-8929-3ec6ae6533f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-59a3983a-f0f5-49e2-b75f-235b2a1419d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642416483-172.17.0.14-1599351168960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-1c85e9c7-f931-4375-bad8-7f6e22fc8743,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b8727080-bfde-4701-ae77-0530a88c8e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-ec66b2c7-5425-4c80-91da-81c1d4e397e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-8a0f250e-96d2-481f-bb69-6805a24aa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-affab2c9-da15-45bd-a7d4-45b7be3fe036,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-7397eae4-7cb6-454f-bebb-e8eb0ec7619b,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-61128fc2-699d-4ae1-abaf-a418930fa178,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-cf28e3f5-19bc-4c87-90ae-a9e84650175a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642416483-172.17.0.14-1599351168960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-1c85e9c7-f931-4375-bad8-7f6e22fc8743,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b8727080-bfde-4701-ae77-0530a88c8e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-ec66b2c7-5425-4c80-91da-81c1d4e397e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-8a0f250e-96d2-481f-bb69-6805a24aa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-affab2c9-da15-45bd-a7d4-45b7be3fe036,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-7397eae4-7cb6-454f-bebb-e8eb0ec7619b,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-61128fc2-699d-4ae1-abaf-a418930fa178,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-cf28e3f5-19bc-4c87-90ae-a9e84650175a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85896990-172.17.0.14-1599351671113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-6bd972d2-0699-4ec9-a814-1424dfd61823,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-df7d311b-ceb0-4241-972c-4751c0687a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-35f9d917-6e0b-4666-b7b3-5e949285f934,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-97f26cca-a0f6-450b-9d98-e376ae0855ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b02efde-f809-48a6-885e-24e1db6003db,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-137f4ba4-d424-43e8-a9f7-9c78bbdcfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-25ad0a2f-8e50-46bf-8279-8a7f0e3f46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-06404c57-f622-46f6-8052-62b32a4c6d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85896990-172.17.0.14-1599351671113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-6bd972d2-0699-4ec9-a814-1424dfd61823,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-df7d311b-ceb0-4241-972c-4751c0687a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-35f9d917-6e0b-4666-b7b3-5e949285f934,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-97f26cca-a0f6-450b-9d98-e376ae0855ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b02efde-f809-48a6-885e-24e1db6003db,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-137f4ba4-d424-43e8-a9f7-9c78bbdcfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-25ad0a2f-8e50-46bf-8279-8a7f0e3f46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-06404c57-f622-46f6-8052-62b32a4c6d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925839702-172.17.0.14-1599351701456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-cd843cc7-5b91-421f-96a6-98660d914afc,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-480c9f21-137e-496b-96eb-4f6f7946f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-412d375b-c420-4806-b633-b10d792b3633,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-31aee47f-950e-4d7b-98d4-4ad97c63bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-de0cd7c3-d37d-464e-b50f-8264a44ed0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-872dfc8e-4f66-4cb2-9e5c-9bbb95dbf5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-f124b866-0aea-4761-ab01-61254660aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-0fe80b60-93b7-4310-94c4-c2c9964e4ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925839702-172.17.0.14-1599351701456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-cd843cc7-5b91-421f-96a6-98660d914afc,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-480c9f21-137e-496b-96eb-4f6f7946f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-412d375b-c420-4806-b633-b10d792b3633,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-31aee47f-950e-4d7b-98d4-4ad97c63bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-de0cd7c3-d37d-464e-b50f-8264a44ed0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-872dfc8e-4f66-4cb2-9e5c-9bbb95dbf5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-f124b866-0aea-4761-ab01-61254660aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-0fe80b60-93b7-4310-94c4-c2c9964e4ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989117601-172.17.0.14-1599351905435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-5eb2d561-540e-4164-a026-6e2472e58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-ad1b77a0-9d58-4c0a-9e41-140370343a36,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-321a9565-3533-4923-b67a-e3bd8912bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-137d989e-f584-4f31-8324-63449e8d61bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-a3239155-0131-4e58-a525-32a274ee7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-038dfc40-ae8e-4f0a-9133-edb5be720d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-63d309cc-6585-4d35-93fa-d234cd7ed3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-47598e79-51ad-4f5b-837d-491e2f9f4b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989117601-172.17.0.14-1599351905435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-5eb2d561-540e-4164-a026-6e2472e58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-ad1b77a0-9d58-4c0a-9e41-140370343a36,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-321a9565-3533-4923-b67a-e3bd8912bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-137d989e-f584-4f31-8324-63449e8d61bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-a3239155-0131-4e58-a525-32a274ee7b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-038dfc40-ae8e-4f0a-9133-edb5be720d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-63d309cc-6585-4d35-93fa-d234cd7ed3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-47598e79-51ad-4f5b-837d-491e2f9f4b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989861229-172.17.0.14-1599352198403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-665b2e59-55c3-4e0e-97c3-0e620aad8682,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-851acdd6-85c3-4507-af52-cdd86d71f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-733e1866-4ecf-4eed-ad6d-322e11af421b,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-b23e8fb4-bec2-43df-9668-e55b10d597b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-e5161f94-6280-46c2-9fe0-456aaced32b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-45f67e5e-d0c6-4789-81a0-af9a013962b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8e0fb836-0d49-4399-9590-3967f7e2ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-c4851b63-751e-4275-8578-2c676781ffbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989861229-172.17.0.14-1599352198403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-665b2e59-55c3-4e0e-97c3-0e620aad8682,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-851acdd6-85c3-4507-af52-cdd86d71f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-733e1866-4ecf-4eed-ad6d-322e11af421b,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-b23e8fb4-bec2-43df-9668-e55b10d597b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-e5161f94-6280-46c2-9fe0-456aaced32b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-45f67e5e-d0c6-4789-81a0-af9a013962b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8e0fb836-0d49-4399-9590-3967f7e2ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-c4851b63-751e-4275-8578-2c676781ffbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33089493-172.17.0.14-1599352432915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-0e2237b3-0f5f-4c43-9a7e-e6b474795aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-d379f4a5-919f-4bdf-9fac-b513616a5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-dea28c95-47c7-43be-ab58-c79b67761c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e9b0d3d8-17c0-4bc9-8d42-b67806cc2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-638b8860-fb98-4ea3-ac07-28dc551e1287,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-f57b9f96-fdca-41fb-b731-8582c79c3cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-b3243fad-3606-474f-ac4d-c282758821b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-8ed9eff7-9b78-429a-8b4d-cafd9e7701c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33089493-172.17.0.14-1599352432915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-0e2237b3-0f5f-4c43-9a7e-e6b474795aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-d379f4a5-919f-4bdf-9fac-b513616a5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-dea28c95-47c7-43be-ab58-c79b67761c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e9b0d3d8-17c0-4bc9-8d42-b67806cc2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-638b8860-fb98-4ea3-ac07-28dc551e1287,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-f57b9f96-fdca-41fb-b731-8582c79c3cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-b3243fad-3606-474f-ac4d-c282758821b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-8ed9eff7-9b78-429a-8b4d-cafd9e7701c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187990461-172.17.0.14-1599352572982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-5209cc81-be5a-4fbb-928a-361783f2169f,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c57dbfb2-0711-4217-8217-3cf061cdc2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-fdda0fdb-aa03-44cd-b528-4cad6e4328f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-6163f4dc-752d-40d5-b00a-2347b7709577,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-d57b81b0-684d-4881-80c5-1934b482b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-5a265b44-ba24-452f-9f20-f7b76ea8ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-0c958f6f-75dd-4fff-b420-4053cd30654b,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-79b8ab49-099f-477c-9e4e-28ff118e5817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187990461-172.17.0.14-1599352572982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-5209cc81-be5a-4fbb-928a-361783f2169f,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c57dbfb2-0711-4217-8217-3cf061cdc2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-fdda0fdb-aa03-44cd-b528-4cad6e4328f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-6163f4dc-752d-40d5-b00a-2347b7709577,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-d57b81b0-684d-4881-80c5-1934b482b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-5a265b44-ba24-452f-9f20-f7b76ea8ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-0c958f6f-75dd-4fff-b420-4053cd30654b,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-79b8ab49-099f-477c-9e4e-28ff118e5817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788511115-172.17.0.14-1599352778811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-4f5e1db8-a08c-44dc-971a-881274ac93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-8c3cfd53-4ed5-4fc4-bbeb-382709c0b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-72ea69fe-5a99-4a5f-be88-14d594315323,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2ac4800e-4401-4a3d-afba-891020037c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-bdf014bb-f024-45dc-9c32-13855761f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-75f66035-ab2a-40bd-8584-94055515e456,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d47eb544-82a6-4260-95fd-17fbe6771621,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-57136633-a456-4778-9b35-97fb69526f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788511115-172.17.0.14-1599352778811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-4f5e1db8-a08c-44dc-971a-881274ac93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-8c3cfd53-4ed5-4fc4-bbeb-382709c0b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-72ea69fe-5a99-4a5f-be88-14d594315323,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2ac4800e-4401-4a3d-afba-891020037c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-bdf014bb-f024-45dc-9c32-13855761f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-75f66035-ab2a-40bd-8584-94055515e456,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d47eb544-82a6-4260-95fd-17fbe6771621,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-57136633-a456-4778-9b35-97fb69526f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666639377-172.17.0.14-1599352867675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-8199637e-b2c1-4ec2-815c-35a125495952,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-e6a6fce8-95cb-4448-8b3d-017f387a4317,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-8f0814ae-9a18-44b9-b9e4-71142d12da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c1626d5f-caaa-4f74-a46f-7616ab5f7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-f83e07d5-3f3f-4996-8515-2ab2209748f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-1f6e4177-2e60-47ba-8775-73a0b92ef7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-19612b21-20f7-406d-bb01-c6dcd88d3c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-3c8b0165-9e36-4266-9288-4af5e68bcae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666639377-172.17.0.14-1599352867675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-8199637e-b2c1-4ec2-815c-35a125495952,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-e6a6fce8-95cb-4448-8b3d-017f387a4317,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-8f0814ae-9a18-44b9-b9e4-71142d12da74,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c1626d5f-caaa-4f74-a46f-7616ab5f7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-f83e07d5-3f3f-4996-8515-2ab2209748f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-1f6e4177-2e60-47ba-8775-73a0b92ef7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-19612b21-20f7-406d-bb01-c6dcd88d3c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-3c8b0165-9e36-4266-9288-4af5e68bcae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165402285-172.17.0.14-1599353028707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-de729f41-b383-4e17-bc49-7ad4404401f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-68af984a-59d2-4d22-9e1d-30f5dc8889a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-ecdab18d-0271-49a9-b681-950ec947a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-a801073a-0103-4829-9f18-310abebfefbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a8b18c12-45ed-42a5-ac83-205ba73a6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-eee2c961-ffe8-43f7-bb7b-2611fdb1826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-0e669d16-ceb6-41c1-88ea-9509cdbe3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a8397880-9e8c-4a1f-82cc-b048054ea3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165402285-172.17.0.14-1599353028707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-de729f41-b383-4e17-bc49-7ad4404401f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-68af984a-59d2-4d22-9e1d-30f5dc8889a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-ecdab18d-0271-49a9-b681-950ec947a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-a801073a-0103-4829-9f18-310abebfefbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a8b18c12-45ed-42a5-ac83-205ba73a6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-eee2c961-ffe8-43f7-bb7b-2611fdb1826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-0e669d16-ceb6-41c1-88ea-9509cdbe3a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a8397880-9e8c-4a1f-82cc-b048054ea3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73837487-172.17.0.14-1599353156275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-16df2a0b-0206-49d0-8f58-a67db1c261c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-fb5d429d-ff23-499c-8b4d-27d3f3205aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-a426c6e2-d098-4be9-8f1e-ebc9e2450f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-36d328ff-9759-4d6d-99b5-915776de4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-24364711-a06a-4724-89ca-c41d06435716,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-37a6c9ed-7ed0-4f67-824a-d5d7ce27b523,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-28f5e518-078c-4358-91f7-9022875ad01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-c911d1d9-df2c-4f75-8e0b-a7f362033dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73837487-172.17.0.14-1599353156275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34819,DS-16df2a0b-0206-49d0-8f58-a67db1c261c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-fb5d429d-ff23-499c-8b4d-27d3f3205aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-a426c6e2-d098-4be9-8f1e-ebc9e2450f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-36d328ff-9759-4d6d-99b5-915776de4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-24364711-a06a-4724-89ca-c41d06435716,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-37a6c9ed-7ed0-4f67-824a-d5d7ce27b523,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-28f5e518-078c-4358-91f7-9022875ad01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-c911d1d9-df2c-4f75-8e0b-a7f362033dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: integrity
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484742752-172.17.0.14-1599353565180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-d9079c52-15d0-49c7-8214-96e32428989a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-0b383b11-c0d9-4632-b01a-a71689d30224,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-b290c9e4-cd89-41dc-ae92-3bedc7dddce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-75d2a81e-f4ef-4eb8-a9bb-db901fac5593,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-48845eb7-0b99-44c3-a57e-4c51440e6871,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-c374fd73-369e-4a17-804a-5c96aa3f2d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-8a8888dd-37ab-4bdb-981e-32f2c8b27688,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-42493e6b-1032-4c0c-873f-b6c35ac0888f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484742752-172.17.0.14-1599353565180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-d9079c52-15d0-49c7-8214-96e32428989a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-0b383b11-c0d9-4632-b01a-a71689d30224,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-b290c9e4-cd89-41dc-ae92-3bedc7dddce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-75d2a81e-f4ef-4eb8-a9bb-db901fac5593,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-48845eb7-0b99-44c3-a57e-4c51440e6871,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-c374fd73-369e-4a17-804a-5c96aa3f2d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-8a8888dd-37ab-4bdb-981e-32f2c8b27688,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-42493e6b-1032-4c0c-873f-b6c35ac0888f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5021
