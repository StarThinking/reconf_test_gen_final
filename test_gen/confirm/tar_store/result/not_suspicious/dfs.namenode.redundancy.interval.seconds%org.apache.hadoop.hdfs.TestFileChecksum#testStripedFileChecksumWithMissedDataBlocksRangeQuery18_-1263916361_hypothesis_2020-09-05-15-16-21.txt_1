reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106812869-172.17.0.14-1599319182306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35505,DS-bf1fd59e-2756-44b8-9eac-ea11a7cd9790,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-405aaa39-8dc0-4f86-87e2-a6e5b731a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-721bc757-dd28-4831-9a01-7eb6773ad7da,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-65b51c12-65c6-4d9b-870e-3e3cf0d64bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-80a0fd0e-c41e-4f26-83fd-979d410c8cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-40ca8286-f67e-42d1-904f-0acc67679eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-385395e8-2927-4e6e-a993-abc84435c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-c8d9f8ba-134b-47d8-8137-a0bf2d196a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106812869-172.17.0.14-1599319182306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35505,DS-bf1fd59e-2756-44b8-9eac-ea11a7cd9790,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-405aaa39-8dc0-4f86-87e2-a6e5b731a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-721bc757-dd28-4831-9a01-7eb6773ad7da,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-65b51c12-65c6-4d9b-870e-3e3cf0d64bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-80a0fd0e-c41e-4f26-83fd-979d410c8cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-40ca8286-f67e-42d1-904f-0acc67679eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-385395e8-2927-4e6e-a993-abc84435c88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-c8d9f8ba-134b-47d8-8137-a0bf2d196a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863920001-172.17.0.14-1599319294788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34983,DS-79ac84e7-7ac5-4fac-bc0b-72732922bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-cec86ebe-9b38-4c5a-97ba-a7b4aba0d999,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-281988bd-b586-49f6-9451-d0bd20f2c232,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-234b123a-3b0f-4fe3-980c-df32ff05af80,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-9721b07f-6dd0-4573-acf4-7e54e3dbe96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-884e0f1a-39f5-4d2a-832b-5206b236ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-248a2472-c662-4c8a-8b96-93442484c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-42edab66-4bce-4681-ac51-082db187f351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863920001-172.17.0.14-1599319294788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34983,DS-79ac84e7-7ac5-4fac-bc0b-72732922bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-cec86ebe-9b38-4c5a-97ba-a7b4aba0d999,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-281988bd-b586-49f6-9451-d0bd20f2c232,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-234b123a-3b0f-4fe3-980c-df32ff05af80,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-9721b07f-6dd0-4573-acf4-7e54e3dbe96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-884e0f1a-39f5-4d2a-832b-5206b236ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-248a2472-c662-4c8a-8b96-93442484c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-42edab66-4bce-4681-ac51-082db187f351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463582978-172.17.0.14-1599319412902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-cc60a7d4-8822-41a8-8b3d-8d5c654ad26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-7f90a35c-f34e-41c7-a350-9bbe38d6e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-54ebf88f-1568-4480-8792-945efd4681c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-58967849-6804-47af-88c9-dc4094715ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-6fdbb3d1-5e64-4da4-8400-f57685ca2494,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-0a00c8fa-2b9c-4855-98f2-adaf5f5f0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-e07ff2b9-5e82-4de7-89d1-1d2d741ab497,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8aeaef2f-ea8c-4265-b006-6db76d3701b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463582978-172.17.0.14-1599319412902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-cc60a7d4-8822-41a8-8b3d-8d5c654ad26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-7f90a35c-f34e-41c7-a350-9bbe38d6e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-54ebf88f-1568-4480-8792-945efd4681c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-58967849-6804-47af-88c9-dc4094715ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-6fdbb3d1-5e64-4da4-8400-f57685ca2494,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-0a00c8fa-2b9c-4855-98f2-adaf5f5f0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-e07ff2b9-5e82-4de7-89d1-1d2d741ab497,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8aeaef2f-ea8c-4265-b006-6db76d3701b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602187350-172.17.0.14-1599319586386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-df12b6ae-f0d6-4ea9-9adf-51394689ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-a4918c62-399e-46c6-b73e-07959ac5cdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-b7716775-8765-444e-9e86-ca0c32f9fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-fa14ab38-df4f-42ab-850b-cfa9f7b57c41,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-66d91b98-110f-4b99-8aab-5304105b40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-dece1753-b455-4323-bf39-e06238a5aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-18b6ba2b-58c9-4970-9fcc-fc5ee247d109,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-2ffcffbb-eff3-44ec-9440-5c5d4f41365d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602187350-172.17.0.14-1599319586386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-df12b6ae-f0d6-4ea9-9adf-51394689ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-a4918c62-399e-46c6-b73e-07959ac5cdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-b7716775-8765-444e-9e86-ca0c32f9fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-fa14ab38-df4f-42ab-850b-cfa9f7b57c41,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-66d91b98-110f-4b99-8aab-5304105b40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-dece1753-b455-4323-bf39-e06238a5aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-18b6ba2b-58c9-4970-9fcc-fc5ee247d109,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-2ffcffbb-eff3-44ec-9440-5c5d4f41365d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433985954-172.17.0.14-1599320087095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-661c4a63-54fa-42b9-8926-8699b69cc9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-f2eafe4b-016c-48d5-ab97-7f15f4e3043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c6721d1d-0bc6-4a14-9755-6d4dc6929850,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-3abac71a-1ec2-420b-93ce-116b52b3a178,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-87530897-de8c-4309-948c-a38b30a556ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-e461f002-d539-4d89-9f5b-f82fee664dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-421d939e-ecc9-4d3b-975b-c21df82c2057,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-e71e7a18-d245-40be-b145-501e1e98af3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433985954-172.17.0.14-1599320087095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-661c4a63-54fa-42b9-8926-8699b69cc9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-f2eafe4b-016c-48d5-ab97-7f15f4e3043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c6721d1d-0bc6-4a14-9755-6d4dc6929850,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-3abac71a-1ec2-420b-93ce-116b52b3a178,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-87530897-de8c-4309-948c-a38b30a556ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-e461f002-d539-4d89-9f5b-f82fee664dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-421d939e-ecc9-4d3b-975b-c21df82c2057,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-e71e7a18-d245-40be-b145-501e1e98af3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354210965-172.17.0.14-1599320143637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-05eb89ce-d2c7-4b51-8d3f-188095b9ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-d97151d6-3e4d-45ea-9661-65b2e55f5ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-6facb922-648e-4114-bcbf-654dc72f8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-45e47901-edda-465b-9826-9450f915e040,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-d04ecfc1-2e6a-4876-90f8-00265a2efd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-dc5e0ba7-f85b-44e6-a80a-67e0eed0c992,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-55f2f4c2-62fc-4b5b-abd8-cd90cad3674e,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-fc927e5b-844f-4bda-896e-9972b24f31c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354210965-172.17.0.14-1599320143637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-05eb89ce-d2c7-4b51-8d3f-188095b9ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-d97151d6-3e4d-45ea-9661-65b2e55f5ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-6facb922-648e-4114-bcbf-654dc72f8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-45e47901-edda-465b-9826-9450f915e040,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-d04ecfc1-2e6a-4876-90f8-00265a2efd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-dc5e0ba7-f85b-44e6-a80a-67e0eed0c992,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-55f2f4c2-62fc-4b5b-abd8-cd90cad3674e,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-fc927e5b-844f-4bda-896e-9972b24f31c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920091617-172.17.0.14-1599320278629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44773,DS-b16cc6d1-d3ee-4d51-b271-329a9a1d7c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-16ed8c91-b532-45fb-b34a-4652fce95091,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-879c3853-3222-4dd5-a82b-b8d23484938d,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-03083bdc-fb05-4dbb-935f-d934fd8c8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-6b490078-c26c-4d4f-a0b9-088808e1eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-32797b85-448c-4438-a832-3076f97a7e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-c0c888a0-5c41-4dc0-bbf3-92e1d42371c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-57303156-37f7-49cc-a210-624826c4fd54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920091617-172.17.0.14-1599320278629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44773,DS-b16cc6d1-d3ee-4d51-b271-329a9a1d7c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-16ed8c91-b532-45fb-b34a-4652fce95091,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-879c3853-3222-4dd5-a82b-b8d23484938d,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-03083bdc-fb05-4dbb-935f-d934fd8c8dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-6b490078-c26c-4d4f-a0b9-088808e1eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-32797b85-448c-4438-a832-3076f97a7e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-c0c888a0-5c41-4dc0-bbf3-92e1d42371c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-57303156-37f7-49cc-a210-624826c4fd54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497819609-172.17.0.14-1599320540564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-719a672d-3fb4-4356-9209-e54805ed70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-85b845c7-105d-4794-bd28-febda5057140,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e422b3b1-2551-42c6-8ab6-68845bfd0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-e5b8fe2e-9597-450f-a463-f3b45f56fe74,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-5eb796cd-27e7-4aeb-90cd-ab38fc8fe363,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-392e7576-e83f-4cb2-8739-20ba157506cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-52e97c73-35dd-4250-8405-168a4e326439,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-be7e1f4b-3a79-4f39-a24c-4f4d26987cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497819609-172.17.0.14-1599320540564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-719a672d-3fb4-4356-9209-e54805ed70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-85b845c7-105d-4794-bd28-febda5057140,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e422b3b1-2551-42c6-8ab6-68845bfd0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-e5b8fe2e-9597-450f-a463-f3b45f56fe74,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-5eb796cd-27e7-4aeb-90cd-ab38fc8fe363,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-392e7576-e83f-4cb2-8739-20ba157506cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-52e97c73-35dd-4250-8405-168a4e326439,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-be7e1f4b-3a79-4f39-a24c-4f4d26987cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649006428-172.17.0.14-1599320627682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-bc5b7b1a-5054-4ada-ab40-b6b0a07f287f,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bcec593e-99fc-4805-91e4-307a62354e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-f11f5579-cc32-49a3-852e-0643fde6f598,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-58de7b53-015e-4ea7-a4d4-c6989447f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-00ad00ee-a4bf-4a0f-b547-a3b9ff8f9b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b4aec54d-760f-413e-9522-aeac7ffddacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-329a64cf-56a9-403e-8e91-ebab325713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-962ce5f8-ae73-438a-a6d8-739cac1b5122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649006428-172.17.0.14-1599320627682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-bc5b7b1a-5054-4ada-ab40-b6b0a07f287f,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bcec593e-99fc-4805-91e4-307a62354e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-f11f5579-cc32-49a3-852e-0643fde6f598,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-58de7b53-015e-4ea7-a4d4-c6989447f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-00ad00ee-a4bf-4a0f-b547-a3b9ff8f9b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b4aec54d-760f-413e-9522-aeac7ffddacb,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-329a64cf-56a9-403e-8e91-ebab325713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-962ce5f8-ae73-438a-a6d8-739cac1b5122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036330334-172.17.0.14-1599321075336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-451675d0-954a-40d3-bfc2-92b70e13b6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-d8d8b171-ed89-4b45-9ad3-0fc83c047c46,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-2f227ca9-eab7-4cd1-8797-57fc64e7b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-edfb4809-bc0c-446c-8839-6414e960d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-5054f2e7-3da4-4b87-86dc-20e8b0c62ede,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-6af7194c-6d2d-40f4-9e79-26959e36f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-61e573e0-7003-4daf-9757-9db93902971b,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-497e87af-2772-44a9-8ecc-a8595e523ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036330334-172.17.0.14-1599321075336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42299,DS-451675d0-954a-40d3-bfc2-92b70e13b6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-d8d8b171-ed89-4b45-9ad3-0fc83c047c46,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-2f227ca9-eab7-4cd1-8797-57fc64e7b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-edfb4809-bc0c-446c-8839-6414e960d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-5054f2e7-3da4-4b87-86dc-20e8b0c62ede,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-6af7194c-6d2d-40f4-9e79-26959e36f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-61e573e0-7003-4daf-9757-9db93902971b,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-497e87af-2772-44a9-8ecc-a8595e523ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069290561-172.17.0.14-1599321462552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-4c63a53f-9f65-4a36-81bd-b4c55d991942,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-831faa46-fb28-4339-9659-e2b91a087a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-73d84032-96e9-4213-ad72-22cbba37f839,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-6ea4efd5-43a8-4325-92be-8cb3c7673bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4dc596b0-da28-4b31-a06b-214645059365,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-e8706d82-0ea6-450d-8804-908c82984421,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-40a6f395-7666-47ff-91bc-46706c5c7552,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-82e387c0-0806-4d32-83c2-2a4233cb591c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069290561-172.17.0.14-1599321462552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-4c63a53f-9f65-4a36-81bd-b4c55d991942,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-831faa46-fb28-4339-9659-e2b91a087a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-73d84032-96e9-4213-ad72-22cbba37f839,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-6ea4efd5-43a8-4325-92be-8cb3c7673bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4dc596b0-da28-4b31-a06b-214645059365,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-e8706d82-0ea6-450d-8804-908c82984421,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-40a6f395-7666-47ff-91bc-46706c5c7552,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-82e387c0-0806-4d32-83c2-2a4233cb591c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789038022-172.17.0.14-1599321520832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-5d7cabe8-7599-4726-85e2-388fc5b78562,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-298f72ee-b0e7-4756-9280-e2b3eb26a434,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-9dd84b4c-ecfc-4fbf-988c-f0d2d556f404,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-97425886-9392-450e-b132-ed941c1800ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5c11e2fc-8ced-42b5-9428-4ba86b4b335c,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-81a34565-43de-4020-ac42-a4f19b2d4213,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-74834586-0582-454a-8b01-6f106dc751c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f593cbe9-4008-44d6-99b9-a868e789580f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789038022-172.17.0.14-1599321520832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-5d7cabe8-7599-4726-85e2-388fc5b78562,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-298f72ee-b0e7-4756-9280-e2b3eb26a434,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-9dd84b4c-ecfc-4fbf-988c-f0d2d556f404,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-97425886-9392-450e-b132-ed941c1800ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5c11e2fc-8ced-42b5-9428-4ba86b4b335c,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-81a34565-43de-4020-ac42-a4f19b2d4213,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-74834586-0582-454a-8b01-6f106dc751c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f593cbe9-4008-44d6-99b9-a868e789580f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705749823-172.17.0.14-1599321698995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-3b21973f-4128-436e-bb95-df6a0a6ad2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-d30969e9-8d34-4eaf-a3f2-ec2a01914464,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-2b87325b-68d4-44ec-a0bf-3a07443ecf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-0c40fae9-43a7-4802-af85-c24515c6111f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-da3da25e-c36a-4626-a2b8-81dac9590080,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-904dcec4-9b6f-4fc4-a837-6d50d7868f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-fa2208fa-f056-4b8d-a6ec-e9878c1cafa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-5b98a598-e3d5-4bc4-9d11-b261ade84753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705749823-172.17.0.14-1599321698995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-3b21973f-4128-436e-bb95-df6a0a6ad2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-d30969e9-8d34-4eaf-a3f2-ec2a01914464,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-2b87325b-68d4-44ec-a0bf-3a07443ecf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-0c40fae9-43a7-4802-af85-c24515c6111f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-da3da25e-c36a-4626-a2b8-81dac9590080,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-904dcec4-9b6f-4fc4-a837-6d50d7868f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-fa2208fa-f056-4b8d-a6ec-e9878c1cafa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-5b98a598-e3d5-4bc4-9d11-b261ade84753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622286283-172.17.0.14-1599321840387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-e84ce567-3883-44ca-9acd-65e0d613a146,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-5f5b5372-7c64-4797-9989-434ee1fa0424,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-3d7de42d-f1a3-408c-84da-5b04a7741943,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5c586b3f-e4e4-4e07-a226-b005aec16579,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-123b8a9f-6f4a-415d-8804-9e987cc1b871,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-edbd011d-c130-45e4-912c-8a8184c4c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-892e9724-8193-43ac-87ce-7211acb299fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-885db444-4a9f-4b29-85b0-7f67b07a513a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622286283-172.17.0.14-1599321840387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-e84ce567-3883-44ca-9acd-65e0d613a146,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-5f5b5372-7c64-4797-9989-434ee1fa0424,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-3d7de42d-f1a3-408c-84da-5b04a7741943,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5c586b3f-e4e4-4e07-a226-b005aec16579,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-123b8a9f-6f4a-415d-8804-9e987cc1b871,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-edbd011d-c130-45e4-912c-8a8184c4c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-892e9724-8193-43ac-87ce-7211acb299fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-885db444-4a9f-4b29-85b0-7f67b07a513a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254110678-172.17.0.14-1599321927073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-c1529fa2-3c39-4711-9b92-409a60df03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-8c83ef3e-7bce-484c-9302-41d68b6918f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d1d1f637-fdb6-446d-8fa0-bb18180c224c,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-165590a1-e1f5-48fb-b237-aaabbfa477c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-34bd3b0a-c04d-4033-a803-d3b32c8ea0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-ff9e26d0-657f-4795-932b-64b7bda1ea83,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-b14dfe2b-b374-4545-859d-cf817e8985b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-15b22ef2-c4ac-4eb2-9343-b339ff732afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254110678-172.17.0.14-1599321927073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-c1529fa2-3c39-4711-9b92-409a60df03d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-8c83ef3e-7bce-484c-9302-41d68b6918f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d1d1f637-fdb6-446d-8fa0-bb18180c224c,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-165590a1-e1f5-48fb-b237-aaabbfa477c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-34bd3b0a-c04d-4033-a803-d3b32c8ea0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-ff9e26d0-657f-4795-932b-64b7bda1ea83,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-b14dfe2b-b374-4545-859d-cf817e8985b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-15b22ef2-c4ac-4eb2-9343-b339ff732afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611133176-172.17.0.14-1599322158921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41334,DS-3e4ad8e0-2010-4820-8359-46bc960172d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-9f38dab9-b22e-4800-ad76-f26f896dd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-ab5d7b66-8316-4649-a211-03f562050f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-78cf9998-0c48-4ecb-9799-6d7ddd5c7ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-6debeed9-22e3-406e-bbbd-8d9d885c2390,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-23a55d56-741c-44f5-aff0-199296671128,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-b10db630-eb89-4e27-bbeb-6e6c145bfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-009d2c25-ff8d-4583-8b16-926c7a572a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611133176-172.17.0.14-1599322158921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41334,DS-3e4ad8e0-2010-4820-8359-46bc960172d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-9f38dab9-b22e-4800-ad76-f26f896dd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-ab5d7b66-8316-4649-a211-03f562050f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-78cf9998-0c48-4ecb-9799-6d7ddd5c7ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-6debeed9-22e3-406e-bbbd-8d9d885c2390,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-23a55d56-741c-44f5-aff0-199296671128,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-b10db630-eb89-4e27-bbeb-6e6c145bfdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-009d2c25-ff8d-4583-8b16-926c7a572a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37939301-172.17.0.14-1599322269626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37789,DS-b911fce1-227b-4af6-bc56-0302c36e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-76aa5524-5cdc-4ae2-a9ba-b8f1da643dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-115160df-814a-4a03-9332-00efdbd5eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-045f1d0c-7783-4410-ab17-62be80f5a7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-922949cc-c2f9-4935-8d94-b03935023cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-5e128539-e151-437b-ae1e-e8e9ead05bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-d991a4c2-01d1-4e12-9f59-9c15e9a17ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-a5342ce0-2225-451b-9ca7-571341936c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37939301-172.17.0.14-1599322269626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37789,DS-b911fce1-227b-4af6-bc56-0302c36e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-76aa5524-5cdc-4ae2-a9ba-b8f1da643dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-115160df-814a-4a03-9332-00efdbd5eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-045f1d0c-7783-4410-ab17-62be80f5a7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-922949cc-c2f9-4935-8d94-b03935023cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-5e128539-e151-437b-ae1e-e8e9ead05bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-d991a4c2-01d1-4e12-9f59-9c15e9a17ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-a5342ce0-2225-451b-9ca7-571341936c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630433093-172.17.0.14-1599322770550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45340,DS-af63b7c2-558d-41ca-a224-0df1c9487218,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-ad7411cc-3230-4af7-a576-70e0eca74c11,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-6e6116fe-bab2-4c29-b405-d87c42fce995,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-21bc165f-d21d-4267-ba70-e8e297bb4537,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-99d608d1-946f-4f7e-b3fd-b8a50d455752,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-43409482-d270-487b-874d-899ba23a6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c2315421-b840-40fa-83c6-c8d02d0cfa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-875f67fe-0a41-4bbf-9227-6f55c7bd1b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630433093-172.17.0.14-1599322770550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45340,DS-af63b7c2-558d-41ca-a224-0df1c9487218,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-ad7411cc-3230-4af7-a576-70e0eca74c11,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-6e6116fe-bab2-4c29-b405-d87c42fce995,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-21bc165f-d21d-4267-ba70-e8e297bb4537,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-99d608d1-946f-4f7e-b3fd-b8a50d455752,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-43409482-d270-487b-874d-899ba23a6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c2315421-b840-40fa-83c6-c8d02d0cfa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-875f67fe-0a41-4bbf-9227-6f55c7bd1b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026016785-172.17.0.14-1599323195147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-33bd888b-96a3-4ccc-9863-a975294c7c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-cf0362f3-050d-404d-8d90-b9561da2742b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-5573771a-f8c1-4cf3-87dc-4240b061826b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-31945b67-cb0a-4ce7-b3e1-8ed36027c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-5bc2701c-e2b0-4295-b8a6-303d65a348b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-1d1d8590-3b77-4513-a00f-50d555a4ec68,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e61a9dab-96b1-4268-be8e-f4842276eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-d76bbc1c-55ae-4122-8e07-90aad162363e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026016785-172.17.0.14-1599323195147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-33bd888b-96a3-4ccc-9863-a975294c7c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-cf0362f3-050d-404d-8d90-b9561da2742b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-5573771a-f8c1-4cf3-87dc-4240b061826b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-31945b67-cb0a-4ce7-b3e1-8ed36027c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-5bc2701c-e2b0-4295-b8a6-303d65a348b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-1d1d8590-3b77-4513-a00f-50d555a4ec68,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e61a9dab-96b1-4268-be8e-f4842276eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-d76bbc1c-55ae-4122-8e07-90aad162363e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4257
