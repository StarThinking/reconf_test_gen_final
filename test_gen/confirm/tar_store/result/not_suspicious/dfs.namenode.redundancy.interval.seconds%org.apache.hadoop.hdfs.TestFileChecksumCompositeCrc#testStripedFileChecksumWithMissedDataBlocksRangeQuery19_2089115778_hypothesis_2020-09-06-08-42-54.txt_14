reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442914124-172.17.0.8-1599382418959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40641,DS-991e60e1-b32b-4efb-a1e0-68b426125073,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-91997f85-c0af-4da3-9fa3-13b7dc8bd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-c33ef80e-e5f5-4b82-8d92-d4103e7cbd19,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-52b083f2-7c1b-4bde-ba1c-ba6a619dfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-11ab0abc-a0d9-4a2b-8538-68e5bf136058,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-b6cc5967-3add-40ba-9050-9f659836f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-6f35a876-673b-4846-9679-91444f1021e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-78b05de8-cf6d-4e20-885d-c7d69158101b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442914124-172.17.0.8-1599382418959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40641,DS-991e60e1-b32b-4efb-a1e0-68b426125073,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-91997f85-c0af-4da3-9fa3-13b7dc8bd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-c33ef80e-e5f5-4b82-8d92-d4103e7cbd19,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-52b083f2-7c1b-4bde-ba1c-ba6a619dfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-11ab0abc-a0d9-4a2b-8538-68e5bf136058,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-b6cc5967-3add-40ba-9050-9f659836f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-6f35a876-673b-4846-9679-91444f1021e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-78b05de8-cf6d-4e20-885d-c7d69158101b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818738837-172.17.0.8-1599382749031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-33340dbf-c829-4bb6-8507-acbe93965024,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-98fb96ea-cace-4b7e-8d9a-0b780168fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-fb9ad2d4-8342-4d99-b8c3-0c30c1a08302,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-9b518457-0674-46e4-b420-21e6d69f8413,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-5975ad37-0dc0-41c1-b843-756eb492e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-be694a4a-348d-43e4-a955-981da9138ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-567b5f27-3760-490c-a9ec-00505c1542fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-71be95ed-bc66-48fc-9fb3-1a9c1b1097a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818738837-172.17.0.8-1599382749031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-33340dbf-c829-4bb6-8507-acbe93965024,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-98fb96ea-cace-4b7e-8d9a-0b780168fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-fb9ad2d4-8342-4d99-b8c3-0c30c1a08302,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-9b518457-0674-46e4-b420-21e6d69f8413,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-5975ad37-0dc0-41c1-b843-756eb492e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-be694a4a-348d-43e4-a955-981da9138ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-567b5f27-3760-490c-a9ec-00505c1542fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-71be95ed-bc66-48fc-9fb3-1a9c1b1097a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246629970-172.17.0.8-1599382958154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-4a27f463-15c6-47a2-ab42-5958f7fe31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-1164a924-0b69-4719-a2ef-f3aec0a84471,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-212e578d-6336-4e1f-9d9a-5bf5dc1e6b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-98c1d8fb-fa28-4d9a-91dd-4ce87f60cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-e1eabac5-8a1d-48f8-a267-594734ac3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-1931a14a-a5da-4226-9875-404dca2b620e,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-46fde9d9-257e-416f-85c2-1b7c6383eba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-61bec154-d8cf-4f4a-81d0-8b1782b47135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246629970-172.17.0.8-1599382958154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-4a27f463-15c6-47a2-ab42-5958f7fe31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-1164a924-0b69-4719-a2ef-f3aec0a84471,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-212e578d-6336-4e1f-9d9a-5bf5dc1e6b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-98c1d8fb-fa28-4d9a-91dd-4ce87f60cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-e1eabac5-8a1d-48f8-a267-594734ac3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-1931a14a-a5da-4226-9875-404dca2b620e,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-46fde9d9-257e-416f-85c2-1b7c6383eba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-61bec154-d8cf-4f4a-81d0-8b1782b47135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459712947-172.17.0.8-1599383045972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-56d06fc5-3b14-4cde-82dc-7c11bb399702,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-b02a6342-003d-4a43-837d-6146652d0138,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-97e03562-e6fd-44b0-a0b0-a70b24a04f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a0ea4d60-5d79-4353-8ba4-263400b81072,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-d4ba6503-92dd-4585-865e-2fec5183cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-75b4c54f-c057-4f21-8d5c-ba5084beef08,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-acc52e64-2c40-40d4-9c9b-ada64f62eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-325a9dc6-6de3-4088-84ad-9bf5c9175b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459712947-172.17.0.8-1599383045972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-56d06fc5-3b14-4cde-82dc-7c11bb399702,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-b02a6342-003d-4a43-837d-6146652d0138,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-97e03562-e6fd-44b0-a0b0-a70b24a04f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a0ea4d60-5d79-4353-8ba4-263400b81072,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-d4ba6503-92dd-4585-865e-2fec5183cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-75b4c54f-c057-4f21-8d5c-ba5084beef08,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-acc52e64-2c40-40d4-9c9b-ada64f62eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-325a9dc6-6de3-4088-84ad-9bf5c9175b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566388814-172.17.0.8-1599383834101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-9f242d45-a463-4f4c-a39f-045cb0ef66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-73973440-a33f-44d8-923c-0c8dfee09969,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-de180e66-7e92-4ded-babd-02f24cf2e405,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-6b790414-a1f9-47b6-ba94-a41ab0df9e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-a95d30b6-70e9-4258-ac2e-d118ba47665d,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-32a7fec3-c8d1-4e66-a351-2237e1e92426,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-42e4d4a5-2aee-4c05-9f54-89085b041ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b437525c-7a1c-4115-8a66-11fb6e6dffe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566388814-172.17.0.8-1599383834101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-9f242d45-a463-4f4c-a39f-045cb0ef66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-73973440-a33f-44d8-923c-0c8dfee09969,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-de180e66-7e92-4ded-babd-02f24cf2e405,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-6b790414-a1f9-47b6-ba94-a41ab0df9e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-a95d30b6-70e9-4258-ac2e-d118ba47665d,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-32a7fec3-c8d1-4e66-a351-2237e1e92426,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-42e4d4a5-2aee-4c05-9f54-89085b041ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-b437525c-7a1c-4115-8a66-11fb6e6dffe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717293963-172.17.0.8-1599383972350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-ba7d00bf-426f-4e74-b9bc-e22263351ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-811120f6-71c7-41de-af38-904cfdba3206,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-264992b6-3c2f-4661-add5-49c46c298540,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c32a33d4-7a54-4dd8-9089-1dbed8aefa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-98594eff-ab29-418f-983f-cbe16074e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-1e6cc8c9-2773-468c-8fb0-2710054ace2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-5452fda9-526e-4aaa-958c-b323e14133f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f476843e-0a2d-4770-88a4-2227364a37f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717293963-172.17.0.8-1599383972350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-ba7d00bf-426f-4e74-b9bc-e22263351ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-811120f6-71c7-41de-af38-904cfdba3206,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-264992b6-3c2f-4661-add5-49c46c298540,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c32a33d4-7a54-4dd8-9089-1dbed8aefa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-98594eff-ab29-418f-983f-cbe16074e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-1e6cc8c9-2773-468c-8fb0-2710054ace2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-5452fda9-526e-4aaa-958c-b323e14133f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f476843e-0a2d-4770-88a4-2227364a37f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547605559-172.17.0.8-1599384712301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-57abe02d-2c58-408b-89e1-ba8ddbbe688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-17a05531-73d5-4c07-8c2c-db9c211b7c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-83133cbc-a110-4c22-a936-7cd5ccc24c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-d07a5c8f-2752-48e2-90af-6fd6bf1b734e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b6baa646-6344-4568-a3c3-32a3eb40ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-dc1f1e7d-26a0-4973-ac0b-4235fbc51a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-d0762fd2-14ac-4a80-a70b-e41170550170,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-eacfdeed-2292-406a-82ea-b58d39cce492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547605559-172.17.0.8-1599384712301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-57abe02d-2c58-408b-89e1-ba8ddbbe688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-17a05531-73d5-4c07-8c2c-db9c211b7c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-83133cbc-a110-4c22-a936-7cd5ccc24c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-d07a5c8f-2752-48e2-90af-6fd6bf1b734e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b6baa646-6344-4568-a3c3-32a3eb40ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-dc1f1e7d-26a0-4973-ac0b-4235fbc51a95,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-d0762fd2-14ac-4a80-a70b-e41170550170,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-eacfdeed-2292-406a-82ea-b58d39cce492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797590104-172.17.0.8-1599384927235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-b38b1a48-b743-4f93-ae30-78b820bd56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-c3223d03-9eb7-4802-b770-2de93376ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-7b6ac787-d0e6-4bde-a75c-138414587096,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-1d012c04-1705-40be-a3b8-69422aeade3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-5a894a11-60f7-46ba-ad7e-2ca9a2fd95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-108ae777-1881-4a12-bc93-49e266f48156,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-73f86791-4f56-4ff9-8cd7-15eeb1d9752e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-78bacd70-4b2b-4217-a869-46ece06cc403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797590104-172.17.0.8-1599384927235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-b38b1a48-b743-4f93-ae30-78b820bd56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-c3223d03-9eb7-4802-b770-2de93376ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-7b6ac787-d0e6-4bde-a75c-138414587096,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-1d012c04-1705-40be-a3b8-69422aeade3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-5a894a11-60f7-46ba-ad7e-2ca9a2fd95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-108ae777-1881-4a12-bc93-49e266f48156,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-73f86791-4f56-4ff9-8cd7-15eeb1d9752e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-78bacd70-4b2b-4217-a869-46ece06cc403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308057543-172.17.0.8-1599385301090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43713,DS-a30370c4-93b2-4c7f-92e2-c226c41739a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-7eb693c8-79bc-4ade-bec1-06d572b92a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-8f2c3e11-28b4-43f3-9fc2-dbbc0f81148c,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b3c32750-341a-45e1-a939-f16ead58651e,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-dcd9ae05-b7aa-425c-a570-263bbc758160,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-e58e24a4-286f-412b-a3f1-43d98473f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-af4dc2ca-5b73-4dad-8ec9-4cb2cf667606,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-743e9a07-ab95-4b56-8c60-1d41ae00560c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308057543-172.17.0.8-1599385301090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43713,DS-a30370c4-93b2-4c7f-92e2-c226c41739a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-7eb693c8-79bc-4ade-bec1-06d572b92a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-8f2c3e11-28b4-43f3-9fc2-dbbc0f81148c,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b3c32750-341a-45e1-a939-f16ead58651e,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-dcd9ae05-b7aa-425c-a570-263bbc758160,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-e58e24a4-286f-412b-a3f1-43d98473f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-af4dc2ca-5b73-4dad-8ec9-4cb2cf667606,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-743e9a07-ab95-4b56-8c60-1d41ae00560c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317579641-172.17.0.8-1599385559603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-869f8fe5-4994-4916-90cc-c6f42bde49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-b363fa77-bad6-4f25-9204-100e3ca2f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-7c2d83fa-3dba-49d7-91dd-92f1a570ae51,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-cf87c3a3-cffd-45e7-b3f0-b8910ed2232a,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d5ded9c5-11d3-41fa-9d4c-7790bf54b101,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-3c99bfac-53f3-49cc-917d-0ccc079d9084,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-c8f410f0-e0cd-4d96-8785-e483e996d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-20a9edbb-6113-417f-be9b-37e0d3e9988d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317579641-172.17.0.8-1599385559603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-869f8fe5-4994-4916-90cc-c6f42bde49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-b363fa77-bad6-4f25-9204-100e3ca2f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-7c2d83fa-3dba-49d7-91dd-92f1a570ae51,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-cf87c3a3-cffd-45e7-b3f0-b8910ed2232a,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d5ded9c5-11d3-41fa-9d4c-7790bf54b101,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-3c99bfac-53f3-49cc-917d-0ccc079d9084,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-c8f410f0-e0cd-4d96-8785-e483e996d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-20a9edbb-6113-417f-be9b-37e0d3e9988d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
Warn: test org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19 has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107112282-172.17.0.8-1599386738258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-5453bcec-1b66-44c0-b9a3-a0e8fced1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-6d59742c-cc70-483a-a088-e85dc5156daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-1717ead8-2a38-4739-9732-76af76eda060,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-3c8aa103-5f73-4c36-8974-e4261ff2c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fa9f1a0d-58e8-4dca-b6ca-badf6c876e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-09a6f8aa-9d4f-4476-af89-8eb745a262ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-2677be9f-bf5d-4297-82dc-962dc95a75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-384d6942-7897-445e-ad9b-f35fb5707e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107112282-172.17.0.8-1599386738258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-5453bcec-1b66-44c0-b9a3-a0e8fced1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-6d59742c-cc70-483a-a088-e85dc5156daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-1717ead8-2a38-4739-9732-76af76eda060,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-3c8aa103-5f73-4c36-8974-e4261ff2c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fa9f1a0d-58e8-4dca-b6ca-badf6c876e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-09a6f8aa-9d4f-4476-af89-8eb745a262ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-2677be9f-bf5d-4297-82dc-962dc95a75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-384d6942-7897-445e-ad9b-f35fb5707e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019941925-172.17.0.8-1599386820628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-8e2b5b39-6ec1-4f98-9c60-b63f9198bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-9649d89b-9ddb-422f-8dc4-f2c967006fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1b6d0a74-b2de-4756-b29e-1ab0b26665e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-c6ead79e-f861-449f-8394-01c9a7bc6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-458d610c-bca2-4447-8b25-ed8f68bc776e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-d32003ad-5332-4de4-b0b1-8683ea59df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-5bb3b62f-2288-45ba-b519-c31f9efe6185,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-e928f5ad-27a8-4696-a10c-14fc94c9e3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019941925-172.17.0.8-1599386820628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-8e2b5b39-6ec1-4f98-9c60-b63f9198bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-9649d89b-9ddb-422f-8dc4-f2c967006fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1b6d0a74-b2de-4756-b29e-1ab0b26665e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-c6ead79e-f861-449f-8394-01c9a7bc6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-458d610c-bca2-4447-8b25-ed8f68bc776e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-d32003ad-5332-4de4-b0b1-8683ea59df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-5bb3b62f-2288-45ba-b519-c31f9efe6185,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-e928f5ad-27a8-4696-a10c-14fc94c9e3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885952060-172.17.0.8-1599386870474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-0aebdf88-3bc6-4f60-8f58-98a700ff5d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-69308814-fda9-4f01-b2b1-591de6172f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-ff978e76-4288-4486-8b4c-bf662863e660,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-b7c99364-1b76-49b1-878c-56ba73ef9793,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-9a9a5c4b-8d72-4f05-b486-831816fc179d,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-de97fac4-5ca2-48f1-999a-c9e1f3252c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-2b0a6df6-786d-4a7c-b682-c2f39a1e9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-cf860b0f-01d0-4f4a-b11d-a1b7b01a5342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885952060-172.17.0.8-1599386870474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-0aebdf88-3bc6-4f60-8f58-98a700ff5d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-69308814-fda9-4f01-b2b1-591de6172f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-ff978e76-4288-4486-8b4c-bf662863e660,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-b7c99364-1b76-49b1-878c-56ba73ef9793,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-9a9a5c4b-8d72-4f05-b486-831816fc179d,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-de97fac4-5ca2-48f1-999a-c9e1f3252c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-2b0a6df6-786d-4a7c-b682-c2f39a1e9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-cf860b0f-01d0-4f4a-b11d-a1b7b01a5342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861418633-172.17.0.8-1599387165795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-903e5063-e89c-48d0-96ab-7677b8517cad,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-85016fc2-d66f-4ed9-b5b1-015a57c72702,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-62c52f1c-2ee1-4652-bb7e-e9da220d9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b2ae9de9-ae04-4315-ac18-37de13ccf936,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d688a8d7-038f-4755-a5db-14722c9e325b,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-f0317609-8d7b-4f1d-830e-4584f37d564a,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-323f0100-2ab2-45af-9ec0-5c3e5e5cef69,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-ffff4171-54aa-4e84-98f3-23a97ca60eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861418633-172.17.0.8-1599387165795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-903e5063-e89c-48d0-96ab-7677b8517cad,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-85016fc2-d66f-4ed9-b5b1-015a57c72702,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-62c52f1c-2ee1-4652-bb7e-e9da220d9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b2ae9de9-ae04-4315-ac18-37de13ccf936,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d688a8d7-038f-4755-a5db-14722c9e325b,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-f0317609-8d7b-4f1d-830e-4584f37d564a,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-323f0100-2ab2-45af-9ec0-5c3e5e5cef69,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-ffff4171-54aa-4e84-98f3-23a97ca60eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5400
