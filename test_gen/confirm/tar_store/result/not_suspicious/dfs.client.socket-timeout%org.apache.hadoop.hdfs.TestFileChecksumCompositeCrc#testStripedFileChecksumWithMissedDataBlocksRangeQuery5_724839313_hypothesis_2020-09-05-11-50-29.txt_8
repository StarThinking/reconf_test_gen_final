reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903568027-172.17.0.19-1599306730643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-45a82aed-2136-40ae-89af-15fcb2f35483,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-51f91486-a54d-4fb5-b8f0-c4f48e692975,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-9b5a9e1d-40db-4257-a125-ad82e3e14532,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-cc319f4b-a282-4a3e-8204-bb66831ac4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-f86a6b34-e7ec-4a42-925d-089422b9a997,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-b390725c-c990-4bfa-b51e-2aff96f095c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-8dbb7e22-ac10-4d71-9794-4bca4c37b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-ba69a634-3a50-417e-8e04-1009d64d1cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903568027-172.17.0.19-1599306730643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44002,DS-45a82aed-2136-40ae-89af-15fcb2f35483,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-51f91486-a54d-4fb5-b8f0-c4f48e692975,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-9b5a9e1d-40db-4257-a125-ad82e3e14532,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-cc319f4b-a282-4a3e-8204-bb66831ac4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-f86a6b34-e7ec-4a42-925d-089422b9a997,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-b390725c-c990-4bfa-b51e-2aff96f095c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-8dbb7e22-ac10-4d71-9794-4bca4c37b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-ba69a634-3a50-417e-8e04-1009d64d1cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49922823-172.17.0.19-1599307097519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-094a12bf-eca9-4f3f-9749-5a271d1c78d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-30867f91-f3e1-45d0-8f4b-fe18f67546b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-d96c948c-2b8c-4bb6-ad77-e2b71dbb22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-510ba14f-4de3-4a11-a277-2b18587688f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9d2595bb-95a1-41c5-95fb-ab4a75d15473,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-0b96822f-a496-44c6-af79-7a21ccc26e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0541a802-1669-4cf8-bdcd-399674a3a0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-f1f3d45f-8f31-47e2-917e-5c9086f0c9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49922823-172.17.0.19-1599307097519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-094a12bf-eca9-4f3f-9749-5a271d1c78d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-30867f91-f3e1-45d0-8f4b-fe18f67546b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-d96c948c-2b8c-4bb6-ad77-e2b71dbb22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-510ba14f-4de3-4a11-a277-2b18587688f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-9d2595bb-95a1-41c5-95fb-ab4a75d15473,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-0b96822f-a496-44c6-af79-7a21ccc26e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0541a802-1669-4cf8-bdcd-399674a3a0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-f1f3d45f-8f31-47e2-917e-5c9086f0c9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051977504-172.17.0.19-1599307233475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40701,DS-1e5ad218-21d8-4e5c-b30e-823acf10c037,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-685ac423-3206-493c-ada6-01ad8a4c401b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-bb7d229b-b4c2-4b0a-b0c2-ed276cb6fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-15d227e2-7208-4be0-8699-de31bf16fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-e6f26ab2-8b63-4617-8d6d-b04491a02162,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-5c672cc0-88fa-435c-9f0a-7d1a11299655,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-7b3c3f7e-a823-4566-a02e-9837666ba9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-52f508d1-44f8-4252-8899-bafd648e1fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051977504-172.17.0.19-1599307233475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40701,DS-1e5ad218-21d8-4e5c-b30e-823acf10c037,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-685ac423-3206-493c-ada6-01ad8a4c401b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-bb7d229b-b4c2-4b0a-b0c2-ed276cb6fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-15d227e2-7208-4be0-8699-de31bf16fe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-e6f26ab2-8b63-4617-8d6d-b04491a02162,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-5c672cc0-88fa-435c-9f0a-7d1a11299655,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-7b3c3f7e-a823-4566-a02e-9837666ba9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-52f508d1-44f8-4252-8899-bafd648e1fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587229297-172.17.0.19-1599307394818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-b37e48d0-2e0f-4fd0-a941-b81db3edc78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-fb03f8c3-42ef-4f0a-9f92-b1a6e14c5ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-7aa75085-ddb6-472c-bd17-4c4cc10e4f25,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-0ed47a8b-2e73-48d2-b09d-98a2bc6425bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-03b185bb-39a2-4828-8e49-32364daae1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-76dbe76c-dec0-4827-bf02-33282def5682,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-c4477979-46c6-4f44-acf8-26090f1b8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-7e59fd84-bec7-4412-b37b-11f14d69fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587229297-172.17.0.19-1599307394818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-b37e48d0-2e0f-4fd0-a941-b81db3edc78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-fb03f8c3-42ef-4f0a-9f92-b1a6e14c5ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-7aa75085-ddb6-472c-bd17-4c4cc10e4f25,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-0ed47a8b-2e73-48d2-b09d-98a2bc6425bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-03b185bb-39a2-4828-8e49-32364daae1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-76dbe76c-dec0-4827-bf02-33282def5682,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-c4477979-46c6-4f44-acf8-26090f1b8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-7e59fd84-bec7-4412-b37b-11f14d69fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227325244-172.17.0.19-1599307514948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-0fe8906c-f723-438a-85f2-12c8897eee67,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-258c540b-4fc5-4be8-a703-d081fc30dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-e2234e0b-c841-404d-b382-2f91241af2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-8bb06b74-132f-46aa-8687-16b944f9a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-327e6c9c-16bb-4ea4-aba2-396cc9840412,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-45a364af-ac93-40f3-b845-a9f1e2b95a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-51ff96f5-13b5-4881-baaf-07c346299ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c0676ea-a858-4471-9770-ac6232bbb1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227325244-172.17.0.19-1599307514948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-0fe8906c-f723-438a-85f2-12c8897eee67,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-258c540b-4fc5-4be8-a703-d081fc30dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-e2234e0b-c841-404d-b382-2f91241af2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-8bb06b74-132f-46aa-8687-16b944f9a55a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-327e6c9c-16bb-4ea4-aba2-396cc9840412,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-45a364af-ac93-40f3-b845-a9f1e2b95a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-51ff96f5-13b5-4881-baaf-07c346299ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c0676ea-a858-4471-9770-ac6232bbb1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357770318-172.17.0.19-1599308301386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-f7b14114-dd6e-4196-aced-e9407d972a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-76c0e9d4-e386-459b-abc3-4c326dd3346d,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-b935539c-a4e2-4dbb-8e3d-ec3a20eb16de,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-ea32df39-09e7-4bd0-b420-7721dd907f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-0308b37e-d12c-438f-8c97-ef79ad405b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-1fcca0fb-e99d-428d-9a1b-f2ef7ed5155d,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-d9cadd5e-2ea9-4461-ae50-ff31641f1953,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-1dd59bb8-11a2-47c6-bf23-726e2aa17426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357770318-172.17.0.19-1599308301386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-f7b14114-dd6e-4196-aced-e9407d972a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-76c0e9d4-e386-459b-abc3-4c326dd3346d,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-b935539c-a4e2-4dbb-8e3d-ec3a20eb16de,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-ea32df39-09e7-4bd0-b420-7721dd907f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-0308b37e-d12c-438f-8c97-ef79ad405b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-1fcca0fb-e99d-428d-9a1b-f2ef7ed5155d,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-d9cadd5e-2ea9-4461-ae50-ff31641f1953,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-1dd59bb8-11a2-47c6-bf23-726e2aa17426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584631167-172.17.0.19-1599308466200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42837,DS-d535d116-9e00-45ba-8a77-74fc24759233,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-9f9ae11e-18f8-47ef-8265-9ca10d3e6f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-7cb1fe5c-8784-49b8-a764-cf601e7398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-5953324e-2b2e-48c5-b6e6-80e708ea33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-80c6424f-4708-48dc-9fe6-91636c316621,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-1ab30557-aaec-4dcd-ba96-e81be3d1fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b222d82e-befb-453a-aeab-9b7c0642fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-2f4bff19-9954-4e19-8a07-3962b10c6d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584631167-172.17.0.19-1599308466200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42837,DS-d535d116-9e00-45ba-8a77-74fc24759233,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-9f9ae11e-18f8-47ef-8265-9ca10d3e6f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-7cb1fe5c-8784-49b8-a764-cf601e7398c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-5953324e-2b2e-48c5-b6e6-80e708ea33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-80c6424f-4708-48dc-9fe6-91636c316621,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-1ab30557-aaec-4dcd-ba96-e81be3d1fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b222d82e-befb-453a-aeab-9b7c0642fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-2f4bff19-9954-4e19-8a07-3962b10c6d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514132783-172.17.0.19-1599309396000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-903651ba-1e3a-4855-a142-0f22a8e6b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-d7bf7ccd-cf63-48be-b96c-36f962020c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-1155e854-1b09-464c-8240-5d95da436a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-417dc6a8-6b1b-414b-b6ed-6eafc288f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-3d1b2c4c-1b69-4158-8520-aceea7cf69fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-d7bb78a7-f139-4ecc-81d3-1d5413a26061,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-53054a46-ceb7-4108-8370-6b761e0ce7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-81526d73-88c5-437d-a0fd-dcc20fde94c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514132783-172.17.0.19-1599309396000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-903651ba-1e3a-4855-a142-0f22a8e6b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-d7bf7ccd-cf63-48be-b96c-36f962020c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-1155e854-1b09-464c-8240-5d95da436a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-417dc6a8-6b1b-414b-b6ed-6eafc288f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-3d1b2c4c-1b69-4158-8520-aceea7cf69fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-d7bb78a7-f139-4ecc-81d3-1d5413a26061,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-53054a46-ceb7-4108-8370-6b761e0ce7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-81526d73-88c5-437d-a0fd-dcc20fde94c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144067263-172.17.0.19-1599309477163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-12920a26-710a-4203-a510-0ef470096e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-491537ac-855b-42c4-a645-8ed23b52be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-13615024-b8f2-4301-a2b6-c30cd8dabd68,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-a286d182-0526-4045-9b0f-d990180da895,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-4e0e350f-68f3-4290-99ad-1eeacbd43ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-cbfc5f7c-d075-47b5-8839-c2641cf263f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-89cb0597-4b87-41d5-ae1a-67348634de35,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-033c79b8-fee9-4248-99c2-fe958cd84991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144067263-172.17.0.19-1599309477163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-12920a26-710a-4203-a510-0ef470096e66,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-491537ac-855b-42c4-a645-8ed23b52be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-13615024-b8f2-4301-a2b6-c30cd8dabd68,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-a286d182-0526-4045-9b0f-d990180da895,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-4e0e350f-68f3-4290-99ad-1eeacbd43ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-cbfc5f7c-d075-47b5-8839-c2641cf263f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-89cb0597-4b87-41d5-ae1a-67348634de35,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-033c79b8-fee9-4248-99c2-fe958cd84991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168480543-172.17.0.19-1599309510497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-413f26ad-3532-4749-adec-899665ce94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-1c6c6a70-9baf-459d-aec7-f9faf24e74f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-7d7fe350-2350-40e4-9b23-9367f337968f,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-f9d64aab-fac1-410c-b1f6-a1f7892171cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-50d11fd6-05af-4ce9-817e-6b233a6e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-d7dea880-fb2c-451c-a6bb-ce6ccdc74627,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-c0a73727-16c6-45aa-80e6-c9f12f7f0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-1441a2ba-3ce2-48e9-b7fb-927aad1ffe2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168480543-172.17.0.19-1599309510497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-413f26ad-3532-4749-adec-899665ce94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-1c6c6a70-9baf-459d-aec7-f9faf24e74f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-7d7fe350-2350-40e4-9b23-9367f337968f,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-f9d64aab-fac1-410c-b1f6-a1f7892171cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-50d11fd6-05af-4ce9-817e-6b233a6e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-d7dea880-fb2c-451c-a6bb-ce6ccdc74627,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-c0a73727-16c6-45aa-80e6-c9f12f7f0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-1441a2ba-3ce2-48e9-b7fb-927aad1ffe2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286014957-172.17.0.19-1599309665637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-3ab9f854-c35e-4091-b75e-f8b268a060ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-208a523f-27dc-4416-8684-3688cb647282,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-6036b693-b1a9-4021-9a87-d6ea42b8e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-cef72b92-305d-4d78-a83e-d3a34cccafed,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-70e5879a-78c3-44c3-a218-0d7728fd6fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-9c162138-10bf-4ef3-9c49-6fd652435470,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-3f5825c8-d84b-4791-b863-291ab8db946c,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a7957adf-9f60-4a44-9a74-f162d732a68d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286014957-172.17.0.19-1599309665637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-3ab9f854-c35e-4091-b75e-f8b268a060ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-208a523f-27dc-4416-8684-3688cb647282,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-6036b693-b1a9-4021-9a87-d6ea42b8e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-cef72b92-305d-4d78-a83e-d3a34cccafed,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-70e5879a-78c3-44c3-a218-0d7728fd6fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-9c162138-10bf-4ef3-9c49-6fd652435470,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-3f5825c8-d84b-4791-b863-291ab8db946c,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a7957adf-9f60-4a44-9a74-f162d732a68d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164279372-172.17.0.19-1599309848122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-f6a61cc6-8311-432f-8230-f75d9dac9581,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-64e65abe-6df2-45b2-9926-8f8b38da3a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5da5842d-d247-4610-b21c-90ebaacd47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-62cb0747-c9ee-49b7-899a-9d6a17fcd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-a985fac0-34e6-4022-8ef3-2623b48534a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-07bf1a65-2e2e-4b67-889b-630204f74250,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4a859a9c-e3af-4ce3-9821-ac2672bfaa30,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-e5b6b8e5-7c7f-44cf-add5-0ee125910987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164279372-172.17.0.19-1599309848122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-f6a61cc6-8311-432f-8230-f75d9dac9581,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-64e65abe-6df2-45b2-9926-8f8b38da3a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-5da5842d-d247-4610-b21c-90ebaacd47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-62cb0747-c9ee-49b7-899a-9d6a17fcd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-a985fac0-34e6-4022-8ef3-2623b48534a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-07bf1a65-2e2e-4b67-889b-630204f74250,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4a859a9c-e3af-4ce3-9821-ac2672bfaa30,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-e5b6b8e5-7c7f-44cf-add5-0ee125910987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115624697-172.17.0.19-1599309958268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-0da10a22-06e4-4d15-bd1d-08dcd9ebee92,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-96ec0ea4-7527-478c-ac1c-4beb73523107,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-a5a0d1cc-c28f-423a-844c-a61ffd7c03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-afb2ddb4-31d6-4fe2-926b-2e05a4669504,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-06fedcac-0a9f-49c9-9134-1d245a827324,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-3fd85605-65a0-468c-a1a2-695ebd8616a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-9542417b-da23-4e6e-b770-7bdf65eb965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-1f9b6290-ea63-4199-914b-de5e395c6076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115624697-172.17.0.19-1599309958268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-0da10a22-06e4-4d15-bd1d-08dcd9ebee92,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-96ec0ea4-7527-478c-ac1c-4beb73523107,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-a5a0d1cc-c28f-423a-844c-a61ffd7c03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-afb2ddb4-31d6-4fe2-926b-2e05a4669504,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-06fedcac-0a9f-49c9-9134-1d245a827324,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-3fd85605-65a0-468c-a1a2-695ebd8616a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-9542417b-da23-4e6e-b770-7bdf65eb965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-1f9b6290-ea63-4199-914b-de5e395c6076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298501459-172.17.0.19-1599310107444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-6c8cf3cd-39ed-49ea-a554-d24fd9c3b1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e08a1ef0-b031-4bcf-8a43-242f39e386cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-ffbd6635-6d2f-4e98-b4a2-561557d73cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-7e7c0e5e-0770-4fb4-8f1e-6190255461bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-ef743b56-baa0-4334-863a-739b23b4fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-3f91ad5f-0507-460f-be8b-b5bc79b3ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-2d04969b-bb88-4524-92ee-54dece0348fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-81287e5f-e7e0-4800-aa0b-7e7d10209a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298501459-172.17.0.19-1599310107444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-6c8cf3cd-39ed-49ea-a554-d24fd9c3b1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e08a1ef0-b031-4bcf-8a43-242f39e386cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-ffbd6635-6d2f-4e98-b4a2-561557d73cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-7e7c0e5e-0770-4fb4-8f1e-6190255461bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-ef743b56-baa0-4334-863a-739b23b4fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-3f91ad5f-0507-460f-be8b-b5bc79b3ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-2d04969b-bb88-4524-92ee-54dece0348fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-81287e5f-e7e0-4800-aa0b-7e7d10209a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823388210-172.17.0.19-1599310230749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-c4b60997-26f2-44e1-8e28-92711fe83839,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-a3ce48b0-e34c-4a17-bab2-480407b5b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-386208bd-e24b-42c0-bb19-29236bb503cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7ac994da-4607-4a4f-83c8-fa97d1653adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-a6ed40ed-e9b5-487d-ba05-9674ba991eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1e76c0f4-1adc-4444-85e5-daae5e1b5d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3d54fba8-77a9-4ba3-9c2f-6c9cc513cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f0a79ac0-8ad0-4582-80a3-005643ef3e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823388210-172.17.0.19-1599310230749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-c4b60997-26f2-44e1-8e28-92711fe83839,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-a3ce48b0-e34c-4a17-bab2-480407b5b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-386208bd-e24b-42c0-bb19-29236bb503cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7ac994da-4607-4a4f-83c8-fa97d1653adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-a6ed40ed-e9b5-487d-ba05-9674ba991eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1e76c0f4-1adc-4444-85e5-daae5e1b5d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-3d54fba8-77a9-4ba3-9c2f-6c9cc513cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f0a79ac0-8ad0-4582-80a3-005643ef3e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718846193-172.17.0.19-1599310564059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-0d734d7e-3c9d-40aa-b089-71a3a80d02a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b85cbf8d-357c-402e-be68-381a9214a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9b0295cd-d45d-4c31-b516-e9b6119ed83b,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-09c96d0f-69fb-4332-9542-03041216f568,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-bc592184-8cfa-4cff-8635-943a93b6cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-528fee95-6b48-42c3-a177-d6d006c6d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-7211ea0c-7ebf-4599-b944-2cecee077bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-53f11836-0a03-49af-9b72-012a1777c40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718846193-172.17.0.19-1599310564059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-0d734d7e-3c9d-40aa-b089-71a3a80d02a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-b85cbf8d-357c-402e-be68-381a9214a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9b0295cd-d45d-4c31-b516-e9b6119ed83b,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-09c96d0f-69fb-4332-9542-03041216f568,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-bc592184-8cfa-4cff-8635-943a93b6cb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-528fee95-6b48-42c3-a177-d6d006c6d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-7211ea0c-7ebf-4599-b944-2cecee077bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-53f11836-0a03-49af-9b72-012a1777c40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824891305-172.17.0.19-1599311039025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-b8045091-ca4d-485e-93cb-2a6d7e3bcb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d71b5e7f-c345-46cc-828a-73c6d584827b,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-425ca589-34c7-4d2c-8546-e14869f3b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-759722a1-df10-41c4-9e24-7ab0a6cf191c,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-07c84383-d51e-48b6-8777-d0bdfda97721,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-f930e182-df3a-4191-98e4-686d70836956,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-6ad8f9e3-8d4e-460a-ae8e-93e75fc45632,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-21ffd6c1-724d-4555-900b-b4df73809d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824891305-172.17.0.19-1599311039025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-b8045091-ca4d-485e-93cb-2a6d7e3bcb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d71b5e7f-c345-46cc-828a-73c6d584827b,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-425ca589-34c7-4d2c-8546-e14869f3b471,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-759722a1-df10-41c4-9e24-7ab0a6cf191c,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-07c84383-d51e-48b6-8777-d0bdfda97721,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-f930e182-df3a-4191-98e4-686d70836956,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-6ad8f9e3-8d4e-460a-ae8e-93e75fc45632,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-21ffd6c1-724d-4555-900b-b4df73809d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491988852-172.17.0.19-1599311250129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37578,DS-29e44b0a-aea8-4c70-808e-cb09a0f6d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e35a9f1f-af98-47e9-a99e-863cec98add5,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-9db83273-20e1-4ccd-8fab-564839783f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-d950a2d0-ab36-4dc3-82c8-af937095ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-eed231bf-ce37-42c5-a9b6-d789d65810b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-fc1578eb-d6a2-45eb-bdae-ff317e0d78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-7a204d9f-882a-49d6-8666-b6d22ce93a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-40313d15-d74c-4164-b8b0-1a6ca336a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491988852-172.17.0.19-1599311250129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37578,DS-29e44b0a-aea8-4c70-808e-cb09a0f6d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e35a9f1f-af98-47e9-a99e-863cec98add5,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-9db83273-20e1-4ccd-8fab-564839783f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-d950a2d0-ab36-4dc3-82c8-af937095ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-eed231bf-ce37-42c5-a9b6-d789d65810b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-fc1578eb-d6a2-45eb-bdae-ff317e0d78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-7a204d9f-882a-49d6-8666-b6d22ce93a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-40313d15-d74c-4164-b8b0-1a6ca336a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5478
