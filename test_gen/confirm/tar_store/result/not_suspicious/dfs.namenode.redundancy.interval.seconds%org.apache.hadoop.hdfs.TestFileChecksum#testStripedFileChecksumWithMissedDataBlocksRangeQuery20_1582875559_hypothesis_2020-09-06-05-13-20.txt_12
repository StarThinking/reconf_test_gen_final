reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056667864-172.17.0.19-1599369431115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43945,DS-839de8b7-352c-4db4-9870-7dec628a2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-900f7cfa-1344-4c5f-8aef-0826ab84aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-8cb76062-4c4f-4b8e-b091-744228fcc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-4dee4403-ee66-40b8-8fcd-1fe1a611f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-fc94f347-5122-43a9-8677-92789b8f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-e1a1dd30-83a9-4eed-bcfe-1d426c4f1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-36737659-a3b9-4ce8-ace2-e15a058b1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-0772dfdb-da29-4977-9d5f-0d7cf9f06432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056667864-172.17.0.19-1599369431115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43945,DS-839de8b7-352c-4db4-9870-7dec628a2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-900f7cfa-1344-4c5f-8aef-0826ab84aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-8cb76062-4c4f-4b8e-b091-744228fcc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-4dee4403-ee66-40b8-8fcd-1fe1a611f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-fc94f347-5122-43a9-8677-92789b8f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-e1a1dd30-83a9-4eed-bcfe-1d426c4f1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-36737659-a3b9-4ce8-ace2-e15a058b1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-0772dfdb-da29-4977-9d5f-0d7cf9f06432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094496048-172.17.0.19-1599369997662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-4059f64b-f9d9-4d1e-92b9-b503dcb6453a,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-7c003754-f548-4fa4-9d38-624c67e89e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-976e87c3-da86-4ede-b6ba-7b29cae3d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-834f4779-561e-488d-a782-153cb10326df,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-bc73f518-bab4-4638-b083-6c58a9736548,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-e8db380c-b2cf-442c-9c3e-4f2d29354683,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-b53b0113-4de2-462d-87e1-26b8a7a75ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-2baa422b-5a84-46f2-b760-2a7a6b960249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094496048-172.17.0.19-1599369997662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-4059f64b-f9d9-4d1e-92b9-b503dcb6453a,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-7c003754-f548-4fa4-9d38-624c67e89e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-976e87c3-da86-4ede-b6ba-7b29cae3d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-834f4779-561e-488d-a782-153cb10326df,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-bc73f518-bab4-4638-b083-6c58a9736548,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-e8db380c-b2cf-442c-9c3e-4f2d29354683,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-b53b0113-4de2-462d-87e1-26b8a7a75ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-2baa422b-5a84-46f2-b760-2a7a6b960249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523879926-172.17.0.19-1599370721269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-200bcc65-92f2-4b5c-8bdd-b9f0d1b8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a14f9c35-4d88-4a82-9e12-5dc61bcb971b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f2fa171e-9a48-40f0-8c74-02996cc2352a,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2e7ae095-e5d6-4e90-98c8-c68327e3da13,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-49fd5ae3-c51e-4573-8ade-3c436e01b5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-3c51a5a6-60d1-47c6-8cef-f5c7beee4743,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-399b8e7c-0e1c-4814-b2fe-e946b13b8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-47fef9bc-bb5d-47e9-a934-64c1b1f880b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523879926-172.17.0.19-1599370721269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-200bcc65-92f2-4b5c-8bdd-b9f0d1b8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-a14f9c35-4d88-4a82-9e12-5dc61bcb971b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f2fa171e-9a48-40f0-8c74-02996cc2352a,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2e7ae095-e5d6-4e90-98c8-c68327e3da13,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-49fd5ae3-c51e-4573-8ade-3c436e01b5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-3c51a5a6-60d1-47c6-8cef-f5c7beee4743,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-399b8e7c-0e1c-4814-b2fe-e946b13b8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-47fef9bc-bb5d-47e9-a934-64c1b1f880b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330677460-172.17.0.19-1599371242780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-6f5da42c-6a27-43c2-acf7-c6d912ac1641,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-2321316b-55a1-4b84-92ac-9702b04a7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d70860a1-b4c3-43cd-9651-f4b311c9e587,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-e73f0a06-ad3c-4f69-9bb8-0389694097e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-de1c54bf-5a38-4ae1-91a4-aa49c0a282c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-3d9b8aac-368c-4ae3-b970-ad7d157bff05,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-eb0e87d5-e549-472c-bb5d-58f779d62467,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-20de0a65-0d01-4c3e-a7f3-865174430661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330677460-172.17.0.19-1599371242780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-6f5da42c-6a27-43c2-acf7-c6d912ac1641,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-2321316b-55a1-4b84-92ac-9702b04a7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d70860a1-b4c3-43cd-9651-f4b311c9e587,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-e73f0a06-ad3c-4f69-9bb8-0389694097e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-de1c54bf-5a38-4ae1-91a4-aa49c0a282c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-3d9b8aac-368c-4ae3-b970-ad7d157bff05,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-eb0e87d5-e549-472c-bb5d-58f779d62467,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-20de0a65-0d01-4c3e-a7f3-865174430661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666919435-172.17.0.19-1599371279841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-0fa99e4c-7c99-41f0-b9eb-c3113e8e253e,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-dac65756-6860-47a9-8290-48880b26cf87,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-ca754512-702d-483b-9d58-1d78c29542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-f5d5bb47-6ea7-4e5a-be2b-d01ad6b04ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-729d2dea-27c0-426e-a183-a098a8cb80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-c1014fce-94e4-43bc-9ad5-d387c02022d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-1ce4a698-4533-4d19-8b45-04157ee392fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-e8cac083-62f6-425c-9c3d-897fa13ce609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666919435-172.17.0.19-1599371279841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-0fa99e4c-7c99-41f0-b9eb-c3113e8e253e,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-dac65756-6860-47a9-8290-48880b26cf87,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-ca754512-702d-483b-9d58-1d78c29542e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-f5d5bb47-6ea7-4e5a-be2b-d01ad6b04ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-729d2dea-27c0-426e-a183-a098a8cb80f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-c1014fce-94e4-43bc-9ad5-d387c02022d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-1ce4a698-4533-4d19-8b45-04157ee392fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-e8cac083-62f6-425c-9c3d-897fa13ce609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435655746-172.17.0.19-1599371694479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-2bc36747-61ed-4907-93ae-b27216152ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-245542d1-a155-4440-8785-c4320983e3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-4dff1868-6ebc-46e4-b361-77db636f070a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fb5790dd-d61c-409f-bf6c-4005a1f890c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-6eacb3dc-7c04-4ded-a82f-cbe8712ccbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-77ff40af-236d-492c-999b-6c5d32ff9d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-e71f5cb1-fa84-4ea3-8fbd-6cbccf7b2130,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-9d49eb21-d34c-404b-9e67-0b3e850ca178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435655746-172.17.0.19-1599371694479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-2bc36747-61ed-4907-93ae-b27216152ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-245542d1-a155-4440-8785-c4320983e3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-4dff1868-6ebc-46e4-b361-77db636f070a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-fb5790dd-d61c-409f-bf6c-4005a1f890c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-6eacb3dc-7c04-4ded-a82f-cbe8712ccbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-77ff40af-236d-492c-999b-6c5d32ff9d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-e71f5cb1-fa84-4ea3-8fbd-6cbccf7b2130,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-9d49eb21-d34c-404b-9e67-0b3e850ca178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471121857-172.17.0.19-1599371860551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-7df65106-ab50-4890-8185-b7ea58c5c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-d78ce91d-da42-42b0-a05c-8d156bb241d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-f9a8c806-495e-4b76-a0ee-a83ced6740d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9a309ecd-47b7-4aa9-a793-c051b4017cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-a2c032d5-5419-4bb0-8c8a-ee698c010615,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-a9c30487-8f2e-4cd7-87f7-acc4b8923c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-ab34165a-ca4e-492f-8080-858146117ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-384043ac-1fd6-474e-8d81-6d1465c46ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471121857-172.17.0.19-1599371860551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-7df65106-ab50-4890-8185-b7ea58c5c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-d78ce91d-da42-42b0-a05c-8d156bb241d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-f9a8c806-495e-4b76-a0ee-a83ced6740d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9a309ecd-47b7-4aa9-a793-c051b4017cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-a2c032d5-5419-4bb0-8c8a-ee698c010615,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-a9c30487-8f2e-4cd7-87f7-acc4b8923c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-ab34165a-ca4e-492f-8080-858146117ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-384043ac-1fd6-474e-8d81-6d1465c46ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194910097-172.17.0.19-1599371964163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-0f2722c1-0389-43a5-896c-4abb2e4e579c,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-267bcf49-d566-4cf8-9755-dca9ff689e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-c1737c02-d30e-4cfa-8014-24dcd094b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-022efa56-899b-421c-9970-2f0cd1872713,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-96b596c2-5545-45d4-ab37-dcc48ba38c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1dcb735b-e423-494f-958f-425608d45659,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab112477-6f2d-476a-8282-ca6af84c76c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-75ac51f1-3968-4344-8a95-880c82e8b93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194910097-172.17.0.19-1599371964163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-0f2722c1-0389-43a5-896c-4abb2e4e579c,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-267bcf49-d566-4cf8-9755-dca9ff689e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-c1737c02-d30e-4cfa-8014-24dcd094b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-022efa56-899b-421c-9970-2f0cd1872713,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-96b596c2-5545-45d4-ab37-dcc48ba38c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1dcb735b-e423-494f-958f-425608d45659,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab112477-6f2d-476a-8282-ca6af84c76c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-75ac51f1-3968-4344-8a95-880c82e8b93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846865818-172.17.0.19-1599373128131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44385,DS-606deae9-20d9-479d-ad00-c92653479657,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-0a195f72-8840-4cdd-924c-580ed0e4da28,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-99344caf-454f-4dab-9206-593b0a76cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-2a10dca0-3b6b-4b8d-b800-dabae5b7b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-fb6ddc4d-173c-4809-b1c7-7a975e154ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-17746574-2fac-4807-b029-665f5d8d271a,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f2f11f22-e83f-4137-a22a-0be2ba2cfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b4a7fbd8-52e4-4d82-850b-b430a9a2c24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846865818-172.17.0.19-1599373128131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44385,DS-606deae9-20d9-479d-ad00-c92653479657,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-0a195f72-8840-4cdd-924c-580ed0e4da28,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-99344caf-454f-4dab-9206-593b0a76cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-2a10dca0-3b6b-4b8d-b800-dabae5b7b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-fb6ddc4d-173c-4809-b1c7-7a975e154ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-17746574-2fac-4807-b029-665f5d8d271a,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f2f11f22-e83f-4137-a22a-0be2ba2cfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-b4a7fbd8-52e4-4d82-850b-b430a9a2c24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690106161-172.17.0.19-1599373434720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-3cccb433-19df-450d-9ade-0b9dfa9ca22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-e3db2eb8-3d56-4b04-9143-f3b5ded3fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-5a1bfe10-e647-47a7-8536-f59cf299010f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-a9e2b2be-323d-4518-96ff-a5d922fc5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-65410151-ffa8-44b5-b1b5-ed6c0ba15ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-bec6feea-03bd-4d99-81cd-49c4f60d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3164c6bd-6371-428f-b066-ebf94b316ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-70300ffa-872e-4438-9a3c-1b48be94b6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690106161-172.17.0.19-1599373434720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-3cccb433-19df-450d-9ade-0b9dfa9ca22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-e3db2eb8-3d56-4b04-9143-f3b5ded3fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-5a1bfe10-e647-47a7-8536-f59cf299010f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-a9e2b2be-323d-4518-96ff-a5d922fc5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-65410151-ffa8-44b5-b1b5-ed6c0ba15ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-bec6feea-03bd-4d99-81cd-49c4f60d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3164c6bd-6371-428f-b066-ebf94b316ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-70300ffa-872e-4438-9a3c-1b48be94b6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379382592-172.17.0.19-1599374062034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-a363440e-cbcd-4821-91bf-349e3707ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-b5bb882b-e83f-4847-9718-38d7b388cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7a55b5da-dacd-4156-b5a3-78510d659471,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-16355209-7337-4c72-8332-95ad54cc6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-9a18b331-ed25-4bf5-9aa6-1ca0153ffe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-4ee682d2-f14b-4535-a688-c1011c93e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-afa7f5ad-41fb-489f-bd89-94798fb4433d,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-1d9af8cc-6374-403e-99b8-53e097a01fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379382592-172.17.0.19-1599374062034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-a363440e-cbcd-4821-91bf-349e3707ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-b5bb882b-e83f-4847-9718-38d7b388cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-7a55b5da-dacd-4156-b5a3-78510d659471,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-16355209-7337-4c72-8332-95ad54cc6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-9a18b331-ed25-4bf5-9aa6-1ca0153ffe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-4ee682d2-f14b-4535-a688-c1011c93e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-afa7f5ad-41fb-489f-bd89-94798fb4433d,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-1d9af8cc-6374-403e-99b8-53e097a01fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361021868-172.17.0.19-1599374095937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38493,DS-da0bbbd7-74ae-4e7b-b5b1-9d5498000c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-1c0ee346-d0a6-4df7-9b14-501580d0cd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-64efbd06-2aec-4c91-901e-9c703d2d8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-56877113-e8f8-44b3-a10f-99c15438027d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-e69e8326-59f7-4f07-9ae6-bb26fc4d6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-31ed09ad-f1d9-479f-aad5-1d047d375d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5ddaa758-701c-4dd4-96e3-8e998219140c,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-caea8f5e-3253-4b4a-9a73-6e75d95e74da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361021868-172.17.0.19-1599374095937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38493,DS-da0bbbd7-74ae-4e7b-b5b1-9d5498000c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-1c0ee346-d0a6-4df7-9b14-501580d0cd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-64efbd06-2aec-4c91-901e-9c703d2d8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-56877113-e8f8-44b3-a10f-99c15438027d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-e69e8326-59f7-4f07-9ae6-bb26fc4d6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-31ed09ad-f1d9-479f-aad5-1d047d375d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-5ddaa758-701c-4dd4-96e3-8e998219140c,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-caea8f5e-3253-4b4a-9a73-6e75d95e74da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969457478-172.17.0.19-1599374188229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-7b1880be-58ae-41d8-bf87-2746bfbd10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-293eaa85-d870-427e-b704-cc4059d8c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-12782ed3-9be8-4a29-afb7-5c0655cab92e,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-0dfe37e1-bba0-4ac9-8ace-3f1042ec50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-86d113a4-d261-4b95-bd8f-b6d5c4679dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-00aca392-551e-4666-9d1a-13e9b3c29cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-2069a180-96c0-410f-b1e2-7127b6eba064,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-058f52d2-d91f-4f4b-938f-93ff3af998a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969457478-172.17.0.19-1599374188229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-7b1880be-58ae-41d8-bf87-2746bfbd10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-293eaa85-d870-427e-b704-cc4059d8c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-12782ed3-9be8-4a29-afb7-5c0655cab92e,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-0dfe37e1-bba0-4ac9-8ace-3f1042ec50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-86d113a4-d261-4b95-bd8f-b6d5c4679dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-00aca392-551e-4666-9d1a-13e9b3c29cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-2069a180-96c0-410f-b1e2-7127b6eba064,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-058f52d2-d91f-4f4b-938f-93ff3af998a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5040
