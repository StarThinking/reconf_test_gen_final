reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941173093-172.17.0.11-1599378763552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-47172d82-f254-442c-95bb-b5e1b63a1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-43ac80dd-9096-4513-9cfa-22e067a66c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-c2318896-0f00-4ee6-a4d4-fa5728f487db,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-9a8fa05d-e660-4952-9791-1478f0912967,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-6d82102f-0373-4700-8ad2-d9cb9b62271b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-926713f0-9bab-4b67-ab04-4fd4ca77d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-d442f028-2543-418d-a448-bb0c835578bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6f0f68fa-8cb7-458d-81a3-7c61f4dc4d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941173093-172.17.0.11-1599378763552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-47172d82-f254-442c-95bb-b5e1b63a1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-43ac80dd-9096-4513-9cfa-22e067a66c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-c2318896-0f00-4ee6-a4d4-fa5728f487db,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-9a8fa05d-e660-4952-9791-1478f0912967,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-6d82102f-0373-4700-8ad2-d9cb9b62271b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-926713f0-9bab-4b67-ab04-4fd4ca77d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-d442f028-2543-418d-a448-bb0c835578bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6f0f68fa-8cb7-458d-81a3-7c61f4dc4d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130899150-172.17.0.11-1599378922114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-4e5b4b94-eaca-4953-8449-c1f9e2144957,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-89e06b98-b352-4814-9493-1bc847599cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-018ef8b4-6aef-4c93-bf82-608b88a33924,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-fb16cfda-fb12-40dc-b8ad-58861400bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-6aee0b0b-526c-4058-aeb4-3d9c926caea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-30281f85-d775-447d-aeb0-4cf92b782497,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-a0011669-a037-418a-beb7-0146213517f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-76e66bef-282e-4841-b824-8d95bf07c97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130899150-172.17.0.11-1599378922114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-4e5b4b94-eaca-4953-8449-c1f9e2144957,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-89e06b98-b352-4814-9493-1bc847599cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-018ef8b4-6aef-4c93-bf82-608b88a33924,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-fb16cfda-fb12-40dc-b8ad-58861400bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-6aee0b0b-526c-4058-aeb4-3d9c926caea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-30281f85-d775-447d-aeb0-4cf92b782497,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-a0011669-a037-418a-beb7-0146213517f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-76e66bef-282e-4841-b824-8d95bf07c97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140295042-172.17.0.11-1599378954173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ac01c0ba-d948-4cfa-ab41-5954c9eb8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-d4cb2896-f52c-4693-98f4-0c915af0ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-188b9dbc-0c87-4f7b-94c4-e5d4b9b8c082,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-b89a534b-d308-41f7-a205-3c0427a77418,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-fe8bda4f-9e58-465b-a71a-6e2aa2ad547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-3b197fe3-b8dd-4567-9c87-6c1ea7dbaacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-e812e4fc-dbeb-466f-88c4-de04065019e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-a880e4f7-6fb6-4328-ac29-814cf211e7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140295042-172.17.0.11-1599378954173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ac01c0ba-d948-4cfa-ab41-5954c9eb8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-d4cb2896-f52c-4693-98f4-0c915af0ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-188b9dbc-0c87-4f7b-94c4-e5d4b9b8c082,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-b89a534b-d308-41f7-a205-3c0427a77418,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-fe8bda4f-9e58-465b-a71a-6e2aa2ad547d,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-3b197fe3-b8dd-4567-9c87-6c1ea7dbaacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-e812e4fc-dbeb-466f-88c4-de04065019e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-a880e4f7-6fb6-4328-ac29-814cf211e7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313620354-172.17.0.11-1599379069400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-e99735de-de82-4054-aae9-bbb5d0c71906,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-bc16ec54-1431-47e5-a541-8472148ea5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-2b491bf3-350b-4828-8384-f7121709c550,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-357b88ef-ba1c-4468-b523-f3426236ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-46a7cdbd-e4a7-46ef-bd64-e951f52eb51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-026c4d8f-399d-46cc-8920-3dcb444b8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-aa58d9bc-3296-4d40-bb81-d94faf01f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ad73318a-0533-4688-8d6b-4c2b1d6f4223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313620354-172.17.0.11-1599379069400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-e99735de-de82-4054-aae9-bbb5d0c71906,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-bc16ec54-1431-47e5-a541-8472148ea5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-2b491bf3-350b-4828-8384-f7121709c550,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-357b88ef-ba1c-4468-b523-f3426236ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-46a7cdbd-e4a7-46ef-bd64-e951f52eb51b,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-026c4d8f-399d-46cc-8920-3dcb444b8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-aa58d9bc-3296-4d40-bb81-d94faf01f8af,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ad73318a-0533-4688-8d6b-4c2b1d6f4223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193345584-172.17.0.11-1599379429639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-3cc20157-155e-4aab-9f3d-a58834bde080,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-52f22bd9-0efb-42b0-af9b-f5a4c581132c,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-dea5ebd9-59fb-45dc-ac0a-012ee27af8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-7d25db83-395f-4b10-8015-daeb20dd4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-24ff06c6-860e-4061-81fe-13dd5143ca07,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-d3d8b7e4-c809-44db-be78-ceb816d8b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-3291d183-ba69-4865-a854-123f6c575642,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-ab32c946-086f-4109-8389-fbbf0da6c759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193345584-172.17.0.11-1599379429639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-3cc20157-155e-4aab-9f3d-a58834bde080,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-52f22bd9-0efb-42b0-af9b-f5a4c581132c,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-dea5ebd9-59fb-45dc-ac0a-012ee27af8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-7d25db83-395f-4b10-8015-daeb20dd4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-24ff06c6-860e-4061-81fe-13dd5143ca07,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-d3d8b7e4-c809-44db-be78-ceb816d8b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-3291d183-ba69-4865-a854-123f6c575642,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-ab32c946-086f-4109-8389-fbbf0da6c759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446379531-172.17.0.11-1599379494679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-e2f0447b-9e81-4a28-90fb-f02784d73a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8e34c695-517e-4e24-914a-03846fffb440,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-e1c486b1-efbf-447f-adbd-fac23c9e1ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-a5be71ba-189f-4692-8e1e-b97d3fa17b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-63c5f349-56b1-4c22-9aa0-37ea7cf9d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-dd5cd42a-dbf7-4408-abf9-d635c98b21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-50c315fd-901e-4d02-9a4d-c02c497fb32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ea3e3beb-cc6b-460b-a64e-66018632d3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446379531-172.17.0.11-1599379494679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33067,DS-e2f0447b-9e81-4a28-90fb-f02784d73a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8e34c695-517e-4e24-914a-03846fffb440,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-e1c486b1-efbf-447f-adbd-fac23c9e1ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-a5be71ba-189f-4692-8e1e-b97d3fa17b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-63c5f349-56b1-4c22-9aa0-37ea7cf9d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-dd5cd42a-dbf7-4408-abf9-d635c98b21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-50c315fd-901e-4d02-9a4d-c02c497fb32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ea3e3beb-cc6b-460b-a64e-66018632d3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007372669-172.17.0.11-1599380762798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-5aa0ee20-ae22-454e-a605-c8f7d7be8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-179aeb91-f7a8-4422-ba14-be3cdd655f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2eb557ef-b081-4f40-a988-df7e4a20c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-025f1c1f-47e6-4dd1-aa37-7959a6f3bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-a2cb7f1c-a9e9-4f83-bff8-a0d7b2ed3bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-b1374450-d350-416d-82b1-1cad5b5f7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-99c1f903-8fd4-4255-95f0-c97ba90ac81e,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3a11c5a5-ab47-45e0-b71d-5f51a82f69ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007372669-172.17.0.11-1599380762798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-5aa0ee20-ae22-454e-a605-c8f7d7be8f63,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-179aeb91-f7a8-4422-ba14-be3cdd655f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2eb557ef-b081-4f40-a988-df7e4a20c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-025f1c1f-47e6-4dd1-aa37-7959a6f3bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-a2cb7f1c-a9e9-4f83-bff8-a0d7b2ed3bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-b1374450-d350-416d-82b1-1cad5b5f7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-99c1f903-8fd4-4255-95f0-c97ba90ac81e,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3a11c5a5-ab47-45e0-b71d-5f51a82f69ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946949427-172.17.0.11-1599381344541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-e44e3fad-bfa4-4218-8203-7936ef436c93,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-a438a6bc-9c85-4884-a4f3-5c05959cfae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-363df7ba-0ee6-4cfb-a5cd-be722dd84269,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-d41f732a-b252-4cc9-bfea-be8db82f5401,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-7e1e6628-0f33-49be-8709-4c580f913d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-e7b44971-6a4d-423b-9cc0-d4dd3cc12078,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-b18afe22-0a81-44de-8e72-774b628cf7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-44652963-64c2-4dc3-936d-05e9c688cb5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946949427-172.17.0.11-1599381344541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-e44e3fad-bfa4-4218-8203-7936ef436c93,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-a438a6bc-9c85-4884-a4f3-5c05959cfae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-363df7ba-0ee6-4cfb-a5cd-be722dd84269,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-d41f732a-b252-4cc9-bfea-be8db82f5401,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-7e1e6628-0f33-49be-8709-4c580f913d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-e7b44971-6a4d-423b-9cc0-d4dd3cc12078,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-b18afe22-0a81-44de-8e72-774b628cf7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-44652963-64c2-4dc3-936d-05e9c688cb5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527578455-172.17.0.11-1599382571621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45023,DS-182bdbb9-5ddd-4efc-a6a2-ea5f774adf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-5fc1b9e9-c60d-4094-807b-c5d2bb7a5822,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-0a70cb9f-3457-4197-ab3a-1d4ba247393f,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-5f38a1f5-c1fc-4d90-a803-789e2d8c6afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-b0ab1122-7c59-4cb9-a54e-2ddc361c3844,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-1d663d63-feaa-4dd1-8eb0-a6d740d6ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-6ef0ef60-0ef3-4942-8d0d-9d20600c75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-7288074d-32fb-4502-af46-38223668487e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527578455-172.17.0.11-1599382571621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45023,DS-182bdbb9-5ddd-4efc-a6a2-ea5f774adf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-5fc1b9e9-c60d-4094-807b-c5d2bb7a5822,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-0a70cb9f-3457-4197-ab3a-1d4ba247393f,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-5f38a1f5-c1fc-4d90-a803-789e2d8c6afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-b0ab1122-7c59-4cb9-a54e-2ddc361c3844,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-1d663d63-feaa-4dd1-8eb0-a6d740d6ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-6ef0ef60-0ef3-4942-8d0d-9d20600c75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-7288074d-32fb-4502-af46-38223668487e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366631671-172.17.0.11-1599382633713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33977,DS-edfcb7ce-e1b3-4228-a275-2f705b0b5272,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-79cc1c55-0814-4abe-8d4f-53b15b622d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-caadcf9b-8767-41d3-b6d2-86c6bb1dc3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-14d16449-a3de-44a2-9947-10ac3ed56225,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-3a0d8746-f53b-412b-a4b2-a88993d293f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-a28d017c-8eee-4afa-bc7d-ed9f6afa2923,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-9102efb0-ccdb-44a7-9e8d-432328e89bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-a8243e20-e035-4c74-be1b-08541053648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366631671-172.17.0.11-1599382633713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33977,DS-edfcb7ce-e1b3-4228-a275-2f705b0b5272,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-79cc1c55-0814-4abe-8d4f-53b15b622d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-caadcf9b-8767-41d3-b6d2-86c6bb1dc3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-14d16449-a3de-44a2-9947-10ac3ed56225,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-3a0d8746-f53b-412b-a4b2-a88993d293f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-a28d017c-8eee-4afa-bc7d-ed9f6afa2923,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-9102efb0-ccdb-44a7-9e8d-432328e89bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-a8243e20-e035-4c74-be1b-08541053648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033457915-172.17.0.11-1599383047915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-22187828-1e0d-4780-815a-d9edb9d0c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-92bb5dfe-40df-4939-b08f-d7e491592da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-4794ad2d-f0de-4f70-8b89-fd9a13d8e685,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-784ffe78-481d-4dd8-9792-6c782b1c9d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-641b5fc6-e8d7-4572-832f-bbea2fd56024,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-de6404c4-d0d9-457d-93b9-f71984f6e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-8f62611d-5e0f-41e9-a5a5-d351458762f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-2da82225-ba8f-411b-9bf3-1322126f5b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033457915-172.17.0.11-1599383047915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-22187828-1e0d-4780-815a-d9edb9d0c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-92bb5dfe-40df-4939-b08f-d7e491592da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-4794ad2d-f0de-4f70-8b89-fd9a13d8e685,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-784ffe78-481d-4dd8-9792-6c782b1c9d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-641b5fc6-e8d7-4572-832f-bbea2fd56024,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-de6404c4-d0d9-457d-93b9-f71984f6e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-8f62611d-5e0f-41e9-a5a5-d351458762f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-2da82225-ba8f-411b-9bf3-1322126f5b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655713747-172.17.0.11-1599383577404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35388,DS-098e2823-9786-47d7-a7fe-e903bd180a11,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-289b9f5f-f33a-4f88-ac77-6d86cf3b56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-17a09769-e1c0-499a-8fe6-5104478bf247,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-59787284-5d11-460f-bb59-3e3b5cac1210,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-9153bbae-3283-4c2d-841d-7bd214ad741d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-c19af00e-ba26-4123-a579-9fa01591277c,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a432e5de-91cf-491f-9176-60f8e84f1d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-5882005f-0852-42a3-8b22-65ed2632ae5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655713747-172.17.0.11-1599383577404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35388,DS-098e2823-9786-47d7-a7fe-e903bd180a11,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-289b9f5f-f33a-4f88-ac77-6d86cf3b56ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-17a09769-e1c0-499a-8fe6-5104478bf247,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-59787284-5d11-460f-bb59-3e3b5cac1210,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-9153bbae-3283-4c2d-841d-7bd214ad741d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-c19af00e-ba26-4123-a579-9fa01591277c,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a432e5de-91cf-491f-9176-60f8e84f1d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-5882005f-0852-42a3-8b22-65ed2632ae5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4970
