reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355300051-172.17.0.13-1599386617464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-1d26ff4d-455b-439d-9b09-24c8a8d6ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-1fe44e06-fb49-4d2c-ada1-59fcebf96c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-8e17a03f-4b79-4a3e-b253-e4217818f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-c70bcf05-83b9-4fae-b970-5a7ab9158085,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-be45f9b6-6e00-4529-adcd-37ce5e3aba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-9db2fcae-d4f0-417c-92e1-9d33351ee04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-54189898-17bf-4205-b97d-55c209b23bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-4dd69e33-876f-4a71-8c8d-d97ba0f3de95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355300051-172.17.0.13-1599386617464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-1d26ff4d-455b-439d-9b09-24c8a8d6ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-1fe44e06-fb49-4d2c-ada1-59fcebf96c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-8e17a03f-4b79-4a3e-b253-e4217818f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-c70bcf05-83b9-4fae-b970-5a7ab9158085,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-be45f9b6-6e00-4529-adcd-37ce5e3aba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-9db2fcae-d4f0-417c-92e1-9d33351ee04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-54189898-17bf-4205-b97d-55c209b23bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-4dd69e33-876f-4a71-8c8d-d97ba0f3de95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704159509-172.17.0.13-1599387079656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-af099750-9c9e-42fc-8274-fccc7d3c8e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-f74c1142-2a2d-4370-96f9-d043b9b7fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-ed60f75b-0d3b-4fca-8c2b-1335ddefa296,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-955cf0bc-3d9f-4642-9e73-cb3d887fa3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-aa5da22b-a177-4ff3-80cc-287a8788eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-9bebab04-f3a5-4b02-9b84-fe9188630a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-eec5f0ed-102a-4804-b7b1-169f9d34a579,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-38f2da07-2bbd-4d90-ad1f-baa59ac023fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704159509-172.17.0.13-1599387079656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-af099750-9c9e-42fc-8274-fccc7d3c8e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-f74c1142-2a2d-4370-96f9-d043b9b7fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-ed60f75b-0d3b-4fca-8c2b-1335ddefa296,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-955cf0bc-3d9f-4642-9e73-cb3d887fa3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-aa5da22b-a177-4ff3-80cc-287a8788eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-9bebab04-f3a5-4b02-9b84-fe9188630a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-eec5f0ed-102a-4804-b7b1-169f9d34a579,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-38f2da07-2bbd-4d90-ad1f-baa59ac023fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725391383-172.17.0.13-1599388254462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36012,DS-88f3cb79-287b-4d93-8531-26e5ee6538e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fdaf1f0d-0fb4-46d6-9732-1fd3f45053dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-267414cc-b2c0-4764-bc12-a75f8dad31a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2e544e96-4d93-4247-a086-0bc055daee83,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-1c8a8b2b-8ad0-43f4-a8f0-fdd8ea9490a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-d92e041f-c2a2-4497-bc49-803c6c51c17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d7933a4e-ad8e-4e0a-9e8d-a0290c3c9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-8351192f-bf19-4a21-8628-ff943621219e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725391383-172.17.0.13-1599388254462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36012,DS-88f3cb79-287b-4d93-8531-26e5ee6538e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fdaf1f0d-0fb4-46d6-9732-1fd3f45053dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-267414cc-b2c0-4764-bc12-a75f8dad31a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2e544e96-4d93-4247-a086-0bc055daee83,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-1c8a8b2b-8ad0-43f4-a8f0-fdd8ea9490a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-d92e041f-c2a2-4497-bc49-803c6c51c17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d7933a4e-ad8e-4e0a-9e8d-a0290c3c9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-8351192f-bf19-4a21-8628-ff943621219e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510513040-172.17.0.13-1599388515126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-02b97c88-502b-41f2-8e8f-943aec177ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-89498dfc-3335-40b7-ab6b-9469c199919f,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-402f7554-bd57-4f81-ba6c-72b355c553c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-77f66e49-0230-4cae-83db-ed355061bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-946c791c-16ab-4c69-9716-5f100ee6a849,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-1d96fd93-fdc2-4f91-8b56-3cd3e934f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-ea4839cf-776c-4ee0-b5da-ce72dbb52f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-76c0069b-2e02-4d76-9885-68973347aac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510513040-172.17.0.13-1599388515126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-02b97c88-502b-41f2-8e8f-943aec177ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-89498dfc-3335-40b7-ab6b-9469c199919f,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-402f7554-bd57-4f81-ba6c-72b355c553c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-77f66e49-0230-4cae-83db-ed355061bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-946c791c-16ab-4c69-9716-5f100ee6a849,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-1d96fd93-fdc2-4f91-8b56-3cd3e934f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-ea4839cf-776c-4ee0-b5da-ce72dbb52f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-76c0069b-2e02-4d76-9885-68973347aac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115884657-172.17.0.13-1599388918694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-d670ca89-98fb-4371-9541-51383f0f4610,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-e2349c26-5d23-40e2-923e-f24edb08753c,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-1354ee64-e665-4a73-a18d-e62b2bcdc15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-e85283b5-5424-4823-bd85-11546b898cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-f3d3d30b-8ddb-4efd-9ca1-b40fa6e22c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-2e09e613-4fe6-4e06-b5d9-a696bedaad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-16bee624-c6d9-4ff8-b0e7-75f115bc0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-2057e36e-b2f9-4953-9910-3096c6e3341a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115884657-172.17.0.13-1599388918694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-d670ca89-98fb-4371-9541-51383f0f4610,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-e2349c26-5d23-40e2-923e-f24edb08753c,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-1354ee64-e665-4a73-a18d-e62b2bcdc15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-e85283b5-5424-4823-bd85-11546b898cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-f3d3d30b-8ddb-4efd-9ca1-b40fa6e22c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-2e09e613-4fe6-4e06-b5d9-a696bedaad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-16bee624-c6d9-4ff8-b0e7-75f115bc0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-2057e36e-b2f9-4953-9910-3096c6e3341a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044005391-172.17.0.13-1599389073013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-315dfd09-ca77-4aaa-a0d6-df915ffc28aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-7ad099b7-c9a4-42fa-870f-ab673bb8c6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-dafb163e-1d68-4861-862f-ad3e2f7499f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-f3241003-b8d5-40d4-80cd-2bd147e50148,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-af2b4456-21ca-419a-8299-c865db3fe170,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-4dd3984d-93e0-4057-ae7c-65a78f8b6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-b5383cb8-05a2-4119-b10c-ae211cab3933,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-81b55b84-ec42-42b0-b6ef-6f82a2a97d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044005391-172.17.0.13-1599389073013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-315dfd09-ca77-4aaa-a0d6-df915ffc28aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-7ad099b7-c9a4-42fa-870f-ab673bb8c6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-dafb163e-1d68-4861-862f-ad3e2f7499f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-f3241003-b8d5-40d4-80cd-2bd147e50148,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-af2b4456-21ca-419a-8299-c865db3fe170,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-4dd3984d-93e0-4057-ae7c-65a78f8b6e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-b5383cb8-05a2-4119-b10c-ae211cab3933,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-81b55b84-ec42-42b0-b6ef-6f82a2a97d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966903356-172.17.0.13-1599389125181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-2814bd92-5e9e-4ab5-824f-761818010826,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-104f2ef4-e0a3-424b-9abb-56d3765c3198,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-608f22d7-1236-406a-aadd-65ab8b072c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c3526e5d-5132-4161-92d3-7bbfe6c377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6a6e48c4-4dc3-4f2e-a7e0-83701042f772,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-27c7084c-a409-4fba-91c6-0e9162a81f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-15eba153-1e67-4a88-ac15-80a13f78eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4a5c062a-67c0-479d-8702-69bfeb626066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966903356-172.17.0.13-1599389125181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-2814bd92-5e9e-4ab5-824f-761818010826,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-104f2ef4-e0a3-424b-9abb-56d3765c3198,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-608f22d7-1236-406a-aadd-65ab8b072c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-c3526e5d-5132-4161-92d3-7bbfe6c377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6a6e48c4-4dc3-4f2e-a7e0-83701042f772,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-27c7084c-a409-4fba-91c6-0e9162a81f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-15eba153-1e67-4a88-ac15-80a13f78eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-4a5c062a-67c0-479d-8702-69bfeb626066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489013382-172.17.0.13-1599389142276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-06c26cdb-825b-435c-a5ca-01caed624068,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-eb4f8422-dac2-4397-9ee0-4a68508a7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-3c4cc976-31d9-48dc-9cae-5bc46e33e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-a5480b82-07dd-4629-ae1d-ee051b308879,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-4e0b217f-d6e6-455b-9849-815c05a5a899,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-3a803701-db14-46a1-9362-40c37c87666d,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-33130b70-1785-4128-b3d5-2c6a9e3a817a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-fbe1b4cd-c9df-4d58-a2d9-5bc67ee2534f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489013382-172.17.0.13-1599389142276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-06c26cdb-825b-435c-a5ca-01caed624068,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-eb4f8422-dac2-4397-9ee0-4a68508a7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-3c4cc976-31d9-48dc-9cae-5bc46e33e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-a5480b82-07dd-4629-ae1d-ee051b308879,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-4e0b217f-d6e6-455b-9849-815c05a5a899,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-3a803701-db14-46a1-9362-40c37c87666d,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-33130b70-1785-4128-b3d5-2c6a9e3a817a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-fbe1b4cd-c9df-4d58-a2d9-5bc67ee2534f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787553896-172.17.0.13-1599389594904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-bcf0c5d6-b62b-456c-87e3-ef29c58b030d,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-36716dd2-ae38-43e6-8e04-8286080a30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-0aa61e42-c6a4-4252-ae74-b96b112234f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-9445527d-5564-42ab-abb6-9d9fb202bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-a6e0ce72-7265-4672-ae55-b785ebda6571,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-66b1a097-0d8b-4d42-841b-0a9a940dc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-5f5b7019-c988-465f-87aa-7cc41c4320e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-87984984-b413-46d5-9220-9b59a4c973a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787553896-172.17.0.13-1599389594904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-bcf0c5d6-b62b-456c-87e3-ef29c58b030d,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-36716dd2-ae38-43e6-8e04-8286080a30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-0aa61e42-c6a4-4252-ae74-b96b112234f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-9445527d-5564-42ab-abb6-9d9fb202bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-a6e0ce72-7265-4672-ae55-b785ebda6571,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-66b1a097-0d8b-4d42-841b-0a9a940dc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-5f5b7019-c988-465f-87aa-7cc41c4320e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-87984984-b413-46d5-9220-9b59a4c973a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250163390-172.17.0.13-1599389612192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-a4de31b8-2a9f-4b4c-b03f-06d475a0d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-2623f7ef-eb92-4e8d-82ee-8f38ad446ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fdcf821c-9bf3-4fb6-a01e-a3f08354b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-148a24b0-c225-4c87-b0c9-63aa7478f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d100cd79-c0e0-400f-9da5-2d5f0b77aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-0803abef-b5d8-468f-97ab-6963cef9d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-27442706-1b87-4b04-9773-239dd0f1fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fa4a4e49-9612-403d-a40e-07e4cce949cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250163390-172.17.0.13-1599389612192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-a4de31b8-2a9f-4b4c-b03f-06d475a0d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-2623f7ef-eb92-4e8d-82ee-8f38ad446ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-fdcf821c-9bf3-4fb6-a01e-a3f08354b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-148a24b0-c225-4c87-b0c9-63aa7478f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d100cd79-c0e0-400f-9da5-2d5f0b77aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-0803abef-b5d8-468f-97ab-6963cef9d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-27442706-1b87-4b04-9773-239dd0f1fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fa4a4e49-9612-403d-a40e-07e4cce949cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382819267-172.17.0.13-1599389838789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-f7566eed-21b1-4b6d-98b6-7f338f2a6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-511ee083-bdcb-4ba4-af4e-2ddb152919be,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-1a77adc4-ff14-4264-a8a3-f1d8fd697008,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-ec632dfa-9d2a-4c10-9105-e38a4ce162c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-016406cd-cd86-4c03-aedc-ad0707830cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-48b4f2bf-cb0f-409d-a55a-9a58234908a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-e248c1f1-649e-40a1-862e-efdf70e2e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fe3ef3b4-25a8-4e46-b8ee-9b30dacfb10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382819267-172.17.0.13-1599389838789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40223,DS-f7566eed-21b1-4b6d-98b6-7f338f2a6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-511ee083-bdcb-4ba4-af4e-2ddb152919be,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-1a77adc4-ff14-4264-a8a3-f1d8fd697008,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-ec632dfa-9d2a-4c10-9105-e38a4ce162c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-016406cd-cd86-4c03-aedc-ad0707830cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-48b4f2bf-cb0f-409d-a55a-9a58234908a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-e248c1f1-649e-40a1-862e-efdf70e2e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fe3ef3b4-25a8-4e46-b8ee-9b30dacfb10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4169
