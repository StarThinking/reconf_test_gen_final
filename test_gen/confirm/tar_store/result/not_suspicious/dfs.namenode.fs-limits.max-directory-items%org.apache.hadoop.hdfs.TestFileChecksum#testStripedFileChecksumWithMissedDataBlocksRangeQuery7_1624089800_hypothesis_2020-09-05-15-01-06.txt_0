reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245784409-172.17.0.3-1599318469684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-df72addb-c06f-4a8b-b063-ad47d1d03095,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-3bbfaca1-49e0-4822-ac44-7ddfa442701c,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-fb8e7432-87bc-4bbe-8e1d-3e158fb85f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-0d001abd-0419-45ab-8877-9ef4a204ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-e982056a-6581-4df6-b6de-be44d3e97498,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-70facb3b-4272-4a52-b570-fac5eea50482,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-677faa87-0839-4601-a4da-3437ef5df18b,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-363153be-a9c3-41fa-b92f-6b1d57c99c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245784409-172.17.0.3-1599318469684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-df72addb-c06f-4a8b-b063-ad47d1d03095,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-3bbfaca1-49e0-4822-ac44-7ddfa442701c,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-fb8e7432-87bc-4bbe-8e1d-3e158fb85f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-0d001abd-0419-45ab-8877-9ef4a204ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-e982056a-6581-4df6-b6de-be44d3e97498,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-70facb3b-4272-4a52-b570-fac5eea50482,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-677faa87-0839-4601-a4da-3437ef5df18b,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-363153be-a9c3-41fa-b92f-6b1d57c99c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217628186-172.17.0.3-1599318637590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-cfbdbcb4-761d-42f2-a4ec-6d11ba15c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-6cc9d6ef-271e-4f68-accd-45c3999ae208,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a607119b-7988-4a96-a7c3-f55de2e9a639,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-56cdbc6c-7d36-433d-89e0-c6bcc5179bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-18802f1e-0201-4d67-8f68-919bdf403e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-5b3f7b10-052e-4f25-ada5-5508a26ca792,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-aff57dcf-60fb-4032-850e-33156cd1fe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-cad09a2a-d2e9-4653-897a-3ec3b7202d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217628186-172.17.0.3-1599318637590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-cfbdbcb4-761d-42f2-a4ec-6d11ba15c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-6cc9d6ef-271e-4f68-accd-45c3999ae208,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a607119b-7988-4a96-a7c3-f55de2e9a639,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-56cdbc6c-7d36-433d-89e0-c6bcc5179bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-18802f1e-0201-4d67-8f68-919bdf403e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-5b3f7b10-052e-4f25-ada5-5508a26ca792,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-aff57dcf-60fb-4032-850e-33156cd1fe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-cad09a2a-d2e9-4653-897a-3ec3b7202d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346319609-172.17.0.3-1599318717385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-a84d803a-d2c7-44a5-b6db-879b49789ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-50c8dd82-6745-4bee-a942-c5df91985ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-a2fdd7a2-c4f1-4735-8c50-cc8ea6e7c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f54468c2-b925-4b14-89c7-04e5a1f69372,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-461629e5-cb9d-4ec8-90ee-ac4272f7935a,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-bac3848c-a754-4086-945b-f6cbf89e6045,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8b37b30a-b7ba-4000-965f-87da24cc1922,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-af035017-58b6-4926-b02f-81387a0aebef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346319609-172.17.0.3-1599318717385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-a84d803a-d2c7-44a5-b6db-879b49789ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-50c8dd82-6745-4bee-a942-c5df91985ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-a2fdd7a2-c4f1-4735-8c50-cc8ea6e7c9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f54468c2-b925-4b14-89c7-04e5a1f69372,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-461629e5-cb9d-4ec8-90ee-ac4272f7935a,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-bac3848c-a754-4086-945b-f6cbf89e6045,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8b37b30a-b7ba-4000-965f-87da24cc1922,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-af035017-58b6-4926-b02f-81387a0aebef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236142768-172.17.0.3-1599318756689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-e3be7607-badd-478b-9620-d109e79d22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-23c74009-dd41-4714-8dfc-a9dc7c76bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-c2135a7f-7cac-4226-a891-0b4237c26822,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-332b07bb-bc19-4bdb-95b5-a609d2f243f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-1d79fda2-a102-4427-a8de-5c6f6d472ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-54831727-3b24-4e3e-95d0-d8cb881a2141,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-eb9268bf-b20b-456f-ac05-b1b39f93894d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-3dbacfcf-a899-47f3-9ecd-1758ff410f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236142768-172.17.0.3-1599318756689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-e3be7607-badd-478b-9620-d109e79d22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-23c74009-dd41-4714-8dfc-a9dc7c76bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-c2135a7f-7cac-4226-a891-0b4237c26822,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-332b07bb-bc19-4bdb-95b5-a609d2f243f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-1d79fda2-a102-4427-a8de-5c6f6d472ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-54831727-3b24-4e3e-95d0-d8cb881a2141,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-eb9268bf-b20b-456f-ac05-b1b39f93894d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-3dbacfcf-a899-47f3-9ecd-1758ff410f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010421712-172.17.0.3-1599318848705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-35f41eff-e642-408e-ab16-8f15dfbc004a,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-dd48e444-9dd5-4af2-8c12-f892ed98e533,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-490cc610-6502-4577-8d6a-772d328d675c,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-986e3104-02b5-475b-9c85-8b9e86715120,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-fb93e083-42a1-418a-84db-8f267ac0458e,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-5b89a640-49c1-42bd-87a1-abe6f38221af,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-c3b298b5-adcb-4563-b479-c9aa897a78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-cd8dd951-3672-405c-9694-69ece1082741,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010421712-172.17.0.3-1599318848705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-35f41eff-e642-408e-ab16-8f15dfbc004a,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-dd48e444-9dd5-4af2-8c12-f892ed98e533,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-490cc610-6502-4577-8d6a-772d328d675c,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-986e3104-02b5-475b-9c85-8b9e86715120,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-fb93e083-42a1-418a-84db-8f267ac0458e,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-5b89a640-49c1-42bd-87a1-abe6f38221af,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-c3b298b5-adcb-4563-b479-c9aa897a78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-cd8dd951-3672-405c-9694-69ece1082741,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426935820-172.17.0.3-1599318879762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-a3dc0029-85cb-491a-a1cf-e9c4ba906234,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-d0f6855a-f2c4-4b8d-a6ef-10ecf5cfa251,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-04ab760d-bd59-420f-a68e-cbe6e5809a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-7f678fff-3a87-47d0-b4b2-60b9a8c58401,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-ccf554f0-f0fa-4ec7-9ba6-ff6065969520,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-86fa2690-bef4-496d-8881-dce5a89dd5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-243db3a9-225c-4b11-a25e-9f802d60f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-9b93e242-2e0d-4d4a-b8d2-5dae8bb76e4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426935820-172.17.0.3-1599318879762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-a3dc0029-85cb-491a-a1cf-e9c4ba906234,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-d0f6855a-f2c4-4b8d-a6ef-10ecf5cfa251,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-04ab760d-bd59-420f-a68e-cbe6e5809a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-7f678fff-3a87-47d0-b4b2-60b9a8c58401,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-ccf554f0-f0fa-4ec7-9ba6-ff6065969520,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-86fa2690-bef4-496d-8881-dce5a89dd5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-243db3a9-225c-4b11-a25e-9f802d60f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-9b93e242-2e0d-4d4a-b8d2-5dae8bb76e4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052430894-172.17.0.3-1599319310121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-fef26069-25fb-46d1-9438-a132a95b547b,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-680e45ad-7b9b-48ac-8724-0065b02919d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-927c7d59-d7b3-486e-9682-5581dedc7254,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-7f92dc9c-b1b2-40ec-9ba6-28d98551cab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-5f9ff4aa-9b9d-48fa-a520-0dd639df0eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b303b5fd-3bbc-4b7b-9310-72ddec184d68,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-a2bdd997-d2d2-4c03-a34e-b22b48310539,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-bd6bfb48-e79f-4ce2-b14a-a6e149bf93b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052430894-172.17.0.3-1599319310121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-fef26069-25fb-46d1-9438-a132a95b547b,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-680e45ad-7b9b-48ac-8724-0065b02919d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-927c7d59-d7b3-486e-9682-5581dedc7254,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-7f92dc9c-b1b2-40ec-9ba6-28d98551cab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-5f9ff4aa-9b9d-48fa-a520-0dd639df0eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b303b5fd-3bbc-4b7b-9310-72ddec184d68,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-a2bdd997-d2d2-4c03-a34e-b22b48310539,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-bd6bfb48-e79f-4ce2-b14a-a6e149bf93b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112959507-172.17.0.3-1599320073461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-83ba69b2-435c-4a22-bf82-0fb1c7663755,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-0d74f33d-a68d-4360-927b-46e60db6ca77,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1a68b73b-849f-4b8c-a402-4bd04f83ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-a590e691-5f48-4a62-bb70-a65a2a16d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-48af47d1-198a-4447-8cfe-fd75df838c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-3d398be5-5577-473d-a665-68e0f5ccfdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-2717f110-700a-4f89-b812-06c3475f6f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-7f1f0bae-90ff-449b-ba20-76440b0ef161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112959507-172.17.0.3-1599320073461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-83ba69b2-435c-4a22-bf82-0fb1c7663755,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-0d74f33d-a68d-4360-927b-46e60db6ca77,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1a68b73b-849f-4b8c-a402-4bd04f83ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-a590e691-5f48-4a62-bb70-a65a2a16d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-48af47d1-198a-4447-8cfe-fd75df838c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-3d398be5-5577-473d-a665-68e0f5ccfdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-2717f110-700a-4f89-b812-06c3475f6f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-7f1f0bae-90ff-449b-ba20-76440b0ef161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303570158-172.17.0.3-1599320244623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36315,DS-7de477e2-13f8-4e5d-bd02-50b8bfaa53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1911f019-d1e8-4539-9cb3-0e892bb5d238,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-fe5adb13-f118-468a-9cbc-71b23090e919,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-36d784ec-01e0-45c8-9136-2de45ebbea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-6f8bfb44-49bd-42d0-bd4e-9179b26063a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d2bc1603-ff42-4891-a123-bae4cf3e9e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-5b5e9d66-22be-4e75-ac13-6f3a7494fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-c1718f24-a68d-438d-bd44-13bffb7e9e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303570158-172.17.0.3-1599320244623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36315,DS-7de477e2-13f8-4e5d-bd02-50b8bfaa53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1911f019-d1e8-4539-9cb3-0e892bb5d238,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-fe5adb13-f118-468a-9cbc-71b23090e919,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-36d784ec-01e0-45c8-9136-2de45ebbea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-6f8bfb44-49bd-42d0-bd4e-9179b26063a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d2bc1603-ff42-4891-a123-bae4cf3e9e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-5b5e9d66-22be-4e75-ac13-6f3a7494fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-c1718f24-a68d-438d-bd44-13bffb7e9e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103449942-172.17.0.3-1599320305209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-3903a0bd-6c1f-4763-ac1c-62fae4a99606,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-75eef83f-362b-426a-a5bc-9ebf697086f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-c3d7f20a-7c07-47a2-9bc0-4a89012238f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-860eb4c1-4ae6-4518-bea8-07ce4750b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-86a94583-23fe-4069-a797-9ecc283b9457,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-a22964d4-f3e9-4fcc-86c5-c52e9c83c318,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-1e124e88-0f19-40d5-8ed5-74308ae52b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-42b774ee-01d5-45b4-94c5-82b60b8fcb61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103449942-172.17.0.3-1599320305209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-3903a0bd-6c1f-4763-ac1c-62fae4a99606,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-75eef83f-362b-426a-a5bc-9ebf697086f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-c3d7f20a-7c07-47a2-9bc0-4a89012238f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-860eb4c1-4ae6-4518-bea8-07ce4750b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-86a94583-23fe-4069-a797-9ecc283b9457,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-a22964d4-f3e9-4fcc-86c5-c52e9c83c318,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-1e124e88-0f19-40d5-8ed5-74308ae52b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-42b774ee-01d5-45b4-94c5-82b60b8fcb61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631290709-172.17.0.3-1599320370240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-dc350c2a-a17b-4493-9539-08d11f902085,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-013f6851-046c-474b-b3f3-3bcafe1b05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-a3cb578d-6f1a-4e9c-8f1a-e7c1e8fbd83b,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-a2686e5a-a2a9-4c74-8bba-ba179a1e3bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-42aa6871-ff68-4e81-9e01-3b489be91f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-db4ad0b6-2dd0-4dac-972f-c1060fd4a267,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-fc61fce6-7ca3-44cb-a8c4-1d7c5d3182c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-6ef361f0-9999-40a4-81a1-6e5eff5c4cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631290709-172.17.0.3-1599320370240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-dc350c2a-a17b-4493-9539-08d11f902085,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-013f6851-046c-474b-b3f3-3bcafe1b05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-a3cb578d-6f1a-4e9c-8f1a-e7c1e8fbd83b,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-a2686e5a-a2a9-4c74-8bba-ba179a1e3bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-42aa6871-ff68-4e81-9e01-3b489be91f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-db4ad0b6-2dd0-4dac-972f-c1060fd4a267,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-fc61fce6-7ca3-44cb-a8c4-1d7c5d3182c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-6ef361f0-9999-40a4-81a1-6e5eff5c4cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267532923-172.17.0.3-1599320555019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-a97f0880-ef7d-4ddc-97c0-40b49a227260,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-9d1a53f9-8a0b-4c12-a675-43591812106d,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-29329e79-41b6-4c62-9e44-e7b2b00d8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a5b2a500-e750-4317-9b56-b89bde893f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c6b0e90e-082e-47ee-967b-311e11e5c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-41c92037-dd3b-495c-8ead-fdf6fae93811,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-76d58603-ba9e-4c37-a80f-52f434db8708,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-b71103f6-223c-4659-b66a-efe56493ef82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267532923-172.17.0.3-1599320555019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-a97f0880-ef7d-4ddc-97c0-40b49a227260,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-9d1a53f9-8a0b-4c12-a675-43591812106d,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-29329e79-41b6-4c62-9e44-e7b2b00d8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a5b2a500-e750-4317-9b56-b89bde893f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c6b0e90e-082e-47ee-967b-311e11e5c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-41c92037-dd3b-495c-8ead-fdf6fae93811,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-76d58603-ba9e-4c37-a80f-52f434db8708,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-b71103f6-223c-4659-b66a-efe56493ef82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257850066-172.17.0.3-1599320619846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-ec972a7f-d46a-40f7-8504-3885037fcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-7044986a-5943-4371-896d-0af37c16c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-1fb29b55-0638-420d-a32f-7acc53eb70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-65cde7d4-9a9b-4025-9d9e-23519f10d235,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-8179e710-63fb-41dc-8780-03b2cc46621e,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-accfc8d2-c701-4e23-8c4b-cd5fda1d34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-53c6fcc9-f486-4b34-98f8-39bac46971c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-e03358ef-8031-4e22-b73c-09c5278ae455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257850066-172.17.0.3-1599320619846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-ec972a7f-d46a-40f7-8504-3885037fcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-7044986a-5943-4371-896d-0af37c16c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-1fb29b55-0638-420d-a32f-7acc53eb70f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-65cde7d4-9a9b-4025-9d9e-23519f10d235,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-8179e710-63fb-41dc-8780-03b2cc46621e,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-accfc8d2-c701-4e23-8c4b-cd5fda1d34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-53c6fcc9-f486-4b34-98f8-39bac46971c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-e03358ef-8031-4e22-b73c-09c5278ae455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355861344-172.17.0.3-1599320850826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-b45cb852-1fc1-4602-97ad-20b687ad5771,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b6e82dcb-dc53-4c1d-bc54-49ba086dd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-68e89561-6ed0-4173-af79-5b898f907d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-a2b270dd-208c-4061-b0e7-94a282c347ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-d7396162-deaf-47c0-bb3d-32fe8cf09748,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-bb375edb-809a-4a3e-accc-815590fffcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-1d426a4e-80d7-4679-8563-5f025db1d991,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-52236fd8-8622-42c3-9674-2608108b597b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355861344-172.17.0.3-1599320850826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-b45cb852-1fc1-4602-97ad-20b687ad5771,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b6e82dcb-dc53-4c1d-bc54-49ba086dd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-68e89561-6ed0-4173-af79-5b898f907d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-a2b270dd-208c-4061-b0e7-94a282c347ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-d7396162-deaf-47c0-bb3d-32fe8cf09748,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-bb375edb-809a-4a3e-accc-815590fffcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-1d426a4e-80d7-4679-8563-5f025db1d991,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-52236fd8-8622-42c3-9674-2608108b597b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774411449-172.17.0.3-1599320997671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-c0f19e55-3617-44a2-ace2-4ae60f1bdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e3805642-045a-47c1-8d10-a1a22a2f867b,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-4d282634-6e61-435a-a367-1d0736e2db13,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-c61fb3a8-000e-4951-9faa-5e20f5e8d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-eb7e82c9-e30c-46e1-9128-06d1e64d7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-31068578-cbfa-4e13-8736-232e1dd35dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-b9b2ca6e-9a0e-42e0-88e7-5913cbdf9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-fe3e381c-97da-44cb-8302-753b948d0057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774411449-172.17.0.3-1599320997671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-c0f19e55-3617-44a2-ace2-4ae60f1bdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e3805642-045a-47c1-8d10-a1a22a2f867b,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-4d282634-6e61-435a-a367-1d0736e2db13,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-c61fb3a8-000e-4951-9faa-5e20f5e8d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-eb7e82c9-e30c-46e1-9128-06d1e64d7e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-31068578-cbfa-4e13-8736-232e1dd35dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-b9b2ca6e-9a0e-42e0-88e7-5913cbdf9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-fe3e381c-97da-44cb-8302-753b948d0057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922494494-172.17.0.3-1599321208189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-36ebfd0a-8b8f-435a-86d9-5908c84c8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-cdd0c4d1-7169-4d94-8b6c-79fac86603f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-111b1d43-2f60-45e4-8803-3f9d7ac8b3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-b4156399-e05e-4b02-94ba-a97d2ff64e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-89c9810f-9fa0-481b-8a62-0319b5f1a138,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-48a2cb31-a76b-404a-97b3-3eb9986e77e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-b66989c1-3626-4f12-b77a-ce83f006dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-10bd2397-dd20-41af-8fb8-639f5aa094f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922494494-172.17.0.3-1599321208189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-36ebfd0a-8b8f-435a-86d9-5908c84c8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-cdd0c4d1-7169-4d94-8b6c-79fac86603f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-111b1d43-2f60-45e4-8803-3f9d7ac8b3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-b4156399-e05e-4b02-94ba-a97d2ff64e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-89c9810f-9fa0-481b-8a62-0319b5f1a138,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-48a2cb31-a76b-404a-97b3-3eb9986e77e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-b66989c1-3626-4f12-b77a-ce83f006dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-10bd2397-dd20-41af-8fb8-639f5aa094f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931508867-172.17.0.3-1599321442396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-e54f48bf-2307-4102-9a00-afbf0e2cbe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-10459d99-ee92-4c6e-9e79-778a0518daab,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-126734b2-cb72-4c3a-94f8-3cd351e2f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-5ec3e03a-04a0-4c9c-8135-18076a674d96,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-9d7c9034-8306-47ad-888d-17a8cbfd8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5ffcd207-994b-477e-a256-76f1d04919aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-1eebb049-bdb5-44d2-93ae-7028d78c3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-29c4a762-224f-4c94-9a25-1d9c965bb265,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931508867-172.17.0.3-1599321442396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-e54f48bf-2307-4102-9a00-afbf0e2cbe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-10459d99-ee92-4c6e-9e79-778a0518daab,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-126734b2-cb72-4c3a-94f8-3cd351e2f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-5ec3e03a-04a0-4c9c-8135-18076a674d96,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-9d7c9034-8306-47ad-888d-17a8cbfd8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-5ffcd207-994b-477e-a256-76f1d04919aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-1eebb049-bdb5-44d2-93ae-7028d78c3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-29c4a762-224f-4c94-9a25-1d9c965bb265,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353146325-172.17.0.3-1599321766671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-c0b76449-0174-4d5d-b5f6-01e78c1c7967,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-113b005e-bd11-4d02-8c5c-1c1b6663a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-ad923a39-9634-4e7d-8070-5c1e25f169e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-1129dd19-40ab-416f-84b9-b330c7402987,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-d88f31a9-155a-4684-bb6b-ae287f8efe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fa696da3-abb6-4040-aa3a-ebc9333d5750,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-e95310f9-452a-4d29-ba6a-639aeb284376,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-7003c1b6-7e65-4d86-a4e8-ea2939ba833b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353146325-172.17.0.3-1599321766671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-c0b76449-0174-4d5d-b5f6-01e78c1c7967,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-113b005e-bd11-4d02-8c5c-1c1b6663a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-ad923a39-9634-4e7d-8070-5c1e25f169e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-1129dd19-40ab-416f-84b9-b330c7402987,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-d88f31a9-155a-4684-bb6b-ae287f8efe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fa696da3-abb6-4040-aa3a-ebc9333d5750,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-e95310f9-452a-4d29-ba6a-639aeb284376,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-7003c1b6-7e65-4d86-a4e8-ea2939ba833b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750467630-172.17.0.3-1599322233512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-18287aca-7afd-4be9-92ae-28b32723bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-0e00e34b-165c-4f67-b1a4-03ed1e0753a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-78c6dc39-6722-4592-8d82-edb9312f986b,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-afe71f2f-eddc-446f-a6ac-0b466d3110bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3b385d5b-3ef5-49dd-843d-7b64cd7bd867,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-2884c560-1771-43e4-ac8d-958d275e5382,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7b083102-b5e7-4ddb-bba7-b527fe4cc030,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-4cf3a7f4-8b44-4d59-8f2c-37a6708f7ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750467630-172.17.0.3-1599322233512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-18287aca-7afd-4be9-92ae-28b32723bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-0e00e34b-165c-4f67-b1a4-03ed1e0753a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-78c6dc39-6722-4592-8d82-edb9312f986b,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-afe71f2f-eddc-446f-a6ac-0b466d3110bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-3b385d5b-3ef5-49dd-843d-7b64cd7bd867,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-2884c560-1771-43e4-ac8d-958d275e5382,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7b083102-b5e7-4ddb-bba7-b527fe4cc030,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-4cf3a7f4-8b44-4d59-8f2c-37a6708f7ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665781386-172.17.0.3-1599322547044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-77cf7f88-920d-4d43-92dc-5318f91566b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-8e62d144-a863-47ae-a44f-5c5e81ded6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-6ee369f2-7014-4d95-8628-6bde857ece3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-505407cd-4a0c-42ca-960a-d5e7f949a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-2715a970-42e4-4b0e-9364-189f7b2cdcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-23dcfaae-e348-4ce1-a926-5da51d8ae2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-a74d7e60-2f70-48dc-8a12-a362f135bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b45385f4-fccf-45e3-987d-c19814761039,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665781386-172.17.0.3-1599322547044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-77cf7f88-920d-4d43-92dc-5318f91566b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-8e62d144-a863-47ae-a44f-5c5e81ded6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-6ee369f2-7014-4d95-8628-6bde857ece3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-505407cd-4a0c-42ca-960a-d5e7f949a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-2715a970-42e4-4b0e-9364-189f7b2cdcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-23dcfaae-e348-4ce1-a926-5da51d8ae2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-a74d7e60-2f70-48dc-8a12-a362f135bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b45385f4-fccf-45e3-987d-c19814761039,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312734957-172.17.0.3-1599322618370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-037cc871-737a-48e2-a441-dfed7090425d,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-71949a7f-40e9-421e-b1fe-0e9dda7c0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-660d1263-3269-421c-85b9-b9ff99ac045d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-8f574acd-89e1-450f-b0ee-66a2e094ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-f33d27b7-a324-43ab-9401-057ada5fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5459181c-eca6-4f95-b974-674e73d24e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-003e7992-98a4-415e-82c5-474065943f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-c0003ce3-b079-403d-89b6-31a02078b1e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312734957-172.17.0.3-1599322618370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-037cc871-737a-48e2-a441-dfed7090425d,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-71949a7f-40e9-421e-b1fe-0e9dda7c0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-660d1263-3269-421c-85b9-b9ff99ac045d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-8f574acd-89e1-450f-b0ee-66a2e094ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-f33d27b7-a324-43ab-9401-057ada5fb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5459181c-eca6-4f95-b974-674e73d24e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-003e7992-98a4-415e-82c5-474065943f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-c0003ce3-b079-403d-89b6-31a02078b1e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046568613-172.17.0.3-1599322768163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-61649b8d-dc42-4e6e-9f52-44f153d86908,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-f4d38740-2478-4196-a1c8-17c1a38007ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-55abb508-c2c9-468b-bc9f-f80c16f3c42a,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-69b5f991-ea31-445e-8051-b2298699129d,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7768728f-5d38-46f0-87c0-3c17fbc4c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-e81495bf-9842-48e4-8e0f-0b8fc3afb87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-70da0bee-fbf8-4e2b-95b2-7d06f2696e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0bd8ca72-1e3a-4249-8e80-ab680161df41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046568613-172.17.0.3-1599322768163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-61649b8d-dc42-4e6e-9f52-44f153d86908,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-f4d38740-2478-4196-a1c8-17c1a38007ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-55abb508-c2c9-468b-bc9f-f80c16f3c42a,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-69b5f991-ea31-445e-8051-b2298699129d,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7768728f-5d38-46f0-87c0-3c17fbc4c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-e81495bf-9842-48e4-8e0f-0b8fc3afb87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-70da0bee-fbf8-4e2b-95b2-7d06f2696e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0bd8ca72-1e3a-4249-8e80-ab680161df41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088990060-172.17.0.3-1599322947154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-6bfa3ea2-2415-43a3-b036-20ff7a90b734,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-666b7220-7ed1-4f23-876a-44fcdf351f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-3e829c14-9885-41d0-945d-33136174d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-dbb9aa21-16d8-4a88-8325-74dd45c2154c,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-a4c077a2-7fb3-45ab-b0a8-bf93ff83258e,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-70c3c0ac-ee83-475d-adaf-7f90a9e6ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a02abbc5-5c42-4074-a51f-c5e745310d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-f777f89e-b010-4e91-aeb5-a285c40d970d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088990060-172.17.0.3-1599322947154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-6bfa3ea2-2415-43a3-b036-20ff7a90b734,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-666b7220-7ed1-4f23-876a-44fcdf351f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-3e829c14-9885-41d0-945d-33136174d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-dbb9aa21-16d8-4a88-8325-74dd45c2154c,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-a4c077a2-7fb3-45ab-b0a8-bf93ff83258e,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-70c3c0ac-ee83-475d-adaf-7f90a9e6ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a02abbc5-5c42-4074-a51f-c5e745310d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-f777f89e-b010-4e91-aeb5-a285c40d970d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729265380-172.17.0.3-1599323056528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-e4e738b5-2db9-437c-9f40-43b10404460c,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-914abe4e-6bbb-473f-ba0b-bd7867fbae90,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-28e3747c-961e-43c2-ab3a-5aac461d8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-579651d9-dbc8-46b9-8c9f-409c7d592ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-96694966-2185-48ee-bce1-29022bbf5552,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-102b596d-6575-4411-a84d-949d18d48942,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-17da0562-e6de-4c76-84ff-a1044a06adca,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-5f505081-8bf3-44f0-a8b7-efa16ff73b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729265380-172.17.0.3-1599323056528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-e4e738b5-2db9-437c-9f40-43b10404460c,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-914abe4e-6bbb-473f-ba0b-bd7867fbae90,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-28e3747c-961e-43c2-ab3a-5aac461d8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-579651d9-dbc8-46b9-8c9f-409c7d592ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-96694966-2185-48ee-bce1-29022bbf5552,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-102b596d-6575-4411-a84d-949d18d48942,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-17da0562-e6de-4c76-84ff-a1044a06adca,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-5f505081-8bf3-44f0-a8b7-efa16ff73b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5153
