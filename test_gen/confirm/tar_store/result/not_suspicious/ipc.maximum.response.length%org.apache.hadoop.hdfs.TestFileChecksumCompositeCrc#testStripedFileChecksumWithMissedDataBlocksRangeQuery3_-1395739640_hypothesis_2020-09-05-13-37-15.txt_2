reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939598976-172.17.0.10-1599313097216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-9cfb4d29-6a2d-4c1c-b73d-a17e382cf416,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-b5cf22f1-b403-407f-b1b1-d12927761bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-efbb01d2-e914-4754-9ccf-a422fdc09f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-0b98aca9-a346-456d-b7f0-f051f34d5d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-047befcb-eda4-4259-9953-b3d669dff51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-824d067c-4794-459c-8d2e-66b0bf6db434,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-15251c12-61d3-471d-aeb8-45337f29dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-624717f2-ba11-4ec3-8310-3dcd19e17853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939598976-172.17.0.10-1599313097216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-9cfb4d29-6a2d-4c1c-b73d-a17e382cf416,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-b5cf22f1-b403-407f-b1b1-d12927761bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-efbb01d2-e914-4754-9ccf-a422fdc09f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-0b98aca9-a346-456d-b7f0-f051f34d5d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-047befcb-eda4-4259-9953-b3d669dff51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-824d067c-4794-459c-8d2e-66b0bf6db434,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-15251c12-61d3-471d-aeb8-45337f29dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-624717f2-ba11-4ec3-8310-3dcd19e17853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910695372-172.17.0.10-1599313976562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-2a7ca1e0-afa2-4bc1-932f-e45bc76a72a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-cd6982a1-9060-464b-b1ce-0a5db3ce3567,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-874bcc00-636d-49d2-b3bf-4ab6c35b39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-666a9313-ed79-46de-bfaf-8592f3a3cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-b23d4e26-4720-47a6-9926-24a3f6b6176f,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-bcec36f2-7e21-48d3-a9b3-4ec0f905ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-f0e836ab-98bd-49a5-b3a2-71843dd493c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-fa8dc189-e64d-4b91-94e3-24b8731227d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910695372-172.17.0.10-1599313976562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-2a7ca1e0-afa2-4bc1-932f-e45bc76a72a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-cd6982a1-9060-464b-b1ce-0a5db3ce3567,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-874bcc00-636d-49d2-b3bf-4ab6c35b39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-666a9313-ed79-46de-bfaf-8592f3a3cf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-b23d4e26-4720-47a6-9926-24a3f6b6176f,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-bcec36f2-7e21-48d3-a9b3-4ec0f905ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-f0e836ab-98bd-49a5-b3a2-71843dd493c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-fa8dc189-e64d-4b91-94e3-24b8731227d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581259928-172.17.0.10-1599314391157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-817a4077-a4c8-4674-b48c-548bbe9c05dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-71f13af3-cbff-46a4-99aa-dd27a18305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-1b8743db-31a7-4a49-8180-ebb911367c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-2bf95f1d-b0e4-42bd-a852-45cbee359cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-5e764713-9a00-4ac2-b556-b69e6009a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-5b328576-8ab7-4823-8a1b-039129364fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-f614efe3-a5e1-4376-87cc-335149e934c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-e79d1d0e-bc13-4385-92e6-6cfc5d05abc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581259928-172.17.0.10-1599314391157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-817a4077-a4c8-4674-b48c-548bbe9c05dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-71f13af3-cbff-46a4-99aa-dd27a18305e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-1b8743db-31a7-4a49-8180-ebb911367c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-2bf95f1d-b0e4-42bd-a852-45cbee359cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-5e764713-9a00-4ac2-b556-b69e6009a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-5b328576-8ab7-4823-8a1b-039129364fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-f614efe3-a5e1-4376-87cc-335149e934c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-e79d1d0e-bc13-4385-92e6-6cfc5d05abc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195007349-172.17.0.10-1599314715980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-2657993b-7b6f-422f-8406-a22a357f0ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-152b68d6-7db9-4b1d-86ec-8581c875c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f0f6bb25-eec5-476f-a6a1-d489e028fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-bffed27c-4684-480e-921a-092a6ebc81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0ac060b0-30bd-4b29-bffe-5bc65d99612f,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-0aedaa0f-9cd0-429c-9904-d7e5feefa4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-7adf8538-96e2-4574-ba4b-c5c8a7fe67be,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-938ba7f1-02a7-4876-a0d8-5a1fd30a3e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195007349-172.17.0.10-1599314715980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-2657993b-7b6f-422f-8406-a22a357f0ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-152b68d6-7db9-4b1d-86ec-8581c875c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f0f6bb25-eec5-476f-a6a1-d489e028fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-bffed27c-4684-480e-921a-092a6ebc81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0ac060b0-30bd-4b29-bffe-5bc65d99612f,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-0aedaa0f-9cd0-429c-9904-d7e5feefa4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-7adf8538-96e2-4574-ba4b-c5c8a7fe67be,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-938ba7f1-02a7-4876-a0d8-5a1fd30a3e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882802464-172.17.0.10-1599314916455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-bd4db0ae-5f26-48d9-b1e8-2395a28a958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-1a22971f-fc3d-4cae-8903-2623d0f27078,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-548190ee-8b8d-4b23-8ec7-d3403a257be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-225e92b0-5731-4bf7-bee4-60dca97a81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-cb22f816-a799-42e7-ad58-d8ddb5285bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-e28bf582-b734-4044-aeec-a20003c71737,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-6c3c5ada-74fb-46e3-8f5a-9b8a8a47abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-4070df9c-061c-4f3a-8ed1-137014c53cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882802464-172.17.0.10-1599314916455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-bd4db0ae-5f26-48d9-b1e8-2395a28a958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-1a22971f-fc3d-4cae-8903-2623d0f27078,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-548190ee-8b8d-4b23-8ec7-d3403a257be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-225e92b0-5731-4bf7-bee4-60dca97a81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-cb22f816-a799-42e7-ad58-d8ddb5285bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-e28bf582-b734-4044-aeec-a20003c71737,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-6c3c5ada-74fb-46e3-8f5a-9b8a8a47abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-4070df9c-061c-4f3a-8ed1-137014c53cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228459610-172.17.0.10-1599314995348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-5994423d-7af4-4470-8425-e17871dd9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-0416abfb-16cf-4cf7-8861-a39a12ef3ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-71d53cce-22b4-48d8-830b-6ca98a11900a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-8505affc-db8c-4bf5-a23f-74022f45d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-47b1b10a-b156-4005-bec8-b5ccbccd6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-6bb6e29d-0397-43bb-953b-fff142327cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-b175a169-d6a2-4fe8-9ef7-7c9591c47f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-bffb507f-7aaf-43eb-aed6-f93227c8bc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228459610-172.17.0.10-1599314995348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-5994423d-7af4-4470-8425-e17871dd9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-0416abfb-16cf-4cf7-8861-a39a12ef3ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-71d53cce-22b4-48d8-830b-6ca98a11900a,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-8505affc-db8c-4bf5-a23f-74022f45d5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-47b1b10a-b156-4005-bec8-b5ccbccd6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-6bb6e29d-0397-43bb-953b-fff142327cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-b175a169-d6a2-4fe8-9ef7-7c9591c47f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-bffb507f-7aaf-43eb-aed6-f93227c8bc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114887187-172.17.0.10-1599315236963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-c9fc6ecd-59b0-4c8f-85a2-a6ab686f53e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-fab1972e-36ff-4bdc-98f2-0527a6cc94a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-437d014a-c309-400b-bdde-2bcb748182ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-701f2240-ee36-46b1-9756-67f647082732,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-ec4abaee-83a6-4de4-b39e-0c0e922efea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-db24b9c0-04a5-4cd0-941a-1dcf0133ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-d10a3827-d6b0-4487-ac2f-5760e7f6a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-95e95ce1-d1ef-48b7-ad72-a670812311e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114887187-172.17.0.10-1599315236963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-c9fc6ecd-59b0-4c8f-85a2-a6ab686f53e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-fab1972e-36ff-4bdc-98f2-0527a6cc94a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-437d014a-c309-400b-bdde-2bcb748182ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-701f2240-ee36-46b1-9756-67f647082732,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-ec4abaee-83a6-4de4-b39e-0c0e922efea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-db24b9c0-04a5-4cd0-941a-1dcf0133ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-d10a3827-d6b0-4487-ac2f-5760e7f6a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-95e95ce1-d1ef-48b7-ad72-a670812311e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371946844-172.17.0.10-1599315303861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-e5eb193b-2456-4496-be8f-d06d21534a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-9bfb7d36-326b-47a3-8296-b89e6392353d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-01253d2d-263c-4769-9ae4-739807cf3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-55d38d1c-b0a0-48d7-b341-e12727d6a486,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-8762d407-70e0-4269-84f6-5e036b8552af,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-9baa40cf-5d91-4ef3-87e7-7e4fd3142031,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-f8cdce14-7dfa-4528-a2d0-a31f79b22f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d7018102-8d3e-4cf7-8902-c520c2bf389c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371946844-172.17.0.10-1599315303861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-e5eb193b-2456-4496-be8f-d06d21534a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-9bfb7d36-326b-47a3-8296-b89e6392353d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-01253d2d-263c-4769-9ae4-739807cf3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-55d38d1c-b0a0-48d7-b341-e12727d6a486,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-8762d407-70e0-4269-84f6-5e036b8552af,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-9baa40cf-5d91-4ef3-87e7-7e4fd3142031,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-f8cdce14-7dfa-4528-a2d0-a31f79b22f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d7018102-8d3e-4cf7-8902-c520c2bf389c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232731289-172.17.0.10-1599315348207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-832c1423-d6bf-473a-8bb5-65d7dcedfa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-e83ba7a3-31aa-4f99-a0fb-9fcaecb1c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-9a62ca21-8ba3-4aca-9882-4071516812d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b8baff69-eb08-4226-b814-9d3f0d3248bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-d77d37f9-7572-405a-90f3-86c7a66c9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-27df52df-75bf-4fd9-bda7-52cd1ec6564d,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-551a4959-5be2-44a7-836b-d70a8779f837,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-d750b6d5-100b-4512-9bbb-f8eeecde6e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232731289-172.17.0.10-1599315348207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-832c1423-d6bf-473a-8bb5-65d7dcedfa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-e83ba7a3-31aa-4f99-a0fb-9fcaecb1c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-9a62ca21-8ba3-4aca-9882-4071516812d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b8baff69-eb08-4226-b814-9d3f0d3248bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-d77d37f9-7572-405a-90f3-86c7a66c9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-27df52df-75bf-4fd9-bda7-52cd1ec6564d,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-551a4959-5be2-44a7-836b-d70a8779f837,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-d750b6d5-100b-4512-9bbb-f8eeecde6e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059763470-172.17.0.10-1599315804953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-2416bd21-9bd8-4004-becc-36e504f415ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-21dc310f-87dc-4fd7-8b03-566db0fc5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-cc526813-d351-405d-8267-8cebc174d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-b735c774-4b46-4fca-85c6-19a70e999f56,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-6076487f-5cab-457a-a50b-01299c19b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-a0e440d6-d6b9-4839-bd63-71d4d98431d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-73e35005-9f68-4390-8188-808a836a02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-d964ee1f-967b-4868-a8c5-28a32f25a0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059763470-172.17.0.10-1599315804953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-2416bd21-9bd8-4004-becc-36e504f415ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-21dc310f-87dc-4fd7-8b03-566db0fc5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-cc526813-d351-405d-8267-8cebc174d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-b735c774-4b46-4fca-85c6-19a70e999f56,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-6076487f-5cab-457a-a50b-01299c19b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-a0e440d6-d6b9-4839-bd63-71d4d98431d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-73e35005-9f68-4390-8188-808a836a02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-d964ee1f-967b-4868-a8c5-28a32f25a0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341849544-172.17.0.10-1599315972064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-01762f83-79b9-470b-8bba-b3335c9030b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-0d755eb4-2616-4fdd-b855-7df49069847f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-47ea85d8-ab44-4ae7-b9a2-88518f15478b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-7388bf0e-a060-4ffa-ba7f-26e6046d3600,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d881fc00-d499-4d04-922c-3ea7590b897b,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-aa82029a-d822-44e1-bd7a-6d87554aeadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-7b734996-5e3b-44d6-94e3-160e9fbd90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-fb1a33d3-1d91-4655-a473-e4adf5a2c2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341849544-172.17.0.10-1599315972064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-01762f83-79b9-470b-8bba-b3335c9030b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-0d755eb4-2616-4fdd-b855-7df49069847f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-47ea85d8-ab44-4ae7-b9a2-88518f15478b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-7388bf0e-a060-4ffa-ba7f-26e6046d3600,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d881fc00-d499-4d04-922c-3ea7590b897b,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-aa82029a-d822-44e1-bd7a-6d87554aeadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-7b734996-5e3b-44d6-94e3-160e9fbd90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-fb1a33d3-1d91-4655-a473-e4adf5a2c2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402945704-172.17.0.10-1599316219352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-6bfbe40c-3e67-4261-b45d-b1654cf6001c,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-223250c6-e071-487d-a5d2-32b2cc845984,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-763f98d3-2671-41ec-a3ae-7820b5f3d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-42fb78f0-ca6a-4f87-8e4e-52538f06e444,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-0221e158-2cb9-405e-9e95-254daff2797e,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-4bdd2380-6c2c-4fc3-80ee-04ad87c9d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-50340cc0-64f6-4a3a-9450-ff5b69d2f5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-ccd8179a-a89f-4cca-a014-9290fac4b3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402945704-172.17.0.10-1599316219352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-6bfbe40c-3e67-4261-b45d-b1654cf6001c,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-223250c6-e071-487d-a5d2-32b2cc845984,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-763f98d3-2671-41ec-a3ae-7820b5f3d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-42fb78f0-ca6a-4f87-8e4e-52538f06e444,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-0221e158-2cb9-405e-9e95-254daff2797e,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-4bdd2380-6c2c-4fc3-80ee-04ad87c9d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-50340cc0-64f6-4a3a-9450-ff5b69d2f5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-ccd8179a-a89f-4cca-a014-9290fac4b3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467873951-172.17.0.10-1599316262666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-b6e11d33-0e7f-4d84-993f-24c91c173775,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-d771a94d-5a48-42d4-9128-69b90d7b1be6,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3d309509-d5ac-4994-bcf4-06856d9b5091,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a89fb988-0fee-4729-abd9-953502a3f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-7604208e-99a2-48a4-8e6b-5432e4ef3e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-0eef0397-f11e-4351-a29f-c26339ed213a,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-eb47fcd8-629d-4031-b020-25094040c665,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-7bc4f58a-296c-4653-8ce6-34000b06903a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467873951-172.17.0.10-1599316262666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36591,DS-b6e11d33-0e7f-4d84-993f-24c91c173775,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-d771a94d-5a48-42d4-9128-69b90d7b1be6,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3d309509-d5ac-4994-bcf4-06856d9b5091,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a89fb988-0fee-4729-abd9-953502a3f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-7604208e-99a2-48a4-8e6b-5432e4ef3e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-0eef0397-f11e-4351-a29f-c26339ed213a,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-eb47fcd8-629d-4031-b020-25094040c665,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-7bc4f58a-296c-4653-8ce6-34000b06903a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562208929-172.17.0.10-1599316681234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41569,DS-7bf03052-213d-45a3-af34-5b02abe8086e,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-12c3d4dc-5dc8-4122-b053-b8dc35502b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-dbf92a51-c72b-4ff4-a29c-5311ec6a3738,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-664f0ea0-6f8c-4693-912d-810a5b081085,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-88056777-695f-44b3-b80a-10399bf986cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e52fb4f8-9fbe-4938-a86c-26d8bce32eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-c3a7643f-af3c-404a-93d8-631d751292f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-3718072e-ca5c-46df-b2dc-4ddc2c47dc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562208929-172.17.0.10-1599316681234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41569,DS-7bf03052-213d-45a3-af34-5b02abe8086e,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-12c3d4dc-5dc8-4122-b053-b8dc35502b46,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-dbf92a51-c72b-4ff4-a29c-5311ec6a3738,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-664f0ea0-6f8c-4693-912d-810a5b081085,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-88056777-695f-44b3-b80a-10399bf986cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e52fb4f8-9fbe-4938-a86c-26d8bce32eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-c3a7643f-af3c-404a-93d8-631d751292f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-3718072e-ca5c-46df-b2dc-4ddc2c47dc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352572638-172.17.0.10-1599316841683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-97815691-c456-400d-9134-1a8f1172e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a7d66d7c-312c-4fe8-b148-5e53be8b2bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-65fdd0c9-0f11-41e4-8f3c-93993ace08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-1a04baab-9b84-4af1-a269-2f3400192c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-7778b52a-fad9-4860-b062-244f0ca69d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-d6012614-62dc-48ea-9d60-4112618f9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-89bb9d55-d25e-439f-9da6-6234b2df6ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-dd127266-cd8b-4923-abd3-c2dcb8403cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352572638-172.17.0.10-1599316841683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-97815691-c456-400d-9134-1a8f1172e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a7d66d7c-312c-4fe8-b148-5e53be8b2bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-65fdd0c9-0f11-41e4-8f3c-93993ace08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-1a04baab-9b84-4af1-a269-2f3400192c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-7778b52a-fad9-4860-b062-244f0ca69d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-d6012614-62dc-48ea-9d60-4112618f9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-89bb9d55-d25e-439f-9da6-6234b2df6ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-dd127266-cd8b-4923-abd3-c2dcb8403cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278096282-172.17.0.10-1599317273108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-a0447e8d-bfd9-4b24-8535-ae0649194b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-0aba2840-2c28-4050-b900-240c0bfd65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b30954aa-3b52-415a-a620-5e4f45b63fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-772df77b-279a-4840-a891-e0b27e5c424a,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-96b7ae84-f764-4002-8c5a-fa999e1fa8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2526d35f-9a57-4f25-8e93-f51e7c5e675d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-f1ab197d-4dee-44c2-8d20-d4668a0217d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-bb6fdd30-e040-451a-b954-83a69b2e0ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278096282-172.17.0.10-1599317273108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-a0447e8d-bfd9-4b24-8535-ae0649194b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-0aba2840-2c28-4050-b900-240c0bfd65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b30954aa-3b52-415a-a620-5e4f45b63fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-772df77b-279a-4840-a891-e0b27e5c424a,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-96b7ae84-f764-4002-8c5a-fa999e1fa8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-2526d35f-9a57-4f25-8e93-f51e7c5e675d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-f1ab197d-4dee-44c2-8d20-d4668a0217d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-bb6fdd30-e040-451a-b954-83a69b2e0ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118445394-172.17.0.10-1599317518520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32935,DS-b2a5fdd5-10ef-4d03-a919-a5586661628d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-05f093c8-cd55-4232-bd33-d02be32a1799,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-895deca0-3536-47ca-9dec-f8973dcadd50,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-821104ff-8908-462b-a93c-fd5272b69e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-68675c24-7c5c-4cc8-8b03-f2ff911c3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-7451860c-20df-4fef-8c1a-3f53b289aac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-4da0825c-bf89-4abf-b43c-02b61bb8d687,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-5cbf2eb2-eb45-4afb-a406-9c14600a1705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118445394-172.17.0.10-1599317518520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32935,DS-b2a5fdd5-10ef-4d03-a919-a5586661628d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-05f093c8-cd55-4232-bd33-d02be32a1799,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-895deca0-3536-47ca-9dec-f8973dcadd50,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-821104ff-8908-462b-a93c-fd5272b69e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-68675c24-7c5c-4cc8-8b03-f2ff911c3aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-7451860c-20df-4fef-8c1a-3f53b289aac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-4da0825c-bf89-4abf-b43c-02b61bb8d687,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-5cbf2eb2-eb45-4afb-a406-9c14600a1705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136568530-172.17.0.10-1599317894579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-ff8b8105-241c-41b1-8eeb-1b093111210d,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-bc177aeb-a746-47b0-967d-0a36e2de5329,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-74705dc7-d65b-47e8-ba75-1f1a5c38c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9a44a15d-3b11-4ee6-be28-78968366cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2505bbc6-afbf-4c72-910c-b57f99172724,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-84e7b756-8662-4cb0-a1c9-0ee631076fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-df9df46d-e6dc-486d-b9a5-1296e4edcc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-94feb677-ed8f-48a7-bd9d-c07adf7d5bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136568530-172.17.0.10-1599317894579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-ff8b8105-241c-41b1-8eeb-1b093111210d,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-bc177aeb-a746-47b0-967d-0a36e2de5329,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-74705dc7-d65b-47e8-ba75-1f1a5c38c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9a44a15d-3b11-4ee6-be28-78968366cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-2505bbc6-afbf-4c72-910c-b57f99172724,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-84e7b756-8662-4cb0-a1c9-0ee631076fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-df9df46d-e6dc-486d-b9a5-1296e4edcc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-94feb677-ed8f-48a7-bd9d-c07adf7d5bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894742154-172.17.0.10-1599318061883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-bd70f55b-361c-4f9d-a42e-65e958a95415,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a2b9a3fb-56c9-4a02-b981-86c96453a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-54737b80-f688-475f-ba61-1fc23de2585c,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-9557340c-35e5-46f5-a111-3cc32ee32f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-738654ad-90b5-41d3-ba70-8768254025a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-06ee378e-99bd-4454-b6d8-b74aeafafc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-10b2c545-eab4-4969-a566-f1232872f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-85310a58-7052-4dd0-8325-97da58b6b82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894742154-172.17.0.10-1599318061883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-bd70f55b-361c-4f9d-a42e-65e958a95415,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a2b9a3fb-56c9-4a02-b981-86c96453a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-54737b80-f688-475f-ba61-1fc23de2585c,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-9557340c-35e5-46f5-a111-3cc32ee32f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-738654ad-90b5-41d3-ba70-8768254025a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-06ee378e-99bd-4454-b6d8-b74aeafafc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-10b2c545-eab4-4969-a566-f1232872f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-85310a58-7052-4dd0-8325-97da58b6b82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393867861-172.17.0.10-1599318475575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41824,DS-181eabe6-7e32-4f71-bc01-6690c1902a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-6d96c4f6-efb6-4e13-980e-9f21b23dd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a3ae1daa-fc0c-45ce-a696-0aa81b8b4301,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-87fedd26-3f8a-4cd9-8f51-3d0b28a5908a,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-5bc59310-01c2-49b0-bac4-7cb846d26651,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-b3e20452-3472-4ec8-b44d-0713b7b3478c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-8ddca504-a66c-408a-8137-b33b587d3a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-e15350dd-2d3b-498d-a552-30603acc55cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393867861-172.17.0.10-1599318475575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41824,DS-181eabe6-7e32-4f71-bc01-6690c1902a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-6d96c4f6-efb6-4e13-980e-9f21b23dd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a3ae1daa-fc0c-45ce-a696-0aa81b8b4301,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-87fedd26-3f8a-4cd9-8f51-3d0b28a5908a,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-5bc59310-01c2-49b0-bac4-7cb846d26651,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-b3e20452-3472-4ec8-b44d-0713b7b3478c,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-8ddca504-a66c-408a-8137-b33b587d3a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-e15350dd-2d3b-498d-a552-30603acc55cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856281820-172.17.0.10-1599318549819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-5990b180-1ac7-474b-82b4-7ba9e16c637e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-29848eac-ea27-4c0a-a990-d1c73033112c,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-40b17c78-ec83-47f7-89e9-3a33b6419957,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-dc322fda-b868-4acc-a384-a8d828db3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-c57b150c-7e98-44ec-bbfa-a8ffb382506a,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-e43e4b9a-4640-4bba-90fb-ed3b0a17474a,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-baafbb0d-ed45-4c26-a39a-57a4d2311955,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-ff5add37-2106-4fba-93f5-77fb1d74fd2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856281820-172.17.0.10-1599318549819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-5990b180-1ac7-474b-82b4-7ba9e16c637e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-29848eac-ea27-4c0a-a990-d1c73033112c,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-40b17c78-ec83-47f7-89e9-3a33b6419957,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-dc322fda-b868-4acc-a384-a8d828db3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-c57b150c-7e98-44ec-bbfa-a8ffb382506a,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-e43e4b9a-4640-4bba-90fb-ed3b0a17474a,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-baafbb0d-ed45-4c26-a39a-57a4d2311955,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-ff5add37-2106-4fba-93f5-77fb1d74fd2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5706
