reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955434896-172.17.0.16-1599378672885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40718,DS-ab72b4e8-1a55-405d-a8b4-555f22ad9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-880ea8be-4dfc-4eb5-8a31-6608fc2ab588,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-f60824b0-b93b-4b3a-9314-c8d8e6ba38a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1a1e977a-8c59-4a09-b804-361080b33d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-575fc4fb-0a27-4fa8-99b4-b8440232d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-1742d844-d8fa-4a71-92af-04f694562999,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-a865ef04-e774-421b-9a9b-04e45d41346f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9c54740c-1f70-4e5d-a667-61b176b2422f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955434896-172.17.0.16-1599378672885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40718,DS-ab72b4e8-1a55-405d-a8b4-555f22ad9d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-880ea8be-4dfc-4eb5-8a31-6608fc2ab588,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-f60824b0-b93b-4b3a-9314-c8d8e6ba38a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1a1e977a-8c59-4a09-b804-361080b33d86,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-575fc4fb-0a27-4fa8-99b4-b8440232d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-1742d844-d8fa-4a71-92af-04f694562999,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-a865ef04-e774-421b-9a9b-04e45d41346f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-9c54740c-1f70-4e5d-a667-61b176b2422f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172927057-172.17.0.16-1599378811013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-61868d88-3ee2-432b-852b-735482dcf705,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-d915ad2e-8765-499b-be90-58418e1b51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-fa56c771-f5b9-4a56-98f2-28bcbae5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-aa1de63c-e853-4849-9a86-488dd51bffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ee83436f-a2e8-469c-8749-a628fa4c4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-29528a50-c768-430c-93cf-bbb38518c16a,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-fd7c03b8-4e77-4895-908c-33b3128a4a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-6f0c61bd-f34c-47c1-b797-d8d4cb5571fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172927057-172.17.0.16-1599378811013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-61868d88-3ee2-432b-852b-735482dcf705,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-d915ad2e-8765-499b-be90-58418e1b51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-fa56c771-f5b9-4a56-98f2-28bcbae5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-aa1de63c-e853-4849-9a86-488dd51bffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ee83436f-a2e8-469c-8749-a628fa4c4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-29528a50-c768-430c-93cf-bbb38518c16a,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-fd7c03b8-4e77-4895-908c-33b3128a4a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-6f0c61bd-f34c-47c1-b797-d8d4cb5571fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482977150-172.17.0.16-1599378906038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-c9badffc-3bef-4ac6-be8e-cd62d4d8243c,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-99e8607a-1452-4013-b58c-98adc23af00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d2b871a8-fe1e-4d80-b747-df45b5b5645f,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a76ac36f-8cda-432a-bcaf-10eaa12ee42a,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-5e20ec13-86db-48bb-8d10-a1884bcb3998,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-deb4720b-9ec5-4ef3-975a-7755b47c2ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-553f1ee0-2769-423b-8153-3d04cc330d36,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-5a701d69-9f1b-44f8-af8f-e1b0ecb91329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482977150-172.17.0.16-1599378906038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-c9badffc-3bef-4ac6-be8e-cd62d4d8243c,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-99e8607a-1452-4013-b58c-98adc23af00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d2b871a8-fe1e-4d80-b747-df45b5b5645f,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a76ac36f-8cda-432a-bcaf-10eaa12ee42a,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-5e20ec13-86db-48bb-8d10-a1884bcb3998,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-deb4720b-9ec5-4ef3-975a-7755b47c2ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-553f1ee0-2769-423b-8153-3d04cc330d36,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-5a701d69-9f1b-44f8-af8f-e1b0ecb91329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702579562-172.17.0.16-1599380112557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-bd527801-c86a-45b4-9d9b-1afd05c8d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ba87a895-adde-4e93-8794-44ea59ab3142,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-7705ac6c-ad6f-4a7a-b170-531b0cde91b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e7ce21b0-46f7-4b53-a40f-f87228529565,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-141cc056-8693-425a-94be-848902b1afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-40f72e0b-d32e-47d7-bfdc-fcea9a81a263,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-e51bd3b8-1b0d-4972-beba-d76256db9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-c29d719c-0444-4433-b6d9-6eb6ea36c963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702579562-172.17.0.16-1599380112557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-bd527801-c86a-45b4-9d9b-1afd05c8d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ba87a895-adde-4e93-8794-44ea59ab3142,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-7705ac6c-ad6f-4a7a-b170-531b0cde91b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-e7ce21b0-46f7-4b53-a40f-f87228529565,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-141cc056-8693-425a-94be-848902b1afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-40f72e0b-d32e-47d7-bfdc-fcea9a81a263,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-e51bd3b8-1b0d-4972-beba-d76256db9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-c29d719c-0444-4433-b6d9-6eb6ea36c963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437576948-172.17.0.16-1599380138273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-1e6005cd-2f9f-42b0-a229-0b733ec8b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-96de82d6-a950-4f43-836f-26c9404797bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-75efd050-07cd-40cd-8004-80297791df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-4870768b-4d9c-4dbf-9291-9fd579df1214,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-7faa7dfe-77df-49c1-b7eb-04df3e5404d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-572e9376-2cb2-478a-8d4f-3f04fb336797,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-9324ece2-cb52-4c41-9c10-1eee8f0e06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-47af79b9-c37a-49e0-8a1c-d9703a0e90be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437576948-172.17.0.16-1599380138273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-1e6005cd-2f9f-42b0-a229-0b733ec8b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-96de82d6-a950-4f43-836f-26c9404797bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-75efd050-07cd-40cd-8004-80297791df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-4870768b-4d9c-4dbf-9291-9fd579df1214,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-7faa7dfe-77df-49c1-b7eb-04df3e5404d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-572e9376-2cb2-478a-8d4f-3f04fb336797,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-9324ece2-cb52-4c41-9c10-1eee8f0e06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-47af79b9-c37a-49e0-8a1c-d9703a0e90be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672264342-172.17.0.16-1599380383028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-e8fc5b47-5333-460e-927b-edbd482d8cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-2ce9d0bb-3c3d-4286-9711-2a337d224fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-33cb61ff-de53-4926-8dae-43e2746e026f,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-da286635-fc95-413e-8f1e-891af01119cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-8b38df65-b290-4b2a-9500-88dffdb7d0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-413a55ee-6922-4eab-ae55-d185cc684c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-3035c3e8-d191-478f-b410-1803d5b366b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-dd8abec5-84af-4c4a-9963-fa6bda6c3b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672264342-172.17.0.16-1599380383028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-e8fc5b47-5333-460e-927b-edbd482d8cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-2ce9d0bb-3c3d-4286-9711-2a337d224fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-33cb61ff-de53-4926-8dae-43e2746e026f,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-da286635-fc95-413e-8f1e-891af01119cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-8b38df65-b290-4b2a-9500-88dffdb7d0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-413a55ee-6922-4eab-ae55-d185cc684c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-3035c3e8-d191-478f-b410-1803d5b366b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-dd8abec5-84af-4c4a-9963-fa6bda6c3b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131646696-172.17.0.16-1599380800100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-e45cbf59-def5-4215-8281-76a75cf4afae,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a28eb1b3-4481-460e-a1ad-c2483b3d6729,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-8cf7f90e-7013-47fa-a538-94f02edf3396,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-c546fff0-5983-431b-aec6-4e938dddbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b2cab794-3126-48a8-891f-233c53492691,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-d302b647-24f3-4788-94ec-6402e4dc0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-6e88aebb-6e08-4d5a-8fca-a2102d8b69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-836a9be4-9b9c-44c0-9288-67ff2b498df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131646696-172.17.0.16-1599380800100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-e45cbf59-def5-4215-8281-76a75cf4afae,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a28eb1b3-4481-460e-a1ad-c2483b3d6729,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-8cf7f90e-7013-47fa-a538-94f02edf3396,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-c546fff0-5983-431b-aec6-4e938dddbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b2cab794-3126-48a8-891f-233c53492691,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-d302b647-24f3-4788-94ec-6402e4dc0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-6e88aebb-6e08-4d5a-8fca-a2102d8b69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-836a9be4-9b9c-44c0-9288-67ff2b498df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137322197-172.17.0.16-1599381222606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-5ac4012b-aba2-401b-bcd0-97d5959ab7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-795838e8-0945-4dc0-95a1-680c4c25a428,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8c1058e4-e179-4027-a2a6-5fb85183f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-8f77a730-9bd6-4c62-bd7d-63c88847ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-a2f0facd-57c8-4054-9f8d-f0bd13265981,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-0add8e55-81d4-45c5-8ede-bf75175d844e,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-24b82b9d-87a1-409f-bb83-7201ae4f7771,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-ecd2f2dd-52ef-48de-9066-02b48d9d2fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137322197-172.17.0.16-1599381222606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-5ac4012b-aba2-401b-bcd0-97d5959ab7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-795838e8-0945-4dc0-95a1-680c4c25a428,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8c1058e4-e179-4027-a2a6-5fb85183f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-8f77a730-9bd6-4c62-bd7d-63c88847ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-a2f0facd-57c8-4054-9f8d-f0bd13265981,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-0add8e55-81d4-45c5-8ede-bf75175d844e,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-24b82b9d-87a1-409f-bb83-7201ae4f7771,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-ecd2f2dd-52ef-48de-9066-02b48d9d2fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675442986-172.17.0.16-1599381748421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-6e37e944-a627-496e-b8ac-693f821ff0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-db794fc6-77fa-4128-8984-141c58e3fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-45d90b04-2e3c-4c73-806e-3f5a6dfef9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-051d2bd7-5fd6-4e34-ac08-181ed4a1e057,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-11a42914-43e6-4fa6-bd42-204484147b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6d5574c0-d44e-454c-b67a-a650b04ea61e,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-1fc460a4-5c05-481a-86d0-231f6976d428,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-81d65714-413f-4ddc-8ae2-77bd4551986b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675442986-172.17.0.16-1599381748421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-6e37e944-a627-496e-b8ac-693f821ff0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-db794fc6-77fa-4128-8984-141c58e3fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-45d90b04-2e3c-4c73-806e-3f5a6dfef9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-051d2bd7-5fd6-4e34-ac08-181ed4a1e057,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-11a42914-43e6-4fa6-bd42-204484147b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6d5574c0-d44e-454c-b67a-a650b04ea61e,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-1fc460a4-5c05-481a-86d0-231f6976d428,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-81d65714-413f-4ddc-8ae2-77bd4551986b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975565319-172.17.0.16-1599382417621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-14ab7196-e471-463e-bc4f-921e2dae400c,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1d50ec5b-1883-40cf-9354-e7497db50526,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-ed6f83f4-db60-44b5-8946-120ff1f04f37,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-074f0ee8-494d-49b2-a578-a81bcba7f710,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-2f565201-2e8e-4682-a2e1-6ef0c299ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-0105ad01-c770-427c-bfe6-e9421d78ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-9bb7576a-55ba-4f64-97e8-c42c44a8673e,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-d56adcc7-6ddd-4e70-a80b-37e645e9b520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975565319-172.17.0.16-1599382417621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-14ab7196-e471-463e-bc4f-921e2dae400c,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1d50ec5b-1883-40cf-9354-e7497db50526,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-ed6f83f4-db60-44b5-8946-120ff1f04f37,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-074f0ee8-494d-49b2-a578-a81bcba7f710,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-2f565201-2e8e-4682-a2e1-6ef0c299ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-0105ad01-c770-427c-bfe6-e9421d78ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-9bb7576a-55ba-4f64-97e8-c42c44a8673e,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-d56adcc7-6ddd-4e70-a80b-37e645e9b520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238805811-172.17.0.16-1599382731306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-f2753529-2767-4d21-8bad-0611de0fc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-fb75cd96-96a5-4646-ac68-f4487aa068f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-936c7e85-4f8d-4a9d-8e8f-70e9c04de103,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-c9104166-e175-4632-8f09-8d9a69f66848,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-984ae746-e672-4611-b376-f4f233115fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-7e24f3fc-646b-4ec5-b36b-7ce86d927cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f695a2bb-da9e-4a8d-9831-e8e80fe24c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-7cab29ed-69c8-433a-ab19-e90cd7940c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238805811-172.17.0.16-1599382731306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-f2753529-2767-4d21-8bad-0611de0fc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-fb75cd96-96a5-4646-ac68-f4487aa068f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-936c7e85-4f8d-4a9d-8e8f-70e9c04de103,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-c9104166-e175-4632-8f09-8d9a69f66848,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-984ae746-e672-4611-b376-f4f233115fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-7e24f3fc-646b-4ec5-b36b-7ce86d927cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f695a2bb-da9e-4a8d-9831-e8e80fe24c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-7cab29ed-69c8-433a-ab19-e90cd7940c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701250830-172.17.0.16-1599382790426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-d00fd530-68f8-4121-b0ef-413012dd9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-af245184-77a8-4d64-9977-503eef9acf82,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-74f20aee-df9b-4d15-8619-9100fed26d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-3afd9c2b-80ee-4197-94bb-5f79107529d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-73fb07b7-0a9f-4c30-8d47-5353d5ae4d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-c655c7c3-c7e4-401e-a627-02e8fec40642,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-80cc6307-0f9d-490f-9465-0d909ad2f703,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-20877601-d899-4323-9174-8def9ddfdcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701250830-172.17.0.16-1599382790426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-d00fd530-68f8-4121-b0ef-413012dd9df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-af245184-77a8-4d64-9977-503eef9acf82,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-74f20aee-df9b-4d15-8619-9100fed26d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-3afd9c2b-80ee-4197-94bb-5f79107529d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-73fb07b7-0a9f-4c30-8d47-5353d5ae4d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-c655c7c3-c7e4-401e-a627-02e8fec40642,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-80cc6307-0f9d-490f-9465-0d909ad2f703,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-20877601-d899-4323-9174-8def9ddfdcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4598
