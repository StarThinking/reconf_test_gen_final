reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633960873-172.17.0.13-1599385214004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-cfa65bc6-460d-45bd-929b-2ddf9738dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-faec446c-8615-4311-8d1b-dc2824cd3879,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-91c97c2f-b5d5-41e0-87b0-943c17e1e44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-c07d70a8-5d39-44be-a7f8-369a9bacfad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c1c8771d-595f-4960-90fe-c93a896c7a34,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-6161334b-0212-4efe-80cd-fdf5793f1a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ac4a2815-1a62-402c-a26f-cf3b5adbbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-894269f4-476e-4f18-8193-527e40ba4fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633960873-172.17.0.13-1599385214004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-cfa65bc6-460d-45bd-929b-2ddf9738dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-faec446c-8615-4311-8d1b-dc2824cd3879,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-91c97c2f-b5d5-41e0-87b0-943c17e1e44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-c07d70a8-5d39-44be-a7f8-369a9bacfad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c1c8771d-595f-4960-90fe-c93a896c7a34,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-6161334b-0212-4efe-80cd-fdf5793f1a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-ac4a2815-1a62-402c-a26f-cf3b5adbbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-894269f4-476e-4f18-8193-527e40ba4fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066984621-172.17.0.13-1599385304783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36586,DS-0885e77f-48d6-464f-8d45-a24c15aa66a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-d4843f44-2c16-4aaa-a0cf-7704fe0ec719,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-239f8744-fadd-4c49-9250-0866879d5472,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-c8f0de8c-3eb5-4e64-b38a-d81320958e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-8eaf26c7-ef77-43f0-a6e7-04406c1955a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-297c3d97-6fce-4816-835b-69bbeb89e128,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-3aa37023-4110-4bcf-b2e5-45d620cbeee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-9c4541c8-97fe-41cf-8281-f03a31ff3969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066984621-172.17.0.13-1599385304783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36586,DS-0885e77f-48d6-464f-8d45-a24c15aa66a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-d4843f44-2c16-4aaa-a0cf-7704fe0ec719,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-239f8744-fadd-4c49-9250-0866879d5472,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-c8f0de8c-3eb5-4e64-b38a-d81320958e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-8eaf26c7-ef77-43f0-a6e7-04406c1955a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-297c3d97-6fce-4816-835b-69bbeb89e128,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-3aa37023-4110-4bcf-b2e5-45d620cbeee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-9c4541c8-97fe-41cf-8281-f03a31ff3969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713581187-172.17.0.13-1599385514848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-0ae1ddc7-e379-4243-9b0d-27e626a92a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-fb1c150f-5366-4498-a6cc-ca93563d86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a5a9ca92-70bb-4d58-9e1e-cc9b21fb9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-ac75197d-267d-4ec5-a2c1-1a5c60cc3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2275ef54-37ff-4c92-b383-d1385f57026a,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-62051671-741c-4b35-8458-f667bfa4ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-4f4b47a5-d4d8-4214-a791-989ee2fe1929,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-30eae628-f822-4858-936b-84f5709d8d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713581187-172.17.0.13-1599385514848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-0ae1ddc7-e379-4243-9b0d-27e626a92a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-fb1c150f-5366-4498-a6cc-ca93563d86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a5a9ca92-70bb-4d58-9e1e-cc9b21fb9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-ac75197d-267d-4ec5-a2c1-1a5c60cc3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2275ef54-37ff-4c92-b383-d1385f57026a,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-62051671-741c-4b35-8458-f667bfa4ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-4f4b47a5-d4d8-4214-a791-989ee2fe1929,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-30eae628-f822-4858-936b-84f5709d8d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418521813-172.17.0.13-1599385551555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-35188e90-eee6-499b-805b-c908402850c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-6d029429-8ead-479b-9919-c6d227f79dea,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-78157a56-3af5-4eca-8dcc-a6da630cef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-6749aedb-42fd-425b-944c-f83e9197312b,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-6617a3a3-eccb-4b9e-b0ab-2f4ac0bf330b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-3c049033-ad5a-48b2-8903-2e0e8b373038,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8cdbc5e2-23a8-496f-9ee7-3cf1909983b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-4ec04401-479c-4b7e-b48f-9363bcb2d26f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418521813-172.17.0.13-1599385551555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38569,DS-35188e90-eee6-499b-805b-c908402850c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-6d029429-8ead-479b-9919-c6d227f79dea,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-78157a56-3af5-4eca-8dcc-a6da630cef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-6749aedb-42fd-425b-944c-f83e9197312b,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-6617a3a3-eccb-4b9e-b0ab-2f4ac0bf330b,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-3c049033-ad5a-48b2-8903-2e0e8b373038,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8cdbc5e2-23a8-496f-9ee7-3cf1909983b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-4ec04401-479c-4b7e-b48f-9363bcb2d26f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468382039-172.17.0.13-1599385592297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-cae6a56b-4b0a-4ae1-b124-cf58820db0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-2124edd3-7d5c-4f21-8a0d-e0d39cfefee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-bb613689-736b-4502-a83f-42973a2c162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-47cb024c-6552-4710-b6a7-983855791e71,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-56725df1-b1e6-4086-a057-a0a5186f3514,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-48ffe484-d8c4-4cca-b2f8-9a8598b50fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-c7edc923-47b1-4f74-8281-2a5dc6f2a454,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-1a5b38c8-f53d-45ce-9fc7-fd7356db7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468382039-172.17.0.13-1599385592297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-cae6a56b-4b0a-4ae1-b124-cf58820db0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-2124edd3-7d5c-4f21-8a0d-e0d39cfefee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-bb613689-736b-4502-a83f-42973a2c162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-47cb024c-6552-4710-b6a7-983855791e71,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-56725df1-b1e6-4086-a057-a0a5186f3514,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-48ffe484-d8c4-4cca-b2f8-9a8598b50fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-c7edc923-47b1-4f74-8281-2a5dc6f2a454,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-1a5b38c8-f53d-45ce-9fc7-fd7356db7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808411077-172.17.0.13-1599386091830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-246da506-cb85-4798-baef-45d3b718dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-fa8bf290-493c-451f-ba3a-d682f7cf5439,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-6837fa18-e642-407d-adae-bc386089070e,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-2b5b4bf0-6803-4ad7-bd98-d0ba1e6cc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-dcf5b97c-2b8a-4b0a-ad41-268e2657ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-8833d050-c21b-4267-a0d6-80b90f63d331,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-08a140bd-a817-446b-987b-9337b88517be,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-7301c39b-743a-45f4-b1c2-93b180ea21c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808411077-172.17.0.13-1599386091830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-246da506-cb85-4798-baef-45d3b718dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-fa8bf290-493c-451f-ba3a-d682f7cf5439,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-6837fa18-e642-407d-adae-bc386089070e,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-2b5b4bf0-6803-4ad7-bd98-d0ba1e6cc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-dcf5b97c-2b8a-4b0a-ad41-268e2657ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-8833d050-c21b-4267-a0d6-80b90f63d331,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-08a140bd-a817-446b-987b-9337b88517be,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-7301c39b-743a-45f4-b1c2-93b180ea21c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999862920-172.17.0.13-1599386391903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46428,DS-698ac9aa-5fec-4d6e-926b-92bf69c2e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-678eee26-887c-40d9-bcd4-de3207553d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2e5c7c43-79a9-4abe-8f93-0307c1bc9c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-ea8d603b-5aaf-4044-b7f3-b46633dd360f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-3c7c50d4-1ef7-4960-ad2e-c515eb0290f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-e0043d57-769b-4085-8472-84af8be78a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-18b78f3e-c1d4-4ecb-b3ce-ecaabb5bc438,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-9db53d4c-9ab8-49f7-8f78-6eda3670c229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999862920-172.17.0.13-1599386391903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46428,DS-698ac9aa-5fec-4d6e-926b-92bf69c2e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-678eee26-887c-40d9-bcd4-de3207553d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-2e5c7c43-79a9-4abe-8f93-0307c1bc9c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-ea8d603b-5aaf-4044-b7f3-b46633dd360f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-3c7c50d4-1ef7-4960-ad2e-c515eb0290f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-e0043d57-769b-4085-8472-84af8be78a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-18b78f3e-c1d4-4ecb-b3ce-ecaabb5bc438,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-9db53d4c-9ab8-49f7-8f78-6eda3670c229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718071741-172.17.0.13-1599386417998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-f5f3dbcc-b489-44e3-ac09-408be757546f,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-dc7ab0c8-a903-4295-b423-3ed65a6771de,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-b9fa00b3-2166-488b-b196-5dcbf265cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-97faad43-9bda-44d1-b459-40fc81206547,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-b50e30b7-4806-46ac-bbb7-eb54b95ce9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-31570364-234b-4537-a990-dc0ae54e3e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d626552f-58f0-4e85-a4dc-e30e631f71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-939892e8-4695-4999-906a-0600dbf85af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718071741-172.17.0.13-1599386417998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-f5f3dbcc-b489-44e3-ac09-408be757546f,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-dc7ab0c8-a903-4295-b423-3ed65a6771de,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-b9fa00b3-2166-488b-b196-5dcbf265cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-97faad43-9bda-44d1-b459-40fc81206547,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-b50e30b7-4806-46ac-bbb7-eb54b95ce9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-31570364-234b-4537-a990-dc0ae54e3e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d626552f-58f0-4e85-a4dc-e30e631f71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-939892e8-4695-4999-906a-0600dbf85af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951745287-172.17.0.13-1599386538122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-b5e204ea-2238-4801-9bd4-44aa1cb35367,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-3272df4d-dbf6-473c-8bd1-295d7b533038,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-a49c79de-cf62-4118-873c-ce6abffb1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6c0c8dc3-54b2-4486-a1e3-23567c909ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d5a7fd74-057f-47d0-adda-9dcdb7e4d634,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-0303c294-aa62-4596-9f1e-a9c5319acaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-03504f15-7dd4-4dfa-97be-a47b80688a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-64a42b3c-dec5-4285-a59b-c15c8ae41acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951745287-172.17.0.13-1599386538122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-b5e204ea-2238-4801-9bd4-44aa1cb35367,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-3272df4d-dbf6-473c-8bd1-295d7b533038,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-a49c79de-cf62-4118-873c-ce6abffb1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-6c0c8dc3-54b2-4486-a1e3-23567c909ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d5a7fd74-057f-47d0-adda-9dcdb7e4d634,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-0303c294-aa62-4596-9f1e-a9c5319acaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-03504f15-7dd4-4dfa-97be-a47b80688a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-64a42b3c-dec5-4285-a59b-c15c8ae41acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659908023-172.17.0.13-1599386715230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-b94e1d25-e4b0-442e-a921-b982239347ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-09363c5b-a979-4025-b7a8-3598ab072ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-f002988c-4129-4d15-b4da-1f049248eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d035d90e-60e4-4776-80b9-d9d1df53f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0d2c39df-bf17-4ff8-8357-231ea02f8015,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-6b151482-660d-4f39-acbf-2d3e70c106fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-6b7849e4-8895-4dbf-a288-6ecbdbd93eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d760e904-0f81-4f44-b7bf-547f41d3ab25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659908023-172.17.0.13-1599386715230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-b94e1d25-e4b0-442e-a921-b982239347ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-09363c5b-a979-4025-b7a8-3598ab072ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-f002988c-4129-4d15-b4da-1f049248eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d035d90e-60e4-4776-80b9-d9d1df53f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0d2c39df-bf17-4ff8-8357-231ea02f8015,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-6b151482-660d-4f39-acbf-2d3e70c106fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-6b7849e4-8895-4dbf-a288-6ecbdbd93eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-d760e904-0f81-4f44-b7bf-547f41d3ab25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933702024-172.17.0.13-1599386777026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-39cf566e-5606-4619-944d-d8b86101e042,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-6767a115-f539-4400-8588-fc3b44e6792a,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-037b873d-0c59-4a70-b497-9cbbcf977972,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2ba63cb4-89f2-46bd-9c23-b69be710d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-b169efbe-d140-470f-aa28-74c77a217142,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-3ccba7f1-522f-463c-bed3-41a1945fbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-ae671b57-a1fd-4823-83f7-d3b2878d1569,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-5e3ccc74-668f-4643-8cb4-0d24125e87d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933702024-172.17.0.13-1599386777026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-39cf566e-5606-4619-944d-d8b86101e042,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-6767a115-f539-4400-8588-fc3b44e6792a,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-037b873d-0c59-4a70-b497-9cbbcf977972,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2ba63cb4-89f2-46bd-9c23-b69be710d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-b169efbe-d140-470f-aa28-74c77a217142,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-3ccba7f1-522f-463c-bed3-41a1945fbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-ae671b57-a1fd-4823-83f7-d3b2878d1569,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-5e3ccc74-668f-4643-8cb4-0d24125e87d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59969205-172.17.0.13-1599387477754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-fb2e71af-ba00-46be-97ed-fc79f5d2495c,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-20b61ac3-5b63-4ad1-83c2-da3140bdb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-c19d7221-5c3a-48c3-abf8-0b272078e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-857d9794-0c3f-49ec-a51c-a049c7731c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-70c885e8-dca1-4b3f-b198-0e002beaebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-1581385a-f970-4a62-a6ae-bdc4ae655749,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-4e0e6a45-f7dc-4506-99c7-06852dbcb7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c3f12941-3945-4c1b-90bd-8702e96dff09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59969205-172.17.0.13-1599387477754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-fb2e71af-ba00-46be-97ed-fc79f5d2495c,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-20b61ac3-5b63-4ad1-83c2-da3140bdb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-c19d7221-5c3a-48c3-abf8-0b272078e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-857d9794-0c3f-49ec-a51c-a049c7731c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-70c885e8-dca1-4b3f-b198-0e002beaebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-1581385a-f970-4a62-a6ae-bdc4ae655749,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-4e0e6a45-f7dc-4506-99c7-06852dbcb7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c3f12941-3945-4c1b-90bd-8702e96dff09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339555854-172.17.0.13-1599387909925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-36d9c074-9fec-47a5-b2fd-f3972e5bc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-82381489-b911-45ce-bf84-884457aa9370,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-53beac94-bd60-4e7a-845f-32396aee7012,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-33508701-ef7b-4f65-8fa8-1d393a7fd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-d41a8473-50b7-458b-87c0-e21ac8c49bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a934d7e4-73cb-4335-ba7d-197c53b8f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-5fe155b1-ae35-445e-94eb-900e9d3ad636,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-44aa9366-37ac-49a4-8e51-4478f14bacbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339555854-172.17.0.13-1599387909925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-36d9c074-9fec-47a5-b2fd-f3972e5bc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-82381489-b911-45ce-bf84-884457aa9370,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-53beac94-bd60-4e7a-845f-32396aee7012,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-33508701-ef7b-4f65-8fa8-1d393a7fd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-d41a8473-50b7-458b-87c0-e21ac8c49bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a934d7e4-73cb-4335-ba7d-197c53b8f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-5fe155b1-ae35-445e-94eb-900e9d3ad636,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-44aa9366-37ac-49a4-8e51-4478f14bacbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004984310-172.17.0.13-1599387943521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-c3de7c29-5ddb-4023-958a-09394bad1b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e4ac44e9-6409-459b-b627-658985da4496,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f44caa75-b1e5-4e1b-8d42-e52ac246c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-cdb56f1b-d8ff-43f9-aad6-c511009262f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-64b50071-6acd-4ac0-91b2-2fd45a5da984,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-fff4f4ba-b2c7-4cd9-bab0-a859711e6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-da5d1c7b-270b-446d-b3bd-e928f29c0834,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-95c04ba1-c1f6-4bc4-9be9-09d04fd68f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004984310-172.17.0.13-1599387943521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-c3de7c29-5ddb-4023-958a-09394bad1b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e4ac44e9-6409-459b-b627-658985da4496,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f44caa75-b1e5-4e1b-8d42-e52ac246c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-cdb56f1b-d8ff-43f9-aad6-c511009262f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-64b50071-6acd-4ac0-91b2-2fd45a5da984,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-fff4f4ba-b2c7-4cd9-bab0-a859711e6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-da5d1c7b-270b-446d-b3bd-e928f29c0834,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-95c04ba1-c1f6-4bc4-9be9-09d04fd68f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58160523-172.17.0.13-1599388491765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33616,DS-d4346963-c5db-4b8e-9a8c-988cc76f1d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-255395cc-cb44-4f5d-a6c3-f6e60864623f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-3720f810-5df8-45c8-af78-bdf6388717d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fc616ae5-9d08-419f-a4e5-db71b57a4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-5c116acd-0e3f-43c3-a371-faadb317ea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-fa65db38-7f6e-4b09-b6b6-ce4527072ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bf5bf5d7-948e-4d04-befe-0299e3508595,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-805b585d-17d7-4096-b7db-51143e7d94a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58160523-172.17.0.13-1599388491765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33616,DS-d4346963-c5db-4b8e-9a8c-988cc76f1d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-255395cc-cb44-4f5d-a6c3-f6e60864623f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-3720f810-5df8-45c8-af78-bdf6388717d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fc616ae5-9d08-419f-a4e5-db71b57a4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-5c116acd-0e3f-43c3-a371-faadb317ea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-fa65db38-7f6e-4b09-b6b6-ce4527072ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bf5bf5d7-948e-4d04-befe-0299e3508595,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-805b585d-17d7-4096-b7db-51143e7d94a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42455288-172.17.0.13-1599388650298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-2d0dba51-c48f-44d7-bb5d-56bc72de399a,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-c11bb1f0-ec40-46c8-8d98-0e03330bbf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-04bcd05e-c0c6-4564-a0b5-dd9f603f16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-c7a834f8-f343-4b07-a2b1-15144547f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-f03a9e5e-c061-47d5-94e7-24a6012b1ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-9456dd6b-640f-45f0-b567-c8193151bf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-0a651f55-d729-4099-b415-495052e358d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-e634df89-daf2-4c56-bc70-0ab4a375e16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42455288-172.17.0.13-1599388650298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-2d0dba51-c48f-44d7-bb5d-56bc72de399a,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-c11bb1f0-ec40-46c8-8d98-0e03330bbf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-04bcd05e-c0c6-4564-a0b5-dd9f603f16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-c7a834f8-f343-4b07-a2b1-15144547f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-f03a9e5e-c061-47d5-94e7-24a6012b1ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-9456dd6b-640f-45f0-b567-c8193151bf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-0a651f55-d729-4099-b415-495052e358d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-e634df89-daf2-4c56-bc70-0ab4a375e16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293250886-172.17.0.13-1599388980079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-cfcdae8e-6617-4b59-b45a-3f50bc5f59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-8e52008b-d96f-440d-b663-31b2345111d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-fb2ff6db-2529-4a49-ba7f-32f7bae6ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-15297bf9-48c6-4c35-ad69-d58c6f3426ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-152791b2-371f-4aad-b3ad-1f51753e06aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-f11ece9f-fcbe-493e-935c-bf2ba529fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-8f0e8a3d-20cd-4ce2-acc6-6653658929c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-eae5b3eb-8669-41ed-92e0-a8d827716bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293250886-172.17.0.13-1599388980079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-cfcdae8e-6617-4b59-b45a-3f50bc5f59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-8e52008b-d96f-440d-b663-31b2345111d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-fb2ff6db-2529-4a49-ba7f-32f7bae6ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-15297bf9-48c6-4c35-ad69-d58c6f3426ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-152791b2-371f-4aad-b3ad-1f51753e06aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-f11ece9f-fcbe-493e-935c-bf2ba529fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-8f0e8a3d-20cd-4ce2-acc6-6653658929c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-eae5b3eb-8669-41ed-92e0-a8d827716bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664967182-172.17.0.13-1599389060433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-70cbdd50-7dfc-4467-aed5-5d354f4f4318,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-b7e63246-b81d-47a2-917d-1982872984fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-00eeeb31-efc4-4a77-8862-d3fb33d6092c,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-eafd7931-9416-4dec-a2dd-3718cb93e684,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-30a16889-61ed-4837-8969-eb17c750a393,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2f6c9f7c-f13a-4544-a535-0238bae73de1,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d4b97947-47dd-4750-a8f9-d7fdb11f77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-0aca0330-6ac9-45c5-8cc2-7063bf769901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664967182-172.17.0.13-1599389060433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-70cbdd50-7dfc-4467-aed5-5d354f4f4318,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-b7e63246-b81d-47a2-917d-1982872984fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-00eeeb31-efc4-4a77-8862-d3fb33d6092c,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-eafd7931-9416-4dec-a2dd-3718cb93e684,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-30a16889-61ed-4837-8969-eb17c750a393,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2f6c9f7c-f13a-4544-a535-0238bae73de1,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-d4b97947-47dd-4750-a8f9-d7fdb11f77b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-0aca0330-6ac9-45c5-8cc2-7063bf769901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312309598-172.17.0.13-1599389173539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-b495e644-a176-4b69-b631-78f58f0e7092,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b2b63f55-efbc-46bd-a943-5af7e628a104,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-97c0e88b-4f9c-433a-af72-d2dd54057318,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-4f939c13-e01b-4a15-81bf-e7a316d64591,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-8a27c94f-298f-419c-ad68-b6bd3c1ae4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-5da1c699-c0c0-4edc-b89f-0e9416d36906,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-9774b7b6-f690-4fb7-8b39-dd022dbebfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-5fb23004-68c1-467e-83f2-7519119b442a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312309598-172.17.0.13-1599389173539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-b495e644-a176-4b69-b631-78f58f0e7092,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-b2b63f55-efbc-46bd-a943-5af7e628a104,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-97c0e88b-4f9c-433a-af72-d2dd54057318,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-4f939c13-e01b-4a15-81bf-e7a316d64591,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-8a27c94f-298f-419c-ad68-b6bd3c1ae4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-5da1c699-c0c0-4edc-b89f-0e9416d36906,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-9774b7b6-f690-4fb7-8b39-dd022dbebfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-5fb23004-68c1-467e-83f2-7519119b442a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4298
