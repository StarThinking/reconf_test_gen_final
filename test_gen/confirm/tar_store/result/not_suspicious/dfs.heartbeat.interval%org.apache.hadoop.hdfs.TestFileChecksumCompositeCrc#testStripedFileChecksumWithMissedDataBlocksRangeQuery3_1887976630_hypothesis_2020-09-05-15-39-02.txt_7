reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046721146-172.17.0.14-1599320703419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-ed2e2258-98d8-402c-8ea1-a0a4d20bee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-c2394b8e-0e35-4518-92b5-4ff62881fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6e8a5132-e2da-4115-abf6-7bc0630e8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-88dec777-152c-4a98-96eb-84e23975402d,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-adc4bb5a-9bbc-4e24-99d0-f899a08e3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-4cddf8d7-f7a6-4558-b847-f975fd49a530,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-2008d005-89fe-4c3a-903a-bfd115b88b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-5057bcc0-2125-4205-a4ea-3d3281195dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046721146-172.17.0.14-1599320703419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-ed2e2258-98d8-402c-8ea1-a0a4d20bee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-c2394b8e-0e35-4518-92b5-4ff62881fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6e8a5132-e2da-4115-abf6-7bc0630e8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-88dec777-152c-4a98-96eb-84e23975402d,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-adc4bb5a-9bbc-4e24-99d0-f899a08e3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-4cddf8d7-f7a6-4558-b847-f975fd49a530,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-2008d005-89fe-4c3a-903a-bfd115b88b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-5057bcc0-2125-4205-a4ea-3d3281195dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403844076-172.17.0.14-1599321374440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-41fdd589-8e21-49d4-9d92-daddc72db289,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-c0618fe6-8dc3-425b-b70c-b52d36044cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-cb81d223-f10e-4c03-b247-12a35bf17be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-ba5d60bd-8fcf-40df-878b-45843e46b127,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-71697802-e3b3-42f7-abc4-cd33045f1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-9e83a604-2566-4dc2-b1ff-034c4a98b125,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-89f391a9-07b9-4ea1-b9ce-8635623fe03c,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8e81d56a-6f06-4d21-aa24-1c24c839d963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403844076-172.17.0.14-1599321374440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-41fdd589-8e21-49d4-9d92-daddc72db289,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-c0618fe6-8dc3-425b-b70c-b52d36044cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-cb81d223-f10e-4c03-b247-12a35bf17be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-ba5d60bd-8fcf-40df-878b-45843e46b127,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-71697802-e3b3-42f7-abc4-cd33045f1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-9e83a604-2566-4dc2-b1ff-034c4a98b125,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-89f391a9-07b9-4ea1-b9ce-8635623fe03c,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8e81d56a-6f06-4d21-aa24-1c24c839d963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663298678-172.17.0.14-1599321414108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38498,DS-74c99bd8-01ee-4fe0-8804-8b7c0aa78c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-496894bb-8791-41dd-a32c-d60aa2c8f351,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6c3e6d56-15e0-49c2-8d4a-dbbe1101120c,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-f69cc1ad-108d-4e22-95eb-63956e23fd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-e09d88b3-7c2e-4cf5-ace1-2bf9700ce1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ba6053a0-3657-4987-94f4-6931ab970014,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c9c868a9-1970-47b0-84af-d25bd4c48f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-1d9402cc-9d2e-4178-9e88-6d13933898d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663298678-172.17.0.14-1599321414108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38498,DS-74c99bd8-01ee-4fe0-8804-8b7c0aa78c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-496894bb-8791-41dd-a32c-d60aa2c8f351,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-6c3e6d56-15e0-49c2-8d4a-dbbe1101120c,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-f69cc1ad-108d-4e22-95eb-63956e23fd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-e09d88b3-7c2e-4cf5-ace1-2bf9700ce1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ba6053a0-3657-4987-94f4-6931ab970014,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c9c868a9-1970-47b0-84af-d25bd4c48f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-1d9402cc-9d2e-4178-9e88-6d13933898d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024549853-172.17.0.14-1599321620033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-e9998762-962c-474e-8ee2-e4706e514432,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-243d3b3e-afb3-4f77-a6e2-de51c9a1858b,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-3f01bc6b-7822-44fa-9558-4bcf6442d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b4780584-5e4f-4865-a713-92437d01a384,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-62cc2548-7cb8-417f-b516-de47fa6db834,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-72b6fc47-5d89-446e-9b4d-9c5efdae2113,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-d1be1d29-75b5-4cf2-a1bf-42c1ba8f70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-7a565ca2-eb48-4494-927f-0f3d8c6f0d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024549853-172.17.0.14-1599321620033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-e9998762-962c-474e-8ee2-e4706e514432,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-243d3b3e-afb3-4f77-a6e2-de51c9a1858b,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-3f01bc6b-7822-44fa-9558-4bcf6442d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b4780584-5e4f-4865-a713-92437d01a384,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-62cc2548-7cb8-417f-b516-de47fa6db834,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-72b6fc47-5d89-446e-9b4d-9c5efdae2113,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-d1be1d29-75b5-4cf2-a1bf-42c1ba8f70bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-7a565ca2-eb48-4494-927f-0f3d8c6f0d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990790184-172.17.0.14-1599322616056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-f5569db5-969b-4227-be62-4d500c277e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-528a0ee8-9378-4ce6-aac7-de5c875a7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-5a7fca10-7f2e-4f8e-9cbe-a383ab040266,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-cdb55d86-b842-462b-bc4a-ac1dbf341173,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4c36458a-2d5f-4281-9425-98c0e4490ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-efffaec8-15ff-427c-a700-f0b53bc42c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-bfa1bd1f-bbdd-434c-9368-4415c532751f,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-7c7d0060-5455-428f-a3c0-d093cd7f2e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990790184-172.17.0.14-1599322616056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-f5569db5-969b-4227-be62-4d500c277e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-528a0ee8-9378-4ce6-aac7-de5c875a7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-5a7fca10-7f2e-4f8e-9cbe-a383ab040266,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-cdb55d86-b842-462b-bc4a-ac1dbf341173,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4c36458a-2d5f-4281-9425-98c0e4490ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-efffaec8-15ff-427c-a700-f0b53bc42c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-bfa1bd1f-bbdd-434c-9368-4415c532751f,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-7c7d0060-5455-428f-a3c0-d093cd7f2e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235233170-172.17.0.14-1599322876396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-23ea340d-b587-471c-b867-609bb7a07b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-1ad6e0af-ca3a-4ce5-a881-aaeac6de5173,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-498732b4-5fde-4247-b2e3-becccca11718,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-c40e914c-168a-4559-9136-462dd09960f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-dd142507-82d4-4f0c-b384-6dd69867fc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-9eb8d5f8-7943-48e3-bfbb-ea7cc4af78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-ee27842f-30ec-404f-86d9-09cd506fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-259bf8e1-4349-4875-9e23-d81deb24bf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235233170-172.17.0.14-1599322876396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43906,DS-23ea340d-b587-471c-b867-609bb7a07b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-1ad6e0af-ca3a-4ce5-a881-aaeac6de5173,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-498732b4-5fde-4247-b2e3-becccca11718,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-c40e914c-168a-4559-9136-462dd09960f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-dd142507-82d4-4f0c-b384-6dd69867fc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-9eb8d5f8-7943-48e3-bfbb-ea7cc4af78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-ee27842f-30ec-404f-86d9-09cd506fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-259bf8e1-4349-4875-9e23-d81deb24bf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889454398-172.17.0.14-1599323277316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-12fe74cb-948a-4b60-946d-c256523ebaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-58ee641f-b31d-424c-9e87-1b901846d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-3791fc43-8673-4f4c-9ba5-e61d1e000682,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-b2506123-3c7f-4b9b-a3f8-cce06afa21da,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-2afa86bb-ff69-4ca0-9a4d-c4842fccda17,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-f6621aa3-9e25-47e4-a4e4-bafe4035d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-005b6700-e757-4639-9b6c-e772d747f22a,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-8621aa23-a54d-4630-9bd2-8a73632e6a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889454398-172.17.0.14-1599323277316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-12fe74cb-948a-4b60-946d-c256523ebaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-58ee641f-b31d-424c-9e87-1b901846d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-3791fc43-8673-4f4c-9ba5-e61d1e000682,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-b2506123-3c7f-4b9b-a3f8-cce06afa21da,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-2afa86bb-ff69-4ca0-9a4d-c4842fccda17,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-f6621aa3-9e25-47e4-a4e4-bafe4035d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-005b6700-e757-4639-9b6c-e772d747f22a,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-8621aa23-a54d-4630-9bd2-8a73632e6a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461344490-172.17.0.14-1599323645132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-3c1eb2c5-e365-44e0-b8a4-e158d6f19edf,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-cffed2d3-e2ab-462f-ac7e-b1107c2c3d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-7f4cd3bc-7eb9-492f-8ca8-5c12fffa4ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a0fed4cf-5a0a-4ed9-9c22-0d2a09385259,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-5e8275a8-de72-45eb-a977-fd2df3173198,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-d195843c-29e4-44ed-9002-ee7bb3fc9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-839fc6da-1c48-4098-bfc7-0c2ed5738c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-cfc0e007-24ff-4450-a6f9-37d55bd21190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461344490-172.17.0.14-1599323645132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-3c1eb2c5-e365-44e0-b8a4-e158d6f19edf,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-cffed2d3-e2ab-462f-ac7e-b1107c2c3d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-7f4cd3bc-7eb9-492f-8ca8-5c12fffa4ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a0fed4cf-5a0a-4ed9-9c22-0d2a09385259,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-5e8275a8-de72-45eb-a977-fd2df3173198,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-d195843c-29e4-44ed-9002-ee7bb3fc9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-839fc6da-1c48-4098-bfc7-0c2ed5738c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-cfc0e007-24ff-4450-a6f9-37d55bd21190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553582781-172.17.0.14-1599324079362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36391,DS-65118427-a412-4207-8d13-be6472e3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-99c937c2-22ea-41e6-b3d8-e2e4d46a1dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-91463f9e-d726-4400-8e72-0f89b644ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-e28dded0-5872-4f91-89cf-ef3a03f6b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-d57f7c58-adb4-4759-b64a-6af6f5c0048f,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3eeef6b2-8068-46db-bd3c-868864c65587,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-c0bcc592-5a25-4d38-85ee-276b72e0f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-d734b4c5-2461-4037-9129-f21db29099fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553582781-172.17.0.14-1599324079362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36391,DS-65118427-a412-4207-8d13-be6472e3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-99c937c2-22ea-41e6-b3d8-e2e4d46a1dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-91463f9e-d726-4400-8e72-0f89b644ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-e28dded0-5872-4f91-89cf-ef3a03f6b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-d57f7c58-adb4-4759-b64a-6af6f5c0048f,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3eeef6b2-8068-46db-bd3c-868864c65587,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-c0bcc592-5a25-4d38-85ee-276b72e0f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-d734b4c5-2461-4037-9129-f21db29099fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068404245-172.17.0.14-1599324154455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-5c4abb53-78d4-4d1d-a2eb-b49553b0db26,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-2c062686-ea43-4b98-9379-c03a4c24c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-dd2645fb-d68c-45af-a0c6-67887d569aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-71a53002-ee52-4c0d-b2ad-020e179724af,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-c2eff1e1-ff54-4db7-b21d-aec4aea4ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-23770e9c-2197-4d41-89a1-cfc37342e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-04fc1ddf-06bf-4d2c-babc-797df54705db,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-5106f00f-550a-4773-aaf6-f94e84ee46bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068404245-172.17.0.14-1599324154455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-5c4abb53-78d4-4d1d-a2eb-b49553b0db26,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-2c062686-ea43-4b98-9379-c03a4c24c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-dd2645fb-d68c-45af-a0c6-67887d569aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-71a53002-ee52-4c0d-b2ad-020e179724af,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-c2eff1e1-ff54-4db7-b21d-aec4aea4ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-23770e9c-2197-4d41-89a1-cfc37342e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-04fc1ddf-06bf-4d2c-babc-797df54705db,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-5106f00f-550a-4773-aaf6-f94e84ee46bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486331589-172.17.0.14-1599324235971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-e40fcc20-ee67-4457-96f6-4f5628ae64db,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-dfc26257-e737-4ea6-916d-5eefbdeaf771,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-f4361a40-db1c-45d5-b922-772dceaf3111,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6e7b2414-3599-4475-bd46-5c83ce6205ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-6e9fa186-08ef-4173-831e-2c3027489027,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-085ed9f5-603d-4ad4-87c1-f46b91e8fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-3c037142-13fa-49dd-9376-cad36f17807c,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-50f481f7-a461-48cb-9616-a68ff008d951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486331589-172.17.0.14-1599324235971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-e40fcc20-ee67-4457-96f6-4f5628ae64db,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-dfc26257-e737-4ea6-916d-5eefbdeaf771,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-f4361a40-db1c-45d5-b922-772dceaf3111,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-6e7b2414-3599-4475-bd46-5c83ce6205ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-6e9fa186-08ef-4173-831e-2c3027489027,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-085ed9f5-603d-4ad4-87c1-f46b91e8fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-3c037142-13fa-49dd-9376-cad36f17807c,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-50f481f7-a461-48cb-9616-a68ff008d951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245766461-172.17.0.14-1599324305743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-d717b288-e7a3-449e-940f-27cca88c84e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-392de421-a725-4862-8442-ea21b63740ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-144995cd-c1f0-4d36-aad3-4d8156847031,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-0759ca54-60c5-401c-b846-0cec672ed513,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6f1ae953-0164-43dc-ad6c-fd7b3165a9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-5ceef6a2-7951-4a44-87e6-0a0ded5478db,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-7bb5d0ba-ec07-4f46-9f9f-335d15412d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-38005ba4-eebf-4aea-9f9a-65e6df8f3c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245766461-172.17.0.14-1599324305743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-d717b288-e7a3-449e-940f-27cca88c84e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-392de421-a725-4862-8442-ea21b63740ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-144995cd-c1f0-4d36-aad3-4d8156847031,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-0759ca54-60c5-401c-b846-0cec672ed513,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6f1ae953-0164-43dc-ad6c-fd7b3165a9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-5ceef6a2-7951-4a44-87e6-0a0ded5478db,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-7bb5d0ba-ec07-4f46-9f9f-335d15412d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-38005ba4-eebf-4aea-9f9a-65e6df8f3c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603146712-172.17.0.14-1599324635295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-3b15401e-ae8a-4832-8ab9-3e4c72edb9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-de23670d-dfbb-44c8-b3ad-9c0fa5c9340d,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-d17aafcb-889c-415e-a623-4c884e238770,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-00590d7b-5d9f-4f6a-9a03-4e6dc4c9a8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-c54c52d3-1fd8-49af-bff8-eac68bd2693f,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b06c30fc-27af-4b5a-8482-339eca2efce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-5877a9f3-3ff4-4cd0-9a59-919cf3caa277,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-462552d8-11f4-4257-aab9-23419b919d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603146712-172.17.0.14-1599324635295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-3b15401e-ae8a-4832-8ab9-3e4c72edb9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-de23670d-dfbb-44c8-b3ad-9c0fa5c9340d,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-d17aafcb-889c-415e-a623-4c884e238770,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-00590d7b-5d9f-4f6a-9a03-4e6dc4c9a8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-c54c52d3-1fd8-49af-bff8-eac68bd2693f,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b06c30fc-27af-4b5a-8482-339eca2efce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-5877a9f3-3ff4-4cd0-9a59-919cf3caa277,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-462552d8-11f4-4257-aab9-23419b919d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933682412-172.17.0.14-1599324723762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-72b7f4a3-52b9-4f14-afb5-1b924d2a07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-8d05e06b-2160-454f-8fb9-d52dc82a698f,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-6f5292f7-3e76-43f7-a809-a81a754912e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-25c9b3bb-96a0-4a48-bd8d-5d8de324f185,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-44fae886-d6e4-4596-bd3d-5c54312884b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-c8414ab7-69d9-4f33-8351-70b73c395534,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-61dfbf12-977a-4301-ac3b-3f4b0544bfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b8051e43-5f0d-4c3c-83e4-c61c252aaf46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933682412-172.17.0.14-1599324723762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-72b7f4a3-52b9-4f14-afb5-1b924d2a07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-8d05e06b-2160-454f-8fb9-d52dc82a698f,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-6f5292f7-3e76-43f7-a809-a81a754912e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-25c9b3bb-96a0-4a48-bd8d-5d8de324f185,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-44fae886-d6e4-4596-bd3d-5c54312884b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-c8414ab7-69d9-4f33-8351-70b73c395534,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-61dfbf12-977a-4301-ac3b-3f4b0544bfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b8051e43-5f0d-4c3c-83e4-c61c252aaf46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939226594-172.17.0.14-1599325505056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43234,DS-ccc15eca-f831-460b-9b1b-aa24e4150901,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-1cb89d8c-e72d-4536-a8f9-9de5ccbbab51,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-5c50aca5-4064-48aa-9e4c-224f0fefdf21,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-688bfa20-63ce-453b-b30a-97accbbd7861,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-78458363-31a7-4e94-b538-597701840287,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-fbb325fa-065c-4063-906a-ed55ab1b2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-7426b3c5-10a7-4fba-bf9f-7724770d6a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f376572f-cf3a-47ed-b02b-2d496e100265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939226594-172.17.0.14-1599325505056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43234,DS-ccc15eca-f831-460b-9b1b-aa24e4150901,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-1cb89d8c-e72d-4536-a8f9-9de5ccbbab51,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-5c50aca5-4064-48aa-9e4c-224f0fefdf21,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-688bfa20-63ce-453b-b30a-97accbbd7861,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-78458363-31a7-4e94-b538-597701840287,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-fbb325fa-065c-4063-906a-ed55ab1b2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-7426b3c5-10a7-4fba-bf9f-7724770d6a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f376572f-cf3a-47ed-b02b-2d496e100265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5616
