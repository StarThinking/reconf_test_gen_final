reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110148032-172.17.0.13-1599381310328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-440bd9e7-a192-42fa-84ab-f1f0639c137f,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8ecbca71-4fb8-479d-8605-d84ef38b11a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-00ae6f7c-82b5-4a14-83eb-7dfe9daa0768,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-42ec4a46-6665-4026-a6fe-019de571959a,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-988ddf4b-06fc-477c-a1c7-f42bbe76fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-f628d965-2b0a-4c3c-a0a4-f82daab04822,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-fd1fa172-47d6-457c-8e4a-e53bcf6cf0db,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-a746ce43-59b0-47f3-8fd0-c008a0ded4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110148032-172.17.0.13-1599381310328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-440bd9e7-a192-42fa-84ab-f1f0639c137f,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8ecbca71-4fb8-479d-8605-d84ef38b11a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-00ae6f7c-82b5-4a14-83eb-7dfe9daa0768,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-42ec4a46-6665-4026-a6fe-019de571959a,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-988ddf4b-06fc-477c-a1c7-f42bbe76fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-f628d965-2b0a-4c3c-a0a4-f82daab04822,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-fd1fa172-47d6-457c-8e4a-e53bcf6cf0db,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-a746ce43-59b0-47f3-8fd0-c008a0ded4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735991381-172.17.0.13-1599381815910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-1757dc04-3174-44d4-a5c6-77e0b142583c,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-b79210ac-d9db-4d2d-9883-ce71dedc24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-fbfa7730-bbb4-49b3-9d4e-2842ccaeb142,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-9421851d-ad2a-40a9-90af-79822c2b4889,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-28f07f79-93f0-4682-9f04-ee9e92903c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-5474d808-3715-4dc2-9ac8-cc2cfa45ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-3de28923-4441-407d-8829-c2e57f906c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-f16ac212-23a7-4300-bc70-164495912c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735991381-172.17.0.13-1599381815910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-1757dc04-3174-44d4-a5c6-77e0b142583c,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-b79210ac-d9db-4d2d-9883-ce71dedc24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-fbfa7730-bbb4-49b3-9d4e-2842ccaeb142,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-9421851d-ad2a-40a9-90af-79822c2b4889,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-28f07f79-93f0-4682-9f04-ee9e92903c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-5474d808-3715-4dc2-9ac8-cc2cfa45ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-3de28923-4441-407d-8829-c2e57f906c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-f16ac212-23a7-4300-bc70-164495912c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402266649-172.17.0.13-1599381904818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-425270bf-7be6-43d5-8acd-8ff11087a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-4afa6ea5-4e54-4278-aeca-c2ab9a4929ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-719ce8da-9bb1-434e-9f6a-408cd7cd25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-750afb96-2d2e-43e9-9dda-82d362094abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-a8643262-82fa-4b2d-a1f1-0707c394eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-006b1e3a-0dfb-4c21-9d2f-3349463149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-427100da-cad3-4e58-a3a9-cfcc46117eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a5fd72e6-836f-4ba2-b757-2e44735e60b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402266649-172.17.0.13-1599381904818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-425270bf-7be6-43d5-8acd-8ff11087a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-4afa6ea5-4e54-4278-aeca-c2ab9a4929ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-719ce8da-9bb1-434e-9f6a-408cd7cd25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-750afb96-2d2e-43e9-9dda-82d362094abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-a8643262-82fa-4b2d-a1f1-0707c394eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-006b1e3a-0dfb-4c21-9d2f-3349463149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-427100da-cad3-4e58-a3a9-cfcc46117eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a5fd72e6-836f-4ba2-b757-2e44735e60b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849982158-172.17.0.13-1599381998481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-06cdc7e2-06be-4924-86f1-7d803e1825c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-e3305d87-37fe-4864-9ee1-b87f1b8bfa43,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-1b5d569f-d7d7-40dc-9e7c-a2663f137eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-3977e347-75ce-4600-b943-683d92407ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3bd1f8f6-7e40-48b5-9809-9399dfc0421c,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-9aaf6c25-dea6-4539-8722-78a15871851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-6f486346-e054-4095-8830-877659f464ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-af3ca649-04a6-407d-8d1f-09eaae497cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849982158-172.17.0.13-1599381998481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-06cdc7e2-06be-4924-86f1-7d803e1825c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-e3305d87-37fe-4864-9ee1-b87f1b8bfa43,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-1b5d569f-d7d7-40dc-9e7c-a2663f137eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-3977e347-75ce-4600-b943-683d92407ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3bd1f8f6-7e40-48b5-9809-9399dfc0421c,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-9aaf6c25-dea6-4539-8722-78a15871851e,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-6f486346-e054-4095-8830-877659f464ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-af3ca649-04a6-407d-8d1f-09eaae497cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603798202-172.17.0.13-1599382159155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38887,DS-1768cca5-1caf-41c7-99b8-7fcc1c0c5649,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-869f90e8-1c31-4d8c-840f-379f206f807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-9a941c34-6622-4b4d-9950-ab322777969b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-84b37525-a77c-464c-a0a7-172a0b74fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-0ffa40f3-6686-4cf8-8e1b-3d1b6ce27d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-e3955537-cc69-48a4-a978-4d3b755d90e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-079bc63b-79ef-40c1-b2e5-33f9318f9f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-517ab5bb-1c44-4134-9d0e-d0c73ad5d454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603798202-172.17.0.13-1599382159155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38887,DS-1768cca5-1caf-41c7-99b8-7fcc1c0c5649,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-869f90e8-1c31-4d8c-840f-379f206f807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-9a941c34-6622-4b4d-9950-ab322777969b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-84b37525-a77c-464c-a0a7-172a0b74fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-0ffa40f3-6686-4cf8-8e1b-3d1b6ce27d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-e3955537-cc69-48a4-a978-4d3b755d90e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-079bc63b-79ef-40c1-b2e5-33f9318f9f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-517ab5bb-1c44-4134-9d0e-d0c73ad5d454,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366096595-172.17.0.13-1599382250717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-4810b94c-1dca-4850-af16-8909c4ff5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-9c24e5a6-2671-4eab-bf32-2cb37feb6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-f0fc5d73-fc24-441f-91f3-4acf41fa1176,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-a2469959-b719-47e4-86fd-abb89f2ac459,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-8336986f-a328-4b51-873b-fe1f9d1a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-e2f195de-8edd-4da1-ae28-98f3f3df7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-163d6c32-97b5-40e2-9901-27e7814af519,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a4938c60-701f-4cb6-8d46-b7135b24691a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366096595-172.17.0.13-1599382250717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-4810b94c-1dca-4850-af16-8909c4ff5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-9c24e5a6-2671-4eab-bf32-2cb37feb6d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-f0fc5d73-fc24-441f-91f3-4acf41fa1176,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-a2469959-b719-47e4-86fd-abb89f2ac459,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-8336986f-a328-4b51-873b-fe1f9d1a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-e2f195de-8edd-4da1-ae28-98f3f3df7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-163d6c32-97b5-40e2-9901-27e7814af519,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a4938c60-701f-4cb6-8d46-b7135b24691a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814325028-172.17.0.13-1599382315857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-7de2828b-adcc-4bc8-9966-5eec1c3d06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-2879d7be-4d43-4731-a20d-4fd79579616b,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-dc4b57f6-e3f6-4fb9-8723-4b8e56cf69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-6fc9ee59-efac-4f91-bef4-240e52a18a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1f97c5f5-ed2a-41a4-843b-0a39687870d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-bd9a8cec-16fe-4057-84aa-726533044183,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c3dc5e00-25c1-456a-8773-563d183c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-52a934f1-1784-4b26-93f0-3f50d2f4ae69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814325028-172.17.0.13-1599382315857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-7de2828b-adcc-4bc8-9966-5eec1c3d06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-2879d7be-4d43-4731-a20d-4fd79579616b,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-dc4b57f6-e3f6-4fb9-8723-4b8e56cf69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-6fc9ee59-efac-4f91-bef4-240e52a18a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1f97c5f5-ed2a-41a4-843b-0a39687870d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-bd9a8cec-16fe-4057-84aa-726533044183,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c3dc5e00-25c1-456a-8773-563d183c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-52a934f1-1784-4b26-93f0-3f50d2f4ae69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933631079-172.17.0.13-1599382443068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42399,DS-2eb8a48a-fac3-4eda-9716-1c0be7f07361,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-5b03d57a-0ac2-480e-9416-c3322a19dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-f68040dc-1b21-4ab7-8607-50a9329d0bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-b97a7e27-d409-41aa-b089-049b8c247c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-4e043887-1d99-42f0-a835-bff768b5c836,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-677857c8-2932-4a61-87c7-2c0793080e31,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-8b628e76-079c-4ff9-ae08-8053568d26e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8f02d826-8d92-4f34-8c23-dab47405b284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933631079-172.17.0.13-1599382443068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42399,DS-2eb8a48a-fac3-4eda-9716-1c0be7f07361,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-5b03d57a-0ac2-480e-9416-c3322a19dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-f68040dc-1b21-4ab7-8607-50a9329d0bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-b97a7e27-d409-41aa-b089-049b8c247c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-4e043887-1d99-42f0-a835-bff768b5c836,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-677857c8-2932-4a61-87c7-2c0793080e31,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-8b628e76-079c-4ff9-ae08-8053568d26e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-8f02d826-8d92-4f34-8c23-dab47405b284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422198411-172.17.0.13-1599382813466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-255f7791-6c7f-4c6d-a8f8-81c82f7386bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-8a9c6e22-6d01-40ed-aea0-bac6b0154a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-4fb0151e-cf2d-4878-9496-b707ea765c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-c3d67f56-bf93-427d-9770-cfd378d41487,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-408c081c-d01e-483e-8d5d-e83f5e7acfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-0e010000-e4b6-492d-b4dc-77a32edfb240,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-85dd1b81-fbf3-44b4-8b8d-5d42d42da676,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-8cd9e928-62b8-49cd-a2c7-1104b585be0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422198411-172.17.0.13-1599382813466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-255f7791-6c7f-4c6d-a8f8-81c82f7386bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-8a9c6e22-6d01-40ed-aea0-bac6b0154a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-4fb0151e-cf2d-4878-9496-b707ea765c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-c3d67f56-bf93-427d-9770-cfd378d41487,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-408c081c-d01e-483e-8d5d-e83f5e7acfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-0e010000-e4b6-492d-b4dc-77a32edfb240,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-85dd1b81-fbf3-44b4-8b8d-5d42d42da676,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-8cd9e928-62b8-49cd-a2c7-1104b585be0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355131097-172.17.0.13-1599383434131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-e6b9c329-1674-4ad5-aa99-260a9bd87655,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-78b58247-05ac-47d9-bf9b-c47bb6c4819e,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-6d98b2e9-d264-4e30-b28f-215f4351e575,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-ea677cf1-9c0b-4ec0-9ca5-c96d76b7f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ebc83974-f106-4dce-8326-44670ee966c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-d8a337c1-2b24-476b-afcb-b96d4f9beb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-7132db48-8ea1-4c5f-89fa-b23b0b0eeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-a4643c91-217c-40fa-937c-c700dea2034e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1355131097-172.17.0.13-1599383434131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-e6b9c329-1674-4ad5-aa99-260a9bd87655,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-78b58247-05ac-47d9-bf9b-c47bb6c4819e,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-6d98b2e9-d264-4e30-b28f-215f4351e575,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-ea677cf1-9c0b-4ec0-9ca5-c96d76b7f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ebc83974-f106-4dce-8326-44670ee966c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-d8a337c1-2b24-476b-afcb-b96d4f9beb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-7132db48-8ea1-4c5f-89fa-b23b0b0eeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-a4643c91-217c-40fa-937c-c700dea2034e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917868167-172.17.0.13-1599383492052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-0c40d682-1f16-43ea-a800-2b06d79ee80f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-b87b5898-bd6b-4dda-8bb0-7a5fcdeef254,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-539106eb-9a97-46df-9124-d3ad5b8f6f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-fe0ba2df-bc7a-41b1-8e77-687d9bfa6e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-065909a9-6e45-4eea-b36d-329a058ad038,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-afbd7092-023f-46f2-92fe-19626d868914,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-93b08067-5314-4af7-8f91-dc8ad8ba802a,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-67c450f0-fc43-4e8e-a3ee-6f0466ce1134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917868167-172.17.0.13-1599383492052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-0c40d682-1f16-43ea-a800-2b06d79ee80f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-b87b5898-bd6b-4dda-8bb0-7a5fcdeef254,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-539106eb-9a97-46df-9124-d3ad5b8f6f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-fe0ba2df-bc7a-41b1-8e77-687d9bfa6e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-065909a9-6e45-4eea-b36d-329a058ad038,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-afbd7092-023f-46f2-92fe-19626d868914,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-93b08067-5314-4af7-8f91-dc8ad8ba802a,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-67c450f0-fc43-4e8e-a3ee-6f0466ce1134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191305954-172.17.0.13-1599383639102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-6688b09c-7930-4e22-9258-17700bf1ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-2d864665-012a-436a-92c2-a34fa358f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-47f9717a-80b9-423e-a93b-34581254b969,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-0de76a14-e2a6-4327-b185-5d5b320b6298,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-f9b8cbc0-1685-4c2c-89cd-f715ff411ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-9638b576-bf65-4043-a29b-065fd84d9693,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-0ccabc76-a04e-45ab-8913-6b3391c26a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4c084916-5a27-4b34-8100-7de9dc5e5d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191305954-172.17.0.13-1599383639102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-6688b09c-7930-4e22-9258-17700bf1ee56,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-2d864665-012a-436a-92c2-a34fa358f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-47f9717a-80b9-423e-a93b-34581254b969,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-0de76a14-e2a6-4327-b185-5d5b320b6298,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-f9b8cbc0-1685-4c2c-89cd-f715ff411ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-9638b576-bf65-4043-a29b-065fd84d9693,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-0ccabc76-a04e-45ab-8913-6b3391c26a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4c084916-5a27-4b34-8100-7de9dc5e5d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660409260-172.17.0.13-1599383845406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-139216e4-5fd7-4802-8190-584d0ab3550f,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ca046343-ec93-4ad5-a786-f341bbc2d328,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-1de22ed9-a0bd-4335-a3bb-230cf925d1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-50b219df-104c-4487-a66f-710d782719f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-92b1af9d-b506-42ec-83e6-cee28088b234,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-20d13cc3-128e-46ff-8bc9-a69950a0f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-ecefa343-3439-42c3-8f29-50535465c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-950f38f4-01d7-47f0-be83-259d5c3a2ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660409260-172.17.0.13-1599383845406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-139216e4-5fd7-4802-8190-584d0ab3550f,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-ca046343-ec93-4ad5-a786-f341bbc2d328,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-1de22ed9-a0bd-4335-a3bb-230cf925d1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-50b219df-104c-4487-a66f-710d782719f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-92b1af9d-b506-42ec-83e6-cee28088b234,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-20d13cc3-128e-46ff-8bc9-a69950a0f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-ecefa343-3439-42c3-8f29-50535465c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-950f38f4-01d7-47f0-be83-259d5c3a2ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579828136-172.17.0.13-1599384299514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-8af9706f-84c0-4ae1-a885-675f96f3807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-bc6241f8-4ab8-465f-a4a2-542e3cd09fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-e85e90f7-8272-435c-8a7f-9da897b00adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-258172b3-a799-4865-b3c0-810fc0e39349,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-681a0014-0912-428c-99eb-9c35852d7cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-c5aa9440-aa22-4996-bbb0-abb6633fef76,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a13d4624-a845-42ad-971d-39529ed556a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-0dbd5341-b5a9-4cf6-888b-173a194b57cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579828136-172.17.0.13-1599384299514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-8af9706f-84c0-4ae1-a885-675f96f3807b,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-bc6241f8-4ab8-465f-a4a2-542e3cd09fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-e85e90f7-8272-435c-8a7f-9da897b00adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-258172b3-a799-4865-b3c0-810fc0e39349,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-681a0014-0912-428c-99eb-9c35852d7cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-c5aa9440-aa22-4996-bbb0-abb6633fef76,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a13d4624-a845-42ad-971d-39529ed556a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-0dbd5341-b5a9-4cf6-888b-173a194b57cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502348368-172.17.0.13-1599384327586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-39758ca6-0835-41e7-a8e9-e43a32b23aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-3ad3f163-9773-4e2e-88e5-8e2ccb083b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-b8d81b1b-51cb-426e-a065-3300648cbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-25ff8f08-5fd2-4129-ade1-38fe0da68734,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-573a5d46-2c55-4f09-8956-92d66c5f5f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-47b90e98-36ce-4716-b934-a71cc6f1caec,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-28681fdb-1673-46ad-b3d4-fcf3c8302f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-38ff73ff-321f-4a82-a18f-9ba525834706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502348368-172.17.0.13-1599384327586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-39758ca6-0835-41e7-a8e9-e43a32b23aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-3ad3f163-9773-4e2e-88e5-8e2ccb083b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-b8d81b1b-51cb-426e-a065-3300648cbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-25ff8f08-5fd2-4129-ade1-38fe0da68734,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-573a5d46-2c55-4f09-8956-92d66c5f5f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-47b90e98-36ce-4716-b934-a71cc6f1caec,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-28681fdb-1673-46ad-b3d4-fcf3c8302f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-38ff73ff-321f-4a82-a18f-9ba525834706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174333528-172.17.0.13-1599384854244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-d3529537-249a-41b8-8505-396ab4e5d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0ffece53-bd85-47a5-83c2-eb80b9f6ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-a2ee4744-d0ee-4d99-a429-a3bc5612bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-c837bcfa-2ed6-4151-9711-cb3461bc7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-bb100b6e-04b8-46ec-a409-a8b7234b6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-f709711a-81bd-4058-b951-1cb00097111e,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-3992c102-ff36-418f-97bd-995fcb1b4945,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9c87b0ab-1d9c-4f01-bc20-b7a315fc850d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174333528-172.17.0.13-1599384854244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-d3529537-249a-41b8-8505-396ab4e5d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0ffece53-bd85-47a5-83c2-eb80b9f6ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-a2ee4744-d0ee-4d99-a429-a3bc5612bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-c837bcfa-2ed6-4151-9711-cb3461bc7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-bb100b6e-04b8-46ec-a409-a8b7234b6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-f709711a-81bd-4058-b951-1cb00097111e,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-3992c102-ff36-418f-97bd-995fcb1b4945,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9c87b0ab-1d9c-4f01-bc20-b7a315fc850d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669422745-172.17.0.13-1599384997209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33135,DS-953b9115-d9ed-4e88-b8c5-45e46fbff3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-0507522a-697a-4c07-bbfb-d35032da1b45,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-025bbcbf-d7af-4e0e-afe3-4917619cf80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-abbf0b6d-b134-44d1-bc9f-70853f70b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-d48b8203-0748-49f0-bf03-978922e5f319,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f20b2ef3-058f-4e2b-ba89-eccc4599c239,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-0cf73b37-f7a1-4874-9d46-d3d7167619dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-583a708a-827c-4685-ae78-a78ecca1c143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669422745-172.17.0.13-1599384997209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33135,DS-953b9115-d9ed-4e88-b8c5-45e46fbff3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-0507522a-697a-4c07-bbfb-d35032da1b45,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-025bbcbf-d7af-4e0e-afe3-4917619cf80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-abbf0b6d-b134-44d1-bc9f-70853f70b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-d48b8203-0748-49f0-bf03-978922e5f319,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f20b2ef3-058f-4e2b-ba89-eccc4599c239,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-0cf73b37-f7a1-4874-9d46-d3d7167619dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-583a708a-827c-4685-ae78-a78ecca1c143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590732389-172.17.0.13-1599385089746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35269,DS-4384b6a1-a32a-4b83-9760-0cdac2a1268b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-1d46d20d-c708-4cd5-b7e8-2609fc751826,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-7e003e53-d15e-439a-a66e-0ebdab6f87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-0ac1415d-5baf-4052-9a23-90afce9b4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-43aa23c6-f536-435e-b3db-602438a2231b,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-f352b07f-ca3e-460d-b76d-6186fb8bb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6b641ab0-63af-42a6-843a-f6edd1e2a53a,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-58ce0920-d979-465f-bb58-8c18deca3bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590732389-172.17.0.13-1599385089746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35269,DS-4384b6a1-a32a-4b83-9760-0cdac2a1268b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-1d46d20d-c708-4cd5-b7e8-2609fc751826,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-7e003e53-d15e-439a-a66e-0ebdab6f87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-0ac1415d-5baf-4052-9a23-90afce9b4ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-43aa23c6-f536-435e-b3db-602438a2231b,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-f352b07f-ca3e-460d-b76d-6186fb8bb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6b641ab0-63af-42a6-843a-f6edd1e2a53a,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-58ce0920-d979-465f-bb58-8c18deca3bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942975111-172.17.0.13-1599385340936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-afc4fcd1-483f-450f-bb73-6159deeacc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-606cb3a5-6e6c-4cba-b497-5592c7674b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-39fef625-2795-49b7-b802-11ab57643092,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-bf8cb24c-e68e-48a6-b51b-307e912dbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0efb7c78-718f-46ed-844b-34ba10c50caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-93ebcf6f-8258-440c-9f8b-9b817886d964,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-23d1109c-1be8-49cd-a639-2dc867c8b953,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-01bce7a7-0409-49f2-a54b-f8979970ebb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942975111-172.17.0.13-1599385340936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-afc4fcd1-483f-450f-bb73-6159deeacc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-606cb3a5-6e6c-4cba-b497-5592c7674b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-39fef625-2795-49b7-b802-11ab57643092,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-bf8cb24c-e68e-48a6-b51b-307e912dbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0efb7c78-718f-46ed-844b-34ba10c50caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-93ebcf6f-8258-440c-9f8b-9b817886d964,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-23d1109c-1be8-49cd-a639-2dc867c8b953,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-01bce7a7-0409-49f2-a54b-f8979970ebb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599080101-172.17.0.13-1599385456012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-ad691318-8f58-4836-b03d-686717c3f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-2bdc2ecf-5dd9-4c99-a8b4-83747663ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-70fd0435-197a-4c5b-902f-e0c414c40834,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-2ae3189c-28f5-4af0-b8be-ed53e4ce95c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-34e4fe25-df73-46d1-90dc-66bd7ae31230,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-fd2c3a82-9a93-4fdd-a73c-3919fc1f485c,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-81c66ade-7e0d-4f84-b8ba-0a6b21b3f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-87fcfe38-fa5d-45c1-8290-5b2bd69fbb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599080101-172.17.0.13-1599385456012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-ad691318-8f58-4836-b03d-686717c3f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-2bdc2ecf-5dd9-4c99-a8b4-83747663ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-70fd0435-197a-4c5b-902f-e0c414c40834,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-2ae3189c-28f5-4af0-b8be-ed53e4ce95c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-34e4fe25-df73-46d1-90dc-66bd7ae31230,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-fd2c3a82-9a93-4fdd-a73c-3919fc1f485c,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-81c66ade-7e0d-4f84-b8ba-0a6b21b3f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-87fcfe38-fa5d-45c1-8290-5b2bd69fbb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4401
