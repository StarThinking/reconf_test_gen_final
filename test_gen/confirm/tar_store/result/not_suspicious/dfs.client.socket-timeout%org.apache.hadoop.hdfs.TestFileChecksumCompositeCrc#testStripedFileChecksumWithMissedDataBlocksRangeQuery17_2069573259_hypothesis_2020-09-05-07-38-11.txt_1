reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756332692-172.17.0.4-1599291506350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-3b8720c0-7dc5-4e1e-ab9b-f35dd05b122a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-87d3251f-dece-4e45-99c6-c04664e0f226,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-95c6550b-8f09-43f6-a548-ab572277ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-bfec6a3e-b844-4c14-85b3-a0bd775bc995,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-a3b6ba8e-69cd-483e-8b00-77203180f816,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-761959a3-8e6d-4fe7-b32e-8ad135f8d951,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-27e679dd-479d-45f1-a42c-4e6d411e4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-407ad10f-585a-4817-9e32-d20b5a826908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756332692-172.17.0.4-1599291506350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-3b8720c0-7dc5-4e1e-ab9b-f35dd05b122a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-87d3251f-dece-4e45-99c6-c04664e0f226,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-95c6550b-8f09-43f6-a548-ab572277ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-bfec6a3e-b844-4c14-85b3-a0bd775bc995,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-a3b6ba8e-69cd-483e-8b00-77203180f816,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-761959a3-8e6d-4fe7-b32e-8ad135f8d951,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-27e679dd-479d-45f1-a42c-4e6d411e4cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-407ad10f-585a-4817-9e32-d20b5a826908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670991724-172.17.0.4-1599292047746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-4538cbc0-c349-4baf-b287-7fdd6e682afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-41160c92-b276-48c0-bada-b90e4440c806,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-c4e28a01-02ff-4a59-8827-4d1c0715d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bbd3953f-4fac-4f17-88a4-9517888e594d,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-797cdf41-f6a0-4d80-a15d-cb5beeb0b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-e3b0f2ee-4e8e-4e86-b361-6dc730404eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-d852e542-d870-41e4-90b4-1f1bc6e7c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-3439f362-86d3-4b6c-a21f-e589b14527ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670991724-172.17.0.4-1599292047746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-4538cbc0-c349-4baf-b287-7fdd6e682afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-41160c92-b276-48c0-bada-b90e4440c806,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-c4e28a01-02ff-4a59-8827-4d1c0715d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bbd3953f-4fac-4f17-88a4-9517888e594d,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-797cdf41-f6a0-4d80-a15d-cb5beeb0b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-e3b0f2ee-4e8e-4e86-b361-6dc730404eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-d852e542-d870-41e4-90b4-1f1bc6e7c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-3439f362-86d3-4b6c-a21f-e589b14527ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103350972-172.17.0.4-1599292171724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-7b035c12-6d99-49a8-a40b-5dc974688853,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-68f04e8a-07b1-4c7b-863b-c112effbda32,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-27108a7a-ac94-421c-a1e1-bbb9ea050d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8e2fff92-33aa-458c-b6ec-cc5b3b84467d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-12bf1036-28fb-4353-bca8-aa2d242b1095,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-3113534c-5a77-40f0-a8cf-95b3fc2eb60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-6a3ac8b8-e4cb-4a9d-82ce-0984d7e08439,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-fb9fc225-1075-4948-9454-515adc7e1911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103350972-172.17.0.4-1599292171724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-7b035c12-6d99-49a8-a40b-5dc974688853,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-68f04e8a-07b1-4c7b-863b-c112effbda32,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-27108a7a-ac94-421c-a1e1-bbb9ea050d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8e2fff92-33aa-458c-b6ec-cc5b3b84467d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-12bf1036-28fb-4353-bca8-aa2d242b1095,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-3113534c-5a77-40f0-a8cf-95b3fc2eb60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-6a3ac8b8-e4cb-4a9d-82ce-0984d7e08439,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-fb9fc225-1075-4948-9454-515adc7e1911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628038963-172.17.0.4-1599292280242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-273ffb54-547d-4df1-ba1b-51986441ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-3faf1e34-0d55-488e-9f11-c03fa76343f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-2ebb4926-09b1-4afa-86d8-2beb2fff55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-7c4190b8-bbe2-4b9e-8ba9-13b365b60cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9a67414e-871c-43bd-bf4b-c7cbaec95b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-806fd87a-3724-4edb-b46d-f74269c270b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-2d90fce1-30d6-431b-9045-977b3a4e07b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-1d3351fa-4499-4cca-ab2b-5c3bb5affa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628038963-172.17.0.4-1599292280242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-273ffb54-547d-4df1-ba1b-51986441ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-3faf1e34-0d55-488e-9f11-c03fa76343f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-2ebb4926-09b1-4afa-86d8-2beb2fff55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-7c4190b8-bbe2-4b9e-8ba9-13b365b60cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9a67414e-871c-43bd-bf4b-c7cbaec95b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-806fd87a-3724-4edb-b46d-f74269c270b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-2d90fce1-30d6-431b-9045-977b3a4e07b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-1d3351fa-4499-4cca-ab2b-5c3bb5affa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203826917-172.17.0.4-1599292861276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-f3c34d51-0513-4d7f-a245-77b4f83e55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-18026f74-a30e-4268-82f7-17cd252954ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-d507b238-9d9a-4796-b5ba-efce2b50633a,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-54c45928-90bf-48ca-82e9-c06655a33aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-86f6839f-ec5d-4c5b-8138-476fca0d931d,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2f330f14-e739-47d4-a71f-c4b85f4c7461,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-bf73b619-9c71-4326-9f52-6d680ee2521b,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-bb8b8d14-d56c-422b-85a3-b3dd769e3ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203826917-172.17.0.4-1599292861276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-f3c34d51-0513-4d7f-a245-77b4f83e55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-18026f74-a30e-4268-82f7-17cd252954ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-d507b238-9d9a-4796-b5ba-efce2b50633a,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-54c45928-90bf-48ca-82e9-c06655a33aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-86f6839f-ec5d-4c5b-8138-476fca0d931d,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2f330f14-e739-47d4-a71f-c4b85f4c7461,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-bf73b619-9c71-4326-9f52-6d680ee2521b,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-bb8b8d14-d56c-422b-85a3-b3dd769e3ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450999838-172.17.0.4-1599293148570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-ef405532-23e7-4eac-bb31-14beddd3dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-cea5d805-a6df-48f7-8d1e-9b98a5ebc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ade6832f-3620-43a9-b1ce-942211991278,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-3fc1bf32-e793-4a84-a3b4-f208595b51b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-eb3031f3-b5d6-45df-af2b-43529fc46950,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-adb3aeef-15e0-4c24-ac20-4ef382d03ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3a3ee962-3c3f-4dea-9db4-174fdc6d9403,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-612008fa-42d7-40a9-9f96-807c0df1a5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450999838-172.17.0.4-1599293148570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-ef405532-23e7-4eac-bb31-14beddd3dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-cea5d805-a6df-48f7-8d1e-9b98a5ebc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ade6832f-3620-43a9-b1ce-942211991278,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-3fc1bf32-e793-4a84-a3b4-f208595b51b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-eb3031f3-b5d6-45df-af2b-43529fc46950,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-adb3aeef-15e0-4c24-ac20-4ef382d03ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3a3ee962-3c3f-4dea-9db4-174fdc6d9403,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-612008fa-42d7-40a9-9f96-807c0df1a5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701226672-172.17.0.4-1599293182772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-7156f091-5a84-4b13-a2b1-7ee32e7ec51f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-0677cb8f-5e9a-43a1-970a-04e68cfe4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-7eaddc44-182b-4c24-86e4-91333e9860b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-763935de-b491-41d0-86ae-be00638ae78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-780b6b97-8250-4bab-98c8-6d302bf07c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-e69bc89e-da48-44f3-a316-93ed87a330ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-41d350ec-b865-4a62-986e-01f6bb1f91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-1b7ee033-e11e-4bed-9b51-1e03260799f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701226672-172.17.0.4-1599293182772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-7156f091-5a84-4b13-a2b1-7ee32e7ec51f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-0677cb8f-5e9a-43a1-970a-04e68cfe4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-7eaddc44-182b-4c24-86e4-91333e9860b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-763935de-b491-41d0-86ae-be00638ae78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-780b6b97-8250-4bab-98c8-6d302bf07c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-e69bc89e-da48-44f3-a316-93ed87a330ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-41d350ec-b865-4a62-986e-01f6bb1f91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-1b7ee033-e11e-4bed-9b51-1e03260799f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445133799-172.17.0.4-1599293362270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-c34ac099-76e7-4626-82ea-23e354bfa35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-959ec36a-07fc-4c54-abd9-c339bfea812d,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-29df7a3a-9f01-4be6-883f-21b4758dc883,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-bb40456b-dabb-4ddb-98a6-20db073d0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-b7a18127-86a6-416b-8fad-28964cbb15a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b25561e8-54a7-480e-912e-93a1c765bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-1ff4da47-8716-4b22-8e6e-e2fb8f85a015,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-353885f2-835b-4fb0-92f6-905d378a25a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445133799-172.17.0.4-1599293362270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-c34ac099-76e7-4626-82ea-23e354bfa35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-959ec36a-07fc-4c54-abd9-c339bfea812d,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-29df7a3a-9f01-4be6-883f-21b4758dc883,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-bb40456b-dabb-4ddb-98a6-20db073d0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-b7a18127-86a6-416b-8fad-28964cbb15a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b25561e8-54a7-480e-912e-93a1c765bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-1ff4da47-8716-4b22-8e6e-e2fb8f85a015,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-353885f2-835b-4fb0-92f6-905d378a25a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387737851-172.17.0.4-1599293666020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-fedf3a9d-ff38-4873-80e5-44779e73e929,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-8545091b-0bc4-4c36-bdf2-999b18df8178,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-81b2cf79-d27c-4799-a54f-80d184444055,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-397deec0-35ca-4980-b56e-a41fafa18b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f80ed912-0a2d-40cc-8619-9d67b4caab5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-d206fb6d-e0dd-49e7-87ef-47f340501328,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-ee432b5a-f91c-499b-b0b5-d99e431054e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-ae399859-65fc-431f-b642-b07f274747e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387737851-172.17.0.4-1599293666020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-fedf3a9d-ff38-4873-80e5-44779e73e929,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-8545091b-0bc4-4c36-bdf2-999b18df8178,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-81b2cf79-d27c-4799-a54f-80d184444055,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-397deec0-35ca-4980-b56e-a41fafa18b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f80ed912-0a2d-40cc-8619-9d67b4caab5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-d206fb6d-e0dd-49e7-87ef-47f340501328,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-ee432b5a-f91c-499b-b0b5-d99e431054e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-ae399859-65fc-431f-b642-b07f274747e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865353344-172.17.0.4-1599294114418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-dec5deb4-e1b0-4381-b482-8ad55d9ab6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-51b81434-3cdd-4840-88ba-33bfbe9c8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-5addaab5-3639-4eb0-bce4-bb1339a2d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-73d71e2b-81ec-41fe-944a-c40b22af7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-e7ad0a81-66e0-465e-9a00-7d5b2d414deb,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-4f5fb94a-331c-421c-8467-4d12e1d3bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-e598eb66-61f0-4c9e-a4c1-62e1f41bca75,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-af984fff-faee-4c1f-8f5f-3ccb06b3bc96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865353344-172.17.0.4-1599294114418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37027,DS-dec5deb4-e1b0-4381-b482-8ad55d9ab6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-51b81434-3cdd-4840-88ba-33bfbe9c8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-5addaab5-3639-4eb0-bce4-bb1339a2d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-73d71e2b-81ec-41fe-944a-c40b22af7adc,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-e7ad0a81-66e0-465e-9a00-7d5b2d414deb,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-4f5fb94a-331c-421c-8467-4d12e1d3bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-e598eb66-61f0-4c9e-a4c1-62e1f41bca75,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-af984fff-faee-4c1f-8f5f-3ccb06b3bc96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412570140-172.17.0.4-1599294229086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-311b6582-fef9-42a0-83ac-753911479e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-e89e0d5f-2f09-445f-800a-874b3f188429,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d23f7520-f44b-4e7a-8b92-90b892cfb628,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-a9423395-d568-473b-b853-22e46113d930,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-ab5403d8-ce5c-4486-b95a-f1e6fe3699d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-93669c54-c0f7-4806-942b-1268588afaca,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-75be7ab1-a45e-4b84-afad-ac1a8284d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-ffbf088a-8949-4ba0-b796-1d68be729cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412570140-172.17.0.4-1599294229086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-311b6582-fef9-42a0-83ac-753911479e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-e89e0d5f-2f09-445f-800a-874b3f188429,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d23f7520-f44b-4e7a-8b92-90b892cfb628,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-a9423395-d568-473b-b853-22e46113d930,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-ab5403d8-ce5c-4486-b95a-f1e6fe3699d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-93669c54-c0f7-4806-942b-1268588afaca,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-75be7ab1-a45e-4b84-afad-ac1a8284d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-ffbf088a-8949-4ba0-b796-1d68be729cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069914596-172.17.0.4-1599294738015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-3209de32-e8dd-4c25-ac38-edcdbdbb3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-07ae1ce0-0f80-4582-a973-41b26807dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-7f4af119-9249-448b-a114-b328d5a8fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-c19389e0-e7f7-4995-9ac2-028ace98af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-8e27c67e-3373-4a09-92b6-75da1d077b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8d4e4890-fb59-406b-b85f-5aa55cc79b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-597edbc5-c03e-4f1d-8255-e37a5355a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e9ab4390-6ab1-45ae-8faf-46ba7493bbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069914596-172.17.0.4-1599294738015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-3209de32-e8dd-4c25-ac38-edcdbdbb3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-07ae1ce0-0f80-4582-a973-41b26807dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-7f4af119-9249-448b-a114-b328d5a8fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-c19389e0-e7f7-4995-9ac2-028ace98af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-8e27c67e-3373-4a09-92b6-75da1d077b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8d4e4890-fb59-406b-b85f-5aa55cc79b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-597edbc5-c03e-4f1d-8255-e37a5355a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e9ab4390-6ab1-45ae-8faf-46ba7493bbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500910412-172.17.0.4-1599295031420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-46735026-0dd3-4b75-bbc8-b2a0f7dacf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-84d87f71-7af2-437d-a21e-68d55a99f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-ee2fcebd-f8ba-4794-b8d3-b24b38234e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-bf7a2e9e-2cb4-4b99-b075-77195d362925,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-b61ddae7-d4a5-4f00-a095-58e2a1455d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-829ce094-bf4a-4153-a577-405ef26471bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-d10faefa-c81e-4232-b6bd-82e32ec079b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-c27c7157-537d-451b-9c6d-faa829d0ae9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500910412-172.17.0.4-1599295031420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-46735026-0dd3-4b75-bbc8-b2a0f7dacf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-84d87f71-7af2-437d-a21e-68d55a99f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-ee2fcebd-f8ba-4794-b8d3-b24b38234e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-bf7a2e9e-2cb4-4b99-b075-77195d362925,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-b61ddae7-d4a5-4f00-a095-58e2a1455d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-829ce094-bf4a-4153-a577-405ef26471bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-d10faefa-c81e-4232-b6bd-82e32ec079b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-c27c7157-537d-451b-9c6d-faa829d0ae9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790125701-172.17.0.4-1599295210999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-e158858b-1146-4afa-b3c4-69a550305430,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-9e1d99c4-034b-48ca-b193-c78a5a1f6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-88837d40-d533-487d-a94b-992288c309c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-f5a84d48-1654-4c3f-9973-fb1834f754e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a76c5b1a-3c26-484d-91f0-b2bd5c772473,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-06cbcf7d-98a0-466f-8242-14aa916cb136,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-edf6edea-420d-4f3d-ae9a-b176897ef1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-d352e9d1-e610-4cfd-9cd3-55bfbd409756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790125701-172.17.0.4-1599295210999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-e158858b-1146-4afa-b3c4-69a550305430,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-9e1d99c4-034b-48ca-b193-c78a5a1f6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-88837d40-d533-487d-a94b-992288c309c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-f5a84d48-1654-4c3f-9973-fb1834f754e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a76c5b1a-3c26-484d-91f0-b2bd5c772473,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-06cbcf7d-98a0-466f-8242-14aa916cb136,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-edf6edea-420d-4f3d-ae9a-b176897ef1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-d352e9d1-e610-4cfd-9cd3-55bfbd409756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125933933-172.17.0.4-1599295318236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-61999b9a-0fea-4b38-a8f8-7c8e657b4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-9481c0fa-deb4-4c04-b55a-81583be39ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-51dd0aa8-15fd-4e3b-80fc-86d3590f4f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-f4c6224e-485c-4fe5-be05-926cbe24d836,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-4e15189e-bbe1-4546-9f0a-99e88e2a69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-52655598-81cd-46ef-b39d-97f333eba56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-17cecbe3-9b19-464c-b977-9d39dd6dfe91,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-f0cbb1f8-ff78-4e97-a4ce-64839f69a429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125933933-172.17.0.4-1599295318236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-61999b9a-0fea-4b38-a8f8-7c8e657b4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-9481c0fa-deb4-4c04-b55a-81583be39ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-51dd0aa8-15fd-4e3b-80fc-86d3590f4f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-f4c6224e-485c-4fe5-be05-926cbe24d836,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-4e15189e-bbe1-4546-9f0a-99e88e2a69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-52655598-81cd-46ef-b39d-97f333eba56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-17cecbe3-9b19-464c-b977-9d39dd6dfe91,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-f0cbb1f8-ff78-4e97-a4ce-64839f69a429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796708551-172.17.0.4-1599295425236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-012b1d7f-3416-4d7f-97ee-9e1ed2e117a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-a857391a-728a-4a0d-ae19-efe8b3a40234,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-04bc049c-9b94-41c4-98a2-7cc68130ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-189bde19-5a4a-474f-9130-502670fd295d,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-5310243a-36dc-41a9-9d94-501fc3b2111c,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-4b485acd-ba40-48c0-9984-2a046e12c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d1ed1b17-856e-4ee1-a769-aaffe03590da,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-ddb8d595-1116-4edb-b2f7-492c34ac7a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1796708551-172.17.0.4-1599295425236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-012b1d7f-3416-4d7f-97ee-9e1ed2e117a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-a857391a-728a-4a0d-ae19-efe8b3a40234,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-04bc049c-9b94-41c4-98a2-7cc68130ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-189bde19-5a4a-474f-9130-502670fd295d,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-5310243a-36dc-41a9-9d94-501fc3b2111c,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-4b485acd-ba40-48c0-9984-2a046e12c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d1ed1b17-856e-4ee1-a769-aaffe03590da,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-ddb8d595-1116-4edb-b2f7-492c34ac7a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619986806-172.17.0.4-1599295457979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-45c6909a-cb18-4508-9f4f-81eb61720a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-11dc3e04-a871-4b89-a308-6bcf7518fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-0a595814-f2e3-46b5-8d08-a398d9e71217,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a4942219-b3d7-4065-918b-834cbd50234e,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-ade07ed8-9ca5-48e2-86d3-7bb7c2562e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-4137ca27-18b2-4fcc-b483-de732ebc8684,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-1e767039-2d37-41e8-8661-038f1ea0e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-d39f632d-5432-4e0f-9705-2447852224bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619986806-172.17.0.4-1599295457979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-45c6909a-cb18-4508-9f4f-81eb61720a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-11dc3e04-a871-4b89-a308-6bcf7518fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-0a595814-f2e3-46b5-8d08-a398d9e71217,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a4942219-b3d7-4065-918b-834cbd50234e,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-ade07ed8-9ca5-48e2-86d3-7bb7c2562e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-4137ca27-18b2-4fcc-b483-de732ebc8684,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-1e767039-2d37-41e8-8661-038f1ea0e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-d39f632d-5432-4e0f-9705-2447852224bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073125513-172.17.0.4-1599296118120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-eb6c7d52-43e6-41b6-a53e-5c11e8c14938,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-fe36374c-6bd0-4f04-bbbf-fb38a88761d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fd7ac140-69af-433e-904f-e195716fa512,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-f76188dd-eaaa-4821-b1aa-8bebd4a75195,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d4d21960-990b-499c-b275-f8b8828544ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-36bd89f7-6e70-4318-9af3-5f95ba7cfbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-5b3ecf77-8176-4d3f-8088-d153e7ab2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-d7fcdb61-e6a8-4832-a2c2-f7abc05a22cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073125513-172.17.0.4-1599296118120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-eb6c7d52-43e6-41b6-a53e-5c11e8c14938,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-fe36374c-6bd0-4f04-bbbf-fb38a88761d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fd7ac140-69af-433e-904f-e195716fa512,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-f76188dd-eaaa-4821-b1aa-8bebd4a75195,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d4d21960-990b-499c-b275-f8b8828544ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-36bd89f7-6e70-4318-9af3-5f95ba7cfbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-5b3ecf77-8176-4d3f-8088-d153e7ab2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-d7fcdb61-e6a8-4832-a2c2-f7abc05a22cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78933721-172.17.0.4-1599296157574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-cad4b562-67c4-4be8-9e4d-1b514d77c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-0d7e1311-fcb9-4f58-8f7f-df6b5d0d5682,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-b10e9f05-a69b-4ff3-9b4d-886547092ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-b1a81860-823c-4cd5-9c90-74f5a4bde483,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-654144a9-56c5-4bdd-9fce-06d84f8c891e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-ac5834ca-3f56-4f8a-a6d9-c55f360d8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-c8adb7ef-e5c3-432f-8f7a-c6c319935264,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-c87985e0-1754-45f7-9755-e1603e95408c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78933721-172.17.0.4-1599296157574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-cad4b562-67c4-4be8-9e4d-1b514d77c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-0d7e1311-fcb9-4f58-8f7f-df6b5d0d5682,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-b10e9f05-a69b-4ff3-9b4d-886547092ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-b1a81860-823c-4cd5-9c90-74f5a4bde483,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-654144a9-56c5-4bdd-9fce-06d84f8c891e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-ac5834ca-3f56-4f8a-a6d9-c55f360d8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-c8adb7ef-e5c3-432f-8f7a-c6c319935264,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-c87985e0-1754-45f7-9755-e1603e95408c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309411759-172.17.0.4-1599296370312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-bcef484c-7853-4474-b980-c060271ab5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-f99af5b2-2696-4783-81e5-c270e07fd5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-d41d9bc6-e2fb-4187-a20f-907c0931d053,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-da77fd73-936f-46fb-a175-15b43f19cebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-d34f5824-c37a-4f97-9d76-cbd9f39aeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-9ccde4e9-05d0-4449-91a4-bcc6cc5b55d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-a0cce41a-4cc5-4583-a5b8-443b000579a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-dfa2dae6-1660-4dd0-af9b-4bc8d14299db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309411759-172.17.0.4-1599296370312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-bcef484c-7853-4474-b980-c060271ab5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-f99af5b2-2696-4783-81e5-c270e07fd5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-d41d9bc6-e2fb-4187-a20f-907c0931d053,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-da77fd73-936f-46fb-a175-15b43f19cebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-d34f5824-c37a-4f97-9d76-cbd9f39aeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-9ccde4e9-05d0-4449-91a4-bcc6cc5b55d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-a0cce41a-4cc5-4583-a5b8-443b000579a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-dfa2dae6-1660-4dd0-af9b-4bc8d14299db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169409311-172.17.0.4-1599296737825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-b5e2ba1f-9d56-4b1c-a9ad-df807297c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-173be814-6228-4634-ade0-5da38e34839c,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-2832c200-08c2-4301-ae1f-04281c167e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-bc73bbe0-4d34-456a-a680-e049d0d6b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-c427f473-3c11-4b49-b2ae-356a5ed25a00,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-90b39346-c159-41d7-b98a-ecf534990b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1ec1a6d3-e389-488e-b64c-6d1c0d3ff4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-451f380a-2ee2-42f8-bff0-7d5c0678fb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169409311-172.17.0.4-1599296737825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-b5e2ba1f-9d56-4b1c-a9ad-df807297c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-173be814-6228-4634-ade0-5da38e34839c,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-2832c200-08c2-4301-ae1f-04281c167e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-bc73bbe0-4d34-456a-a680-e049d0d6b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-c427f473-3c11-4b49-b2ae-356a5ed25a00,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-90b39346-c159-41d7-b98a-ecf534990b97,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1ec1a6d3-e389-488e-b64c-6d1c0d3ff4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-451f380a-2ee2-42f8-bff0-7d5c0678fb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5500
