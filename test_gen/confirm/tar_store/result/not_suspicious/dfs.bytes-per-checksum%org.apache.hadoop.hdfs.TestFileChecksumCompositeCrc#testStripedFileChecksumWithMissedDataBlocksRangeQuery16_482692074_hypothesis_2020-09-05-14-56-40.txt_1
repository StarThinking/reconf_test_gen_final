reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697815518-172.17.0.8-1599318033069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-88e8c804-9118-43a8-85e9-36573fd2e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-3dffd233-747f-4cbc-8518-20380bda60b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-a20b47fd-47dc-4ac3-a340-39a09a50cdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7a42635-bbf7-4ae6-80e0-cab1d7b4b267,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-cbe8bc7a-d0e7-4122-a131-0ecc9dd2e312,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-140420f3-b3d3-4ae0-b654-07349655ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-ec174f61-47e9-48d8-b1c0-d27ee0b0f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-baf88ad7-a9b1-4ecf-9767-80cb3f5b6a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697815518-172.17.0.8-1599318033069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-88e8c804-9118-43a8-85e9-36573fd2e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-3dffd233-747f-4cbc-8518-20380bda60b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-a20b47fd-47dc-4ac3-a340-39a09a50cdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7a42635-bbf7-4ae6-80e0-cab1d7b4b267,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-cbe8bc7a-d0e7-4122-a131-0ecc9dd2e312,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-140420f3-b3d3-4ae0-b654-07349655ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-ec174f61-47e9-48d8-b1c0-d27ee0b0f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-baf88ad7-a9b1-4ecf-9767-80cb3f5b6a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980256953-172.17.0.8-1599318133688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-7440d554-516c-4a20-ae5d-f0953df47dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-15e59857-36a2-4b3b-9f4b-bd153f58975d,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-9de70605-aaf2-4676-a5e5-1f2bff645f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f2d27300-cafa-420c-a492-13117822e9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-5971e21f-ed8f-4a4b-81fe-a23e7fe031b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d8c19661-4b74-49c1-8c9e-386201923013,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-82b048e1-98b4-4e91-9115-afa54f3b7cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-5aa457df-b42f-46d4-bc53-0eabcd8aafc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980256953-172.17.0.8-1599318133688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-7440d554-516c-4a20-ae5d-f0953df47dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-15e59857-36a2-4b3b-9f4b-bd153f58975d,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-9de70605-aaf2-4676-a5e5-1f2bff645f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f2d27300-cafa-420c-a492-13117822e9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-5971e21f-ed8f-4a4b-81fe-a23e7fe031b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d8c19661-4b74-49c1-8c9e-386201923013,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-82b048e1-98b4-4e91-9115-afa54f3b7cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-5aa457df-b42f-46d4-bc53-0eabcd8aafc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695100351-172.17.0.8-1599318410857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-9abebec9-600b-4c13-9922-ef855461ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-0de630ac-5ef8-4410-841e-2d05a4db38ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-e707d545-7d50-45b8-9940-e5d6c5bde66a,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3b80275d-6b86-41d5-9a0d-3a85baca2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-99598771-542f-4aeb-85d4-eac4014dd4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-f1585e01-2ed4-40df-8f73-f146a6f33c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-7ec1ea57-ca18-48d1-9905-d3c6c7097ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-bace942f-1586-4461-b44f-334b8615f7df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695100351-172.17.0.8-1599318410857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-9abebec9-600b-4c13-9922-ef855461ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-0de630ac-5ef8-4410-841e-2d05a4db38ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-e707d545-7d50-45b8-9940-e5d6c5bde66a,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3b80275d-6b86-41d5-9a0d-3a85baca2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-99598771-542f-4aeb-85d4-eac4014dd4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-f1585e01-2ed4-40df-8f73-f146a6f33c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-7ec1ea57-ca18-48d1-9905-d3c6c7097ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-bace942f-1586-4461-b44f-334b8615f7df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077016383-172.17.0.8-1599318945872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-00fdcbce-1463-487c-8fb3-cbcd4bb24f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-8de3d744-cb5c-47d6-8210-bf81ea6da14b,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-32e8874c-beb3-4d0c-91db-c7b04fb6eeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-d7d22c32-eb17-4292-8085-eaadaf8bcaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-3c825695-a59b-4691-83ad-292a1d707cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-4f966ea7-0e99-42b2-b994-78721ab95a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-304233c5-63e8-4adc-94db-654c5ea3c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-60b6d19f-24ba-4225-979f-8b95944b1000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077016383-172.17.0.8-1599318945872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-00fdcbce-1463-487c-8fb3-cbcd4bb24f54,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-8de3d744-cb5c-47d6-8210-bf81ea6da14b,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-32e8874c-beb3-4d0c-91db-c7b04fb6eeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-d7d22c32-eb17-4292-8085-eaadaf8bcaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-3c825695-a59b-4691-83ad-292a1d707cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-4f966ea7-0e99-42b2-b994-78721ab95a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-304233c5-63e8-4adc-94db-654c5ea3c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-60b6d19f-24ba-4225-979f-8b95944b1000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052882194-172.17.0.8-1599319059966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45377,DS-ba1514a4-0138-497f-bc8c-0ac9a6593d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-60561b3f-19b6-46b3-bd53-8f672f2755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-fc0474ee-9fcd-4e28-9557-280d5328600f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-8ee8d62a-e7b6-4a27-b3bf-b719135d9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0517c32a-3d32-40ed-8eec-0059d7147c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-08cc105b-8e82-41f7-a252-994ce3546342,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-0a1c6237-2952-495f-9932-de99c188c105,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-b5d490e8-8600-4e7b-be58-b444811b217b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052882194-172.17.0.8-1599319059966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45377,DS-ba1514a4-0138-497f-bc8c-0ac9a6593d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-60561b3f-19b6-46b3-bd53-8f672f2755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-fc0474ee-9fcd-4e28-9557-280d5328600f,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-8ee8d62a-e7b6-4a27-b3bf-b719135d9998,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0517c32a-3d32-40ed-8eec-0059d7147c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-08cc105b-8e82-41f7-a252-994ce3546342,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-0a1c6237-2952-495f-9932-de99c188c105,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-b5d490e8-8600-4e7b-be58-b444811b217b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050547283-172.17.0.8-1599319182853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-ed89b93c-0430-480a-b4c0-55652f1e5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-98336d64-0bb4-4333-bfdc-e6ed5b9d1909,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-eb6c78e4-19ca-4b4a-b57f-05eacab4270c,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-852cdb5b-0828-41db-b1eb-8e633f61731c,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-fe4fd534-b1f1-4b2b-bf29-8cc6fa097be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-15886f14-c20a-48f1-94f8-cb22ea182edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-31575fb3-9631-4ee4-8812-186fc069fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-761fd7c1-432b-4b2b-ace3-4cba43f9c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050547283-172.17.0.8-1599319182853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-ed89b93c-0430-480a-b4c0-55652f1e5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-98336d64-0bb4-4333-bfdc-e6ed5b9d1909,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-eb6c78e4-19ca-4b4a-b57f-05eacab4270c,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-852cdb5b-0828-41db-b1eb-8e633f61731c,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-fe4fd534-b1f1-4b2b-bf29-8cc6fa097be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-15886f14-c20a-48f1-94f8-cb22ea182edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-31575fb3-9631-4ee4-8812-186fc069fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-761fd7c1-432b-4b2b-ace3-4cba43f9c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682464232-172.17.0.8-1599319542101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-fbe3d523-c349-4163-98c1-b9db40f6a871,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-6097ea81-e1c1-4997-8812-954aa33e0c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-eb480f2b-e850-4243-88fe-8c1e9e248670,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-c6598848-6985-443b-972c-4f61ad488cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f41ff6d8-0973-4587-bd49-57c088f515cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-1d399dfd-474b-42c9-8393-2f8ea040cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-9af3495e-6ee5-449d-871c-a1bf0aef824d,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-19ab6bc3-1b4a-447b-8006-59290fa60183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682464232-172.17.0.8-1599319542101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-fbe3d523-c349-4163-98c1-b9db40f6a871,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-6097ea81-e1c1-4997-8812-954aa33e0c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-eb480f2b-e850-4243-88fe-8c1e9e248670,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-c6598848-6985-443b-972c-4f61ad488cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f41ff6d8-0973-4587-bd49-57c088f515cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-1d399dfd-474b-42c9-8393-2f8ea040cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-9af3495e-6ee5-449d-871c-a1bf0aef824d,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-19ab6bc3-1b4a-447b-8006-59290fa60183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024688696-172.17.0.8-1599319775578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-892af7d8-0b69-4dcf-912d-8daaec09545b,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-8e61efc9-4a31-4f7b-9874-6e6435ab585e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-0bd07458-7c69-448f-bc0f-af6e71e5ab49,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-39588ef7-66e4-4273-8d4c-4ca774b0f4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-fad7cfc5-0d7d-4533-8284-e5e75412e987,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-099a83ff-d0bf-47c5-97b6-42c6e3fdeebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-06e45ea4-dbe2-4f29-ae9b-f366c9f36e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b325d04b-6416-4fe1-a41d-1d4c69a0e3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024688696-172.17.0.8-1599319775578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-892af7d8-0b69-4dcf-912d-8daaec09545b,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-8e61efc9-4a31-4f7b-9874-6e6435ab585e,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-0bd07458-7c69-448f-bc0f-af6e71e5ab49,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-39588ef7-66e4-4273-8d4c-4ca774b0f4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-fad7cfc5-0d7d-4533-8284-e5e75412e987,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-099a83ff-d0bf-47c5-97b6-42c6e3fdeebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-06e45ea4-dbe2-4f29-ae9b-f366c9f36e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-b325d04b-6416-4fe1-a41d-1d4c69a0e3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022527167-172.17.0.8-1599320492439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40302,DS-05a18168-2cff-4877-ab17-96fcfb66e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7e428f49-5bab-42b3-97d2-7e5e992a734c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-7325097d-8da0-4ece-8eff-d060b66153d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-44a018f0-4ae0-422e-95c7-e8a67d0d3e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-74fb1c81-def6-498e-9ae7-b4c440317dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c830676e-1273-495f-a057-f3584da27771,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ceb29329-9f60-4455-87a9-8dd37c894455,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-73efc529-25b1-4498-b51f-7d4d37e77d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022527167-172.17.0.8-1599320492439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40302,DS-05a18168-2cff-4877-ab17-96fcfb66e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7e428f49-5bab-42b3-97d2-7e5e992a734c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-7325097d-8da0-4ece-8eff-d060b66153d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-44a018f0-4ae0-422e-95c7-e8a67d0d3e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-74fb1c81-def6-498e-9ae7-b4c440317dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c830676e-1273-495f-a057-f3584da27771,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ceb29329-9f60-4455-87a9-8dd37c894455,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-73efc529-25b1-4498-b51f-7d4d37e77d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341123417-172.17.0.8-1599320576665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-60682f16-33f2-4171-91bc-45acc2526615,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-f7cf0c96-6582-4f7d-8ead-83ef220ea067,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-9db4991f-8534-4a39-abbf-bf7fc58483d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-c22072c8-e463-441a-8074-cb57218f0710,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-69c03e4c-3b66-4df4-b47d-6a0c4e3eda01,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-2abd59b9-aa2c-40fc-80cc-e2e587574515,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-0c3ce217-021a-4ba1-bec2-35bd6fd18d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-6c0944b6-ded5-4751-89c1-0ff9e4817cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341123417-172.17.0.8-1599320576665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-60682f16-33f2-4171-91bc-45acc2526615,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-f7cf0c96-6582-4f7d-8ead-83ef220ea067,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-9db4991f-8534-4a39-abbf-bf7fc58483d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-c22072c8-e463-441a-8074-cb57218f0710,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-69c03e4c-3b66-4df4-b47d-6a0c4e3eda01,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-2abd59b9-aa2c-40fc-80cc-e2e587574515,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-0c3ce217-021a-4ba1-bec2-35bd6fd18d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-6c0944b6-ded5-4751-89c1-0ff9e4817cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804472858-172.17.0.8-1599320864817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-1e68b041-5483-4819-9399-c1967d266bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-3687da27-8e59-4bcd-96a3-3d4c00566921,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-2becd48b-0c20-42cf-bbb4-38efd37c07ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-d379a993-4f69-4a9a-b101-a7b3c9d41b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-b2d512ff-ae81-4ebd-86ca-6de11440c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-87a8e998-208d-436e-bbfe-e4ab50d451b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-d29803bd-3369-49b2-817a-3e799ccadf70,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-76c4a7c5-99b8-4f8e-adc7-6c8f4d91233e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804472858-172.17.0.8-1599320864817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-1e68b041-5483-4819-9399-c1967d266bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-3687da27-8e59-4bcd-96a3-3d4c00566921,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-2becd48b-0c20-42cf-bbb4-38efd37c07ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-d379a993-4f69-4a9a-b101-a7b3c9d41b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-b2d512ff-ae81-4ebd-86ca-6de11440c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-87a8e998-208d-436e-bbfe-e4ab50d451b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-d29803bd-3369-49b2-817a-3e799ccadf70,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-76c4a7c5-99b8-4f8e-adc7-6c8f4d91233e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058025706-172.17.0.8-1599321099944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-b361b38c-c957-4b45-9c96-5fb91e7308c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-420f793a-d445-40ef-a7d6-0fddc24c4647,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-b3f7fd5f-c113-4670-8fb7-417b55fac6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-e6ec69b6-384d-4baf-99dd-3e45e2b73d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-ab703db6-7e0c-42de-b44b-dc465cba7a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-e7aa27e5-fcd8-451d-b360-59ca228060ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-fd313baf-0218-4d5a-b113-faa363c5d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1fac7cfe-bbd3-4067-94c6-41fbdfec5241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058025706-172.17.0.8-1599321099944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-b361b38c-c957-4b45-9c96-5fb91e7308c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-420f793a-d445-40ef-a7d6-0fddc24c4647,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-b3f7fd5f-c113-4670-8fb7-417b55fac6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-e6ec69b6-384d-4baf-99dd-3e45e2b73d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-ab703db6-7e0c-42de-b44b-dc465cba7a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-e7aa27e5-fcd8-451d-b360-59ca228060ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-fd313baf-0218-4d5a-b113-faa363c5d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1fac7cfe-bbd3-4067-94c6-41fbdfec5241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399105386-172.17.0.8-1599321137276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35836,DS-9fe93082-7e15-4b6d-8643-da13406d8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-06c7b157-e623-403a-a09f-c93e7cb5c318,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-23f8f3f5-0fd9-4b91-bf42-3fe72db7c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-40f9d785-bae0-4cb7-8105-838c88570026,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d6a6152b-7e7b-4fcd-9cd3-d8c480822380,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-aa290244-ee82-474c-94ee-ae28b992e14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-8fbd1137-5713-4016-9e43-b6005b502e01,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-ffcabb1a-1ac4-4ff4-bb8b-1a948fcf8af7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399105386-172.17.0.8-1599321137276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35836,DS-9fe93082-7e15-4b6d-8643-da13406d8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-06c7b157-e623-403a-a09f-c93e7cb5c318,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-23f8f3f5-0fd9-4b91-bf42-3fe72db7c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-40f9d785-bae0-4cb7-8105-838c88570026,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d6a6152b-7e7b-4fcd-9cd3-d8c480822380,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-aa290244-ee82-474c-94ee-ae28b992e14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-8fbd1137-5713-4016-9e43-b6005b502e01,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-ffcabb1a-1ac4-4ff4-bb8b-1a948fcf8af7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721018219-172.17.0.8-1599321200138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45822,DS-82d16d62-7f0b-4f8e-bea0-f5a99e97b703,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-4a444fac-cfe8-46c0-925e-b6fb5c905666,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2da5331d-5b52-484b-abe2-c8a7ddfdd288,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-b1689018-6b1e-4d7a-b7cf-75e5fa666929,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-907b3ba1-f3ec-40f6-b7dd-e8d67da9d493,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0da48667-edd5-4511-98eb-3b92548f4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-7eab2458-5553-40dc-9454-ab4d3b7d1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-cc49cd85-7678-45a1-9def-6e8f58afcc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721018219-172.17.0.8-1599321200138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45822,DS-82d16d62-7f0b-4f8e-bea0-f5a99e97b703,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-4a444fac-cfe8-46c0-925e-b6fb5c905666,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2da5331d-5b52-484b-abe2-c8a7ddfdd288,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-b1689018-6b1e-4d7a-b7cf-75e5fa666929,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-907b3ba1-f3ec-40f6-b7dd-e8d67da9d493,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0da48667-edd5-4511-98eb-3b92548f4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-7eab2458-5553-40dc-9454-ab4d3b7d1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-cc49cd85-7678-45a1-9def-6e8f58afcc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399220390-172.17.0.8-1599321389476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-2fe9e582-209f-45c1-b660-4f8ab8bf8d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-23ab3e02-3dd2-4c8e-9781-2d4c83fb953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-4bdafacc-144e-47c9-94f1-7a4e7c32d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-ef836eea-1f9e-491c-9ffc-57f928b3de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-e116b4a3-a6c9-4352-92fc-4e3f36787197,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-ba6b5fd8-2981-401a-849b-791cb6e2a9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-3be8f60a-f94f-4cae-9839-1a4fb8e9fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-ff4e4a99-48d7-40b8-9fd4-a4bd9738f8f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399220390-172.17.0.8-1599321389476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-2fe9e582-209f-45c1-b660-4f8ab8bf8d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-23ab3e02-3dd2-4c8e-9781-2d4c83fb953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-4bdafacc-144e-47c9-94f1-7a4e7c32d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-ef836eea-1f9e-491c-9ffc-57f928b3de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-e116b4a3-a6c9-4352-92fc-4e3f36787197,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-ba6b5fd8-2981-401a-849b-791cb6e2a9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-3be8f60a-f94f-4cae-9839-1a4fb8e9fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-ff4e4a99-48d7-40b8-9fd4-a4bd9738f8f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399480914-172.17.0.8-1599321458987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-7ab8af31-1b6a-445a-a616-fc863fc35286,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-6f8157a7-c447-4bfa-9f62-f6cba2ac198e,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-265dc93e-50b4-4bf0-a598-f29c0f048e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b1696ee1-8d4e-4ea8-a101-00cc06d1ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5717ae11-7c72-4198-ac3d-194398d9fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-a1fa94ad-44e5-497f-833e-a2ca9be68fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c20770fe-1e80-4238-9650-eb8814372bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9bb76812-b09e-4cbc-981b-0d0d3c0a6d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399480914-172.17.0.8-1599321458987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-7ab8af31-1b6a-445a-a616-fc863fc35286,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-6f8157a7-c447-4bfa-9f62-f6cba2ac198e,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-265dc93e-50b4-4bf0-a598-f29c0f048e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-b1696ee1-8d4e-4ea8-a101-00cc06d1ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-5717ae11-7c72-4198-ac3d-194398d9fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-a1fa94ad-44e5-497f-833e-a2ca9be68fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c20770fe-1e80-4238-9650-eb8814372bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9bb76812-b09e-4cbc-981b-0d0d3c0a6d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880039686-172.17.0.8-1599321835103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-695b517e-bac2-40a2-9808-284c8275864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-5236ba66-25a0-4560-ab3c-a70c51fee1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-7bb1d83b-3d2c-4fb3-b4c8-749541343ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-461255fe-f85f-49a3-b6ed-2e982c129b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-86f22894-beff-4065-8b27-e05195479267,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-44faee1d-8d54-4c2d-aad9-ba1989c01017,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b130c8d4-fdcd-4056-9bb8-944aa7853199,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-6b9fa6e5-ea8b-4e36-9bfb-501227e97e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880039686-172.17.0.8-1599321835103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-695b517e-bac2-40a2-9808-284c8275864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-5236ba66-25a0-4560-ab3c-a70c51fee1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-7bb1d83b-3d2c-4fb3-b4c8-749541343ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-461255fe-f85f-49a3-b6ed-2e982c129b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-86f22894-beff-4065-8b27-e05195479267,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-44faee1d-8d54-4c2d-aad9-ba1989c01017,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b130c8d4-fdcd-4056-9bb8-944aa7853199,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-6b9fa6e5-ea8b-4e36-9bfb-501227e97e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 2048
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121766924-172.17.0.8-1599322271614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42845,DS-8a403c7b-162c-4509-b28d-b758af4cda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-a4a19862-e0ba-4d6c-880d-0194df7a4139,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-4d880366-d80a-47be-9e9c-86d2e2d2191f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-2b543bda-2016-4a7a-91b3-d0cec8c0a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-daf44045-066a-4503-9fdc-6efa1e265fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-86a49e00-697c-4a30-9605-9702a43e2435,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-95543602-0c3c-4036-8a53-d5ac14d6c074,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-8c4e0e05-ab8d-442c-8c12-9721d1888644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121766924-172.17.0.8-1599322271614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42845,DS-8a403c7b-162c-4509-b28d-b758af4cda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-a4a19862-e0ba-4d6c-880d-0194df7a4139,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-4d880366-d80a-47be-9e9c-86d2e2d2191f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-2b543bda-2016-4a7a-91b3-d0cec8c0a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-daf44045-066a-4503-9fdc-6efa1e265fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-86a49e00-697c-4a30-9605-9702a43e2435,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-95543602-0c3c-4036-8a53-d5ac14d6c074,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-8c4e0e05-ab8d-442c-8c12-9721d1888644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4657
