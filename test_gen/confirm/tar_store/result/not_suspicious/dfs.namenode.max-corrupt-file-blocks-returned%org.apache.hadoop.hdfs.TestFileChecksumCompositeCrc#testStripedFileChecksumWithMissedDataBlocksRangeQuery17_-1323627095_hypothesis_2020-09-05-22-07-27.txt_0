reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186147527-172.17.0.18-1599343875423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37685,DS-973e24d5-2b9d-4893-92af-054569cbb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-58591898-826c-4af5-a9a4-e49e40edfa81,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-32ef8ae0-5a5c-41bc-8ddc-c075a6757aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-a2180050-391d-4908-8c0f-3f42ceaa7bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-50db10c3-ea70-45c3-8888-7894d5c007fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-4073a2b5-c010-4c9c-9be1-ae23baa38041,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-79ea36a1-604c-42d7-9a04-939f7ffe126d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-70edaa71-be61-4cf9-bf24-b44b73630f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186147527-172.17.0.18-1599343875423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37685,DS-973e24d5-2b9d-4893-92af-054569cbb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-58591898-826c-4af5-a9a4-e49e40edfa81,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-32ef8ae0-5a5c-41bc-8ddc-c075a6757aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-a2180050-391d-4908-8c0f-3f42ceaa7bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-50db10c3-ea70-45c3-8888-7894d5c007fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-4073a2b5-c010-4c9c-9be1-ae23baa38041,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-79ea36a1-604c-42d7-9a04-939f7ffe126d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-70edaa71-be61-4cf9-bf24-b44b73630f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668323728-172.17.0.18-1599343910543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-28fa41d9-f674-4335-a68e-5887aa9ba345,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-dd524aab-8ab4-4dde-955e-86931d5b72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-18d8f4c5-a7f1-49cf-983d-80dce6a313e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-54788e38-59b5-465c-86b6-988999a225d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ed3dc83e-e917-4f5c-a15b-0eb3922d1256,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-b4e76340-5699-4040-aeb5-a16135a59f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-d71ac8c7-521a-4229-9fd6-d54859dcf81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-baba30ac-2e25-49f2-b23a-3454a559c549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668323728-172.17.0.18-1599343910543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34912,DS-28fa41d9-f674-4335-a68e-5887aa9ba345,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-dd524aab-8ab4-4dde-955e-86931d5b72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-18d8f4c5-a7f1-49cf-983d-80dce6a313e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-54788e38-59b5-465c-86b6-988999a225d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ed3dc83e-e917-4f5c-a15b-0eb3922d1256,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-b4e76340-5699-4040-aeb5-a16135a59f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-d71ac8c7-521a-4229-9fd6-d54859dcf81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-baba30ac-2e25-49f2-b23a-3454a559c549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710795531-172.17.0.18-1599344352421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-95c4f083-be8b-485c-b8d8-3438a2ca7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-8006b14a-882b-4f68-9fee-eb3dd00b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-e12441eb-0bcb-462a-a0a2-27399254384b,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-22fd9ee3-2666-449d-b832-d7d341d2b137,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-cbc9e76d-aa09-4f42-877a-0f0a124b8d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2b183438-b1b3-4d50-92bb-ad3d0c888275,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-deaff5ea-284b-4a71-b070-7502dc9afca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-d2472204-f1fe-4c64-bd4c-94c3cadf6cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710795531-172.17.0.18-1599344352421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-95c4f083-be8b-485c-b8d8-3438a2ca7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-8006b14a-882b-4f68-9fee-eb3dd00b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-e12441eb-0bcb-462a-a0a2-27399254384b,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-22fd9ee3-2666-449d-b832-d7d341d2b137,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-cbc9e76d-aa09-4f42-877a-0f0a124b8d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2b183438-b1b3-4d50-92bb-ad3d0c888275,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-deaff5ea-284b-4a71-b070-7502dc9afca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-d2472204-f1fe-4c64-bd4c-94c3cadf6cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602589766-172.17.0.18-1599345231578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-fc6d7ce4-b677-4009-9817-c52e21194def,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-7a65d0ab-feef-44f0-93f3-55847c7f7b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-19f73a3e-def3-4788-93ac-f57917196958,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-cb4fb1f3-41d0-4200-ae16-6331c3ffbd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-a5ae0789-245b-4071-a5a3-f542d4188028,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-5f3093bd-9b8c-4985-b24a-091367364b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-728447bb-90b3-4212-8f00-f80ebe399696,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-7db1e095-c86b-4e07-943f-d496c22d5a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602589766-172.17.0.18-1599345231578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-fc6d7ce4-b677-4009-9817-c52e21194def,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-7a65d0ab-feef-44f0-93f3-55847c7f7b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-19f73a3e-def3-4788-93ac-f57917196958,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-cb4fb1f3-41d0-4200-ae16-6331c3ffbd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-a5ae0789-245b-4071-a5a3-f542d4188028,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-5f3093bd-9b8c-4985-b24a-091367364b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-728447bb-90b3-4212-8f00-f80ebe399696,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-7db1e095-c86b-4e07-943f-d496c22d5a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437811102-172.17.0.18-1599345987035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-967fddfa-8f5c-4485-9aad-89b8dc17bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-180758e2-d4d9-4009-993b-f52fc912db57,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-8797527c-bbaa-4ca6-883b-a7c230e457fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-4cbcb258-c27c-4518-a87d-ebd0f7cd2878,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-7fc56911-f160-4f82-b36c-77db5a8449da,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-ebdb7906-c36a-4977-b409-719429c347ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-7cd48dde-61d2-412e-99c6-c455ebe2a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-9139ad87-4d89-402b-b74e-93532a10df24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437811102-172.17.0.18-1599345987035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-967fddfa-8f5c-4485-9aad-89b8dc17bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-180758e2-d4d9-4009-993b-f52fc912db57,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-8797527c-bbaa-4ca6-883b-a7c230e457fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-4cbcb258-c27c-4518-a87d-ebd0f7cd2878,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-7fc56911-f160-4f82-b36c-77db5a8449da,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-ebdb7906-c36a-4977-b409-719429c347ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-7cd48dde-61d2-412e-99c6-c455ebe2a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-9139ad87-4d89-402b-b74e-93532a10df24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667442908-172.17.0.18-1599346070254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-7935c6a5-93f5-4362-bd89-bf6d8854edae,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-8718ac19-57ae-45f6-bf30-f769f69f9c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-81a8dcbc-c3c1-4cac-ba06-f69fda04ffd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-90646a6d-96ca-47a6-ab5f-c1ca09213788,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-2f1d174d-1ae3-48bd-a442-99ea5edf9f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-adcdb6b9-4c4f-438a-860a-04a222dcaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-1769566a-227d-48c0-b3e3-1f08c9d90821,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-4349ea77-b9eb-41da-a24a-a457ea9385d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667442908-172.17.0.18-1599346070254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-7935c6a5-93f5-4362-bd89-bf6d8854edae,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-8718ac19-57ae-45f6-bf30-f769f69f9c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-81a8dcbc-c3c1-4cac-ba06-f69fda04ffd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-90646a6d-96ca-47a6-ab5f-c1ca09213788,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-2f1d174d-1ae3-48bd-a442-99ea5edf9f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-adcdb6b9-4c4f-438a-860a-04a222dcaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-1769566a-227d-48c0-b3e3-1f08c9d90821,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-4349ea77-b9eb-41da-a24a-a457ea9385d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019360618-172.17.0.18-1599346725626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-e0e6c5e6-8ed8-44d4-8c4b-207c0eaa27c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-eb7c68ab-a78e-487b-b4a9-ea909d1d7278,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-96431dd0-bf57-4da0-b674-56f0be3841ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-978758d7-318c-4fcc-b53f-83674fba147f,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-6fb0c691-02e9-4806-a86a-ad951e617701,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-c3b5b3b8-1c40-4b45-a328-085cd8590d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-78ed90c4-5bf3-4ef0-a50c-ce040f9684a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-b9a25a22-e77f-4577-b6b4-5bf51383ef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019360618-172.17.0.18-1599346725626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-e0e6c5e6-8ed8-44d4-8c4b-207c0eaa27c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-eb7c68ab-a78e-487b-b4a9-ea909d1d7278,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-96431dd0-bf57-4da0-b674-56f0be3841ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-978758d7-318c-4fcc-b53f-83674fba147f,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-6fb0c691-02e9-4806-a86a-ad951e617701,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-c3b5b3b8-1c40-4b45-a328-085cd8590d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-78ed90c4-5bf3-4ef0-a50c-ce040f9684a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-b9a25a22-e77f-4577-b6b4-5bf51383ef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972100295-172.17.0.18-1599346994200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-02ab4b42-8482-442a-a3c1-26ae9a23f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-95e93756-1a94-4644-80c6-f08f102acefa,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-23cd2ef8-cb08-45e7-84d2-2dad1bc9ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ac5ceab7-384b-4abc-8fad-8be51460f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-ab3c79f6-636f-42b8-8c33-228d6a45d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-92c180fe-eef7-4e27-a7d5-f943f4b25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-e7a2f6b9-8574-4f8a-935f-23c375c3130a,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-14c2d04c-f601-4129-a1db-66eaa170a3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972100295-172.17.0.18-1599346994200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-02ab4b42-8482-442a-a3c1-26ae9a23f38b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-95e93756-1a94-4644-80c6-f08f102acefa,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-23cd2ef8-cb08-45e7-84d2-2dad1bc9ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-ac5ceab7-384b-4abc-8fad-8be51460f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-ab3c79f6-636f-42b8-8c33-228d6a45d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-92c180fe-eef7-4e27-a7d5-f943f4b25f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-e7a2f6b9-8574-4f8a-935f-23c375c3130a,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-14c2d04c-f601-4129-a1db-66eaa170a3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645008487-172.17.0.18-1599347277713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-5f4b4dce-5b7f-434a-9b7c-8aac7a8704ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-64a53f79-12ef-4536-bb90-592ea7576342,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-34d073a9-dd82-492f-afb6-69cebdc58d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-fad516fb-b49d-48bf-8f62-6104c6c387a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9aadd76d-d630-4df8-8201-7768a60f7dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-d33db842-1568-4f13-8aa4-3a54ce30fd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-b27a072d-cbe4-4e1c-83ce-b06f8d96cf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-40ac79b2-83ba-445d-bec8-19974702b515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645008487-172.17.0.18-1599347277713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37627,DS-5f4b4dce-5b7f-434a-9b7c-8aac7a8704ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-64a53f79-12ef-4536-bb90-592ea7576342,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-34d073a9-dd82-492f-afb6-69cebdc58d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-fad516fb-b49d-48bf-8f62-6104c6c387a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9aadd76d-d630-4df8-8201-7768a60f7dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-d33db842-1568-4f13-8aa4-3a54ce30fd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-b27a072d-cbe4-4e1c-83ce-b06f8d96cf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-40ac79b2-83ba-445d-bec8-19974702b515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102964215-172.17.0.18-1599348157529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-977316f4-4fd1-4d4d-80d0-2d606b97c403,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-97ea4a87-795a-4633-8c15-a8fab8daeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7f614896-e530-440a-b738-ffd0cfee6d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-b844294e-94ac-4fbe-a3fa-9521330a26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-8935bcec-b304-4665-95b2-5a80d19afdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-5552d717-6122-43a2-8898-3db609926e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-794da3d4-d37e-40a4-b3b0-0354ed6315ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-8d301ee5-e834-470b-913e-b5aaf3587b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102964215-172.17.0.18-1599348157529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-977316f4-4fd1-4d4d-80d0-2d606b97c403,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-97ea4a87-795a-4633-8c15-a8fab8daeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7f614896-e530-440a-b738-ffd0cfee6d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-b844294e-94ac-4fbe-a3fa-9521330a26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-8935bcec-b304-4665-95b2-5a80d19afdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-5552d717-6122-43a2-8898-3db609926e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-794da3d4-d37e-40a4-b3b0-0354ed6315ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-8d301ee5-e834-470b-913e-b5aaf3587b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063565066-172.17.0.18-1599348237070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-2cac9b3a-221c-4a1d-afb5-f35baa4118b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e1049adc-5600-41fd-8f3b-07b02c903155,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-5ce5a48f-3e5c-4e1a-8f6a-e7b8b83a1954,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-41c8304e-a25c-4b05-b3a9-b0ce25c1eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-837174ad-01e3-40b1-9424-39145ab6accd,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-85182791-4e3c-437b-aaf8-66b8eb18deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-23221b92-60a2-4c0d-8c1d-326f7956382d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-c8f9fe1c-eead-4a18-aad2-d69ba3f7d412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063565066-172.17.0.18-1599348237070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-2cac9b3a-221c-4a1d-afb5-f35baa4118b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e1049adc-5600-41fd-8f3b-07b02c903155,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-5ce5a48f-3e5c-4e1a-8f6a-e7b8b83a1954,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-41c8304e-a25c-4b05-b3a9-b0ce25c1eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-837174ad-01e3-40b1-9424-39145ab6accd,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-85182791-4e3c-437b-aaf8-66b8eb18deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-23221b92-60a2-4c0d-8c1d-326f7956382d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-c8f9fe1c-eead-4a18-aad2-d69ba3f7d412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4836
