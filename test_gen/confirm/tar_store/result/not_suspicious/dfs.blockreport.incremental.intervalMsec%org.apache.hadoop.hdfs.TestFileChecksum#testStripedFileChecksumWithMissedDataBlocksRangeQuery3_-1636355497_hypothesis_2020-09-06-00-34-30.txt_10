reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212813287-172.17.0.10-1599352769999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-5e46a1c5-b2f8-46f7-88b6-5fca8d012aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-9b7a5882-52ff-4690-840c-3dff88f9bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-dfe12a8a-6746-4b29-a0b8-8246627f3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-242e7297-1106-4f56-9a11-96137091ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-75add477-a79e-40e4-8f5b-c0b57854b130,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-c2f9ac7d-68e6-41c7-9c1b-0cab6de2351c,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-cb2bdb31-2306-419e-b4b2-10231036ad92,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-d59c16b4-8379-467f-8ef7-ae03376711ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212813287-172.17.0.10-1599352769999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-5e46a1c5-b2f8-46f7-88b6-5fca8d012aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-9b7a5882-52ff-4690-840c-3dff88f9bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-dfe12a8a-6746-4b29-a0b8-8246627f3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-242e7297-1106-4f56-9a11-96137091ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-75add477-a79e-40e4-8f5b-c0b57854b130,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-c2f9ac7d-68e6-41c7-9c1b-0cab6de2351c,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-cb2bdb31-2306-419e-b4b2-10231036ad92,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-d59c16b4-8379-467f-8ef7-ae03376711ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226505801-172.17.0.10-1599352826799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-928cc6dd-fd2a-4b5e-a595-2b57493e4271,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-cdec967f-d781-4a07-b8c0-71faae753b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-40b19d83-9bfc-4ec9-b067-e137d41cc4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-367bda75-6f41-4fc9-99d0-0d6226ec3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-d506b14a-e40a-4625-b260-d5020257c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f7109eff-0b22-4d89-a6e5-efd292cb2e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-15fa21cb-2758-49bd-ad99-4af05a7b4401,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a5f2c197-5664-4c35-8f74-bdd6136aee27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226505801-172.17.0.10-1599352826799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-928cc6dd-fd2a-4b5e-a595-2b57493e4271,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-cdec967f-d781-4a07-b8c0-71faae753b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-40b19d83-9bfc-4ec9-b067-e137d41cc4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-367bda75-6f41-4fc9-99d0-0d6226ec3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-d506b14a-e40a-4625-b260-d5020257c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f7109eff-0b22-4d89-a6e5-efd292cb2e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-15fa21cb-2758-49bd-ad99-4af05a7b4401,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a5f2c197-5664-4c35-8f74-bdd6136aee27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254314761-172.17.0.10-1599352856861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-2b7bd8c7-f8ed-4114-acc0-47cb36b0adea,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-d497de93-5633-436b-a4a2-c5ea856eee50,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-a9e5b8f4-5aeb-4e5f-b90c-b6f577569035,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-52e27a90-15d2-41d2-b05f-3a637b5c91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-35edf98a-29de-4a51-b70e-ae812f3dffff,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a4001536-3dac-4eac-8f83-fa09f7f26c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-c20bd8d4-57c2-4a34-90a3-a7ccf2de9290,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-06fdcd58-df86-4961-9ae5-3c7529601cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254314761-172.17.0.10-1599352856861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40905,DS-2b7bd8c7-f8ed-4114-acc0-47cb36b0adea,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-d497de93-5633-436b-a4a2-c5ea856eee50,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-a9e5b8f4-5aeb-4e5f-b90c-b6f577569035,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-52e27a90-15d2-41d2-b05f-3a637b5c91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-35edf98a-29de-4a51-b70e-ae812f3dffff,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a4001536-3dac-4eac-8f83-fa09f7f26c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-c20bd8d4-57c2-4a34-90a3-a7ccf2de9290,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-06fdcd58-df86-4961-9ae5-3c7529601cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266369720-172.17.0.10-1599352943875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-4392d99e-1990-4b17-9351-cca1601ad9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-d650ef05-fad4-47d7-85b0-dcab98c9dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-065c4f07-6862-4a13-a60d-4ff04c998b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-0501066a-b5a6-4d1d-a466-2cd4b28b19e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-701b7d99-9903-4f44-a5e3-3ebf823e31e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-41afd682-14f7-4ce7-826c-694e7ff57340,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-4226c297-4187-4b9b-9640-e6c6011663a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-56cdefcd-c9d0-49bd-99a0-8f5f3a324276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266369720-172.17.0.10-1599352943875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-4392d99e-1990-4b17-9351-cca1601ad9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-d650ef05-fad4-47d7-85b0-dcab98c9dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-065c4f07-6862-4a13-a60d-4ff04c998b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-0501066a-b5a6-4d1d-a466-2cd4b28b19e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-701b7d99-9903-4f44-a5e3-3ebf823e31e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-41afd682-14f7-4ce7-826c-694e7ff57340,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-4226c297-4187-4b9b-9640-e6c6011663a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-56cdefcd-c9d0-49bd-99a0-8f5f3a324276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87470065-172.17.0.10-1599353059444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-174366b4-3a67-4c7b-bdef-702098859ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-f72fb9b6-86e0-4693-9c43-4b2de8a44297,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-16fed38f-75e6-4ebc-8cd3-fd60971b723d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e93b69fc-3756-471f-bc89-9f983b79a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-0ab1e5c4-3482-43bc-a5ea-65854e5c46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-4118fd18-c472-4e38-b921-be59c2836324,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-f8f67049-dd7f-4d04-b0a3-a4216bfe9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-c8d66eab-3dc2-427e-bd9b-2a093811660e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87470065-172.17.0.10-1599353059444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-174366b4-3a67-4c7b-bdef-702098859ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-f72fb9b6-86e0-4693-9c43-4b2de8a44297,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-16fed38f-75e6-4ebc-8cd3-fd60971b723d,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e93b69fc-3756-471f-bc89-9f983b79a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-0ab1e5c4-3482-43bc-a5ea-65854e5c46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-4118fd18-c472-4e38-b921-be59c2836324,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-f8f67049-dd7f-4d04-b0a3-a4216bfe9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-c8d66eab-3dc2-427e-bd9b-2a093811660e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007212171-172.17.0.10-1599353380175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-71ed8566-3489-4eeb-b2fc-8234b5729456,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5566dde1-2be4-460c-be7f-7548805041d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-4a45208e-f308-4014-b8b9-454238b01433,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-1c56ec62-e3d1-4e3c-8f19-8a16ea00ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-d23ef2e6-86a1-4734-bed9-c4446c1c8687,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-fe1f9402-9818-4ba0-b0a6-d73a71426aff,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-efe6931d-a1fc-42c1-9929-15c89df1367a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-40e8d62c-bdfa-430e-92d2-bba9047b7bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007212171-172.17.0.10-1599353380175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-71ed8566-3489-4eeb-b2fc-8234b5729456,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5566dde1-2be4-460c-be7f-7548805041d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-4a45208e-f308-4014-b8b9-454238b01433,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-1c56ec62-e3d1-4e3c-8f19-8a16ea00ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-d23ef2e6-86a1-4734-bed9-c4446c1c8687,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-fe1f9402-9818-4ba0-b0a6-d73a71426aff,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-efe6931d-a1fc-42c1-9929-15c89df1367a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-40e8d62c-bdfa-430e-92d2-bba9047b7bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071008246-172.17.0.10-1599353474129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-387d36db-97da-49b8-b540-599f75a831b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-c2c44660-b011-446c-9a48-48c093e8c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-b80a7664-c5ef-48bc-8c38-0c0e1c1369bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-a8d76db2-6f6a-4333-83e0-dfadd11945c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-95167205-7b06-4c0a-9301-844864a9ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-dd4a8c8c-460c-4b64-9bed-922c0c15686a,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-564301fc-7d62-44df-a2d9-8f5574a3209a,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-02073d42-e690-4b62-94e7-0182ad4a6bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071008246-172.17.0.10-1599353474129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-387d36db-97da-49b8-b540-599f75a831b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-c2c44660-b011-446c-9a48-48c093e8c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-b80a7664-c5ef-48bc-8c38-0c0e1c1369bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-a8d76db2-6f6a-4333-83e0-dfadd11945c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-95167205-7b06-4c0a-9301-844864a9ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-dd4a8c8c-460c-4b64-9bed-922c0c15686a,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-564301fc-7d62-44df-a2d9-8f5574a3209a,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-02073d42-e690-4b62-94e7-0182ad4a6bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393290621-172.17.0.10-1599353502004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-f437cd7f-366e-4d3a-ba5e-2a279da6457e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-9809276f-ce4f-4e72-a641-e6eadca8b577,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-b17f7b9e-cc77-4335-8253-69d49dbd7db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-71be3c0a-3ef2-4030-a6cd-0dc72dd16a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-606280cc-ada0-4225-be14-b7a7e18c3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-1a444331-07bc-4a41-ab6a-685e5852c7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-238b1a41-b095-436c-8339-859b9d1cb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-0fabd547-5b0d-40f2-9184-cb5b4f109784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393290621-172.17.0.10-1599353502004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-f437cd7f-366e-4d3a-ba5e-2a279da6457e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-9809276f-ce4f-4e72-a641-e6eadca8b577,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-b17f7b9e-cc77-4335-8253-69d49dbd7db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-71be3c0a-3ef2-4030-a6cd-0dc72dd16a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-606280cc-ada0-4225-be14-b7a7e18c3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-1a444331-07bc-4a41-ab6a-685e5852c7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-238b1a41-b095-436c-8339-859b9d1cb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-0fabd547-5b0d-40f2-9184-cb5b4f109784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637198451-172.17.0.10-1599353916459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44620,DS-4b54d873-511f-4c39-804c-c2ddb357e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-bd499f80-8b1f-47e0-adfb-501a48413259,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-78df25ed-c207-43db-a229-b0949f1ae00b,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-b572a1b9-8385-4d7a-81e7-2d29a7e8e154,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-290fbbe6-b546-4135-a964-21a3e10a8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-0b5ad0b2-ca89-46ec-926f-1ad5a92cf312,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b03fb3a5-2f94-4608-9fac-8991fac7f6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-e41e54f0-1022-4d46-a8ba-153f24c68728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637198451-172.17.0.10-1599353916459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44620,DS-4b54d873-511f-4c39-804c-c2ddb357e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-bd499f80-8b1f-47e0-adfb-501a48413259,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-78df25ed-c207-43db-a229-b0949f1ae00b,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-b572a1b9-8385-4d7a-81e7-2d29a7e8e154,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-290fbbe6-b546-4135-a964-21a3e10a8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-0b5ad0b2-ca89-46ec-926f-1ad5a92cf312,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b03fb3a5-2f94-4608-9fac-8991fac7f6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-e41e54f0-1022-4d46-a8ba-153f24c68728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639942992-172.17.0.10-1599354068156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38993,DS-546bd8b7-f8cc-4c27-89b3-9025d59e7bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-9f08dca0-29ec-4ebe-9778-6f72eb012b43,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-9c48fbf7-9985-42e8-aace-9bd1efe3ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-2737e696-ed10-43ac-bb26-d695469d79a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-ec174eaf-f5fe-44f5-8d3b-0a75d3fed25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-f240467d-1ccb-4393-a981-5a11fe3575a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-74932f20-692a-48fc-a2ce-171d3622921b,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-8c54b813-960d-4c55-9373-48a8ab5afcc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639942992-172.17.0.10-1599354068156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38993,DS-546bd8b7-f8cc-4c27-89b3-9025d59e7bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-9f08dca0-29ec-4ebe-9778-6f72eb012b43,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-9c48fbf7-9985-42e8-aace-9bd1efe3ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-2737e696-ed10-43ac-bb26-d695469d79a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-ec174eaf-f5fe-44f5-8d3b-0a75d3fed25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-f240467d-1ccb-4393-a981-5a11fe3575a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-74932f20-692a-48fc-a2ce-171d3622921b,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-8c54b813-960d-4c55-9373-48a8ab5afcc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611124515-172.17.0.10-1599354126672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-cabe5c43-602f-436a-b56e-ac2ee29c1ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-de8cb062-50e2-49af-87fd-ec393ca80f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-07b1341e-1d03-4c76-877f-d49bdfcbf8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-88b4f29f-d7a3-481d-bad5-27324d4f1468,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-30073078-2e44-4805-9cdc-d60d0b7a1736,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-86f95247-d195-4249-809f-2109359ab441,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-34e0ef21-a9bc-4744-887b-a787dec00e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-7e62239e-d811-4b92-b6ee-0e550ad17fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611124515-172.17.0.10-1599354126672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-cabe5c43-602f-436a-b56e-ac2ee29c1ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-de8cb062-50e2-49af-87fd-ec393ca80f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-07b1341e-1d03-4c76-877f-d49bdfcbf8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-88b4f29f-d7a3-481d-bad5-27324d4f1468,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-30073078-2e44-4805-9cdc-d60d0b7a1736,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-86f95247-d195-4249-809f-2109359ab441,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-34e0ef21-a9bc-4744-887b-a787dec00e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-7e62239e-d811-4b92-b6ee-0e550ad17fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004378203-172.17.0.10-1599354351427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-0c45e15f-d7b9-48da-87ab-ee02fd4883eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7a5e3d05-7bb3-485e-8b25-d01e611e43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-e61cc04b-6909-40bb-8ba1-33d21d01c079,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-b6c030c6-312d-45f1-aea8-5561b2c6cc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-2cf8f05d-1064-4d73-8e19-b5fa33c81110,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-ddde7ecd-58fa-4f69-bb96-0f23d8f46caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-ff7647e6-d06f-4767-80c8-9b9d52301663,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-75368563-1b98-468d-bd8f-4eb6ce4be3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004378203-172.17.0.10-1599354351427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-0c45e15f-d7b9-48da-87ab-ee02fd4883eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7a5e3d05-7bb3-485e-8b25-d01e611e43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-e61cc04b-6909-40bb-8ba1-33d21d01c079,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-b6c030c6-312d-45f1-aea8-5561b2c6cc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-2cf8f05d-1064-4d73-8e19-b5fa33c81110,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-ddde7ecd-58fa-4f69-bb96-0f23d8f46caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-ff7647e6-d06f-4767-80c8-9b9d52301663,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-75368563-1b98-468d-bd8f-4eb6ce4be3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024987352-172.17.0.10-1599354466299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-9f07a5d1-3189-4804-8473-6c5ba8dc4bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-b2d8d2cb-6b6d-4784-b8ae-2a752e70334b,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-1dc8106f-c7be-4798-8c0b-15e8cd34ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-dae309e0-905a-472e-984e-c92aa9d31960,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-88affe3e-322b-41e5-bf04-437d3120d243,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-27e0029f-ec10-4c2b-95e9-6f953591eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-2d92e30c-8e9b-4b1e-9548-544f24dad974,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-f78e6e7a-43a2-4d87-a61d-664eac0073bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024987352-172.17.0.10-1599354466299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-9f07a5d1-3189-4804-8473-6c5ba8dc4bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-b2d8d2cb-6b6d-4784-b8ae-2a752e70334b,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-1dc8106f-c7be-4798-8c0b-15e8cd34ef8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-dae309e0-905a-472e-984e-c92aa9d31960,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-88affe3e-322b-41e5-bf04-437d3120d243,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-27e0029f-ec10-4c2b-95e9-6f953591eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-2d92e30c-8e9b-4b1e-9548-544f24dad974,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-f78e6e7a-43a2-4d87-a61d-664eac0073bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356244654-172.17.0.10-1599354521705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-e02f606e-b790-4893-ad59-2eaf2d15a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-629151d6-ebd7-4227-8295-18f7782b240e,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-94f2de04-62be-4ae3-8b9b-d277ac38600c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-6db5fb1a-6938-4aa4-b766-c2831362b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b95d1925-9dce-4675-8e52-95452ca581be,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-e3f4069d-b6a2-4bcb-8ab5-342b03dd9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-132da757-7e41-4682-bba6-860ef5683d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7fd0d7bc-b4a2-45ea-9479-edf08c060287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356244654-172.17.0.10-1599354521705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45826,DS-e02f606e-b790-4893-ad59-2eaf2d15a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-629151d6-ebd7-4227-8295-18f7782b240e,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-94f2de04-62be-4ae3-8b9b-d277ac38600c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-6db5fb1a-6938-4aa4-b766-c2831362b87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b95d1925-9dce-4675-8e52-95452ca581be,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-e3f4069d-b6a2-4bcb-8ab5-342b03dd9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-132da757-7e41-4682-bba6-860ef5683d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7fd0d7bc-b4a2-45ea-9479-edf08c060287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611561580-172.17.0.10-1599354578780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-cb513f00-0963-4fff-868c-02008e910473,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-60e3faf7-d539-41f2-ab32-8ff407f6c5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-31d9aff1-a5f9-4656-bdca-21461f7e414f,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d57ae6ae-97cc-43fd-9b9d-e1cefaa785be,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8e9882a9-38aa-472f-b6e7-acc1139431a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-e7785317-6d84-43f5-b3fc-eac7300a79b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-161bf61b-d6a2-4197-8ea8-e3bfc5132c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-91e16880-c42a-42b5-95d3-6ee321510be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611561580-172.17.0.10-1599354578780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-cb513f00-0963-4fff-868c-02008e910473,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-60e3faf7-d539-41f2-ab32-8ff407f6c5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-31d9aff1-a5f9-4656-bdca-21461f7e414f,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d57ae6ae-97cc-43fd-9b9d-e1cefaa785be,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8e9882a9-38aa-472f-b6e7-acc1139431a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-e7785317-6d84-43f5-b3fc-eac7300a79b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-161bf61b-d6a2-4197-8ea8-e3bfc5132c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-91e16880-c42a-42b5-95d3-6ee321510be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365359939-172.17.0.10-1599354665660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-e403765b-fd08-449a-bee7-29b257ee7cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-c77d9ac2-67a8-49f1-9037-f722859c227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-7dd9dce7-727c-4154-9c3b-cf3086231c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-ef0f2cfe-6449-4fdb-9be6-180c4fd250d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-14c982a6-eb55-43c5-a05d-bbc398a304c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-510a9ff0-f0ed-4327-90fb-a4c22ad1ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-c1b7a1cb-f5e2-4c74-b46e-124598394720,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-4ca89d71-3e9d-4807-8b67-9451fa32d693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365359939-172.17.0.10-1599354665660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-e403765b-fd08-449a-bee7-29b257ee7cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-c77d9ac2-67a8-49f1-9037-f722859c227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-7dd9dce7-727c-4154-9c3b-cf3086231c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-ef0f2cfe-6449-4fdb-9be6-180c4fd250d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-14c982a6-eb55-43c5-a05d-bbc398a304c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-510a9ff0-f0ed-4327-90fb-a4c22ad1ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-c1b7a1cb-f5e2-4c74-b46e-124598394720,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-4ca89d71-3e9d-4807-8b67-9451fa32d693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092482592-172.17.0.10-1599354921460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-73710e9d-58ea-40de-8672-938d75509619,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-bc1fdb19-1869-4ca8-a85d-a02a6c4259fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-2048f696-cef7-42f3-bb45-21a56e4a30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-65ef22d1-b65f-42f1-8e07-5ac96e1a445c,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-b42a52c0-6b95-4cd7-80ca-a3bebfc0e5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-e568577b-b2e6-4d0d-a3b7-ba2df6d7ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-3de22594-1ad5-444e-ac83-e1e01cd3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-cddbcab8-94b7-45ab-b646-d711cb55feeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092482592-172.17.0.10-1599354921460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-73710e9d-58ea-40de-8672-938d75509619,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-bc1fdb19-1869-4ca8-a85d-a02a6c4259fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-2048f696-cef7-42f3-bb45-21a56e4a30cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-65ef22d1-b65f-42f1-8e07-5ac96e1a445c,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-b42a52c0-6b95-4cd7-80ca-a3bebfc0e5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-e568577b-b2e6-4d0d-a3b7-ba2df6d7ea4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-3de22594-1ad5-444e-ac83-e1e01cd3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-cddbcab8-94b7-45ab-b646-d711cb55feeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243822887-172.17.0.10-1599355264489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34404,DS-10a3fc9c-b247-4a52-b049-1c379816fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-bd9cec6e-329c-4046-b0d0-47cf185853af,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-200f4203-4f84-41d1-b065-ad8224371643,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-cfea43c4-9a8e-4de9-b6be-7070dd81aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-d66223ac-1149-40ae-b4eb-6931683d0665,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-1279f359-c577-4324-89a2-910c78606962,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-ee02790c-01c7-4bc3-baee-5ea21618c071,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-f9fbb370-ff4e-43aa-8d8a-873db2050251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243822887-172.17.0.10-1599355264489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34404,DS-10a3fc9c-b247-4a52-b049-1c379816fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-bd9cec6e-329c-4046-b0d0-47cf185853af,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-200f4203-4f84-41d1-b065-ad8224371643,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-cfea43c4-9a8e-4de9-b6be-7070dd81aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-d66223ac-1149-40ae-b4eb-6931683d0665,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-1279f359-c577-4324-89a2-910c78606962,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-ee02790c-01c7-4bc3-baee-5ea21618c071,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-f9fbb370-ff4e-43aa-8d8a-873db2050251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128378405-172.17.0.10-1599355649450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-95ec4934-e085-4b88-942f-3fe40b3133fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-015119d2-7f30-4c92-94c2-80902296ee51,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-108f4bbd-94ec-431e-b59b-08d55ba666f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-1c211299-f5f5-42f3-bc95-e518480817ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-0ef34f06-0cd1-4a25-8f5e-142539f728e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-a6df74b1-1733-4e6b-9343-ad94587cb2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-de37b8dd-3566-453e-8fb9-ff5729cfc6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6a82df7e-4496-4bfc-a25a-c2149896f61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128378405-172.17.0.10-1599355649450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-95ec4934-e085-4b88-942f-3fe40b3133fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-015119d2-7f30-4c92-94c2-80902296ee51,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-108f4bbd-94ec-431e-b59b-08d55ba666f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-1c211299-f5f5-42f3-bc95-e518480817ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-0ef34f06-0cd1-4a25-8f5e-142539f728e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-a6df74b1-1733-4e6b-9343-ad94587cb2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-de37b8dd-3566-453e-8fb9-ff5729cfc6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6a82df7e-4496-4bfc-a25a-c2149896f61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987136729-172.17.0.10-1599356238569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-8e1f7fc1-2ebe-4b1e-9a39-1e8412e2dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-34c4e381-6ade-4503-b9d1-b636ccd9f106,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-9bb42152-485f-4f06-9c17-6207e1fc1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-e7626745-0fb3-4f7e-85b3-d4bf77438533,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-156e74c4-1960-4cf2-88a5-1b6a2974902f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-41f4fcd8-5069-4317-8788-19f5bfd25cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e9ad8282-1cb5-47fb-957f-12f4beaf6593,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1b2849bc-8274-4b3e-9e05-afa698ad1c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987136729-172.17.0.10-1599356238569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-8e1f7fc1-2ebe-4b1e-9a39-1e8412e2dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-34c4e381-6ade-4503-b9d1-b636ccd9f106,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-9bb42152-485f-4f06-9c17-6207e1fc1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-e7626745-0fb3-4f7e-85b3-d4bf77438533,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-156e74c4-1960-4cf2-88a5-1b6a2974902f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-41f4fcd8-5069-4317-8788-19f5bfd25cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e9ad8282-1cb5-47fb-957f-12f4beaf6593,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1b2849bc-8274-4b3e-9e05-afa698ad1c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583341035-172.17.0.10-1599356295094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-4d565553-216b-49f0-a6da-c2790a619cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-7b0b7fd4-1223-4879-a98a-7d78d5cc5bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-fe1fe1b5-7f4f-409e-b13b-ca62e90f6dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-cf93045d-d84d-4aa4-a39e-5546ce3a53cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-be0ef477-1049-4426-9f3b-96e99c781a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-c26e65ea-4b10-4051-ae44-c98253e06019,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-534204e0-716f-4280-9c99-41190c8680fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-30274bca-542f-4b07-ba23-ad297e28deab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583341035-172.17.0.10-1599356295094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-4d565553-216b-49f0-a6da-c2790a619cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-7b0b7fd4-1223-4879-a98a-7d78d5cc5bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-fe1fe1b5-7f4f-409e-b13b-ca62e90f6dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-cf93045d-d84d-4aa4-a39e-5546ce3a53cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-be0ef477-1049-4426-9f3b-96e99c781a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-c26e65ea-4b10-4051-ae44-c98253e06019,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-534204e0-716f-4280-9c99-41190c8680fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-30274bca-542f-4b07-ba23-ad297e28deab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346836172-172.17.0.10-1599356413361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-4abbe0a4-eda1-4dc5-9f39-851a0f8af00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-be96bb07-d55f-459d-bbea-f4116236e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-6d130f54-961f-4914-907b-c5b1cf96688f,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a68edf99-aa6d-4fd1-8589-ba5731674789,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-8e2aec7b-a244-4957-87cb-3a8f5a07f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-d9575670-c55b-4321-9de5-7fc88aa9897b,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-dd693a9f-2da1-46e5-8bc1-d48f26c60534,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-3de65c44-6ac3-4e76-85f5-8a9fe82abc49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346836172-172.17.0.10-1599356413361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-4abbe0a4-eda1-4dc5-9f39-851a0f8af00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-be96bb07-d55f-459d-bbea-f4116236e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-6d130f54-961f-4914-907b-c5b1cf96688f,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-a68edf99-aa6d-4fd1-8589-ba5731674789,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-8e2aec7b-a244-4957-87cb-3a8f5a07f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-d9575670-c55b-4321-9de5-7fc88aa9897b,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-dd693a9f-2da1-46e5-8bc1-d48f26c60534,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-3de65c44-6ac3-4e76-85f5-8a9fe82abc49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4356
