reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230545863-172.17.0.7-1599325317984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-235ae410-469f-4737-9681-6d0f70f0df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-7a8b2649-953c-4cd1-8485-16d7ebb8c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-c26cee59-826f-44fb-8ce6-d7e067129a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1d8a03d2-ef9f-4055-82d0-e3f5c69a57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-730d02e8-eed3-4182-9b29-e2c2d5c4c278,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-0d6aea58-1f4b-4265-b5b3-22be54ecf0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-534713bd-4c68-4887-81ac-e6a2787d6b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-7c32d1b0-de63-491d-9dd3-43b4fbae2977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230545863-172.17.0.7-1599325317984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-235ae410-469f-4737-9681-6d0f70f0df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-7a8b2649-953c-4cd1-8485-16d7ebb8c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-c26cee59-826f-44fb-8ce6-d7e067129a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1d8a03d2-ef9f-4055-82d0-e3f5c69a57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-730d02e8-eed3-4182-9b29-e2c2d5c4c278,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-0d6aea58-1f4b-4265-b5b3-22be54ecf0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-534713bd-4c68-4887-81ac-e6a2787d6b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-7c32d1b0-de63-491d-9dd3-43b4fbae2977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616896309-172.17.0.7-1599325359673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-58af6039-6587-4e95-9a05-71bfcbec1a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-41154f35-7b52-49d0-83d0-b88eab2d2fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-85ce10d7-78e3-4243-ad88-96ecb1a4ce62,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-a198cc5f-6850-4450-9ab9-c0b84d62d047,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-062f05c9-07e4-4879-bf22-74870b8bf361,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-2aafbf8b-1f85-4651-84a6-69fa6e6ed331,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-4eeea1f4-0f5c-4f3f-8b0e-1db0cc7302ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-de7b1c04-94db-4ecc-b200-70be1f1f9061,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616896309-172.17.0.7-1599325359673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35913,DS-58af6039-6587-4e95-9a05-71bfcbec1a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-41154f35-7b52-49d0-83d0-b88eab2d2fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-85ce10d7-78e3-4243-ad88-96ecb1a4ce62,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-a198cc5f-6850-4450-9ab9-c0b84d62d047,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-062f05c9-07e4-4879-bf22-74870b8bf361,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-2aafbf8b-1f85-4651-84a6-69fa6e6ed331,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-4eeea1f4-0f5c-4f3f-8b0e-1db0cc7302ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-de7b1c04-94db-4ecc-b200-70be1f1f9061,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986563524-172.17.0.7-1599325484013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-5689c07d-76fd-46e1-9411-a053bdfec506,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-cba61712-2769-40c4-bb57-6617710a5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fcf56888-84a2-475f-84aa-b28ddb298c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-eab5d034-1f6c-4701-a02a-df9fa9c759a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-87bae2bd-1d9d-4dfc-8385-9ac0444eb474,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-6a2cd725-6341-429b-ad43-1fa675cb5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-df916ddd-7072-46a7-9702-888dea092d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6a8cd133-13e1-40a0-b81b-da0ec43c5c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986563524-172.17.0.7-1599325484013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43969,DS-5689c07d-76fd-46e1-9411-a053bdfec506,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-cba61712-2769-40c4-bb57-6617710a5dab,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fcf56888-84a2-475f-84aa-b28ddb298c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-eab5d034-1f6c-4701-a02a-df9fa9c759a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-87bae2bd-1d9d-4dfc-8385-9ac0444eb474,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-6a2cd725-6341-429b-ad43-1fa675cb5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-df916ddd-7072-46a7-9702-888dea092d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6a8cd133-13e1-40a0-b81b-da0ec43c5c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370298876-172.17.0.7-1599325568174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-43339372-9a7e-4c3f-803b-e9d3ee640b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7f915ecc-233b-48dd-a67b-2186332db2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-355ec1d0-6e38-4e47-aa52-aaa32e33d726,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-73c8512e-8f5d-48c5-b2b8-d4c74ef1d65c,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-14c6dda0-1301-491b-a058-7aa1ec8ef43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-2a78ff81-b8b8-42f2-ad1d-305198d3078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-a8e424fa-3841-48c6-9cd5-81bc7c262792,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-adb59967-8b27-4cf1-8c15-4681ce2e9b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370298876-172.17.0.7-1599325568174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-43339372-9a7e-4c3f-803b-e9d3ee640b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7f915ecc-233b-48dd-a67b-2186332db2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-355ec1d0-6e38-4e47-aa52-aaa32e33d726,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-73c8512e-8f5d-48c5-b2b8-d4c74ef1d65c,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-14c6dda0-1301-491b-a058-7aa1ec8ef43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-2a78ff81-b8b8-42f2-ad1d-305198d3078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-a8e424fa-3841-48c6-9cd5-81bc7c262792,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-adb59967-8b27-4cf1-8c15-4681ce2e9b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631481540-172.17.0.7-1599325737761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-a0af543c-f838-4ef9-a847-e5d6683bcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-af1dd511-96af-4e81-8d83-084e8ae1ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-e1097cc7-c2b8-4e37-9ce1-51344c3623d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-2f4c07ee-f220-41ce-a524-5170cace4739,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-48f0e207-d978-4fa8-97f3-9329ccb46300,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-519b1e2f-bdb8-47fb-b434-c904a8338503,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-abd9da2a-f8f2-43d9-aad5-d7a5c3c27efb,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-a5df3ac2-1237-49e1-886e-e9bc8290d5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631481540-172.17.0.7-1599325737761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-a0af543c-f838-4ef9-a847-e5d6683bcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-af1dd511-96af-4e81-8d83-084e8ae1ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-e1097cc7-c2b8-4e37-9ce1-51344c3623d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-2f4c07ee-f220-41ce-a524-5170cace4739,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-48f0e207-d978-4fa8-97f3-9329ccb46300,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-519b1e2f-bdb8-47fb-b434-c904a8338503,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-abd9da2a-f8f2-43d9-aad5-d7a5c3c27efb,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-a5df3ac2-1237-49e1-886e-e9bc8290d5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024868016-172.17.0.7-1599325914998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-3346ec94-95c6-4229-8a34-0b15f67f9715,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-9ab348ef-6d4a-4b2f-be42-44149b85dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2fb48ef9-f8b2-4cf6-a8d9-9148f4d67a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-769e56f1-0998-4062-b2f5-6cb8e9265650,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-cd54268e-8037-4233-bf99-6503e3642973,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-7316e3d5-4c73-4c0d-b249-bbf1a267cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-ddce76cb-1ed9-428d-b2d1-1c389b25e950,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-f1ca6f5a-db9c-4716-959d-b8f51a8de017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024868016-172.17.0.7-1599325914998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-3346ec94-95c6-4229-8a34-0b15f67f9715,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-9ab348ef-6d4a-4b2f-be42-44149b85dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2fb48ef9-f8b2-4cf6-a8d9-9148f4d67a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-769e56f1-0998-4062-b2f5-6cb8e9265650,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-cd54268e-8037-4233-bf99-6503e3642973,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-7316e3d5-4c73-4c0d-b249-bbf1a267cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-ddce76cb-1ed9-428d-b2d1-1c389b25e950,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-f1ca6f5a-db9c-4716-959d-b8f51a8de017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991670669-172.17.0.7-1599326087601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35020,DS-3bd2c7d4-9b75-4132-82d0-978333c6ca1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-ed1c0444-c214-4008-86b6-97c5ef240045,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b8daec72-ba5e-4126-b34b-829d9e4513f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2e9316da-65d1-44fe-bd46-94aa51259d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-90e656a8-6781-4091-91e4-824bd0ee43ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-39e0258d-ccd3-4495-aed9-38340a142ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-f75b9028-928b-447e-aa57-769c4b6bad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-8dbc61fe-04a5-43c5-a9e5-277229914f7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991670669-172.17.0.7-1599326087601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35020,DS-3bd2c7d4-9b75-4132-82d0-978333c6ca1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-ed1c0444-c214-4008-86b6-97c5ef240045,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b8daec72-ba5e-4126-b34b-829d9e4513f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2e9316da-65d1-44fe-bd46-94aa51259d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-90e656a8-6781-4091-91e4-824bd0ee43ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-39e0258d-ccd3-4495-aed9-38340a142ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-f75b9028-928b-447e-aa57-769c4b6bad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-8dbc61fe-04a5-43c5-a9e5-277229914f7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682696406-172.17.0.7-1599326659633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33567,DS-54802a54-0b4f-466a-afad-5c0fcb5d18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-5c4932f9-d8ae-4954-9e01-0cd93b9b6448,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-9035ffbe-2d09-4a07-a0c1-8eab9e4e623f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-50296cfb-6b66-498d-9cd0-dcdb9fb706cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-3e997319-9711-4c6a-96c2-f737c1138fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-6da5ffd1-d48b-45fc-bb8a-706383016b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-bccc82b2-7fdc-4cca-9d52-778e79ee79b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-52e3db33-6c4f-495b-a1bb-5026afb88e79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682696406-172.17.0.7-1599326659633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33567,DS-54802a54-0b4f-466a-afad-5c0fcb5d18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-5c4932f9-d8ae-4954-9e01-0cd93b9b6448,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-9035ffbe-2d09-4a07-a0c1-8eab9e4e623f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-50296cfb-6b66-498d-9cd0-dcdb9fb706cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-3e997319-9711-4c6a-96c2-f737c1138fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-6da5ffd1-d48b-45fc-bb8a-706383016b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-bccc82b2-7fdc-4cca-9d52-778e79ee79b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-52e3db33-6c4f-495b-a1bb-5026afb88e79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418608491-172.17.0.7-1599326821313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-fefca283-3ff0-412e-a619-7c1448e9804f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-2f6d9168-b5c5-490b-bfcd-67cedb193b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-0074f0e4-29c2-4f43-82ec-8cfd4e3e6790,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-d6c3509a-c8aa-490d-ae15-679077ed69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-73c65e17-5ee1-4f85-b2b6-634f5bbe7afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-a031b83e-cce5-4c4c-a0a8-cab37f7c9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-b0148cf3-8e53-44e1-b0a6-6f3833528b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-93c52452-9220-419f-a09f-eacb5b8d8bd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418608491-172.17.0.7-1599326821313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-fefca283-3ff0-412e-a619-7c1448e9804f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-2f6d9168-b5c5-490b-bfcd-67cedb193b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-0074f0e4-29c2-4f43-82ec-8cfd4e3e6790,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-d6c3509a-c8aa-490d-ae15-679077ed69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-73c65e17-5ee1-4f85-b2b6-634f5bbe7afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-a031b83e-cce5-4c4c-a0a8-cab37f7c9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-b0148cf3-8e53-44e1-b0a6-6f3833528b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-93c52452-9220-419f-a09f-eacb5b8d8bd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360963811-172.17.0.7-1599326937397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43659,DS-6d8058eb-c810-4925-b879-6836cfb2cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-367ed3d0-9da7-47c0-a036-2f9bf1f94479,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-e88be37e-dfc8-4dea-913f-546f83f6d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-c1ebc033-3c69-4dff-99bb-f68c967c83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-dcddf3d9-1e2c-432e-a17f-b80e1c0fbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-d5a21f30-c508-4f3b-99af-0f52fee66c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-7520155a-92af-474f-8804-7c7797ad6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-b84f28d6-0043-43f7-86e7-9baba4188bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360963811-172.17.0.7-1599326937397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43659,DS-6d8058eb-c810-4925-b879-6836cfb2cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-367ed3d0-9da7-47c0-a036-2f9bf1f94479,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-e88be37e-dfc8-4dea-913f-546f83f6d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-c1ebc033-3c69-4dff-99bb-f68c967c83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-dcddf3d9-1e2c-432e-a17f-b80e1c0fbb20,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-d5a21f30-c508-4f3b-99af-0f52fee66c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-7520155a-92af-474f-8804-7c7797ad6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-b84f28d6-0043-43f7-86e7-9baba4188bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796569863-172.17.0.7-1599327384968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44211,DS-ed56fddb-e984-4c96-8530-d7b16135420e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-84e33a35-87ec-4f59-9433-e133c5d5b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-22337ab8-6d19-4457-84ff-53bbc0b1a8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-24e326c3-d09d-4151-a0ca-8658dac7a0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-bc124503-f527-4278-aec5-acbcc9c07b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-34206e7b-5d75-469e-897b-cc52ebea79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-66e5b645-57e2-4dd8-a1f0-f37212d6e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-8f38c8b6-cdce-4e8a-a81b-127f3cc15c82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796569863-172.17.0.7-1599327384968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44211,DS-ed56fddb-e984-4c96-8530-d7b16135420e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-84e33a35-87ec-4f59-9433-e133c5d5b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-22337ab8-6d19-4457-84ff-53bbc0b1a8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-24e326c3-d09d-4151-a0ca-8658dac7a0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-bc124503-f527-4278-aec5-acbcc9c07b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-34206e7b-5d75-469e-897b-cc52ebea79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-66e5b645-57e2-4dd8-a1f0-f37212d6e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-8f38c8b6-cdce-4e8a-a81b-127f3cc15c82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004070063-172.17.0.7-1599327450280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-6841bee2-39ba-4562-a921-c374a9113a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-4d8df014-acfd-42f0-9623-7a610da59c86,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-68e93c5c-da2d-414e-81a6-032f6c60a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-b88a4119-75b9-40a3-a4cb-96e173d0d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-ee4a941a-104b-426c-a1cd-9d72ce0f7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-57db4daa-9b5e-4ae0-81d8-52425bd4ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-850571f1-2707-4a62-9605-7ff57606b6af,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-97661063-17ea-4eae-93c3-f0e2904d013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004070063-172.17.0.7-1599327450280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-6841bee2-39ba-4562-a921-c374a9113a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-4d8df014-acfd-42f0-9623-7a610da59c86,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-68e93c5c-da2d-414e-81a6-032f6c60a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-b88a4119-75b9-40a3-a4cb-96e173d0d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-ee4a941a-104b-426c-a1cd-9d72ce0f7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-57db4daa-9b5e-4ae0-81d8-52425bd4ba70,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-850571f1-2707-4a62-9605-7ff57606b6af,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-97661063-17ea-4eae-93c3-f0e2904d013b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855514012-172.17.0.7-1599327562941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-29f46a0d-8303-4347-961a-753eaa35b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-36c65374-fcd1-469a-9bd1-2ffe67ba060d,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-6db3cc81-d5f3-40a4-965e-1aaf62974995,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-80632519-3f09-4904-98af-54e4b381e873,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-d11fd205-8237-48d6-806d-67fa293d9c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-81cae924-a2dc-4273-b9ff-114ab96edf33,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-8ab505aa-9086-43a1-8e34-0977aa9d500c,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-3d836db6-33a0-47ae-bbc1-1033062d176a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855514012-172.17.0.7-1599327562941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-29f46a0d-8303-4347-961a-753eaa35b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-36c65374-fcd1-469a-9bd1-2ffe67ba060d,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-6db3cc81-d5f3-40a4-965e-1aaf62974995,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-80632519-3f09-4904-98af-54e4b381e873,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-d11fd205-8237-48d6-806d-67fa293d9c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-81cae924-a2dc-4273-b9ff-114ab96edf33,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-8ab505aa-9086-43a1-8e34-0977aa9d500c,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-3d836db6-33a0-47ae-bbc1-1033062d176a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315458829-172.17.0.7-1599327868855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-94d40817-33b5-4766-9c60-7c20806f22b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-6ed092bc-912e-4130-b881-f0b764a643d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-272b9b1b-f97e-4325-9587-207c0d852e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-467eafbd-2f72-44e6-a025-61a36493bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-edec3532-f405-426d-8252-1247ea081082,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-534a26f0-692f-416d-86f6-da7251782d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-57b937b7-eb32-4616-bd4e-e8d8832e7e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-696f3d30-315c-47b5-9365-7140f9fed4c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315458829-172.17.0.7-1599327868855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-94d40817-33b5-4766-9c60-7c20806f22b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-6ed092bc-912e-4130-b881-f0b764a643d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-272b9b1b-f97e-4325-9587-207c0d852e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-467eafbd-2f72-44e6-a025-61a36493bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-edec3532-f405-426d-8252-1247ea081082,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-534a26f0-692f-416d-86f6-da7251782d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-57b937b7-eb32-4616-bd4e-e8d8832e7e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-696f3d30-315c-47b5-9365-7140f9fed4c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107423214-172.17.0.7-1599327909926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-c69c5e72-a228-46f2-86d0-dff5ab5b6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-796937c6-b11d-4142-b82a-1ff9b53cd912,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-82a51670-1977-4329-bd91-d464c8874bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-095f8d07-5510-4a89-9a3b-b80b0a006864,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-b9f0a759-398e-413a-85aa-e79e4ff39282,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-a943d6f4-20fd-4da3-96f9-a372738ed84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-e648ae00-642d-4741-927d-733c9d3cd204,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-d16616c3-a777-4e62-940b-0e673d855766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107423214-172.17.0.7-1599327909926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-c69c5e72-a228-46f2-86d0-dff5ab5b6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-796937c6-b11d-4142-b82a-1ff9b53cd912,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-82a51670-1977-4329-bd91-d464c8874bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-095f8d07-5510-4a89-9a3b-b80b0a006864,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-b9f0a759-398e-413a-85aa-e79e4ff39282,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-a943d6f4-20fd-4da3-96f9-a372738ed84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-e648ae00-642d-4741-927d-733c9d3cd204,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-d16616c3-a777-4e62-940b-0e673d855766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053149433-172.17.0.7-1599328088175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-ae2f9a6a-44f6-43df-9c79-0e7283471a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-3916ab23-6e19-422c-98d7-aa9f324743cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-bee28792-ea6b-4212-bc4e-7730dfd0d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-09f651df-1db6-4f14-ad1a-f31eb894fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-dd198a75-96b8-4104-a886-93e57480cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-060d0137-a418-4664-ab67-6fbd211ded28,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-c9f8f5d6-5a67-4983-9a6d-733345f8c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-f2c63865-90d8-46dc-9ab1-65828b548517,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053149433-172.17.0.7-1599328088175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-ae2f9a6a-44f6-43df-9c79-0e7283471a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-3916ab23-6e19-422c-98d7-aa9f324743cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-bee28792-ea6b-4212-bc4e-7730dfd0d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-09f651df-1db6-4f14-ad1a-f31eb894fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-dd198a75-96b8-4104-a886-93e57480cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-060d0137-a418-4664-ab67-6fbd211ded28,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-c9f8f5d6-5a67-4983-9a6d-733345f8c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-f2c63865-90d8-46dc-9ab1-65828b548517,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423374976-172.17.0.7-1599328192738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-a8febf70-91e6-446c-9aef-fe6787a52f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-11d6027f-9715-4550-853e-97c3f1272cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-4db1c00d-8954-46d4-a350-5984bbdf5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-3c222cee-1b09-4f5f-9edf-a657554f6e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-9f928850-6719-48cf-b891-0ffbc45ab604,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-c3a7e60f-c78b-43f5-bd22-8abe102b7d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7ac188ae-2e7b-422b-9164-d8fb3383139d,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-5b1508b0-49a0-468f-a85e-e0ea48f009c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423374976-172.17.0.7-1599328192738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-a8febf70-91e6-446c-9aef-fe6787a52f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-11d6027f-9715-4550-853e-97c3f1272cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-4db1c00d-8954-46d4-a350-5984bbdf5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-3c222cee-1b09-4f5f-9edf-a657554f6e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-9f928850-6719-48cf-b891-0ffbc45ab604,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-c3a7e60f-c78b-43f5-bd22-8abe102b7d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7ac188ae-2e7b-422b-9164-d8fb3383139d,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-5b1508b0-49a0-468f-a85e-e0ea48f009c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715183771-172.17.0.7-1599328228378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-0531ce67-5259-40b5-9386-fbb754b7ab24,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-9883e9b5-736b-4153-afb6-e6eabd100550,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-1cdba94f-7721-406c-95e0-c59a57e533fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-99bc0cd2-c3fe-43e8-afa9-7814a1e0d194,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-f668fced-f1bf-4393-8058-bcecfc427eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-430cef60-a793-49e1-8251-416b556ec5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-266367aa-94e7-45c5-83f1-157cde3051b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-c4d3e7ab-e711-40fa-ad89-edfea9d4f347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715183771-172.17.0.7-1599328228378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-0531ce67-5259-40b5-9386-fbb754b7ab24,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-9883e9b5-736b-4153-afb6-e6eabd100550,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-1cdba94f-7721-406c-95e0-c59a57e533fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-99bc0cd2-c3fe-43e8-afa9-7814a1e0d194,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-f668fced-f1bf-4393-8058-bcecfc427eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-430cef60-a793-49e1-8251-416b556ec5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-266367aa-94e7-45c5-83f1-157cde3051b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-c4d3e7ab-e711-40fa-ad89-edfea9d4f347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741527941-172.17.0.7-1599328404872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-b8aab34a-d054-4e92-a429-611a49e74b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-05d997fd-a9f0-4e8a-a354-ba2b3fb34f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-3894ec1d-32cd-4db4-a318-5bd765191920,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-54f38075-25e8-4825-9b6c-55c4d7f298e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-bc9ceba8-c62e-487b-a35e-6101d277d039,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-5fe9a4b2-2058-43eb-8d2c-2ea98238952c,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-dff5434e-a6ab-410e-bf9f-bee795c80de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-f159f38d-412e-4f25-9630-52a2e8970e0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741527941-172.17.0.7-1599328404872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-b8aab34a-d054-4e92-a429-611a49e74b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-05d997fd-a9f0-4e8a-a354-ba2b3fb34f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-3894ec1d-32cd-4db4-a318-5bd765191920,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-54f38075-25e8-4825-9b6c-55c4d7f298e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-bc9ceba8-c62e-487b-a35e-6101d277d039,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-5fe9a4b2-2058-43eb-8d2c-2ea98238952c,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-dff5434e-a6ab-410e-bf9f-bee795c80de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-f159f38d-412e-4f25-9630-52a2e8970e0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110086125-172.17.0.7-1599328602506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-78b55146-cbfe-4a48-93f5-f99cc2f578db,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5f3a1050-eac0-440e-89a1-eb4516f5f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-d4956521-9a3b-423c-a8e3-3e0125ccd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-8b8520fe-c5ea-4b93-9fec-51a58840302c,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-2bd77993-f91e-4b26-b55f-04e0b12217fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-77346094-2056-4238-b711-b073d07d0563,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-e506ae68-a907-431e-a252-4af73395719a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c9415d5d-25b6-44fc-8d1e-2a92bedfc06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110086125-172.17.0.7-1599328602506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-78b55146-cbfe-4a48-93f5-f99cc2f578db,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5f3a1050-eac0-440e-89a1-eb4516f5f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-d4956521-9a3b-423c-a8e3-3e0125ccd82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-8b8520fe-c5ea-4b93-9fec-51a58840302c,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-2bd77993-f91e-4b26-b55f-04e0b12217fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-77346094-2056-4238-b711-b073d07d0563,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-e506ae68-a907-431e-a252-4af73395719a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c9415d5d-25b6-44fc-8d1e-2a92bedfc06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279931416-172.17.0.7-1599328880387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-1b2b2961-05cc-482d-b06b-3c37a99987bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-c29f5cce-cabd-42da-a497-40a2e1c02709,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-3c9ab6a3-3db3-4d0e-ac4a-73859ba95f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-4d9f5f94-dba9-41fb-915d-1d5168731998,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-59ad6986-25f3-470f-a941-078d820ab38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-bb56bb59-3106-46d6-9aba-caa01c17dbec,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-b1278659-121e-4642-bc4a-f827161a8123,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-2a713f9f-d02d-4abc-88e3-a2d075d45f39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279931416-172.17.0.7-1599328880387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-1b2b2961-05cc-482d-b06b-3c37a99987bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-c29f5cce-cabd-42da-a497-40a2e1c02709,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-3c9ab6a3-3db3-4d0e-ac4a-73859ba95f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-4d9f5f94-dba9-41fb-915d-1d5168731998,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-59ad6986-25f3-470f-a941-078d820ab38f,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-bb56bb59-3106-46d6-9aba-caa01c17dbec,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-b1278659-121e-4642-bc4a-f827161a8123,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-2a713f9f-d02d-4abc-88e3-a2d075d45f39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017609598-172.17.0.7-1599329140449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-97970d81-1a3e-4ebd-bedf-7bc0128215c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-429d2920-c0cf-4b4a-940e-0b953aff3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-7b104bd9-7fa5-466e-aee2-267a8741ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-24a0b6bb-672c-41dc-9508-d796944d770e,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-e8be5612-bccc-47bc-91f1-5ccd35bd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4418a2f4-4c9f-4106-b0e5-b703861b4ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-57fc10d9-e644-40bd-bca4-775260e1b8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-3f6d19a8-ab09-4c58-90c1-7128230f94b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017609598-172.17.0.7-1599329140449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-97970d81-1a3e-4ebd-bedf-7bc0128215c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-429d2920-c0cf-4b4a-940e-0b953aff3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-7b104bd9-7fa5-466e-aee2-267a8741ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-24a0b6bb-672c-41dc-9508-d796944d770e,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-e8be5612-bccc-47bc-91f1-5ccd35bd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4418a2f4-4c9f-4106-b0e5-b703861b4ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-57fc10d9-e644-40bd-bca4-775260e1b8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-3f6d19a8-ab09-4c58-90c1-7128230f94b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888285341-172.17.0.7-1599329476617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-97ef3228-32c2-4edf-bfb7-a44d63c269f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2ef3df5a-36d5-4e16-b82b-45dafb451a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-6656bab1-bcf6-406c-bdbc-54733945f506,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a772a4dc-a1f4-40fc-9f03-b64dbb37415d,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-3ce72b64-bc29-44a3-8903-3c63a603045d,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-8878635b-7d97-4d5e-8e9c-5d4e68fb9b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-37385b6f-1088-4f31-a4da-02e35fafd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-42d5a334-9bb6-4bae-bc36-d14c13d9678b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888285341-172.17.0.7-1599329476617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-97ef3228-32c2-4edf-bfb7-a44d63c269f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2ef3df5a-36d5-4e16-b82b-45dafb451a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-6656bab1-bcf6-406c-bdbc-54733945f506,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a772a4dc-a1f4-40fc-9f03-b64dbb37415d,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-3ce72b64-bc29-44a3-8903-3c63a603045d,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-8878635b-7d97-4d5e-8e9c-5d4e68fb9b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-37385b6f-1088-4f31-a4da-02e35fafd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-42d5a334-9bb6-4bae-bc36-d14c13d9678b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427037568-172.17.0.7-1599329774681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-202ab266-76c1-4f65-8e84-77d171595882,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-2d140cac-679f-4313-8d91-82fd2a904d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-c922c776-f2da-4702-a92e-b5bbe3fa8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-12a1461e-23fd-4eeb-ae43-8bf08d48fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-dde12929-4eeb-46f6-b429-3e6f6916a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-82abcc4b-ca40-4fc5-8c19-d71a45bbd390,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ecf53fdb-75f3-4d1d-9424-77813cd2a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-4bc90142-e017-4e6b-b80b-dcda0f3cd7d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427037568-172.17.0.7-1599329774681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36397,DS-202ab266-76c1-4f65-8e84-77d171595882,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-2d140cac-679f-4313-8d91-82fd2a904d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-c922c776-f2da-4702-a92e-b5bbe3fa8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-12a1461e-23fd-4eeb-ae43-8bf08d48fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-dde12929-4eeb-46f6-b429-3e6f6916a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-82abcc4b-ca40-4fc5-8c19-d71a45bbd390,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ecf53fdb-75f3-4d1d-9424-77813cd2a9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-4bc90142-e017-4e6b-b80b-dcda0f3cd7d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556038500-172.17.0.7-1599329811814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-84723414-c2f1-41c8-b5df-a0e22e45ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-782d0228-c0af-4ce9-add1-943c09c1d638,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-da4fd746-ad87-460c-bd0f-cce56c140977,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-d5c1722f-4106-4b9d-9c6e-5729df9f549e,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-5a4ccc9b-c32d-47c0-b33c-83b640c86eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-1b6f320a-6060-4ce1-8303-6f9dbbf70fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-674bfba5-fefd-4671-8507-a0b87f273d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-73ffe6e3-807e-4110-8972-644bd06bfc2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556038500-172.17.0.7-1599329811814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-84723414-c2f1-41c8-b5df-a0e22e45ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-782d0228-c0af-4ce9-add1-943c09c1d638,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-da4fd746-ad87-460c-bd0f-cce56c140977,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-d5c1722f-4106-4b9d-9c6e-5729df9f549e,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-5a4ccc9b-c32d-47c0-b33c-83b640c86eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-1b6f320a-6060-4ce1-8303-6f9dbbf70fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-674bfba5-fefd-4671-8507-a0b87f273d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-73ffe6e3-807e-4110-8972-644bd06bfc2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037721143-172.17.0.7-1599329977516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37070,DS-7ad856d4-3fcb-4eab-861f-d0255fbdfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-fd5faccf-69ec-4641-a704-ee6748720744,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-651fedf1-c3b7-4e08-9c2d-272a2b1ca137,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-0f41ed78-ff21-4565-a8eb-08cd8d6811a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-05bf7b8e-2888-4d34-9efa-877ee82b6201,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-7cdcb9e1-4a0d-4885-849b-9f498247fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5517060c-6aa8-494e-bc3b-244d5862efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-75596013-e125-4771-93a4-8a0eeb149744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037721143-172.17.0.7-1599329977516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37070,DS-7ad856d4-3fcb-4eab-861f-d0255fbdfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-fd5faccf-69ec-4641-a704-ee6748720744,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-651fedf1-c3b7-4e08-9c2d-272a2b1ca137,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-0f41ed78-ff21-4565-a8eb-08cd8d6811a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-05bf7b8e-2888-4d34-9efa-877ee82b6201,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-7cdcb9e1-4a0d-4885-849b-9f498247fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5517060c-6aa8-494e-bc3b-244d5862efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-75596013-e125-4771-93a4-8a0eeb149744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112486039-172.17.0.7-1599330561783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-a0794dba-891a-437d-a8e8-7746a630f312,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-2a0aedfb-a470-4b20-8398-e98f140ef081,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-7c41baa7-150b-4bf5-ba75-823ccdad4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b82322eb-d66c-476c-ad63-d8651facd1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-36dbc8d3-7c02-4925-b0ac-68d2a1e1b266,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-4a6aedbd-3600-4b96-9468-befee00b481e,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-79f92f02-5da6-4cf5-be8b-3959566ab672,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-81a97748-ae1e-4b73-bf98-9e39d2d4b4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112486039-172.17.0.7-1599330561783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-a0794dba-891a-437d-a8e8-7746a630f312,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-2a0aedfb-a470-4b20-8398-e98f140ef081,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-7c41baa7-150b-4bf5-ba75-823ccdad4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-b82322eb-d66c-476c-ad63-d8651facd1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-36dbc8d3-7c02-4925-b0ac-68d2a1e1b266,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-4a6aedbd-3600-4b96-9468-befee00b481e,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-79f92f02-5da6-4cf5-be8b-3959566ab672,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-81a97748-ae1e-4b73-bf98-9e39d2d4b4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191043651-172.17.0.7-1599330752568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-8be1056a-a603-4d0b-bfdd-e28d4efd9c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-4f5715f8-81be-4d9c-918f-91e8af08f006,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-52a1dd97-1d54-4c1e-b340-51abe4d1062b,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-93882f44-cddf-46a9-bb88-10aed6f1948a,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-4c9feac9-08c6-400f-a0b5-cf364eff207b,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-39b74ffa-8e6d-4a0e-9087-d59e1dae6004,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-ce2ce0fe-0da6-4b64-b091-bbae70f10638,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-8f6fedd1-12ec-4a74-9fdf-d6feefda9de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191043651-172.17.0.7-1599330752568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-8be1056a-a603-4d0b-bfdd-e28d4efd9c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-4f5715f8-81be-4d9c-918f-91e8af08f006,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-52a1dd97-1d54-4c1e-b340-51abe4d1062b,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-93882f44-cddf-46a9-bb88-10aed6f1948a,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-4c9feac9-08c6-400f-a0b5-cf364eff207b,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-39b74ffa-8e6d-4a0e-9087-d59e1dae6004,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-ce2ce0fe-0da6-4b64-b091-bbae70f10638,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-8f6fedd1-12ec-4a74-9fdf-d6feefda9de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690115510-172.17.0.7-1599330930299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-aec5a73d-68fa-47a7-a7cd-c7eadfdaa8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b23bd1e2-cf47-463d-b488-e60b0688adac,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-fba2c795-75ae-4b6e-a7a5-00f2ac693f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-9298ae1f-e450-491d-82eb-5c362d18342a,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-1f62d619-868e-46b2-bb89-d3c06b48e686,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-5ff9f8a9-48c9-417d-bf5b-5d339f25d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2a2e93c3-5877-4f7b-aed1-aa2b64e2726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3ea88064-1b76-4d2a-9b10-cb64117024d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690115510-172.17.0.7-1599330930299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-aec5a73d-68fa-47a7-a7cd-c7eadfdaa8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-b23bd1e2-cf47-463d-b488-e60b0688adac,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-fba2c795-75ae-4b6e-a7a5-00f2ac693f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-9298ae1f-e450-491d-82eb-5c362d18342a,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-1f62d619-868e-46b2-bb89-d3c06b48e686,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-5ff9f8a9-48c9-417d-bf5b-5d339f25d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2a2e93c3-5877-4f7b-aed1-aa2b64e2726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3ea88064-1b76-4d2a-9b10-cb64117024d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5727
