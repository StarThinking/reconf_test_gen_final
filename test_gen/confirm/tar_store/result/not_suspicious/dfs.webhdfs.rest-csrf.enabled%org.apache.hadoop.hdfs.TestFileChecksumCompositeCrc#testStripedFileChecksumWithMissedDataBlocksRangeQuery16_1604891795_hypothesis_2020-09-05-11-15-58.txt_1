reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068843954-172.17.0.19-1599304574607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-6da3f84a-6661-4ee7-ad17-52dc90ad43c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-545c1517-5051-4abb-a008-c7aacce86a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-3320fc46-0696-4925-850d-6d84d09c2b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-22789b74-6ea7-4dda-8170-616974e29edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-11677f9b-184d-41b1-8e75-e5922f7d615b,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-8ab0573d-7f0b-46ec-ac90-e2a65d9e226f,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-7b293b1f-2e8f-4219-b6c3-751afa8c168f,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-d476ca10-5512-4c27-98fd-a035b05d4296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068843954-172.17.0.19-1599304574607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-6da3f84a-6661-4ee7-ad17-52dc90ad43c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-545c1517-5051-4abb-a008-c7aacce86a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-3320fc46-0696-4925-850d-6d84d09c2b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-22789b74-6ea7-4dda-8170-616974e29edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-11677f9b-184d-41b1-8e75-e5922f7d615b,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-8ab0573d-7f0b-46ec-ac90-e2a65d9e226f,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-7b293b1f-2e8f-4219-b6c3-751afa8c168f,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-d476ca10-5512-4c27-98fd-a035b05d4296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332247152-172.17.0.19-1599304894649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-37d4d33b-2133-4b29-b47b-2d3f3521cf87,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-b2f93f4e-3a17-484c-b6ea-98927688567e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-96319adb-5ad8-4854-a14e-0a19ba258646,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-0023cb23-1b16-41ff-ab7b-c2f77df9a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-2f9cdd90-9089-4f4d-909c-fe5d7c228278,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-da45dce4-1645-45a9-be89-d3aa2e6c6575,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-effe22f4-0318-497a-ad74-1ee920c0e523,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-3d2ad50f-2b10-43ce-95bc-f10e1a82c5dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332247152-172.17.0.19-1599304894649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-37d4d33b-2133-4b29-b47b-2d3f3521cf87,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-b2f93f4e-3a17-484c-b6ea-98927688567e,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-96319adb-5ad8-4854-a14e-0a19ba258646,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-0023cb23-1b16-41ff-ab7b-c2f77df9a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-2f9cdd90-9089-4f4d-909c-fe5d7c228278,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-da45dce4-1645-45a9-be89-d3aa2e6c6575,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-effe22f4-0318-497a-ad74-1ee920c0e523,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-3d2ad50f-2b10-43ce-95bc-f10e1a82c5dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858359199-172.17.0.19-1599305574557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-251118cd-6392-4a52-8100-10d61d75b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-af7df8dc-9dbc-4bd0-a603-c232ec5ba51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-72e5f560-25e1-49f7-ba0e-97482801c026,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-4734ca86-7791-4389-b41b-8d93ce50d70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f67e389c-ac8f-4892-b465-4b53add56834,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-af90084a-7112-4abc-a863-9c6c9d9bba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-2fccb3c3-9696-4a05-bee2-79d645f6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-086a0d1f-f708-43cd-91dd-99c1e50f9747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858359199-172.17.0.19-1599305574557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-251118cd-6392-4a52-8100-10d61d75b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-af7df8dc-9dbc-4bd0-a603-c232ec5ba51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-72e5f560-25e1-49f7-ba0e-97482801c026,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-4734ca86-7791-4389-b41b-8d93ce50d70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f67e389c-ac8f-4892-b465-4b53add56834,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-af90084a-7112-4abc-a863-9c6c9d9bba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-2fccb3c3-9696-4a05-bee2-79d645f6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-086a0d1f-f708-43cd-91dd-99c1e50f9747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263157003-172.17.0.19-1599305768066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-bed2564b-85da-4c04-8f9c-93f3fb2d25d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-56f2eb1e-3f25-491e-98fb-466abe574a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-427b4141-f879-44e4-b17f-ed47f66a288d,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-c41a6080-0676-43bf-bd16-25abb10667a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-b52474bf-5dcc-451e-8bdd-b49e0a402089,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1641456b-793b-4a78-b1ee-600da8689b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-192c363f-652b-4dbb-8353-8249688d23d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-f40095ae-a02b-4741-bf41-f7d3c692baa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263157003-172.17.0.19-1599305768066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-bed2564b-85da-4c04-8f9c-93f3fb2d25d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-56f2eb1e-3f25-491e-98fb-466abe574a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-427b4141-f879-44e4-b17f-ed47f66a288d,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-c41a6080-0676-43bf-bd16-25abb10667a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-b52474bf-5dcc-451e-8bdd-b49e0a402089,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1641456b-793b-4a78-b1ee-600da8689b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-192c363f-652b-4dbb-8353-8249688d23d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-f40095ae-a02b-4741-bf41-f7d3c692baa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861131791-172.17.0.19-1599306000959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-68e0cc6e-75e6-4f2b-bdc0-59eed0042b54,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-d88a96c9-1989-41cd-8ff3-d6094d769575,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bd9f4baf-d5f3-4f30-948e-4c147ed19ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-21b7ff54-71a2-42b0-a7c8-860885549848,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-e3a9a465-d16c-4eeb-a079-23c73439895b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-0fcdcfdb-7e5c-4b83-b17f-cc90b9c6e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-37570da4-3bcf-46df-b61a-ac55c703aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-8d616325-2cb1-48ca-a907-4ddc3ee7b52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861131791-172.17.0.19-1599306000959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-68e0cc6e-75e6-4f2b-bdc0-59eed0042b54,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-d88a96c9-1989-41cd-8ff3-d6094d769575,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bd9f4baf-d5f3-4f30-948e-4c147ed19ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-21b7ff54-71a2-42b0-a7c8-860885549848,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-e3a9a465-d16c-4eeb-a079-23c73439895b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-0fcdcfdb-7e5c-4b83-b17f-cc90b9c6e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-37570da4-3bcf-46df-b61a-ac55c703aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-8d616325-2cb1-48ca-a907-4ddc3ee7b52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591895558-172.17.0.19-1599306074930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-90111213-732d-483b-be60-8bfefee93b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d62eb091-c2ce-41fc-a0ea-49e5b8ce4295,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-af009594-12e5-4237-86f4-71d2c17915c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-0fd88937-a8ce-43da-9447-549c75d49759,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-48cc4170-a297-4ffa-a594-25bd7ec916e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-b6d160ed-c790-4e17-afc6-8161fa92a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-800e9147-4184-46af-97cb-bc0067e4815e,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-0247f6e1-4857-4bcb-a65b-deb7ada9e65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591895558-172.17.0.19-1599306074930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-90111213-732d-483b-be60-8bfefee93b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d62eb091-c2ce-41fc-a0ea-49e5b8ce4295,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-af009594-12e5-4237-86f4-71d2c17915c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-0fd88937-a8ce-43da-9447-549c75d49759,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-48cc4170-a297-4ffa-a594-25bd7ec916e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-b6d160ed-c790-4e17-afc6-8161fa92a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-800e9147-4184-46af-97cb-bc0067e4815e,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-0247f6e1-4857-4bcb-a65b-deb7ada9e65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975484905-172.17.0.19-1599306509445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-48102b48-09e6-4543-891b-fbfed35d093d,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-65799b33-c4e9-47eb-a94d-f467295097b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-77db39bc-9927-422a-8797-9ecc45ae0a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-44d9c7a1-d9d6-4c7f-880c-93a83b211b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-7fcc6aa9-055e-4342-b8ad-7c366d40947e,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-922a7b4d-0d35-4d37-b9b0-0cfbc3c0e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-1d943162-6681-4574-9655-6fb0e116cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-f7937f39-5eea-48b5-a568-1c69484fdddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975484905-172.17.0.19-1599306509445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-48102b48-09e6-4543-891b-fbfed35d093d,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-65799b33-c4e9-47eb-a94d-f467295097b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-77db39bc-9927-422a-8797-9ecc45ae0a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-44d9c7a1-d9d6-4c7f-880c-93a83b211b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-7fcc6aa9-055e-4342-b8ad-7c366d40947e,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-922a7b4d-0d35-4d37-b9b0-0cfbc3c0e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-1d943162-6681-4574-9655-6fb0e116cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-f7937f39-5eea-48b5-a568-1c69484fdddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184836413-172.17.0.19-1599306835907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-76c7bf3e-2af1-458a-9103-fbcc915508c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-90c5ccaf-305b-4ea5-a256-ed5a72452ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-618e0dda-644d-495b-808e-0d1906c34d96,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-ca067a9c-9c70-4265-8092-0969b5d44022,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c71bb1ac-74d1-4eb1-bd3c-ed12a67b697d,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-19e8636a-db69-4338-90e4-a48bf41cd2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a24ae9f5-ecc9-456b-a8c3-3d6466074e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-e16a6617-897f-4feb-91d9-981cf0d3e927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184836413-172.17.0.19-1599306835907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-76c7bf3e-2af1-458a-9103-fbcc915508c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-90c5ccaf-305b-4ea5-a256-ed5a72452ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-618e0dda-644d-495b-808e-0d1906c34d96,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-ca067a9c-9c70-4265-8092-0969b5d44022,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c71bb1ac-74d1-4eb1-bd3c-ed12a67b697d,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-19e8636a-db69-4338-90e4-a48bf41cd2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a24ae9f5-ecc9-456b-a8c3-3d6466074e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-e16a6617-897f-4feb-91d9-981cf0d3e927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788977353-172.17.0.19-1599306953297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-d698c475-0d30-4fab-ab4d-0fc75dde9287,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-c7492c72-a4b2-4e1c-94f7-a38bbaeba836,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-fd974bfc-6a42-4f04-ab36-3675cc6d94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-936f8979-4772-46c7-b5f8-150190b124e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-fcb0559f-623f-41be-8966-0e5124194696,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-7ad655ab-184b-426b-b324-6555d60ecb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-476347c5-30e0-4f2c-9921-f04b1795f904,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-2aec11db-2df3-445e-8652-594dde6cdba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788977353-172.17.0.19-1599306953297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-d698c475-0d30-4fab-ab4d-0fc75dde9287,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-c7492c72-a4b2-4e1c-94f7-a38bbaeba836,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-fd974bfc-6a42-4f04-ab36-3675cc6d94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-936f8979-4772-46c7-b5f8-150190b124e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-fcb0559f-623f-41be-8966-0e5124194696,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-7ad655ab-184b-426b-b324-6555d60ecb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-476347c5-30e0-4f2c-9921-f04b1795f904,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-2aec11db-2df3-445e-8652-594dde6cdba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964962270-172.17.0.19-1599307153156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-c9bf7ad0-970b-4e74-8598-9732f4a6d39f,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-9b00b8a5-4e88-4c00-87c7-4ccb6944201f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-62fd02c6-05e8-42aa-96ae-6d9479bc9c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-fc1aa02b-bb7c-49fa-9068-034126c3a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-b1af4f57-5688-432c-8774-afb948bf35db,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-b50c0662-65b6-411c-aee6-de25c1b7f462,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-78dd614c-8dec-4900-bc22-9cdee0f2e519,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-8e22b8a2-89de-4e66-8924-47ff5218e5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964962270-172.17.0.19-1599307153156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37773,DS-c9bf7ad0-970b-4e74-8598-9732f4a6d39f,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-9b00b8a5-4e88-4c00-87c7-4ccb6944201f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-62fd02c6-05e8-42aa-96ae-6d9479bc9c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-fc1aa02b-bb7c-49fa-9068-034126c3a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-b1af4f57-5688-432c-8774-afb948bf35db,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-b50c0662-65b6-411c-aee6-de25c1b7f462,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-78dd614c-8dec-4900-bc22-9cdee0f2e519,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-8e22b8a2-89de-4e66-8924-47ff5218e5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205862334-172.17.0.19-1599307255894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-15195408-18d9-4d64-bfc3-bf14a5c677d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-e7d5fe7e-5e5c-4995-9f62-624cd3fe672f,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-69a1d243-a1da-49dd-bc40-6d9822efe661,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-ac95ec29-daf4-4d4c-8de6-47abe795fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-80d92398-beb4-4dd3-8532-585b2311e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-2a61a46a-7e9a-4343-950b-0f6343a0ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-3c3373ff-18b0-4f73-8ff8-9be9cdfdf4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3239fc93-5c4b-4af7-9c5b-ebdb050a2452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205862334-172.17.0.19-1599307255894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-15195408-18d9-4d64-bfc3-bf14a5c677d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-e7d5fe7e-5e5c-4995-9f62-624cd3fe672f,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-69a1d243-a1da-49dd-bc40-6d9822efe661,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-ac95ec29-daf4-4d4c-8de6-47abe795fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-80d92398-beb4-4dd3-8532-585b2311e60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-2a61a46a-7e9a-4343-950b-0f6343a0ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-3c3373ff-18b0-4f73-8ff8-9be9cdfdf4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3239fc93-5c4b-4af7-9c5b-ebdb050a2452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741810891-172.17.0.19-1599307290613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40736,DS-d184f3a0-9042-4ddb-ae43-4399c4dfe7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-68cbaaa2-24f1-4b34-9693-9cb90e5ead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e7f0d2f9-6ab0-466f-bffe-65453dadfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-7efae46d-d638-4381-a9ae-0d98acb851fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8b5fc7e8-105d-4db9-b64c-ae2b06cf2227,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-9ad88f7c-4162-408d-a635-12c32e018ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-5b1d88f2-52d8-4a86-bc01-d6fa84476de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e3b6aa7a-499a-4394-9b6d-756dce3d3c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741810891-172.17.0.19-1599307290613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40736,DS-d184f3a0-9042-4ddb-ae43-4399c4dfe7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-68cbaaa2-24f1-4b34-9693-9cb90e5ead3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e7f0d2f9-6ab0-466f-bffe-65453dadfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-7efae46d-d638-4381-a9ae-0d98acb851fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8b5fc7e8-105d-4db9-b64c-ae2b06cf2227,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-9ad88f7c-4162-408d-a635-12c32e018ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-5b1d88f2-52d8-4a86-bc01-d6fa84476de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e3b6aa7a-499a-4394-9b6d-756dce3d3c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232178660-172.17.0.19-1599307601454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32877,DS-1bb11bc7-258b-4a03-acf6-1015821e4767,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-51b67f54-b30c-485a-baf7-373433f2f827,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-47ee50d2-ef43-4a53-a515-87c92176aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-5388be5c-00f7-405f-995e-82304d558ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-e9ad5121-b362-4da2-834a-8bc8e5ef8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-768af22b-197a-4983-88d0-460f74d202f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-15c666e8-4297-4317-b3ff-e9d7dcf6c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-355d04dc-959e-4e55-bc9e-1caaa69bbd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232178660-172.17.0.19-1599307601454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32877,DS-1bb11bc7-258b-4a03-acf6-1015821e4767,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-51b67f54-b30c-485a-baf7-373433f2f827,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-47ee50d2-ef43-4a53-a515-87c92176aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-5388be5c-00f7-405f-995e-82304d558ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-e9ad5121-b362-4da2-834a-8bc8e5ef8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-768af22b-197a-4983-88d0-460f74d202f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-15c666e8-4297-4317-b3ff-e9d7dcf6c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-355d04dc-959e-4e55-bc9e-1caaa69bbd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56337263-172.17.0.19-1599308015524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-6edbfbbd-786e-4c69-bedc-de3e8a9a6bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-5e88459e-4c1e-41d6-84ca-2466bde5bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-9b5d0d78-d396-4418-b7fb-e49ff328a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-eca68662-6a2e-4fc1-b4fe-27b3f17d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-32cae357-288e-45d1-a490-344d1facbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-ce83e92d-9c40-4daf-8f9e-450faffe5404,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-8b2a18a7-c044-4cee-b0e7-22e5f3c94b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-b45d1b2b-c64e-414c-aee7-8edc00331e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56337263-172.17.0.19-1599308015524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-6edbfbbd-786e-4c69-bedc-de3e8a9a6bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-5e88459e-4c1e-41d6-84ca-2466bde5bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-9b5d0d78-d396-4418-b7fb-e49ff328a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-eca68662-6a2e-4fc1-b4fe-27b3f17d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-32cae357-288e-45d1-a490-344d1facbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-ce83e92d-9c40-4daf-8f9e-450faffe5404,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-8b2a18a7-c044-4cee-b0e7-22e5f3c94b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-b45d1b2b-c64e-414c-aee7-8edc00331e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569887382-172.17.0.19-1599308198628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-36277e54-b726-4024-b197-b9802e3348e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-4386d95c-7bfe-42bb-b3f2-29749a5dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6b8bc217-b44d-4649-b8fb-260b4c38d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-1b1e5cc0-25ae-4640-8c76-c6de7dbbdeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-7af874f4-98c6-4752-b4fd-33826b0cddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-787ac381-2e38-44d8-8359-c3ceb17ac0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-ff5ad54e-b254-4d23-be91-865f922276e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-02e6894b-7fc2-4033-918a-7b34fc1762e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569887382-172.17.0.19-1599308198628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-36277e54-b726-4024-b197-b9802e3348e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-4386d95c-7bfe-42bb-b3f2-29749a5dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6b8bc217-b44d-4649-b8fb-260b4c38d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-1b1e5cc0-25ae-4640-8c76-c6de7dbbdeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-7af874f4-98c6-4752-b4fd-33826b0cddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-787ac381-2e38-44d8-8359-c3ceb17ac0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-ff5ad54e-b254-4d23-be91-865f922276e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-02e6894b-7fc2-4033-918a-7b34fc1762e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771383389-172.17.0.19-1599308474058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-b4c0f762-958c-4096-994e-afaa4f0900db,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-4dc3d513-9b86-4b7f-9dba-b5696ae8e063,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-ac1924da-3f1c-48f4-ad4f-bfbe92195125,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-5121280c-2622-492c-82a5-56b57bd8ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1fdf85ee-debd-4a4f-8617-cc0a951b970d,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-eff0d665-56b0-4d77-b1cf-abfc1182b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f635e37a-5e61-48ab-b769-6fe19a0eb200,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-b1804411-cf59-40a7-8b38-44f6202e1431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771383389-172.17.0.19-1599308474058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-b4c0f762-958c-4096-994e-afaa4f0900db,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-4dc3d513-9b86-4b7f-9dba-b5696ae8e063,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-ac1924da-3f1c-48f4-ad4f-bfbe92195125,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-5121280c-2622-492c-82a5-56b57bd8ddac,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-1fdf85ee-debd-4a4f-8617-cc0a951b970d,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-eff0d665-56b0-4d77-b1cf-abfc1182b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f635e37a-5e61-48ab-b769-6fe19a0eb200,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-b1804411-cf59-40a7-8b38-44f6202e1431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557172856-172.17.0.19-1599308914123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-db9f3a75-4b70-4454-9182-9d30cb547971,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-63f323c0-a4b9-4fb7-8125-6ae78468eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-bc607c8d-7631-4217-8abc-482c5834ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-b05173c4-9bc9-495d-a7e9-eb91b0daeb86,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-9d615a61-0672-4211-853c-7ad16101c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-81959ee7-72ed-4021-9dc7-80d8204e6f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-2e6a2a55-53d5-4afd-96d1-bc3c87856111,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-20daeb4d-de7e-4696-b7c2-0f193ffddec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557172856-172.17.0.19-1599308914123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-db9f3a75-4b70-4454-9182-9d30cb547971,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-63f323c0-a4b9-4fb7-8125-6ae78468eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-bc607c8d-7631-4217-8abc-482c5834ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-b05173c4-9bc9-495d-a7e9-eb91b0daeb86,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-9d615a61-0672-4211-853c-7ad16101c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-81959ee7-72ed-4021-9dc7-80d8204e6f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-2e6a2a55-53d5-4afd-96d1-bc3c87856111,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-20daeb4d-de7e-4696-b7c2-0f193ffddec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5259
