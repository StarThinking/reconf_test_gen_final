reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713268733-172.17.0.14-1599329885129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-976e5040-cd3f-4857-a496-33fc90a1e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-1dfcc56b-7713-4e41-9aba-f76afd23b603,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-923bcf33-80fb-4fdf-a1f1-4fa2cad320fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-691344ed-a563-4b13-b288-20ba38611c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-4d406e3b-11d7-4708-99cf-23d066168115,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-3460c4c2-a9ed-4931-a0c5-df3eec0f7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-0a597c40-4487-46d0-bc41-d64fe37ac846,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-f415d141-7e8c-4b78-8f0a-a72d22b3ec30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713268733-172.17.0.14-1599329885129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44379,DS-976e5040-cd3f-4857-a496-33fc90a1e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-1dfcc56b-7713-4e41-9aba-f76afd23b603,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-923bcf33-80fb-4fdf-a1f1-4fa2cad320fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-691344ed-a563-4b13-b288-20ba38611c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-4d406e3b-11d7-4708-99cf-23d066168115,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-3460c4c2-a9ed-4931-a0c5-df3eec0f7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-0a597c40-4487-46d0-bc41-d64fe37ac846,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-f415d141-7e8c-4b78-8f0a-a72d22b3ec30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152649654-172.17.0.14-1599330331606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-c37e20e7-391e-43d3-be71-d3b3ef99bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-6d9a4612-c96a-4e9d-b167-5c00e90092d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-4e7dc8ba-5541-4c14-b7da-ae974d271371,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-32f65df9-ab81-4159-ad14-a89e02ade41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-18355f19-363d-414c-92b9-c26261de5dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-e5590771-e022-42f9-b040-c5085206df13,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-bd6128f8-f0e0-4063-b5c0-e28deee8d1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-48aa0e57-1942-4a69-98a7-512ddbf11fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152649654-172.17.0.14-1599330331606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-c37e20e7-391e-43d3-be71-d3b3ef99bcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-6d9a4612-c96a-4e9d-b167-5c00e90092d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-4e7dc8ba-5541-4c14-b7da-ae974d271371,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-32f65df9-ab81-4159-ad14-a89e02ade41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-18355f19-363d-414c-92b9-c26261de5dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-e5590771-e022-42f9-b040-c5085206df13,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-bd6128f8-f0e0-4063-b5c0-e28deee8d1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-48aa0e57-1942-4a69-98a7-512ddbf11fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822415615-172.17.0.14-1599330751567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-8681284c-748d-4e60-b15e-ba7bc8580306,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-7b815731-5b6e-466d-8d58-e3b5216d7252,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-09bb1fbd-8a8a-4909-a7d3-6b36a71c5d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-56a86bbd-a0b7-44ad-a9da-88050ab99da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-287704b6-c5c3-4808-a4ba-aaf00c756e43,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-974f7541-fd56-46c8-927d-946d648c520a,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-d9a885fb-bf4a-4f16-ae05-d76d9cb2806c,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-e30903ac-2e3f-44c2-ac6c-6dfaa5e58095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822415615-172.17.0.14-1599330751567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-8681284c-748d-4e60-b15e-ba7bc8580306,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-7b815731-5b6e-466d-8d58-e3b5216d7252,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-09bb1fbd-8a8a-4909-a7d3-6b36a71c5d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-56a86bbd-a0b7-44ad-a9da-88050ab99da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-287704b6-c5c3-4808-a4ba-aaf00c756e43,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-974f7541-fd56-46c8-927d-946d648c520a,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-d9a885fb-bf4a-4f16-ae05-d76d9cb2806c,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-e30903ac-2e3f-44c2-ac6c-6dfaa5e58095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465740827-172.17.0.14-1599331196232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-77a197c3-c92a-4a7f-b12d-14ba7df943fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-087d6158-e727-4478-bbf7-5e8d55911586,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-6ab298a1-a29d-4534-809e-736119a2056c,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e8adbc1f-0e1d-42d8-8390-5cbff30a74ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-f3c8bbce-4973-4d7b-9922-fb084e3e091e,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-7c93dd61-1764-4237-ab78-2f0bffb47510,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-e6a4fc45-110a-46fa-8a59-fa540777680e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-32b89d2f-1b47-44ac-80c0-8c59fc516840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465740827-172.17.0.14-1599331196232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-77a197c3-c92a-4a7f-b12d-14ba7df943fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-087d6158-e727-4478-bbf7-5e8d55911586,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-6ab298a1-a29d-4534-809e-736119a2056c,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-e8adbc1f-0e1d-42d8-8390-5cbff30a74ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-f3c8bbce-4973-4d7b-9922-fb084e3e091e,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-7c93dd61-1764-4237-ab78-2f0bffb47510,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-e6a4fc45-110a-46fa-8a59-fa540777680e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-32b89d2f-1b47-44ac-80c0-8c59fc516840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524565593-172.17.0.14-1599331254092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-27dd0521-e574-4c1e-8d8c-bb647eb61136,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-2c1fe5f5-b993-4458-9c75-0653a9c28012,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-5c0218dc-8ef1-4d30-93fa-1edbfaedf028,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a6751d4e-e259-44ba-b5be-55db5b0f186a,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-c83a1616-b0c5-4c0e-83ae-e1c00e963318,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-62df86ed-a9a7-44b0-a87b-d68779bbac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-f5c19d9a-1cba-43b7-8b10-51aeb390617e,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-7a601bef-112d-4561-8fa5-d6a5c4ddb178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524565593-172.17.0.14-1599331254092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-27dd0521-e574-4c1e-8d8c-bb647eb61136,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-2c1fe5f5-b993-4458-9c75-0653a9c28012,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-5c0218dc-8ef1-4d30-93fa-1edbfaedf028,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a6751d4e-e259-44ba-b5be-55db5b0f186a,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-c83a1616-b0c5-4c0e-83ae-e1c00e963318,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-62df86ed-a9a7-44b0-a87b-d68779bbac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-f5c19d9a-1cba-43b7-8b10-51aeb390617e,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-7a601bef-112d-4561-8fa5-d6a5c4ddb178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567795911-172.17.0.14-1599331395985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-c0220e74-f3d9-42a1-99de-1f040f1ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-893e5a6b-95c8-4242-8e30-6e3d7da973f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-a9934c93-53f4-4567-b489-4c168d95f321,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-e451ac32-e2c9-45c0-b34a-adb7935d3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-6e332f3b-16f8-4488-bd10-a43c72923acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2c041db6-f847-44f0-a1b1-8643cac1ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-462a8006-6f6a-454b-9fac-038e97c9dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-51bccde8-f574-49cb-a59f-3a53c6549b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567795911-172.17.0.14-1599331395985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-c0220e74-f3d9-42a1-99de-1f040f1ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-893e5a6b-95c8-4242-8e30-6e3d7da973f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-a9934c93-53f4-4567-b489-4c168d95f321,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-e451ac32-e2c9-45c0-b34a-adb7935d3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-6e332f3b-16f8-4488-bd10-a43c72923acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2c041db6-f847-44f0-a1b1-8643cac1ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-462a8006-6f6a-454b-9fac-038e97c9dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-51bccde8-f574-49cb-a59f-3a53c6549b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661858905-172.17.0.14-1599332020342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-a3f682c6-0767-4372-a68a-a02c8eb7ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8b9d15bd-6ed5-4d2c-bc95-0530de57770d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-a58b0c17-d172-4f8b-8a33-19aefc88356c,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-a41ed84f-a39b-4baf-adf4-9cdba5e9e997,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-7ef97774-dc08-4931-a94f-7342622b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-e685f4a6-1490-4624-89be-e8dfd2d9cd75,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-4ee70a41-366d-4459-b05a-3b4dfb3fbd53,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-09064533-be98-4c20-bd62-f9391a4cb070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661858905-172.17.0.14-1599332020342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-a3f682c6-0767-4372-a68a-a02c8eb7ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8b9d15bd-6ed5-4d2c-bc95-0530de57770d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-a58b0c17-d172-4f8b-8a33-19aefc88356c,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-a41ed84f-a39b-4baf-adf4-9cdba5e9e997,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-7ef97774-dc08-4931-a94f-7342622b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-e685f4a6-1490-4624-89be-e8dfd2d9cd75,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-4ee70a41-366d-4459-b05a-3b4dfb3fbd53,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-09064533-be98-4c20-bd62-f9391a4cb070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: File /striped/stripedFileChecksum1 could only be written to 4 of the 6 required nodes for RS-6-3-1024k. There are 4 datanode(s) running and 4 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /striped/stripedFileChecksum1 could only be written to 4 of the 6 required nodes for RS-6-3-1024k. There are 4 datanode(s) running and 4 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock(DFSStripedOutputStream.java:480)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:526)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132151007-172.17.0.14-1599332372444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-9ab8d0c3-4bfc-461d-9f38-f4be5450c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-6dd50917-39ed-4a58-abb8-458671930dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-996edbf6-e8ac-4347-8c8f-09e74f6e5983,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-bf0b4847-4686-4bc0-bdd7-379d50042554,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-dd07d4f6-ac49-482b-88bb-3c9f86cd93d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-c1349796-a411-4793-8b5a-251256ac7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-b82499f2-3be5-4a3c-8ae6-f1caa652d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5109322c-6064-49d7-897e-410f92c39865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132151007-172.17.0.14-1599332372444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-9ab8d0c3-4bfc-461d-9f38-f4be5450c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-6dd50917-39ed-4a58-abb8-458671930dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-996edbf6-e8ac-4347-8c8f-09e74f6e5983,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-bf0b4847-4686-4bc0-bdd7-379d50042554,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-dd07d4f6-ac49-482b-88bb-3c9f86cd93d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-c1349796-a411-4793-8b5a-251256ac7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-b82499f2-3be5-4a3c-8ae6-f1caa652d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5109322c-6064-49d7-897e-410f92c39865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139525071-172.17.0.14-1599332647069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-68cd0a34-990d-4a1f-b6e9-cf3980e0d855,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-2f752761-082e-4bc9-ad5b-7de7179850ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-97aa6fb8-4e5d-4f75-9bd6-b6708dc1c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-0c142725-977b-4061-bc51-c9038032c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-0d58ae38-313b-4e4a-997c-d6c24d475f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c0f0c5a0-83a0-4e0b-9700-1c45d69a59c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-5f644aba-04ab-43f1-b04f-51cc8278fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-8371d70f-0cfe-4632-a08c-3742a671a85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139525071-172.17.0.14-1599332647069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-68cd0a34-990d-4a1f-b6e9-cf3980e0d855,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-2f752761-082e-4bc9-ad5b-7de7179850ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-97aa6fb8-4e5d-4f75-9bd6-b6708dc1c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-0c142725-977b-4061-bc51-c9038032c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-0d58ae38-313b-4e4a-997c-d6c24d475f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c0f0c5a0-83a0-4e0b-9700-1c45d69a59c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-5f644aba-04ab-43f1-b04f-51cc8278fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-8371d70f-0cfe-4632-a08c-3742a671a85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668196448-172.17.0.14-1599333322096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42906,DS-dafe781b-2a9b-42cf-aea3-5102e1700939,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-a5b9b42f-4cd1-4744-a09c-393223288cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-ead2a0c5-10f2-4ffe-9e61-64a4591b4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-a8eec4ca-3153-45a8-904b-140279ca85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-d78b0971-51a8-4e24-a423-6955650c7ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4ee64aef-a926-49e9-95e4-cadc552423e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-0c804777-6ab6-4fe0-be62-5a11e9d7c601,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-d11642c9-0e72-48e6-b92f-03bb9cfebdfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668196448-172.17.0.14-1599333322096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42906,DS-dafe781b-2a9b-42cf-aea3-5102e1700939,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-a5b9b42f-4cd1-4744-a09c-393223288cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-ead2a0c5-10f2-4ffe-9e61-64a4591b4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-a8eec4ca-3153-45a8-904b-140279ca85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-d78b0971-51a8-4e24-a423-6955650c7ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4ee64aef-a926-49e9-95e4-cadc552423e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-0c804777-6ab6-4fe0-be62-5a11e9d7c601,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-d11642c9-0e72-48e6-b92f-03bb9cfebdfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230187343-172.17.0.14-1599334087117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-d3ca3828-6da6-4bd7-8f66-dfd0b9d72bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fd0bc229-5c68-4fb1-b57b-b9cc491ed59d,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-a775fd06-3a94-47e7-9493-6e2eab360afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-f900115f-9e74-4d0d-bee2-53a277283f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-ecdf9d26-c02e-48dd-a152-19a999aa0657,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e18728f5-651e-426e-9c91-834b443e374f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-95cecba2-8546-439f-ba57-4c6bf0b5c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-d3d4eebd-31cc-439f-adeb-f06cab57bde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230187343-172.17.0.14-1599334087117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-d3ca3828-6da6-4bd7-8f66-dfd0b9d72bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fd0bc229-5c68-4fb1-b57b-b9cc491ed59d,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-a775fd06-3a94-47e7-9493-6e2eab360afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-f900115f-9e74-4d0d-bee2-53a277283f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-ecdf9d26-c02e-48dd-a152-19a999aa0657,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e18728f5-651e-426e-9c91-834b443e374f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-95cecba2-8546-439f-ba57-4c6bf0b5c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-d3d4eebd-31cc-439f-adeb-f06cab57bde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058313005-172.17.0.14-1599334785788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-165892a8-679f-43da-88fb-fdb678373ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-3b8c11d0-3cdd-4b06-9661-115f62e827d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-bc4e6c4e-62eb-4ec5-9655-57fd2d58ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-a99db0d0-06b2-466f-892e-034a2b5f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-aedec46c-9c9e-4296-85d1-e3752ed939dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-96a0fe6a-7a24-4d43-b795-40e7e2969a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-07139937-e5a5-4a00-89aa-e54c26fb6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-84ec9142-1e02-4fbe-add7-b06162a1a3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058313005-172.17.0.14-1599334785788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-165892a8-679f-43da-88fb-fdb678373ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-3b8c11d0-3cdd-4b06-9661-115f62e827d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-bc4e6c4e-62eb-4ec5-9655-57fd2d58ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-a99db0d0-06b2-466f-892e-034a2b5f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-aedec46c-9c9e-4296-85d1-e3752ed939dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-96a0fe6a-7a24-4d43-b795-40e7e2969a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-07139937-e5a5-4a00-89aa-e54c26fb6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-84ec9142-1e02-4fbe-add7-b06162a1a3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105604887-172.17.0.14-1599334966147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46190,DS-5dd6c17d-043d-496a-870f-0a9555c93a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-aec68eed-c86c-4268-923b-4a62c609f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-f68d63bc-e9e7-4305-8bc3-4ed4164edcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-b859ce3c-1b04-4d0e-a402-24f0eaef8a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-064f9825-efe1-445a-b35a-0fed51ad1ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-85de9540-3c36-4fd0-b3e4-ce13af59f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-29d3d859-e009-4c26-b1c2-7356de3100cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-ed18850b-a6dc-4b68-bc4b-fabdbc3a393e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105604887-172.17.0.14-1599334966147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46190,DS-5dd6c17d-043d-496a-870f-0a9555c93a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-aec68eed-c86c-4268-923b-4a62c609f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-f68d63bc-e9e7-4305-8bc3-4ed4164edcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-b859ce3c-1b04-4d0e-a402-24f0eaef8a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-064f9825-efe1-445a-b35a-0fed51ad1ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-85de9540-3c36-4fd0-b3e4-ce13af59f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-29d3d859-e009-4c26-b1c2-7356de3100cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-ed18850b-a6dc-4b68-bc4b-fabdbc3a393e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433723166-172.17.0.14-1599335035871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-2941ddb6-2921-4466-8035-be21eb06b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-87ea90d4-238d-4a55-a494-20de3bbf3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-adf3f0cb-f233-4a96-94eb-63fbab0c0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-75646cd9-97e7-40ff-8001-0de39715e0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-8de9eed3-ef54-41a5-b5fe-712845a00e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-e304a7bf-764d-4a5c-ae27-c47fe93cfff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-22d39141-6798-4f77-8c9e-6a9ed5f1a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-8d6b79e0-a0ce-463c-9e5a-12b2efff20b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433723166-172.17.0.14-1599335035871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-2941ddb6-2921-4466-8035-be21eb06b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-87ea90d4-238d-4a55-a494-20de3bbf3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-adf3f0cb-f233-4a96-94eb-63fbab0c0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-75646cd9-97e7-40ff-8001-0de39715e0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-8de9eed3-ef54-41a5-b5fe-712845a00e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-e304a7bf-764d-4a5c-ae27-c47fe93cfff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-22d39141-6798-4f77-8c9e-6a9ed5f1a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-8d6b79e0-a0ce-463c-9e5a-12b2efff20b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368374846-172.17.0.14-1599335442427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46740,DS-70a79943-e309-4600-9d75-84e858deae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-18427fbd-48ba-4b45-9f28-a09fb8f1e171,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-78e1db9d-86ce-41c0-b246-d104e4ec5c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-768ff9ae-4c3b-4ac0-876a-68cf3ab94bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-d53d9708-0777-4422-a52f-800354be6c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d3ac5aa8-2bc8-4865-918c-fb94cc03a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-ea972239-fa92-447a-88ce-8ac0a02d76ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-2e8d0380-2be4-4a02-9dc6-c1bb122fed71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368374846-172.17.0.14-1599335442427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46740,DS-70a79943-e309-4600-9d75-84e858deae55,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-18427fbd-48ba-4b45-9f28-a09fb8f1e171,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-78e1db9d-86ce-41c0-b246-d104e4ec5c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-768ff9ae-4c3b-4ac0-876a-68cf3ab94bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-d53d9708-0777-4422-a52f-800354be6c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d3ac5aa8-2bc8-4865-918c-fb94cc03a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-ea972239-fa92-447a-88ce-8ac0a02d76ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-2e8d0380-2be4-4a02-9dc6-c1bb122fed71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670239061-172.17.0.14-1599335807279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-dca17b1e-d74b-46ed-ac52-5abad0dc84f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-81f3fc8a-30d0-4279-8c17-e780a5079245,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-06bf5b20-f173-4f87-817c-e264b837963e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-87a8f778-7960-491e-9fa0-7fdb610151ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-f6e565e2-7449-4c30-bfb6-c217fe68d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f246e55d-fa07-48ce-8042-14352b9aea64,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-1ac66f8f-cb24-4166-a212-eee2fb76df80,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-3af0c6d8-8759-485a-83de-4a77bf7987f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670239061-172.17.0.14-1599335807279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-dca17b1e-d74b-46ed-ac52-5abad0dc84f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-81f3fc8a-30d0-4279-8c17-e780a5079245,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-06bf5b20-f173-4f87-817c-e264b837963e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-87a8f778-7960-491e-9fa0-7fdb610151ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-f6e565e2-7449-4c30-bfb6-c217fe68d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-f246e55d-fa07-48ce-8042-14352b9aea64,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-1ac66f8f-cb24-4166-a212-eee2fb76df80,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-3af0c6d8-8759-485a-83de-4a77bf7987f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980943986-172.17.0.14-1599335888729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-103af615-508c-47ee-bed8-f23e20344fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-bf4c714f-049e-4991-81ff-dfe72cc24cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-df97e817-3880-4ef5-aaca-92b55fa44c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-f6043bc5-0b03-4101-9fb3-0769f8f56523,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-78516338-5603-41e1-8291-262d2eeca924,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-865811d4-cf26-4339-8142-2ceb8c833a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-f9037ea7-948d-4100-ab5d-f408d5b04ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-524b6dd5-75bc-446e-b8e6-dab804fec3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980943986-172.17.0.14-1599335888729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-103af615-508c-47ee-bed8-f23e20344fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-bf4c714f-049e-4991-81ff-dfe72cc24cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-df97e817-3880-4ef5-aaca-92b55fa44c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-f6043bc5-0b03-4101-9fb3-0769f8f56523,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-78516338-5603-41e1-8291-262d2eeca924,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-865811d4-cf26-4339-8142-2ceb8c833a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-f9037ea7-948d-4100-ab5d-f408d5b04ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-524b6dd5-75bc-446e-b8e6-dab804fec3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71160103-172.17.0.14-1599337604417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-d4dc4687-407a-439e-bca2-10924f19b599,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-8f0d9411-174b-4b08-a94f-c3f30dacb969,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-96359215-6db8-49e3-a2db-513aa256e279,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-06627f82-09a8-47a8-859b-42c45a0a2f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-e487365b-3d94-48e4-94ac-3e8ad1fcbf09,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-d1d438c5-238d-4f18-8926-73a1977c1963,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-ec7cd6c0-c808-4d2d-a30b-9799ee156a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-c17a4060-3d86-4f85-bf29-8ee6c2dfee73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71160103-172.17.0.14-1599337604417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-d4dc4687-407a-439e-bca2-10924f19b599,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-8f0d9411-174b-4b08-a94f-c3f30dacb969,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-96359215-6db8-49e3-a2db-513aa256e279,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-06627f82-09a8-47a8-859b-42c45a0a2f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-e487365b-3d94-48e4-94ac-3e8ad1fcbf09,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-d1d438c5-238d-4f18-8926-73a1977c1963,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-ec7cd6c0-c808-4d2d-a30b-9799ee156a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-c17a4060-3d86-4f85-bf29-8ee6c2dfee73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 8016
