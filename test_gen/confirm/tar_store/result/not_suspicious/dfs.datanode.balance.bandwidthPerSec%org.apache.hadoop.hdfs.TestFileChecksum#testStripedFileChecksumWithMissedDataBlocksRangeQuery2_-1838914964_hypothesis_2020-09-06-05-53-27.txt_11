reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415941836-172.17.0.2-1599371820419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-c3449373-8e03-4fa1-b369-8b3e1f6e3766,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-bd6bc223-f766-41bb-9965-6e1b3504e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-4d386aae-e792-404e-b9df-a5e633e8296f,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-85230ff1-d78e-4583-ae4e-c461778a7846,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-cece25e2-8c3b-4108-a907-79d9c1ccf9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-92f2cbca-3683-4722-a1ef-6e61db8f6302,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9092f1af-c4a8-41c1-a6d4-947530d62bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-b36b8777-2668-4984-9801-c5eda9b87464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415941836-172.17.0.2-1599371820419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-c3449373-8e03-4fa1-b369-8b3e1f6e3766,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-bd6bc223-f766-41bb-9965-6e1b3504e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-4d386aae-e792-404e-b9df-a5e633e8296f,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-85230ff1-d78e-4583-ae4e-c461778a7846,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-cece25e2-8c3b-4108-a907-79d9c1ccf9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-92f2cbca-3683-4722-a1ef-6e61db8f6302,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9092f1af-c4a8-41c1-a6d4-947530d62bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-b36b8777-2668-4984-9801-c5eda9b87464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968614915-172.17.0.2-1599372829052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-8ce20773-c552-4d63-8b79-4d5ea76958af,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-a1111bec-569c-4d93-91c6-7d4a85478cde,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-5f60ea00-e596-4b04-801a-98d828b35220,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-a93fd208-2246-4cfc-a669-a849acb552b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-d2c6f547-278d-4469-a7f2-e85adabc621b,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-c2d9a618-580d-4475-b469-0a72d2e85fde,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-1d9e85f0-2f93-4f76-acee-375be52950db,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-5fa8a572-da65-4549-aa74-f45413d4e763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968614915-172.17.0.2-1599372829052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-8ce20773-c552-4d63-8b79-4d5ea76958af,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-a1111bec-569c-4d93-91c6-7d4a85478cde,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-5f60ea00-e596-4b04-801a-98d828b35220,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-a93fd208-2246-4cfc-a669-a849acb552b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-d2c6f547-278d-4469-a7f2-e85adabc621b,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-c2d9a618-580d-4475-b469-0a72d2e85fde,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-1d9e85f0-2f93-4f76-acee-375be52950db,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-5fa8a572-da65-4549-aa74-f45413d4e763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902143154-172.17.0.2-1599373139969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-0325e7db-9d98-4590-8f98-97f3110dd6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-09c7fad7-a2c2-45f8-9937-5c0b3ce01c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-d127db29-b84b-4ccc-a982-2b30b1ab95df,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-049c84ac-4df1-459b-9f67-892ab7ea6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-661388d6-0f66-4cb0-be49-4dd7c5059796,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-b39805c5-a68d-41c0-afec-4c58e850d829,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-19bc9389-3b28-494f-ac58-035e9a337a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-6c06b2e4-a42f-4e2c-b26d-eb5d19a981bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902143154-172.17.0.2-1599373139969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-0325e7db-9d98-4590-8f98-97f3110dd6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-09c7fad7-a2c2-45f8-9937-5c0b3ce01c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-d127db29-b84b-4ccc-a982-2b30b1ab95df,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-049c84ac-4df1-459b-9f67-892ab7ea6daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-661388d6-0f66-4cb0-be49-4dd7c5059796,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-b39805c5-a68d-41c0-afec-4c58e850d829,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-19bc9389-3b28-494f-ac58-035e9a337a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-6c06b2e4-a42f-4e2c-b26d-eb5d19a981bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755919243-172.17.0.2-1599373175944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-fa24f7b5-a4a4-4d4e-82fd-48804771f033,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-7d5d2d79-ab91-4380-993b-ca3fe17e5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-e0f0c4e0-bb33-4fa1-bbf9-767011dda22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-0111bbc0-0556-4821-96cf-2e4618a640b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e964fbca-d719-4aec-bdde-13dcd35874d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-d2474b5d-2c71-42ee-bb2b-27e36b74b9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-1ac603ee-63e3-4c29-b14b-1d43767ce06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-21699f26-cad6-4c36-b28c-3b221b0739a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755919243-172.17.0.2-1599373175944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-fa24f7b5-a4a4-4d4e-82fd-48804771f033,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-7d5d2d79-ab91-4380-993b-ca3fe17e5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-e0f0c4e0-bb33-4fa1-bbf9-767011dda22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-0111bbc0-0556-4821-96cf-2e4618a640b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-e964fbca-d719-4aec-bdde-13dcd35874d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-d2474b5d-2c71-42ee-bb2b-27e36b74b9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-1ac603ee-63e3-4c29-b14b-1d43767ce06d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-21699f26-cad6-4c36-b28c-3b221b0739a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322719070-172.17.0.2-1599373998695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-a2c6cfc4-a200-4634-b3ef-2a0774938b35,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-c24ada8d-c1d4-409a-9198-acc6cd9cbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-49fed3ff-c99f-43a3-8600-b277c1de5682,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-3472d1a3-39d5-42bc-b05f-e0a658fecb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-9ac68c84-85dc-45bc-984d-00d5c15e7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3cbf3b15-60f2-4812-bcd0-56d860ef9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-618959b0-26ea-4169-b599-b846c9ed68cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7a13de7b-d9ff-4ca5-a82b-ac3385bc75fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322719070-172.17.0.2-1599373998695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-a2c6cfc4-a200-4634-b3ef-2a0774938b35,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-c24ada8d-c1d4-409a-9198-acc6cd9cbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-49fed3ff-c99f-43a3-8600-b277c1de5682,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-3472d1a3-39d5-42bc-b05f-e0a658fecb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-9ac68c84-85dc-45bc-984d-00d5c15e7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3cbf3b15-60f2-4812-bcd0-56d860ef9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-618959b0-26ea-4169-b599-b846c9ed68cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7a13de7b-d9ff-4ca5-a82b-ac3385bc75fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515067638-172.17.0.2-1599374304563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-19397add-a3f3-4dee-ac9a-27955d3f71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-4a045631-e749-4c50-87d4-dc9a9881be21,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6a52b986-f270-4e07-b9be-a4ff0db1ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-5ff0fec6-1951-484d-aabc-d1aeb439e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-a34c546c-68a2-4ed2-9b9c-1ac049cce560,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-4213c975-fc3c-43b8-9394-9032c1a15d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-da8b52db-12fd-4e13-aba8-b87d44c7894b,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-e2b9c5b2-80df-4029-9aad-827f9aee1ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515067638-172.17.0.2-1599374304563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-19397add-a3f3-4dee-ac9a-27955d3f71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-4a045631-e749-4c50-87d4-dc9a9881be21,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-6a52b986-f270-4e07-b9be-a4ff0db1ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-5ff0fec6-1951-484d-aabc-d1aeb439e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-a34c546c-68a2-4ed2-9b9c-1ac049cce560,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-4213c975-fc3c-43b8-9394-9032c1a15d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-da8b52db-12fd-4e13-aba8-b87d44c7894b,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-e2b9c5b2-80df-4029-9aad-827f9aee1ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155261543-172.17.0.2-1599374473951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-727b7aad-bbf1-4342-b8ce-456fa8db2254,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-86c1220a-ae48-41df-ae20-6df4a5fe8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-ae8eb69a-42d6-4c4d-9ccb-ee7409f15698,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-284cf457-98a3-4798-b9f3-1009c91873b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-5af99479-1eff-4495-b6fe-3325f394e5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-fed80a73-e358-4c03-a891-e50e05b83831,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ba1820e7-b6c5-4016-bd57-0d81d97f6607,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-84a2d6ab-e05e-42bf-9eb5-c3c6712cb870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155261543-172.17.0.2-1599374473951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-727b7aad-bbf1-4342-b8ce-456fa8db2254,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-86c1220a-ae48-41df-ae20-6df4a5fe8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-ae8eb69a-42d6-4c4d-9ccb-ee7409f15698,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-284cf457-98a3-4798-b9f3-1009c91873b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-5af99479-1eff-4495-b6fe-3325f394e5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-fed80a73-e358-4c03-a891-e50e05b83831,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ba1820e7-b6c5-4016-bd57-0d81d97f6607,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-84a2d6ab-e05e-42bf-9eb5-c3c6712cb870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299343874-172.17.0.2-1599374686443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-fa8b5e48-fb6c-405b-8dc8-7ca2d2a1a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-564bb225-6bc9-4f44-a0eb-86b673a1b723,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-9857cf50-0623-4f1e-92b4-fb6bfc18f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-618de768-fa5f-47c0-ae39-d19711a8f284,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-c0dd631b-446a-491e-a7e7-cf20b6528179,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-1e418439-50b9-47c2-bc01-ddf89ded353f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-06f242e4-2757-4d78-ab11-e686b0a6c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-955d9bfa-48cb-438d-adbc-22d122889905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299343874-172.17.0.2-1599374686443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-fa8b5e48-fb6c-405b-8dc8-7ca2d2a1a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-564bb225-6bc9-4f44-a0eb-86b673a1b723,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-9857cf50-0623-4f1e-92b4-fb6bfc18f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-618de768-fa5f-47c0-ae39-d19711a8f284,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-c0dd631b-446a-491e-a7e7-cf20b6528179,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-1e418439-50b9-47c2-bc01-ddf89ded353f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-06f242e4-2757-4d78-ab11-e686b0a6c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-955d9bfa-48cb-438d-adbc-22d122889905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043139518-172.17.0.2-1599374901458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-d4167786-65e6-42a7-ad2e-51f4863b452a,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-6decb213-8482-4be8-b039-e4999499b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-23e3131c-2d35-493e-8bf4-a1580a79b469,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-98e0554b-f4d8-4225-bada-209b043c09c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-289e6712-6186-4fac-adf1-4921ee7ece67,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-959f3b44-0398-47dd-b8a3-658f2b1e4108,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-7f980e90-9d0f-4656-a38d-23b642af49fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-1efa758e-0eb6-4ca5-b3c0-19b4309f64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043139518-172.17.0.2-1599374901458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-d4167786-65e6-42a7-ad2e-51f4863b452a,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-6decb213-8482-4be8-b039-e4999499b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-23e3131c-2d35-493e-8bf4-a1580a79b469,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-98e0554b-f4d8-4225-bada-209b043c09c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-289e6712-6186-4fac-adf1-4921ee7ece67,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-959f3b44-0398-47dd-b8a3-658f2b1e4108,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-7f980e90-9d0f-4656-a38d-23b642af49fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-1efa758e-0eb6-4ca5-b3c0-19b4309f64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851536687-172.17.0.2-1599375016965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-6874c4b7-b7c7-4a85-aec9-ed97cf6cdaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-aeeb4e51-2d7f-4b30-bd78-8324038ce5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-89b50b90-a813-4d34-a859-0cb0583d326f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-6401a7e7-b46d-4a55-9db9-5b3cc6536740,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-938a70c7-619e-4768-aef6-6fedb7bfe90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-c708702d-34b1-4274-81e1-593ec8a093d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-1678d621-b734-4fdf-8fc1-c3bc97229375,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-29402068-f053-4375-a5f3-eb3e5c9f2d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851536687-172.17.0.2-1599375016965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-6874c4b7-b7c7-4a85-aec9-ed97cf6cdaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-aeeb4e51-2d7f-4b30-bd78-8324038ce5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-89b50b90-a813-4d34-a859-0cb0583d326f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-6401a7e7-b46d-4a55-9db9-5b3cc6536740,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-938a70c7-619e-4768-aef6-6fedb7bfe90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-c708702d-34b1-4274-81e1-593ec8a093d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-1678d621-b734-4fdf-8fc1-c3bc97229375,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-29402068-f053-4375-a5f3-eb3e5c9f2d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766983580-172.17.0.2-1599375235363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33146,DS-449cc745-7098-42f1-a614-a302d20a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-31aeba7c-e25c-4758-93f9-9bff5e2f5d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5feaa0e2-0980-4ebc-afd4-e49d90f0ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5f652921-a346-4cd8-ab9c-1a3946ebfc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9b5cbd7e-3e79-4eb8-bf91-60432f728b45,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7790b7fe-63f9-438f-9f9e-bf618d956a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-04eb28a9-2e2f-496b-9cd2-804d079b8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-5d8c52d6-007b-43f5-9d84-acb91bf20ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766983580-172.17.0.2-1599375235363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33146,DS-449cc745-7098-42f1-a614-a302d20a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-31aeba7c-e25c-4758-93f9-9bff5e2f5d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-5feaa0e2-0980-4ebc-afd4-e49d90f0ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5f652921-a346-4cd8-ab9c-1a3946ebfc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9b5cbd7e-3e79-4eb8-bf91-60432f728b45,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-7790b7fe-63f9-438f-9f9e-bf618d956a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-04eb28a9-2e2f-496b-9cd2-804d079b8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-5d8c52d6-007b-43f5-9d84-acb91bf20ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623858616-172.17.0.2-1599375637263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-b89cb7d2-3790-45aa-9026-279223da9234,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-92678dd0-4ff3-4e38-9704-881ca6e7081b,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-48d07fa0-b8c5-4723-a704-dec462aa6508,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-df258a92-090d-4e85-b6bd-6b5b1bc3f284,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d89bd4da-64f0-4166-b58a-b0ea4486ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-b76aa5d1-3069-4c9a-825d-6554372e2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c1c44faa-95b5-404b-8182-457e0cca7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-f1d820dd-6421-4cf5-942c-a529bc2ca67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623858616-172.17.0.2-1599375637263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-b89cb7d2-3790-45aa-9026-279223da9234,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-92678dd0-4ff3-4e38-9704-881ca6e7081b,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-48d07fa0-b8c5-4723-a704-dec462aa6508,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-df258a92-090d-4e85-b6bd-6b5b1bc3f284,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d89bd4da-64f0-4166-b58a-b0ea4486ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-b76aa5d1-3069-4c9a-825d-6554372e2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c1c44faa-95b5-404b-8182-457e0cca7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-f1d820dd-6421-4cf5-942c-a529bc2ca67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654280381-172.17.0.2-1599375843365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-3a4b4306-994d-43ac-a49b-9bef31694342,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ed0f8095-cd56-4d7d-b736-f034ab202ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-a4eb98d3-1045-4afb-a082-bb9d7aec24f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-56901bc4-1077-40a1-bcd2-80fff944be1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2c6ed14b-1a0f-4b31-a267-a64d8104bb75,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-0cf24fdc-6d89-4949-8bcf-4326d9cd106c,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-70902f71-dbe3-4030-8c0f-c4a76779ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-c3af59e1-18dd-4c66-a5e5-f0fd22b820bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654280381-172.17.0.2-1599375843365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-3a4b4306-994d-43ac-a49b-9bef31694342,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-ed0f8095-cd56-4d7d-b736-f034ab202ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-a4eb98d3-1045-4afb-a082-bb9d7aec24f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-56901bc4-1077-40a1-bcd2-80fff944be1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2c6ed14b-1a0f-4b31-a267-a64d8104bb75,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-0cf24fdc-6d89-4949-8bcf-4326d9cd106c,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-70902f71-dbe3-4030-8c0f-c4a76779ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-c3af59e1-18dd-4c66-a5e5-f0fd22b820bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229480870-172.17.0.2-1599375913549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-d26a68ff-c292-46b0-9774-27f96ce9dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f860728f-5e2a-42aa-9bbe-4d88ec8d52f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-38c3a029-6b2b-40db-92a6-a7b55761f6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-3110a67c-79df-448c-bdb6-11fda13cd627,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-384501f5-9a1f-448d-b010-92a53433ed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-01053acd-2c95-4bf0-8cd6-48a8e073f41d,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-9f53b40c-d17a-453f-89bc-6b25deb8f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b4317651-e609-42dd-a053-88874c68691c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229480870-172.17.0.2-1599375913549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-d26a68ff-c292-46b0-9774-27f96ce9dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f860728f-5e2a-42aa-9bbe-4d88ec8d52f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-38c3a029-6b2b-40db-92a6-a7b55761f6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-3110a67c-79df-448c-bdb6-11fda13cd627,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-384501f5-9a1f-448d-b010-92a53433ed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-01053acd-2c95-4bf0-8cd6-48a8e073f41d,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-9f53b40c-d17a-453f-89bc-6b25deb8f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b4317651-e609-42dd-a053-88874c68691c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574823370-172.17.0.2-1599376431665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37128,DS-e1aed4aa-9367-4494-98b9-9d428491084e,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-2e2a2a8c-8e4a-4776-94f0-a713c5b9795d,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-19e764ff-7052-4687-96e3-6ba53dfd2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-b20410ea-4d0d-4c9b-8a25-857b843656d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-cdf00fea-e6db-4981-9c1b-97403661400a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-d0d87ef8-9ad1-4a4c-bbeb-5808096b2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-75c2ad5c-aed0-4c38-b69d-59f2e3b8e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-704ce135-98f4-4e46-96cf-bc76933e4cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574823370-172.17.0.2-1599376431665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37128,DS-e1aed4aa-9367-4494-98b9-9d428491084e,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-2e2a2a8c-8e4a-4776-94f0-a713c5b9795d,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-19e764ff-7052-4687-96e3-6ba53dfd2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-b20410ea-4d0d-4c9b-8a25-857b843656d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-cdf00fea-e6db-4981-9c1b-97403661400a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-d0d87ef8-9ad1-4a4c-bbeb-5808096b2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-75c2ad5c-aed0-4c38-b69d-59f2e3b8e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-704ce135-98f4-4e46-96cf-bc76933e4cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778609248-172.17.0.2-1599376607061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35335,DS-2f384945-7867-4b57-b4b1-8ca1f3faa771,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-3426b0f7-71d2-4d59-ab65-108a97b50214,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-78208bdd-c869-435c-9f4a-383cb34011d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3efbbce0-3940-4a7c-ad1e-8599647afc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-6be72141-6b59-4877-a680-313faaa8778c,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-080ee6a6-511e-4c71-a8cb-88213fafb842,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-02d3e9dd-66ae-44c2-b441-3deb60ee8f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-d746a9c0-a5c9-445e-9b8e-45201c5d1786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778609248-172.17.0.2-1599376607061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35335,DS-2f384945-7867-4b57-b4b1-8ca1f3faa771,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-3426b0f7-71d2-4d59-ab65-108a97b50214,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-78208bdd-c869-435c-9f4a-383cb34011d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3efbbce0-3940-4a7c-ad1e-8599647afc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-6be72141-6b59-4877-a680-313faaa8778c,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-080ee6a6-511e-4c71-a8cb-88213fafb842,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-02d3e9dd-66ae-44c2-b441-3deb60ee8f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-d746a9c0-a5c9-445e-9b8e-45201c5d1786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5131
