reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676698486-172.17.0.20-1599317210995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-cdf353a7-e514-4066-9b99-ba353676ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-07bbb4bd-bb15-4d67-9434-af2764eac4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ee3a6b72-53ca-4cd8-a1f4-1af18658634e,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-5ba0904a-fea6-4884-af6a-0058755d86d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-90e05ee9-80f2-4e2c-90b7-31358225457b,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-f9064063-1e3a-4fff-a404-0962a3fc0fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-f3bdb7d6-90d4-4a4c-840f-fe36fef6fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-2452615d-9751-4f6d-b5d9-3be935a57992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676698486-172.17.0.20-1599317210995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-cdf353a7-e514-4066-9b99-ba353676ed65,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-07bbb4bd-bb15-4d67-9434-af2764eac4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ee3a6b72-53ca-4cd8-a1f4-1af18658634e,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-5ba0904a-fea6-4884-af6a-0058755d86d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-90e05ee9-80f2-4e2c-90b7-31358225457b,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-f9064063-1e3a-4fff-a404-0962a3fc0fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-f3bdb7d6-90d4-4a4c-840f-fe36fef6fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-2452615d-9751-4f6d-b5d9-3be935a57992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257053299-172.17.0.20-1599317583724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39621,DS-7a3a9775-8a19-4743-af80-eb276ae8e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-f7a3509b-3382-421b-9c05-edd1967ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-907f99e2-ac1a-4469-8807-0ad1abf45547,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-10a3a150-5ebe-438d-a54f-caab1dbf056d,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-86cf6b87-0d8d-4c2f-8ac3-b8dcd661205d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d447c843-3bc9-45a3-a300-5f53cea0e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-d9f2c555-d503-4eba-9c66-6a4a8bc1b394,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-5db91bc2-fe9f-48a9-841f-f95da6c715b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257053299-172.17.0.20-1599317583724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39621,DS-7a3a9775-8a19-4743-af80-eb276ae8e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-f7a3509b-3382-421b-9c05-edd1967ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-907f99e2-ac1a-4469-8807-0ad1abf45547,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-10a3a150-5ebe-438d-a54f-caab1dbf056d,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-86cf6b87-0d8d-4c2f-8ac3-b8dcd661205d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d447c843-3bc9-45a3-a300-5f53cea0e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-d9f2c555-d503-4eba-9c66-6a4a8bc1b394,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-5db91bc2-fe9f-48a9-841f-f95da6c715b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095453243-172.17.0.20-1599317913552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-3443191a-8408-4375-8d5c-358f314d6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-77d083e3-d7c0-4bd6-9cba-5990bacf5bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-32056c6f-9acb-4b5c-af33-4e6404644ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e29baf2b-b618-494a-ae22-8eb164b829ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-221b66f7-15ef-4cb3-9b82-8439e1a771dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-cba912b7-84b4-439e-b7ed-dbc0e2f2da03,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-e0890b99-c931-4fd5-a5d2-0de2c6d07a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-e2a9dc87-c44f-4916-9ab5-01df7e257cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095453243-172.17.0.20-1599317913552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-3443191a-8408-4375-8d5c-358f314d6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-77d083e3-d7c0-4bd6-9cba-5990bacf5bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-32056c6f-9acb-4b5c-af33-4e6404644ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e29baf2b-b618-494a-ae22-8eb164b829ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-221b66f7-15ef-4cb3-9b82-8439e1a771dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-cba912b7-84b4-439e-b7ed-dbc0e2f2da03,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-e0890b99-c931-4fd5-a5d2-0de2c6d07a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-e2a9dc87-c44f-4916-9ab5-01df7e257cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569703017-172.17.0.20-1599318165688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-738c224c-e434-4377-84a0-7ae8ccf081c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-585e742b-1de4-4113-b14f-d9c670633150,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-dd4a7dff-d75a-44a1-808e-0df12e514614,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-a53c9448-f618-43aa-87e8-d04adf54ba08,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-b1d8fee9-1161-4910-8015-4cf64f7237ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-2adc74c6-9c8a-48e2-88c2-eb2a2ab9f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-9f40c65e-27f3-47cb-a829-2bbb730a1c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a94c3bdf-07c6-4075-aeca-c9afefe3c3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569703017-172.17.0.20-1599318165688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-738c224c-e434-4377-84a0-7ae8ccf081c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-585e742b-1de4-4113-b14f-d9c670633150,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-dd4a7dff-d75a-44a1-808e-0df12e514614,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-a53c9448-f618-43aa-87e8-d04adf54ba08,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-b1d8fee9-1161-4910-8015-4cf64f7237ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-2adc74c6-9c8a-48e2-88c2-eb2a2ab9f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-9f40c65e-27f3-47cb-a829-2bbb730a1c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-a94c3bdf-07c6-4075-aeca-c9afefe3c3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194158326-172.17.0.20-1599318248537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-f88deedc-2666-49d4-838d-6cd7d06f73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-0879a22a-60b9-4eac-99ec-141fcef387f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-3db512bd-1899-4582-ab01-d5159ff19fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-14248d9d-6537-4847-9f55-c9dcc049cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3a0bb857-d333-42ff-aac6-bb2a8e9a5a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-bfe6555a-4c59-44aa-8d6f-17b68d8cd7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-7204c093-dc1c-4462-9714-b3ce7330861d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-d5a94188-2802-4c01-95ce-3b3035bdfbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194158326-172.17.0.20-1599318248537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-f88deedc-2666-49d4-838d-6cd7d06f73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-0879a22a-60b9-4eac-99ec-141fcef387f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-3db512bd-1899-4582-ab01-d5159ff19fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-14248d9d-6537-4847-9f55-c9dcc049cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3a0bb857-d333-42ff-aac6-bb2a8e9a5a63,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-bfe6555a-4c59-44aa-8d6f-17b68d8cd7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-7204c093-dc1c-4462-9714-b3ce7330861d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-d5a94188-2802-4c01-95ce-3b3035bdfbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006141794-172.17.0.20-1599318728584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-299752f6-338f-4fc6-959d-4be36d8cc12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-e7e3a8f5-2b55-4e16-9066-914b80499cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-be4e2621-17e6-4dd6-9cf6-1b5f868632ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7236b786-1d34-43eb-b1b0-72139989519a,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-00123f49-6462-48f8-b19c-17443c4b7e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-8c0af8bb-28e6-4485-a0d3-f4f4a2686c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-48752d9c-0eed-47a6-8d71-b09cb9c772a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-651fd5ac-2c7d-47a6-8fc1-f2df9f342707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006141794-172.17.0.20-1599318728584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-299752f6-338f-4fc6-959d-4be36d8cc12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-e7e3a8f5-2b55-4e16-9066-914b80499cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-be4e2621-17e6-4dd6-9cf6-1b5f868632ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-7236b786-1d34-43eb-b1b0-72139989519a,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-00123f49-6462-48f8-b19c-17443c4b7e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-8c0af8bb-28e6-4485-a0d3-f4f4a2686c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-48752d9c-0eed-47a6-8d71-b09cb9c772a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-651fd5ac-2c7d-47a6-8fc1-f2df9f342707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748877303-172.17.0.20-1599318807959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-bdccfdde-53b4-4690-8b30-54fe298870da,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-93ef28d6-8573-44d0-823f-a0ddfc86e375,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-722214e5-c472-4c6c-a8f3-03d8a1a982a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-6514c8e3-dd03-4f9b-80f9-7b7e5f92338c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-7fd5378f-f407-4b0a-a3d6-ee57b3b5b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-84b52ea9-a295-40a1-8bd3-e5091a97fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-d71f00bf-b406-4a98-9158-f46f0afd9c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-e23fab4e-2981-45be-b0f8-5520a956b145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748877303-172.17.0.20-1599318807959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-bdccfdde-53b4-4690-8b30-54fe298870da,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-93ef28d6-8573-44d0-823f-a0ddfc86e375,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-722214e5-c472-4c6c-a8f3-03d8a1a982a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-6514c8e3-dd03-4f9b-80f9-7b7e5f92338c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-7fd5378f-f407-4b0a-a3d6-ee57b3b5b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-84b52ea9-a295-40a1-8bd3-e5091a97fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-d71f00bf-b406-4a98-9158-f46f0afd9c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-e23fab4e-2981-45be-b0f8-5520a956b145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476232269-172.17.0.20-1599318936158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-22c577a8-6cbf-47a2-a627-96df79261e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-520497e2-b15f-490e-8507-d9b9f81dfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-11109021-d271-4af8-926e-c46551c7bede,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c37778ed-3415-4540-b390-a4b570ea3f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-e59ac14f-d92e-4077-a41b-c3d74a3b8519,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-29b3d625-7f5a-4964-bf0c-bd9c042b3bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6b1f224b-ecf5-458c-905c-3bcc51da9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-34f3bad5-28d3-465d-8836-61bc9b9ba4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476232269-172.17.0.20-1599318936158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-22c577a8-6cbf-47a2-a627-96df79261e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-520497e2-b15f-490e-8507-d9b9f81dfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-11109021-d271-4af8-926e-c46551c7bede,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c37778ed-3415-4540-b390-a4b570ea3f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-e59ac14f-d92e-4077-a41b-c3d74a3b8519,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-29b3d625-7f5a-4964-bf0c-bd9c042b3bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6b1f224b-ecf5-458c-905c-3bcc51da9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-34f3bad5-28d3-465d-8836-61bc9b9ba4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472522953-172.17.0.20-1599320145369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40997,DS-4e73222b-3eb8-455a-9369-cc8b7cad32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-d584fb01-1386-4b34-83cf-647fa9b04265,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-43c527b8-1539-4095-aa40-fbe4f6a21296,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-3cb0a7b3-af8b-43d6-a520-9bf72038f481,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-98e0638a-5305-4650-b456-e01a5bd312e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-998d3252-1425-4c36-82d1-5b9150134475,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-8e00a334-e8cf-4e1e-acba-4e6c952ed6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-2cb5d159-f2f8-4578-920a-8b7012011426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472522953-172.17.0.20-1599320145369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40997,DS-4e73222b-3eb8-455a-9369-cc8b7cad32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-d584fb01-1386-4b34-83cf-647fa9b04265,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-43c527b8-1539-4095-aa40-fbe4f6a21296,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-3cb0a7b3-af8b-43d6-a520-9bf72038f481,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-98e0638a-5305-4650-b456-e01a5bd312e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-998d3252-1425-4c36-82d1-5b9150134475,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-8e00a334-e8cf-4e1e-acba-4e6c952ed6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-2cb5d159-f2f8-4578-920a-8b7012011426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512683900-172.17.0.20-1599320330955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-12be37ff-e68b-4c2e-9fec-4af5570924ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-75e56faf-e619-4c23-89ef-f342152283f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8fafc3d1-e2f0-4176-944e-9641a7277577,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-edf65b9e-cc5a-432a-a2c1-215c53c15653,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-a5069ff8-a7b5-475c-9208-c280b0989277,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-ad1abcd0-a062-4349-afe3-2b2bf49d0434,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-60d2f073-a1f0-499b-a418-2b3134c591b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-ea8ea7dd-2812-4fad-89eb-0818bb262b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512683900-172.17.0.20-1599320330955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-12be37ff-e68b-4c2e-9fec-4af5570924ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-75e56faf-e619-4c23-89ef-f342152283f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8fafc3d1-e2f0-4176-944e-9641a7277577,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-edf65b9e-cc5a-432a-a2c1-215c53c15653,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-a5069ff8-a7b5-475c-9208-c280b0989277,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-ad1abcd0-a062-4349-afe3-2b2bf49d0434,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-60d2f073-a1f0-499b-a418-2b3134c591b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-ea8ea7dd-2812-4fad-89eb-0818bb262b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007221229-172.17.0.20-1599320585477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-b1235981-a26a-4c63-877e-06e2c3a5a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-1da6993e-d351-4acd-ab78-3c3b7fd7d147,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-0668d81e-bd59-4067-b09b-3a9727e62aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-f1a694a6-a562-4ef5-9f8b-88176abebfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-14e084f2-c460-4fca-bce4-19297f712e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a8e20b20-e414-47bf-ad1d-be070ff1a979,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-411ee20b-64d4-44bc-b50d-027daf966a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-795d7669-51e0-4e74-80ad-3359c8ff5315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007221229-172.17.0.20-1599320585477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-b1235981-a26a-4c63-877e-06e2c3a5a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-1da6993e-d351-4acd-ab78-3c3b7fd7d147,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-0668d81e-bd59-4067-b09b-3a9727e62aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-f1a694a6-a562-4ef5-9f8b-88176abebfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-14e084f2-c460-4fca-bce4-19297f712e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a8e20b20-e414-47bf-ad1d-be070ff1a979,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-411ee20b-64d4-44bc-b50d-027daf966a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-795d7669-51e0-4e74-80ad-3359c8ff5315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596798732-172.17.0.20-1599321548446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-917a3ed2-d366-4b8c-9e7b-541d6d197de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ca7a1284-fd54-4318-8ee4-e665ada5bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2bb1178d-8718-4523-8c76-9bab8c854ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-2fab7952-4690-4d92-be0f-28a440e01ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-001ea8cd-502b-49cf-ba0d-4a9b190873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e9301fe4-2c7a-4553-bc98-344456b21f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-e792b0ad-bd73-4abe-bc4f-20b6bd5a226e,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-78ad0587-c65b-423a-9304-7d830b953e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596798732-172.17.0.20-1599321548446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-917a3ed2-d366-4b8c-9e7b-541d6d197de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ca7a1284-fd54-4318-8ee4-e665ada5bcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2bb1178d-8718-4523-8c76-9bab8c854ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-2fab7952-4690-4d92-be0f-28a440e01ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-001ea8cd-502b-49cf-ba0d-4a9b190873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e9301fe4-2c7a-4553-bc98-344456b21f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-e792b0ad-bd73-4abe-bc4f-20b6bd5a226e,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-78ad0587-c65b-423a-9304-7d830b953e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5877
