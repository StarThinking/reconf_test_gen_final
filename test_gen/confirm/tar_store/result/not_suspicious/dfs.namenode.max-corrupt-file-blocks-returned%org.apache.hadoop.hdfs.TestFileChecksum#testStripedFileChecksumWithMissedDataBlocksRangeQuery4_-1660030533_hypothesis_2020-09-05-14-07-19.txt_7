reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560854886-172.17.0.6-1599315353065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-c8503fea-773d-4120-88e7-3913fa541b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-373e7ae2-ab22-40d6-9d38-c998b7cde74e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3712474b-14fc-4db1-96c6-3bf1a15a68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-e770df2c-4158-40e9-a729-6d2683cb5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-c6c225dd-16ad-4260-8c5f-0e9245131941,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-c2259685-6968-4f09-9a56-db64833db259,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ef6a6bef-250a-4481-b6f0-a40009fb5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-a96cf269-671b-4c67-92ca-7233aadfdf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560854886-172.17.0.6-1599315353065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-c8503fea-773d-4120-88e7-3913fa541b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-373e7ae2-ab22-40d6-9d38-c998b7cde74e,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3712474b-14fc-4db1-96c6-3bf1a15a68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-e770df2c-4158-40e9-a729-6d2683cb5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-c6c225dd-16ad-4260-8c5f-0e9245131941,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-c2259685-6968-4f09-9a56-db64833db259,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ef6a6bef-250a-4481-b6f0-a40009fb5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-a96cf269-671b-4c67-92ca-7233aadfdf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078033577-172.17.0.6-1599315544686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35537,DS-78acb815-e913-44be-9b6a-f2bedde186c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-90debba2-1af3-461f-85b0-0c085793e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ffa17d8f-b251-4a30-832c-431552e9a13e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-150a1a02-3452-48e0-83e4-a2a35679de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4c936ecf-424c-4359-a2b9-cecdbd2481df,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-c7e1f332-d573-4bae-b174-d55cef66b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-52433e90-abdf-4e0c-995a-cf5f29f64448,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-843ad2d7-a42a-486b-a193-ad5287eaf3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078033577-172.17.0.6-1599315544686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35537,DS-78acb815-e913-44be-9b6a-f2bedde186c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-90debba2-1af3-461f-85b0-0c085793e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ffa17d8f-b251-4a30-832c-431552e9a13e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-150a1a02-3452-48e0-83e4-a2a35679de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4c936ecf-424c-4359-a2b9-cecdbd2481df,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-c7e1f332-d573-4bae-b174-d55cef66b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-52433e90-abdf-4e0c-995a-cf5f29f64448,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-843ad2d7-a42a-486b-a193-ad5287eaf3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64009529-172.17.0.6-1599315585074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-bd0daeb5-b951-4975-ac69-ff55d3374d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-cdfb8c25-2006-462c-8928-9d20a3abfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d9ab545b-a4da-45f3-a90c-3e4c48ae38a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-36c7b9a2-5d1f-4d59-84c9-44ae5f562e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7fe884c8-ce4b-423e-98ab-4dc4150e2693,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-1f1bcbe9-6e9d-47a8-b170-d42ed73f885f,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-b0013244-6d1f-49ef-b84d-b8b394522b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-5a384769-325a-4cd0-8c58-f8ac7e43599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64009529-172.17.0.6-1599315585074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-bd0daeb5-b951-4975-ac69-ff55d3374d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-cdfb8c25-2006-462c-8928-9d20a3abfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d9ab545b-a4da-45f3-a90c-3e4c48ae38a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-36c7b9a2-5d1f-4d59-84c9-44ae5f562e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7fe884c8-ce4b-423e-98ab-4dc4150e2693,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-1f1bcbe9-6e9d-47a8-b170-d42ed73f885f,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-b0013244-6d1f-49ef-b84d-b8b394522b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-5a384769-325a-4cd0-8c58-f8ac7e43599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424624242-172.17.0.6-1599315660379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-4b5d516a-f40d-4264-9714-41c9fd49f94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-1ecbd4d6-f860-4161-84b9-e7fdd9a81e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-26337b65-b88f-4102-af9f-904e5ad58a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-f65b86d3-73d8-4093-b900-2bff626529cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-9ce68fd5-c61d-4a1a-8114-92e9de424163,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-39a04361-a914-418e-a4e6-133bb2897256,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-f4370fdc-5c9c-4ab9-8c70-3b643d143964,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b1d7a5d6-6963-40c0-b1d3-e527d354318f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424624242-172.17.0.6-1599315660379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-4b5d516a-f40d-4264-9714-41c9fd49f94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-1ecbd4d6-f860-4161-84b9-e7fdd9a81e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-26337b65-b88f-4102-af9f-904e5ad58a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-f65b86d3-73d8-4093-b900-2bff626529cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-9ce68fd5-c61d-4a1a-8114-92e9de424163,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-39a04361-a914-418e-a4e6-133bb2897256,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-f4370fdc-5c9c-4ab9-8c70-3b643d143964,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b1d7a5d6-6963-40c0-b1d3-e527d354318f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460720949-172.17.0.6-1599315833278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-7a4d88a9-71f5-49b2-b382-6cac6834078d,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-9195bf6a-6cbe-4717-a01e-b09bf539f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ce334ec0-f905-4419-b67c-3d6268c3af37,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-f8e2075f-cfe3-4dc2-a12e-04d8cc2aee61,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-782a7901-6716-41fc-b5f9-77e503dee877,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-4bd4c083-3a08-40b5-ae3c-1212ba968f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-f214d878-b61f-4dfb-9ef1-b8dcf38ac131,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-fab7b3a7-3f10-4697-aa16-4e77502f6085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460720949-172.17.0.6-1599315833278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-7a4d88a9-71f5-49b2-b382-6cac6834078d,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-9195bf6a-6cbe-4717-a01e-b09bf539f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ce334ec0-f905-4419-b67c-3d6268c3af37,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-f8e2075f-cfe3-4dc2-a12e-04d8cc2aee61,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-782a7901-6716-41fc-b5f9-77e503dee877,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-4bd4c083-3a08-40b5-ae3c-1212ba968f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-f214d878-b61f-4dfb-9ef1-b8dcf38ac131,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-fab7b3a7-3f10-4697-aa16-4e77502f6085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529293022-172.17.0.6-1599316007714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-26c3d916-65ad-4a26-861f-12a00e2d5b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-0001bc79-2c41-4f74-97bc-cce75f1b7c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-d31ac9d2-4cbb-4954-9708-84ccd58cba67,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-725507e4-a0ce-4e49-b72b-ce9946edb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-0a38f1f0-1f95-47c8-bb03-4a26bf96c2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-388b623b-ea20-494b-8530-ef2fb2c6240c,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-2bc7a97c-ff45-4618-9ea0-ee8fee517956,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-eb9d9496-cab2-431c-884d-fd45bec9f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529293022-172.17.0.6-1599316007714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-26c3d916-65ad-4a26-861f-12a00e2d5b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-0001bc79-2c41-4f74-97bc-cce75f1b7c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-d31ac9d2-4cbb-4954-9708-84ccd58cba67,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-725507e4-a0ce-4e49-b72b-ce9946edb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-0a38f1f0-1f95-47c8-bb03-4a26bf96c2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-388b623b-ea20-494b-8530-ef2fb2c6240c,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-2bc7a97c-ff45-4618-9ea0-ee8fee517956,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-eb9d9496-cab2-431c-884d-fd45bec9f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904980963-172.17.0.6-1599316078696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-03bb2bf2-1692-4425-9b59-196f726e9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-60444125-03f1-445a-9cdf-c8ae75b1c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-7d462ab0-f286-4b50-b87a-839450ab94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-91ff5f09-06ce-412e-ba3e-289b6515df83,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-96335f63-5734-4e0e-9867-9de13b0271a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-21715a93-1789-44be-859d-d02333babed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-80340589-3915-404c-bedb-a122c7f01163,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-8ca7ea3b-0378-470f-be12-4cc47440a0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904980963-172.17.0.6-1599316078696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-03bb2bf2-1692-4425-9b59-196f726e9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-60444125-03f1-445a-9cdf-c8ae75b1c86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-7d462ab0-f286-4b50-b87a-839450ab94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-91ff5f09-06ce-412e-ba3e-289b6515df83,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-96335f63-5734-4e0e-9867-9de13b0271a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-21715a93-1789-44be-859d-d02333babed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-80340589-3915-404c-bedb-a122c7f01163,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-8ca7ea3b-0378-470f-be12-4cc47440a0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621012058-172.17.0.6-1599316142072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-8d43ee65-83fd-4728-bfa5-29e9e7628310,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-7481235e-3f9d-47e8-ad97-9c6f11581897,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b996b7b6-c84b-4ba1-8159-bbdf85c253c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-fe032533-0c1e-422d-ac30-6d5804c6f977,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-69d6daf0-2ad2-4588-8dc5-46084ffa55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-3afeb26f-9c95-4bc0-9f48-829ba54a0d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-4cf8236e-3acd-4e6a-88fb-c58e7b9476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-8e3c82d1-e7e5-49dd-9b1f-ec2aa63fd4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621012058-172.17.0.6-1599316142072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-8d43ee65-83fd-4728-bfa5-29e9e7628310,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-7481235e-3f9d-47e8-ad97-9c6f11581897,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-b996b7b6-c84b-4ba1-8159-bbdf85c253c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-fe032533-0c1e-422d-ac30-6d5804c6f977,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-69d6daf0-2ad2-4588-8dc5-46084ffa55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-3afeb26f-9c95-4bc0-9f48-829ba54a0d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-4cf8236e-3acd-4e6a-88fb-c58e7b9476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-8e3c82d1-e7e5-49dd-9b1f-ec2aa63fd4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172919771-172.17.0.6-1599316271654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-e3f4356b-c497-4cfb-8d01-5e1fdb59029f,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b3532764-85be-428c-b85b-5cd7d7ed7364,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-01a96e31-7891-40be-be82-cd4db34ea546,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-611e51a8-87b7-4211-8502-7cbcf89f3d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-8f4c0119-7e22-4405-a0cf-374bd05e9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a4ed5415-0fe1-442a-bf22-c6dbc58a53f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-2259aa6b-2ae8-405e-bf08-8ae7b47ccd07,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-35ae87dd-9c19-41ab-abfd-63854ed842ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172919771-172.17.0.6-1599316271654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-e3f4356b-c497-4cfb-8d01-5e1fdb59029f,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b3532764-85be-428c-b85b-5cd7d7ed7364,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-01a96e31-7891-40be-be82-cd4db34ea546,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-611e51a8-87b7-4211-8502-7cbcf89f3d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-8f4c0119-7e22-4405-a0cf-374bd05e9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a4ed5415-0fe1-442a-bf22-c6dbc58a53f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-2259aa6b-2ae8-405e-bf08-8ae7b47ccd07,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-35ae87dd-9c19-41ab-abfd-63854ed842ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815361101-172.17.0.6-1599316408426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-36c7947c-35d6-4a7a-9dd1-a53f1d6d969a,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-2fee5a0f-f5b2-4bc3-a1e1-284db2126fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f178f1d8-5ad4-45fd-9240-99d44fa8e335,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-b6545743-8e9c-45bb-ad8b-8671985c310b,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-1692df80-1a60-4f7d-b297-da4c6abcb4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-f557eec8-0040-474a-94e5-4adfc49bbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0c589ea7-550a-4cb0-b3d3-633f0b7feaab,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-42c05383-6b2e-491f-90c4-fc393a511bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815361101-172.17.0.6-1599316408426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-36c7947c-35d6-4a7a-9dd1-a53f1d6d969a,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-2fee5a0f-f5b2-4bc3-a1e1-284db2126fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f178f1d8-5ad4-45fd-9240-99d44fa8e335,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-b6545743-8e9c-45bb-ad8b-8671985c310b,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-1692df80-1a60-4f7d-b297-da4c6abcb4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-f557eec8-0040-474a-94e5-4adfc49bbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0c589ea7-550a-4cb0-b3d3-633f0b7feaab,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-42c05383-6b2e-491f-90c4-fc393a511bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115640741-172.17.0.6-1599316556327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44039,DS-1026c5c2-2619-4e4e-9325-56c9bb78743e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-1377a75e-f2d3-4ba1-9ccf-e2d4ab5854c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-d2779d86-8aa0-43d1-bc7a-7d48b35e7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-4c0267e4-6fe2-46c6-b8be-bed664034095,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-723f30a0-a9a1-4a84-ba86-118fd1dfe66b,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b0b3ead6-d947-4ca3-8cca-ab823f808f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-378d4a2e-31a4-4703-9e8d-df8b6f537a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-011fd618-47fa-4c8d-8555-3ad94853cc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115640741-172.17.0.6-1599316556327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44039,DS-1026c5c2-2619-4e4e-9325-56c9bb78743e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-1377a75e-f2d3-4ba1-9ccf-e2d4ab5854c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-d2779d86-8aa0-43d1-bc7a-7d48b35e7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-4c0267e4-6fe2-46c6-b8be-bed664034095,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-723f30a0-a9a1-4a84-ba86-118fd1dfe66b,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b0b3ead6-d947-4ca3-8cca-ab823f808f50,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-378d4a2e-31a4-4703-9e8d-df8b6f537a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-011fd618-47fa-4c8d-8555-3ad94853cc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647600929-172.17.0.6-1599317554238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42674,DS-725a923c-51a3-435d-97d9-934f768b5676,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-86e4d108-ebda-4944-9691-754396667c20,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-8c758d59-da08-4bff-bd20-ade474eb9228,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-41cbf030-c3a8-4e87-b19a-689e9b048fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-f18f9afa-225c-4bac-983f-8a159756b417,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-54f78143-9414-43a0-a5ce-7d790aee2e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bcf77a9a-c8d8-4b65-9983-995240588c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-256ab27a-36de-41f8-8320-5289334fbd7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647600929-172.17.0.6-1599317554238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42674,DS-725a923c-51a3-435d-97d9-934f768b5676,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-86e4d108-ebda-4944-9691-754396667c20,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-8c758d59-da08-4bff-bd20-ade474eb9228,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-41cbf030-c3a8-4e87-b19a-689e9b048fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-f18f9afa-225c-4bac-983f-8a159756b417,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-54f78143-9414-43a0-a5ce-7d790aee2e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bcf77a9a-c8d8-4b65-9983-995240588c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-256ab27a-36de-41f8-8320-5289334fbd7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331160817-172.17.0.6-1599318734075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-a8910f95-8dee-4165-97fe-adf406c7ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-5820f338-75fd-483c-8972-74c17bb70fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-be81d24c-5373-4303-b326-04e6b3b06b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-05aff4b4-e56b-42b2-9afd-3b4beb50bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-e05e4202-5e78-4951-a452-5c0fedd2cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-d5b99c6b-e269-4e4d-bde1-c1924db01dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-d7b9c327-ec09-4d74-a16b-ae5660669cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-a1ebc851-c92c-4b20-b309-a4947778d3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331160817-172.17.0.6-1599318734075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-a8910f95-8dee-4165-97fe-adf406c7ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-5820f338-75fd-483c-8972-74c17bb70fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-be81d24c-5373-4303-b326-04e6b3b06b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-05aff4b4-e56b-42b2-9afd-3b4beb50bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-e05e4202-5e78-4951-a452-5c0fedd2cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-d5b99c6b-e269-4e4d-bde1-c1924db01dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-d7b9c327-ec09-4d74-a16b-ae5660669cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-a1ebc851-c92c-4b20-b309-a4947778d3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158936343-172.17.0.6-1599318872947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41949,DS-65787c49-c473-452c-b752-39cf22287424,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-48c2280c-50ff-4ed6-be4f-89167726616f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-4c926e5a-3359-452c-8942-3b588ebf57b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-e8ace206-ac5c-4207-9553-d5ebf34cba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5416daa4-7325-4531-a22d-47fd84396794,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a9d25aee-bcae-4df5-9121-7a945ee1eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-30908e0f-3cce-40dc-a229-5fe5b13fecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-ee7ce528-318d-4fcd-8369-768bea544508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158936343-172.17.0.6-1599318872947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41949,DS-65787c49-c473-452c-b752-39cf22287424,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-48c2280c-50ff-4ed6-be4f-89167726616f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-4c926e5a-3359-452c-8942-3b588ebf57b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-e8ace206-ac5c-4207-9553-d5ebf34cba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5416daa4-7325-4531-a22d-47fd84396794,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a9d25aee-bcae-4df5-9121-7a945ee1eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-30908e0f-3cce-40dc-a229-5fe5b13fecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-ee7ce528-318d-4fcd-8369-768bea544508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266441584-172.17.0.6-1599319277756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-dc9f80a9-2f8e-4f04-998d-cd9c3f098de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-5211f829-32eb-4c3f-ac01-f61f2cd8158f,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-4113137c-9cbd-4273-9e5e-681f4921b5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-35db3aab-6d77-4edd-bf98-bce245158d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6a7af0a3-69c5-4482-875b-e1b83df5353d,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-22f32bd3-9c43-45e3-b976-24f78a54cde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-29b56a15-8c71-4d46-a0cb-c6df1fd29c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-0a6e0757-e864-430c-9a87-7db748228ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266441584-172.17.0.6-1599319277756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-dc9f80a9-2f8e-4f04-998d-cd9c3f098de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-5211f829-32eb-4c3f-ac01-f61f2cd8158f,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-4113137c-9cbd-4273-9e5e-681f4921b5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-35db3aab-6d77-4edd-bf98-bce245158d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-6a7af0a3-69c5-4482-875b-e1b83df5353d,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-22f32bd3-9c43-45e3-b976-24f78a54cde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-29b56a15-8c71-4d46-a0cb-c6df1fd29c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-0a6e0757-e864-430c-9a87-7db748228ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947195600-172.17.0.6-1599319541567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-b495a84b-8bf9-449c-99b7-a8a1d99cd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-45b01c7b-3171-4534-abfb-20a85edeae70,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a00554e7-eddf-4e19-83cd-e9a4b6a5bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-e1c43ac0-f619-473e-978f-025a8c5bfd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-fd3c4496-971b-4646-bec1-20a924119e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-8720af60-b8f3-42b1-8b8b-9e5f92a4053a,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-e9ca180d-5a91-4035-bf57-9e7aa3bb1828,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-5289f7ba-5f39-4412-bc88-0a45d56a0a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947195600-172.17.0.6-1599319541567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-b495a84b-8bf9-449c-99b7-a8a1d99cd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-45b01c7b-3171-4534-abfb-20a85edeae70,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a00554e7-eddf-4e19-83cd-e9a4b6a5bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-e1c43ac0-f619-473e-978f-025a8c5bfd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-fd3c4496-971b-4646-bec1-20a924119e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-8720af60-b8f3-42b1-8b8b-9e5f92a4053a,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-e9ca180d-5a91-4035-bf57-9e7aa3bb1828,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-5289f7ba-5f39-4412-bc88-0a45d56a0a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89589490-172.17.0.6-1599319917578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35084,DS-bffb95c8-e4d9-4b0d-afc8-02661240d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b744ad07-7075-4bab-a2b8-d17280dacf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-21c37d4b-0425-4e50-ad1e-7fc9caba4266,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-e3a5aa59-dc4d-4e68-9282-2e746c677e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-bfda6ec0-df7d-4bfb-af3d-9709c218bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-e805e163-1e83-4778-a855-6c50652bdeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-29f805d8-4fe7-4210-869e-9ffe8fd8a002,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-ef284041-9a4b-4b83-b254-95fbc7e564dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89589490-172.17.0.6-1599319917578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35084,DS-bffb95c8-e4d9-4b0d-afc8-02661240d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b744ad07-7075-4bab-a2b8-d17280dacf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-21c37d4b-0425-4e50-ad1e-7fc9caba4266,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-e3a5aa59-dc4d-4e68-9282-2e746c677e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-bfda6ec0-df7d-4bfb-af3d-9709c218bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-e805e163-1e83-4778-a855-6c50652bdeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-29f805d8-4fe7-4210-869e-9ffe8fd8a002,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-ef284041-9a4b-4b83-b254-95fbc7e564dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233917058-172.17.0.6-1599320210640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-cfa01219-3c0b-4d61-aecd-3c233cf5628c,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-f14985ac-62f8-4bcc-9d31-b597e19b98f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-7e72e017-4858-4f86-a6f0-99b8dfb4920d,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-8d71c2c1-6c61-4bd7-9702-81529f211bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-4ad6e467-3902-4425-9780-5487104ee464,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-44d3c131-ac94-43c0-ae8d-348427c00acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-b2c90e58-eec6-4d57-bf23-3b1438b8f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ecc100fd-8e37-4198-82da-93bfd91ac8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233917058-172.17.0.6-1599320210640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-cfa01219-3c0b-4d61-aecd-3c233cf5628c,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-f14985ac-62f8-4bcc-9d31-b597e19b98f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-7e72e017-4858-4f86-a6f0-99b8dfb4920d,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-8d71c2c1-6c61-4bd7-9702-81529f211bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-4ad6e467-3902-4425-9780-5487104ee464,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-44d3c131-ac94-43c0-ae8d-348427c00acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-b2c90e58-eec6-4d57-bf23-3b1438b8f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ecc100fd-8e37-4198-82da-93bfd91ac8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5546
