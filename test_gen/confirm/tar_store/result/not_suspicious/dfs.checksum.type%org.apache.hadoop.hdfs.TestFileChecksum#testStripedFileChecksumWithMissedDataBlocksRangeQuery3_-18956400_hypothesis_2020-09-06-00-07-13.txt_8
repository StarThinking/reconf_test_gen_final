reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747105502-172.17.0.8-1599350845395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-72faa4a7-0715-46c9-8e94-0b5e77bf0191,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-6d1f898d-74e8-43e3-bd9f-602ac6e39bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-90cfb8a6-8387-4b35-b708-450895f885ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-aa35f47c-f899-4e7e-91b4-a479eeed2ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-fecfe48d-d013-478a-915c-2f1ea3fb07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-a02ef564-14d3-463b-a959-b745c7adf1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f62a67db-3f7f-4598-8e1b-260f9a6ab13e,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-15d1891a-cbe4-4318-8232-d7e2d5edc53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747105502-172.17.0.8-1599350845395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-72faa4a7-0715-46c9-8e94-0b5e77bf0191,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-6d1f898d-74e8-43e3-bd9f-602ac6e39bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-90cfb8a6-8387-4b35-b708-450895f885ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-aa35f47c-f899-4e7e-91b4-a479eeed2ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-fecfe48d-d013-478a-915c-2f1ea3fb07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-a02ef564-14d3-463b-a959-b745c7adf1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f62a67db-3f7f-4598-8e1b-260f9a6ab13e,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-15d1891a-cbe4-4318-8232-d7e2d5edc53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033054270-172.17.0.8-1599351082051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-c43b3023-748b-4bb0-8e96-a144e3db65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-7d1e87fc-7829-41e5-913c-f94f69df8255,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-0e4661ee-9960-40ca-b1a6-902dd0899964,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-a1b1cd8e-4273-4b4c-b2f3-fa28eb820aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-d6b1cc26-c171-47b4-94a5-0b5109f5b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-ef43fc45-0ef5-48a9-9186-91416780292c,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-65f11e27-7a8b-4610-8692-6480cfe35a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-2865647f-b91b-46c7-b18a-bd94f5ddaa7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033054270-172.17.0.8-1599351082051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-c43b3023-748b-4bb0-8e96-a144e3db65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-7d1e87fc-7829-41e5-913c-f94f69df8255,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-0e4661ee-9960-40ca-b1a6-902dd0899964,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-a1b1cd8e-4273-4b4c-b2f3-fa28eb820aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-d6b1cc26-c171-47b4-94a5-0b5109f5b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-ef43fc45-0ef5-48a9-9186-91416780292c,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-65f11e27-7a8b-4610-8692-6480cfe35a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-2865647f-b91b-46c7-b18a-bd94f5ddaa7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284802971-172.17.0.8-1599351466209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45722,DS-3fd580b6-14bf-47ae-9f3e-69bd3bebc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-48fccbc7-09fb-4cf6-9297-825be0239c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-84a79525-5abc-43d2-a7b7-ff9183cc60d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-c40788d4-9695-4994-84ba-4f4b04c5d35a,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-eec5a187-e3b5-43e4-bb2a-1fecbba7f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-f728d9da-eadc-4b60-b4c1-ae638418a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-05080f8e-9878-40e3-8fbc-0f902135acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-fa623ed3-aa30-43aa-b478-b610a976a77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284802971-172.17.0.8-1599351466209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45722,DS-3fd580b6-14bf-47ae-9f3e-69bd3bebc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-48fccbc7-09fb-4cf6-9297-825be0239c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-84a79525-5abc-43d2-a7b7-ff9183cc60d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-c40788d4-9695-4994-84ba-4f4b04c5d35a,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-eec5a187-e3b5-43e4-bb2a-1fecbba7f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-f728d9da-eadc-4b60-b4c1-ae638418a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-05080f8e-9878-40e3-8fbc-0f902135acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-fa623ed3-aa30-43aa-b478-b610a976a77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650163507-172.17.0.8-1599352523256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-3700ccf6-80db-4890-be88-c0615f77e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-c95870a4-5d09-4b96-9674-174a785714fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-0b4e1192-2d58-49fe-92d0-2fb8641a2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-560328dc-2f20-42ab-bdc6-a54a88342030,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-5a00681d-0f18-4103-b0b5-f077cac436d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-34881d63-b9e5-4a71-b10b-3646443a5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-9dbf1a90-c3ba-47fc-8afb-f74af49898e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-a1a3d0fb-e163-4f1e-8e22-bc0b46d834ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650163507-172.17.0.8-1599352523256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-3700ccf6-80db-4890-be88-c0615f77e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-c95870a4-5d09-4b96-9674-174a785714fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-0b4e1192-2d58-49fe-92d0-2fb8641a2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-560328dc-2f20-42ab-bdc6-a54a88342030,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-5a00681d-0f18-4103-b0b5-f077cac436d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-34881d63-b9e5-4a71-b10b-3646443a5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-9dbf1a90-c3ba-47fc-8afb-f74af49898e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-a1a3d0fb-e163-4f1e-8e22-bc0b46d834ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620478276-172.17.0.8-1599352561208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-a2fa7b91-5383-4d23-8252-b8c6051f1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-8cae23a5-87aa-48d5-9c6c-b819adcc5640,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-68a0eb33-b1ae-42d6-b7a6-2b9fede20064,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-d83e605f-518c-4ace-ad95-79c8ad27f318,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-72f130ef-8adb-41cc-b7c8-18badb877409,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-568bdcec-7148-424e-8a6f-74fde342bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-e345a7c5-908e-4feb-95c3-fedc9f3d3f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-7e0de762-7dd8-4430-b4b2-ab888cac414c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620478276-172.17.0.8-1599352561208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-a2fa7b91-5383-4d23-8252-b8c6051f1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-8cae23a5-87aa-48d5-9c6c-b819adcc5640,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-68a0eb33-b1ae-42d6-b7a6-2b9fede20064,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-d83e605f-518c-4ace-ad95-79c8ad27f318,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-72f130ef-8adb-41cc-b7c8-18badb877409,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-568bdcec-7148-424e-8a6f-74fde342bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-e345a7c5-908e-4feb-95c3-fedc9f3d3f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-7e0de762-7dd8-4430-b4b2-ab888cac414c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275867099-172.17.0.8-1599353095276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-ada453d8-0ada-49ac-9c5e-25f2eea5161f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-6c46d118-257f-4c72-b476-5a6f83506e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-4c85ee9c-f2f6-4e56-bf84-2a90d9b82e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-1181f9fb-470a-4297-b580-44a0e2fb34bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-17baa930-ab9c-4d4a-bafa-51698b0f2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8c77b7a9-92f9-4f8b-bb42-58461de2f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-6afa7a3b-8d06-46a9-955d-61bb0a464d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-9bef5ea7-1532-4a8a-a8f3-00fa971d2717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275867099-172.17.0.8-1599353095276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-ada453d8-0ada-49ac-9c5e-25f2eea5161f,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-6c46d118-257f-4c72-b476-5a6f83506e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-4c85ee9c-f2f6-4e56-bf84-2a90d9b82e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-1181f9fb-470a-4297-b580-44a0e2fb34bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-17baa930-ab9c-4d4a-bafa-51698b0f2f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8c77b7a9-92f9-4f8b-bb42-58461de2f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-6afa7a3b-8d06-46a9-955d-61bb0a464d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-9bef5ea7-1532-4a8a-a8f3-00fa971d2717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700959485-172.17.0.8-1599354035269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-fecb9764-1c01-4ffb-a168-add8283e9ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d542c420-8e79-4461-8068-3f41c79b316e,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-706fd3e0-fac5-4dd6-a686-a2a3c65f7889,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-3afd98c2-cd94-4021-8193-2a46845fd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-77ea5986-f468-414a-9ad0-291e566dc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-0e1a5148-6bb7-4629-9ceb-ab7e314aa564,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-ac5f513f-929a-47b3-a7b4-7106e7f9d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-d257f14b-837e-482f-9544-65a565116fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700959485-172.17.0.8-1599354035269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-fecb9764-1c01-4ffb-a168-add8283e9ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d542c420-8e79-4461-8068-3f41c79b316e,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-706fd3e0-fac5-4dd6-a686-a2a3c65f7889,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-3afd98c2-cd94-4021-8193-2a46845fd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-77ea5986-f468-414a-9ad0-291e566dc0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-0e1a5148-6bb7-4629-9ceb-ab7e314aa564,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-ac5f513f-929a-47b3-a7b4-7106e7f9d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-d257f14b-837e-482f-9544-65a565116fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075671339-172.17.0.8-1599354628952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-62cb05bb-f35b-4468-9f99-edd50683ca77,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-5de8f947-e182-4f83-b512-edfc9d374eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-ed481ef5-1b7f-4066-aa37-d12e7dc6d555,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-39b337b1-08d0-448b-b02e-c158e12b4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-d5c20fd5-8ab1-4355-9617-dab5f9bd9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-6a2f2383-c45a-4199-a7cd-c5f3a14fc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-00f020b7-f5ac-4997-a348-5c1747f20c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-f3cb8831-ed12-46c8-be45-8070f57173d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075671339-172.17.0.8-1599354628952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-62cb05bb-f35b-4468-9f99-edd50683ca77,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-5de8f947-e182-4f83-b512-edfc9d374eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-ed481ef5-1b7f-4066-aa37-d12e7dc6d555,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-39b337b1-08d0-448b-b02e-c158e12b4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-d5c20fd5-8ab1-4355-9617-dab5f9bd9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-6a2f2383-c45a-4199-a7cd-c5f3a14fc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-00f020b7-f5ac-4997-a348-5c1747f20c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-f3cb8831-ed12-46c8-be45-8070f57173d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818601281-172.17.0.8-1599354931715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44957,DS-2b4d1b96-5bad-4708-8f73-569e724b9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-2042bd17-bfaf-4aaa-8120-5cbbd9e223e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6501438f-89a9-43ca-94bd-4f839abe7794,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-42be2f4e-69e5-41bf-bba5-3fa3814466dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-bd4363ac-fd88-46ea-872e-245664e9c321,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-818bae7b-b3f5-414e-8027-1b608d906160,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-e49bc95b-6ffb-4d2e-98b4-5ffdb998dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-b81f1ad4-235f-484c-8560-21f770ffb7f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818601281-172.17.0.8-1599354931715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44957,DS-2b4d1b96-5bad-4708-8f73-569e724b9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-2042bd17-bfaf-4aaa-8120-5cbbd9e223e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6501438f-89a9-43ca-94bd-4f839abe7794,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-42be2f4e-69e5-41bf-bba5-3fa3814466dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-bd4363ac-fd88-46ea-872e-245664e9c321,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-818bae7b-b3f5-414e-8027-1b608d906160,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-e49bc95b-6ffb-4d2e-98b4-5ffdb998dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-b81f1ad4-235f-484c-8560-21f770ffb7f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041056754-172.17.0.8-1599355014507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-6849106d-d901-4c35-9928-4c326f48d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-28c663bb-de2b-483e-ba74-e00061b2fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-8fa05325-4291-49ea-95cc-ef7475e80149,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d642da1e-8e60-4cf6-81d3-f7f28ff721d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-03674890-a6f9-4f42-ad0f-708b610e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e1c88fb2-f6d8-471c-8483-faf67ee00122,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-7408684a-8683-45f4-aa13-92f551b72e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-7473cc8e-3ebb-418f-b486-92c062569367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041056754-172.17.0.8-1599355014507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-6849106d-d901-4c35-9928-4c326f48d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-28c663bb-de2b-483e-ba74-e00061b2fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-8fa05325-4291-49ea-95cc-ef7475e80149,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d642da1e-8e60-4cf6-81d3-f7f28ff721d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-03674890-a6f9-4f42-ad0f-708b610e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e1c88fb2-f6d8-471c-8483-faf67ee00122,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-7408684a-8683-45f4-aa13-92f551b72e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-7473cc8e-3ebb-418f-b486-92c062569367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376367230-172.17.0.8-1599355052538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43261,DS-88346c6b-c43e-4f99-a222-839150cfefeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-ba4467cf-2055-4a47-96ec-faed9954dd55,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-e2e00438-84cb-4cf5-9c84-4015e1048ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-b8f606d6-ab61-4978-81ee-1d0aa5140c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-480d0428-d427-42e8-9093-ac0da98183cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-4c4224f6-30e8-4a2b-bda2-a18da375cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-a62be443-e6eb-45b9-ac65-2e9baa3a7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4ef0b4b5-3341-4b36-a790-8d80dc889831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376367230-172.17.0.8-1599355052538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43261,DS-88346c6b-c43e-4f99-a222-839150cfefeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-ba4467cf-2055-4a47-96ec-faed9954dd55,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-e2e00438-84cb-4cf5-9c84-4015e1048ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-b8f606d6-ab61-4978-81ee-1d0aa5140c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-480d0428-d427-42e8-9093-ac0da98183cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-4c4224f6-30e8-4a2b-bda2-a18da375cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-a62be443-e6eb-45b9-ac65-2e9baa3a7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4ef0b4b5-3341-4b36-a790-8d80dc889831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215197263-172.17.0.8-1599355096448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35049,DS-33ad41f9-59ef-4ed3-b2d9-55f0940986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ee0970cd-d6ad-49c1-8227-b70a8ce1dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-77bbcb45-5179-477f-9abd-339b9c19ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7d2de296-275b-414b-95e4-3479aa11eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-46ab82e2-e4a4-48db-8b4c-cf48a30348fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-3fe17f00-a586-41f8-b241-da1231e95afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-94d0e7cb-9374-4611-ad80-12c591149a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-6f157448-0fe6-4d19-838f-41c10e62be6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215197263-172.17.0.8-1599355096448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35049,DS-33ad41f9-59ef-4ed3-b2d9-55f0940986b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ee0970cd-d6ad-49c1-8227-b70a8ce1dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-77bbcb45-5179-477f-9abd-339b9c19ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7d2de296-275b-414b-95e4-3479aa11eaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-46ab82e2-e4a4-48db-8b4c-cf48a30348fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-3fe17f00-a586-41f8-b241-da1231e95afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-94d0e7cb-9374-4611-ad80-12c591149a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-6f157448-0fe6-4d19-838f-41c10e62be6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178908153-172.17.0.8-1599355291832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-b8be0489-7bbc-444c-ac2a-3281365f2082,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f0e8436d-bce6-4a4d-a00b-16c0b5fa7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-fc73879d-d1f4-4174-a29b-e923d0dfac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-7259708d-55bd-431c-a815-d381c05094d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-9722c219-8df9-458d-b9e9-2f9f8794b49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-17375b04-ea7a-4eb4-9ba0-b50ef2082fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-1b6725f0-23bb-43f6-9fa3-d9d2c33acd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-2523e2a5-20c6-4e57-a25c-ac4d1a3e544c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178908153-172.17.0.8-1599355291832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-b8be0489-7bbc-444c-ac2a-3281365f2082,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f0e8436d-bce6-4a4d-a00b-16c0b5fa7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-fc73879d-d1f4-4174-a29b-e923d0dfac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-7259708d-55bd-431c-a815-d381c05094d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-9722c219-8df9-458d-b9e9-2f9f8794b49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-17375b04-ea7a-4eb4-9ba0-b50ef2082fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-1b6725f0-23bb-43f6-9fa3-d9d2c33acd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-2523e2a5-20c6-4e57-a25c-ac4d1a3e544c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443645480-172.17.0.8-1599355931751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-182def3d-e5e8-4c69-9013-85cbb2f6ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-222faf59-90f5-45c9-92b2-1bbf8f0a50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-a601b3e1-573f-4d15-8017-fed3d4bc46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-05d05e71-3777-4b48-9dff-d8a23c860131,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e2fb4371-863f-4139-8588-687dafb46a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-e1bbd31a-223e-47da-9ed7-219eb3bcf5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4c6c5aa4-6dd6-40ba-82d1-5cfd5965ce85,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-c7a735e2-f0e0-40c1-9511-a4c90da85566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443645480-172.17.0.8-1599355931751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-182def3d-e5e8-4c69-9013-85cbb2f6ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-222faf59-90f5-45c9-92b2-1bbf8f0a50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-a601b3e1-573f-4d15-8017-fed3d4bc46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-05d05e71-3777-4b48-9dff-d8a23c860131,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e2fb4371-863f-4139-8588-687dafb46a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-e1bbd31a-223e-47da-9ed7-219eb3bcf5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4c6c5aa4-6dd6-40ba-82d1-5cfd5965ce85,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-c7a735e2-f0e0-40c1-9511-a4c90da85566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382187480-172.17.0.8-1599356198765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-cd46908e-5da0-441b-a3ca-378cdf8ff93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d319ec6b-4568-47b3-93cd-31406c5d0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-f1746dc4-6d84-4b56-9c5b-219873c7a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-54d69eee-a15c-419a-9ba1-c897cd2994b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-2628ae58-04b7-47d8-88ef-7790e4a4c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e2be3f3b-c3f6-469c-ab27-178315446301,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-31832ae6-9ee9-4656-aac3-8136671b98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-76116f8b-e2fc-4d4c-b800-2bd39256884b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382187480-172.17.0.8-1599356198765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-cd46908e-5da0-441b-a3ca-378cdf8ff93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d319ec6b-4568-47b3-93cd-31406c5d0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-f1746dc4-6d84-4b56-9c5b-219873c7a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-54d69eee-a15c-419a-9ba1-c897cd2994b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-2628ae58-04b7-47d8-88ef-7790e4a4c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-e2be3f3b-c3f6-469c-ab27-178315446301,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-31832ae6-9ee9-4656-aac3-8136671b98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-76116f8b-e2fc-4d4c-b800-2bd39256884b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520908220-172.17.0.8-1599356309847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-f271731c-4ab3-4021-bf36-ef6dfdf75658,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-568e2ba0-b3cf-4d7a-bc3a-a127ba8e8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e3a35c04-34eb-4653-9510-1d64b2eac51c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-e9b67185-beba-43c3-bdd1-28c6c1851656,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-dd2831f3-ec6f-4286-8bdd-48d4d568912d,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-df350a74-9d7d-4d75-9fc4-02c10374c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-e574eb81-4d5b-47ef-af56-c6d05788295f,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-fe3ad657-8087-466c-a045-fedbc77e4de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520908220-172.17.0.8-1599356309847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-f271731c-4ab3-4021-bf36-ef6dfdf75658,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-568e2ba0-b3cf-4d7a-bc3a-a127ba8e8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e3a35c04-34eb-4653-9510-1d64b2eac51c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-e9b67185-beba-43c3-bdd1-28c6c1851656,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-dd2831f3-ec6f-4286-8bdd-48d4d568912d,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-df350a74-9d7d-4d75-9fc4-02c10374c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-e574eb81-4d5b-47ef-af56-c6d05788295f,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-fe3ad657-8087-466c-a045-fedbc77e4de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579359998-172.17.0.8-1599356351397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-ae978e61-da87-4da9-96a5-98dc9fdc5c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-a8003704-a64b-415b-93ca-baf322076b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-f93455e9-ed56-4594-8eb6-066c03a7e302,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-6499660f-64fa-4369-bef2-b7bd7825c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-506892e6-8d8b-4fb0-9a6f-e6d441e9b684,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-e96e532a-0536-48b3-9e2b-293069759fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-cb835a8c-f69e-4208-aafe-a99363a46cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-da971dbf-1080-4b66-9a3c-9c63324bdf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579359998-172.17.0.8-1599356351397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36178,DS-ae978e61-da87-4da9-96a5-98dc9fdc5c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-a8003704-a64b-415b-93ca-baf322076b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-f93455e9-ed56-4594-8eb6-066c03a7e302,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-6499660f-64fa-4369-bef2-b7bd7825c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-506892e6-8d8b-4fb0-9a6f-e6d441e9b684,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-e96e532a-0536-48b3-9e2b-293069759fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-cb835a8c-f69e-4208-aafe-a99363a46cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-da971dbf-1080-4b66-9a3c-9c63324bdf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5621
