reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974594983-172.17.0.19-1599360345506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-c8ecd43a-87c5-4b86-836f-b18e7b0486f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-c87fcde2-c916-4de1-8c16-323bdc8014f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-9d536a47-04da-48f2-816c-438e02b19770,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-89c973a0-4f65-475d-ac5b-aedebfd8aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-b78633f8-5cff-4dd1-9d31-8bb1642bc883,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-60a1a71d-96d4-4968-ae87-c7fe97049861,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ac33ef79-fe93-43ca-a17a-f4b7e3e8f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-d68d8500-1b36-4e2c-9f21-f14ee31ef02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974594983-172.17.0.19-1599360345506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-c8ecd43a-87c5-4b86-836f-b18e7b0486f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-c87fcde2-c916-4de1-8c16-323bdc8014f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-9d536a47-04da-48f2-816c-438e02b19770,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-89c973a0-4f65-475d-ac5b-aedebfd8aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-b78633f8-5cff-4dd1-9d31-8bb1642bc883,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-60a1a71d-96d4-4968-ae87-c7fe97049861,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ac33ef79-fe93-43ca-a17a-f4b7e3e8f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-d68d8500-1b36-4e2c-9f21-f14ee31ef02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797834702-172.17.0.19-1599360525257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-f77e7546-e414-45c7-b18a-9d677ff8c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-a49f652e-8204-44a2-816a-6ba82d0ec976,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-11bbbe8a-e1c0-4e08-9ff1-ebf142610a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-1413696a-e546-44b5-9d3c-86c110edcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-879f60e2-5621-4082-b101-5e892927ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a66e3a6c-2749-4002-a53d-6daa19f6b20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-8a48455d-637a-4d23-b0a5-8505a1ba02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-5866d98f-de27-4641-9e95-496150f5c849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797834702-172.17.0.19-1599360525257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40574,DS-f77e7546-e414-45c7-b18a-9d677ff8c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-a49f652e-8204-44a2-816a-6ba82d0ec976,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-11bbbe8a-e1c0-4e08-9ff1-ebf142610a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-1413696a-e546-44b5-9d3c-86c110edcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-879f60e2-5621-4082-b101-5e892927ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a66e3a6c-2749-4002-a53d-6daa19f6b20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-8a48455d-637a-4d23-b0a5-8505a1ba02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-5866d98f-de27-4641-9e95-496150f5c849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704092794-172.17.0.19-1599361011628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-348adc17-3e21-4133-844e-5ff94dc275cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-571ec8f3-5f5d-44d5-8fd8-c61552b246f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-2e785a92-100c-4cfa-b6aa-83c079cbaf08,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3e208c7b-ddb4-4e94-a297-e21a2e9a6726,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-94acdaa4-98fd-4ede-9191-4043668d0000,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-bf46d93c-a695-47f4-9ad0-ee56a726c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-7dbf1f59-4175-461c-b1cd-f7f8fc77b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-9dc11be6-0d5a-402d-a86a-c58d6ba6c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704092794-172.17.0.19-1599361011628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-348adc17-3e21-4133-844e-5ff94dc275cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-571ec8f3-5f5d-44d5-8fd8-c61552b246f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-2e785a92-100c-4cfa-b6aa-83c079cbaf08,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3e208c7b-ddb4-4e94-a297-e21a2e9a6726,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-94acdaa4-98fd-4ede-9191-4043668d0000,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-bf46d93c-a695-47f4-9ad0-ee56a726c1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-7dbf1f59-4175-461c-b1cd-f7f8fc77b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-9dc11be6-0d5a-402d-a86a-c58d6ba6c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461897017-172.17.0.19-1599361299619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39486,DS-985dc6f3-3ce2-46d4-b992-b5b61bc6c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-7e95a3ef-f786-4cd8-90c4-d2fe6b75080d,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2d086e25-a183-4b95-987e-a5f834d8f6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-25906df0-4f7b-41c9-97ad-f5d2115a1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-f74ec2ff-3439-469a-8119-4eb0cf3c33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cf76c619-c3b6-4fb1-929f-ac8997afbff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-a99cb801-a964-49e2-93f8-ebdf09e6340d,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-715fccd9-dd87-4f24-a812-03b16c0ada75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461897017-172.17.0.19-1599361299619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39486,DS-985dc6f3-3ce2-46d4-b992-b5b61bc6c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-7e95a3ef-f786-4cd8-90c4-d2fe6b75080d,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2d086e25-a183-4b95-987e-a5f834d8f6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-25906df0-4f7b-41c9-97ad-f5d2115a1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-f74ec2ff-3439-469a-8119-4eb0cf3c33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-cf76c619-c3b6-4fb1-929f-ac8997afbff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-a99cb801-a964-49e2-93f8-ebdf09e6340d,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-715fccd9-dd87-4f24-a812-03b16c0ada75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204241362-172.17.0.19-1599361325368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43497,DS-100fcdda-d5cf-49b6-8d15-f760579b06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-30bae718-24fe-4341-a2d2-ecd2f94356f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-df081e1f-be8e-4f04-916b-ab6a549bdbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-ed87642c-77e0-4914-b1dd-db5ef15e48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-041fafcc-4efb-40ae-8b80-c4c44d99e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-e7fba1e4-2ebb-4226-8c5c-0457f89cd3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9dd56316-197b-4ca2-abea-e59c7665063d,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-52082633-6dcc-4069-ad51-2dd81820a557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204241362-172.17.0.19-1599361325368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43497,DS-100fcdda-d5cf-49b6-8d15-f760579b06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-30bae718-24fe-4341-a2d2-ecd2f94356f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-df081e1f-be8e-4f04-916b-ab6a549bdbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-ed87642c-77e0-4914-b1dd-db5ef15e48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-041fafcc-4efb-40ae-8b80-c4c44d99e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-e7fba1e4-2ebb-4226-8c5c-0457f89cd3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9dd56316-197b-4ca2-abea-e59c7665063d,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-52082633-6dcc-4069-ad51-2dd81820a557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772333355-172.17.0.19-1599361353260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42311,DS-aed257cd-000e-48f4-ab61-194ce1cd2403,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-3bcdddd7-07ce-4d3c-8f7e-9e0a5db64a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-27930cfc-d63d-4ce8-93cd-696372b60387,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-704e017d-8d36-4802-bfd6-fbd3bf9dacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-701f5abc-523b-4c91-9822-d65012dfcb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-938cd700-2261-40e2-82b0-f272aa0b9cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-93008d5b-8247-4f50-99bd-20a603f0e008,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-7e1c656d-a20a-4921-9a53-ff339396a7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772333355-172.17.0.19-1599361353260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42311,DS-aed257cd-000e-48f4-ab61-194ce1cd2403,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-3bcdddd7-07ce-4d3c-8f7e-9e0a5db64a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-27930cfc-d63d-4ce8-93cd-696372b60387,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-704e017d-8d36-4802-bfd6-fbd3bf9dacd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-701f5abc-523b-4c91-9822-d65012dfcb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-938cd700-2261-40e2-82b0-f272aa0b9cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-93008d5b-8247-4f50-99bd-20a603f0e008,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-7e1c656d-a20a-4921-9a53-ff339396a7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370639769-172.17.0.19-1599361888190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-0e9f394a-839b-472b-aad6-bec771c5ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-4a89c326-10fe-41b8-8e4d-e2eb695a386d,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-115c8631-c3d7-4fef-a955-8225b1cb77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-4f2c32ae-ed7b-4cee-8b31-b3223b955dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-11922e74-245b-4221-83cb-53b722c94cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-a656ad19-419c-463c-a7df-5ae1199a5bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-329025ba-48a6-4d95-a5a4-b3b5d4ef8988,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-85ee3ed4-bcc7-42f6-b674-159bcd1635b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370639769-172.17.0.19-1599361888190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-0e9f394a-839b-472b-aad6-bec771c5ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-4a89c326-10fe-41b8-8e4d-e2eb695a386d,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-115c8631-c3d7-4fef-a955-8225b1cb77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-4f2c32ae-ed7b-4cee-8b31-b3223b955dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-11922e74-245b-4221-83cb-53b722c94cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-a656ad19-419c-463c-a7df-5ae1199a5bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-329025ba-48a6-4d95-a5a4-b3b5d4ef8988,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-85ee3ed4-bcc7-42f6-b674-159bcd1635b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723429839-172.17.0.19-1599362037458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-a850d44a-f60d-4862-92ff-18eea68b2fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f184c16f-4ae0-4cbf-8557-cac772b77869,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-1dd5d946-aa23-42ee-974e-6b78dbfa4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-834b507b-7807-4fd2-bba1-9fe641c181ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-e398d5b4-58ea-4d5e-af6f-896028fedf31,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-8fd33528-f01a-4828-9513-b424b212ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-767a5f34-a6d4-4806-9fc0-2bbb84cd5d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-b6e577b0-1cc8-4346-aced-9e3acdc2c345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723429839-172.17.0.19-1599362037458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-a850d44a-f60d-4862-92ff-18eea68b2fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-f184c16f-4ae0-4cbf-8557-cac772b77869,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-1dd5d946-aa23-42ee-974e-6b78dbfa4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-834b507b-7807-4fd2-bba1-9fe641c181ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-e398d5b4-58ea-4d5e-af6f-896028fedf31,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-8fd33528-f01a-4828-9513-b424b212ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-767a5f34-a6d4-4806-9fc0-2bbb84cd5d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-b6e577b0-1cc8-4346-aced-9e3acdc2c345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253640179-172.17.0.19-1599362324808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43696,DS-7891c7e0-ef0d-48fa-8112-f59aa964f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-12f3ed22-0c37-4ef3-8477-c3489af3c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c33b19d6-4700-4faf-b2aa-58f9c78c88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-0ed0bdc2-851d-4788-9bb3-337c1c566906,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-d8e28218-d26a-46fc-82e6-69e4086f76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-800abb1c-7cfa-4e69-a278-2cf034684c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-0229ee2e-2f93-4d44-81d7-a86bf2fdbf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-57b0b1fb-56fe-4eba-aa47-4685be75e946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253640179-172.17.0.19-1599362324808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43696,DS-7891c7e0-ef0d-48fa-8112-f59aa964f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-12f3ed22-0c37-4ef3-8477-c3489af3c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c33b19d6-4700-4faf-b2aa-58f9c78c88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-0ed0bdc2-851d-4788-9bb3-337c1c566906,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-d8e28218-d26a-46fc-82e6-69e4086f76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-800abb1c-7cfa-4e69-a278-2cf034684c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-0229ee2e-2f93-4d44-81d7-a86bf2fdbf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-57b0b1fb-56fe-4eba-aa47-4685be75e946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103568495-172.17.0.19-1599362352744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-e139a80c-7008-4afd-a3a4-81d626fad353,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-05508f18-c200-41ef-beeb-be23bca21f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-8cbe7b1a-4731-430f-9823-68b911af085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-16b3c4d3-2145-4e6f-a8e0-ed95e2542898,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-5c590fcd-c809-4821-8c6f-f78abb87155c,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-d2ff902e-6ab7-4b51-b6ee-b2154cf1fd15,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-443a86a9-b5b0-4edd-8b3c-8ec606c10373,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9dd32c8b-c004-497c-bdd2-813d42e61c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103568495-172.17.0.19-1599362352744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-e139a80c-7008-4afd-a3a4-81d626fad353,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-05508f18-c200-41ef-beeb-be23bca21f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-8cbe7b1a-4731-430f-9823-68b911af085a,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-16b3c4d3-2145-4e6f-a8e0-ed95e2542898,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-5c590fcd-c809-4821-8c6f-f78abb87155c,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-d2ff902e-6ab7-4b51-b6ee-b2154cf1fd15,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-443a86a9-b5b0-4edd-8b3c-8ec606c10373,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9dd32c8b-c004-497c-bdd2-813d42e61c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827413032-172.17.0.19-1599362846438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-51a97e2b-4afc-4b0c-a46c-1aa62f097a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ef0c9d33-41f0-4c3c-b444-6a1edc21e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-f10fa24c-c356-4498-a800-fd98a8f968d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-4ca200a0-463e-4a65-b6a9-c4b382483c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ea169f3f-8b87-4f54-8dff-80b362fe2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-f9278023-4330-485f-8c1d-e57409328dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-387e81c6-446b-4f94-965c-9a2ddd42afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-4c66d084-8b84-4cda-bebd-2e257152b8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827413032-172.17.0.19-1599362846438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-51a97e2b-4afc-4b0c-a46c-1aa62f097a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ef0c9d33-41f0-4c3c-b444-6a1edc21e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-f10fa24c-c356-4498-a800-fd98a8f968d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-4ca200a0-463e-4a65-b6a9-c4b382483c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ea169f3f-8b87-4f54-8dff-80b362fe2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-f9278023-4330-485f-8c1d-e57409328dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-387e81c6-446b-4f94-965c-9a2ddd42afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-4c66d084-8b84-4cda-bebd-2e257152b8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785949267-172.17.0.19-1599362906544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-09a94106-a7c2-42f2-94a3-7f7aa496f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-4dac4b5f-b791-4c93-937a-6698f60f69b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-c85da5f1-7068-4535-9d67-1e534e1d104f,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-495dc10a-6ae7-45d6-915d-fdb1c5bc71cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-fbfa13aa-63f6-4ba3-97c3-4c0e410216cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-551ad09a-7477-4dbf-a7ce-abfdd7c5ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-ecc2164d-7090-4e27-a818-27f5fe35d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-477ac77b-e6bc-4721-b40a-859985b72691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785949267-172.17.0.19-1599362906544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-09a94106-a7c2-42f2-94a3-7f7aa496f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-4dac4b5f-b791-4c93-937a-6698f60f69b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-c85da5f1-7068-4535-9d67-1e534e1d104f,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-495dc10a-6ae7-45d6-915d-fdb1c5bc71cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-fbfa13aa-63f6-4ba3-97c3-4c0e410216cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-551ad09a-7477-4dbf-a7ce-abfdd7c5ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-ecc2164d-7090-4e27-a818-27f5fe35d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-477ac77b-e6bc-4721-b40a-859985b72691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432912904-172.17.0.19-1599363320180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-caf4521b-1cc4-41d1-b789-24ca30728739,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-69f57690-d681-42e6-a07e-8d87ff5a0ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-d277b653-af19-4483-9688-08e63ed3afce,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-530ace3e-4bac-49cc-87b6-f91acd42e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-b8ff204b-1d5b-4862-9877-b8014ce1dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-7a7a726b-fb07-42eb-b6e9-bd19982e9369,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b12d6912-6afd-4bf5-996d-f7b74e7f4436,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-f62ff5e0-8d1a-4514-b6c6-c44b04061817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432912904-172.17.0.19-1599363320180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-caf4521b-1cc4-41d1-b789-24ca30728739,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-69f57690-d681-42e6-a07e-8d87ff5a0ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-d277b653-af19-4483-9688-08e63ed3afce,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-530ace3e-4bac-49cc-87b6-f91acd42e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-b8ff204b-1d5b-4862-9877-b8014ce1dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-7a7a726b-fb07-42eb-b6e9-bd19982e9369,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b12d6912-6afd-4bf5-996d-f7b74e7f4436,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-f62ff5e0-8d1a-4514-b6c6-c44b04061817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108887503-172.17.0.19-1599363374605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-c0a1530e-e65f-4b8c-8239-509594b7c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9c7bb9ee-89d4-42e1-9a0f-e000c456a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-b70c1500-66c6-4380-a1fe-1cd71fe42f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-b0790523-d3fc-4ab8-9fa1-ea710dceeba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-67dcaff1-e1a8-4f32-83fa-1c155aa5ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-e4b6506f-fc51-472b-9053-d660b2833664,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-89dfe682-6998-4cb8-873b-42a05a6634ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-5685ea6e-45a8-40b1-8693-abfef2ab3e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108887503-172.17.0.19-1599363374605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-c0a1530e-e65f-4b8c-8239-509594b7c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9c7bb9ee-89d4-42e1-9a0f-e000c456a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-b70c1500-66c6-4380-a1fe-1cd71fe42f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-b0790523-d3fc-4ab8-9fa1-ea710dceeba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-67dcaff1-e1a8-4f32-83fa-1c155aa5ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-e4b6506f-fc51-472b-9053-d660b2833664,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-89dfe682-6998-4cb8-873b-42a05a6634ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-5685ea6e-45a8-40b1-8693-abfef2ab3e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815289279-172.17.0.19-1599363431504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-1e052702-1914-4ee3-94bc-54451e83b713,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-50e8fce4-1825-4f18-be6a-327a6fb68098,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-42e5d6fc-42f8-466a-8af9-3f504076d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-5e8a1773-6058-461d-bc19-c47d0929f9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-cee51396-1218-4b4f-9cec-2e12321484f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-9047cb87-76a2-4500-ba34-a5bfcfc01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-75bbf9a9-913a-4efc-acbd-105d22d7a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-69e1ab1f-4dd4-4f8b-b122-46db6113f971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815289279-172.17.0.19-1599363431504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-1e052702-1914-4ee3-94bc-54451e83b713,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-50e8fce4-1825-4f18-be6a-327a6fb68098,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-42e5d6fc-42f8-466a-8af9-3f504076d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-5e8a1773-6058-461d-bc19-c47d0929f9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-cee51396-1218-4b4f-9cec-2e12321484f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-9047cb87-76a2-4500-ba34-a5bfcfc01a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-75bbf9a9-913a-4efc-acbd-105d22d7a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-69e1ab1f-4dd4-4f8b-b122-46db6113f971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590000809-172.17.0.19-1599363548500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-5e468b59-abfd-49f8-9dcd-011ac49bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5478c2fe-75df-4e2d-a08a-a4e15bd57fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-ab5f40b9-1331-422d-ab10-f2db8d28bfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d8632efd-6476-4b60-980f-7d5eeb3d26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-48f51c73-7fdf-47f4-97c4-a510be52c171,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-55d6fed4-c097-4a6f-96e2-e25d3add2050,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-ebaa7afb-1127-4e2a-b38e-cd3e408cca61,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9b9a73e5-4a9c-4d45-b0a7-25137aaada88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590000809-172.17.0.19-1599363548500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-5e468b59-abfd-49f8-9dcd-011ac49bd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-5478c2fe-75df-4e2d-a08a-a4e15bd57fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-ab5f40b9-1331-422d-ab10-f2db8d28bfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-d8632efd-6476-4b60-980f-7d5eeb3d26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-48f51c73-7fdf-47f4-97c4-a510be52c171,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-55d6fed4-c097-4a6f-96e2-e25d3add2050,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-ebaa7afb-1127-4e2a-b38e-cd3e408cca61,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9b9a73e5-4a9c-4d45-b0a7-25137aaada88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603434512-172.17.0.19-1599363757157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-36c0c6ea-209e-4ae5-873c-7fd4cfee7661,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a65ece1f-e98e-4be1-82d4-966139f7512d,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-1313f607-1826-4c7b-939b-ef26a12ca825,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4e4e42ff-8c2b-4c85-8cef-b1daa321789e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-cec03ce1-434b-4915-a0d4-a8fd36728115,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-b57963fd-1c05-4d4d-b50e-322c6e21415e,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-42ea00c0-c1d6-43ac-940f-f2c217a03617,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-2616d718-5f62-44cf-9c38-9d0aa950359d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603434512-172.17.0.19-1599363757157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-36c0c6ea-209e-4ae5-873c-7fd4cfee7661,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a65ece1f-e98e-4be1-82d4-966139f7512d,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-1313f607-1826-4c7b-939b-ef26a12ca825,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4e4e42ff-8c2b-4c85-8cef-b1daa321789e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-cec03ce1-434b-4915-a0d4-a8fd36728115,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-b57963fd-1c05-4d4d-b50e-322c6e21415e,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-42ea00c0-c1d6-43ac-940f-f2c217a03617,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-2616d718-5f62-44cf-9c38-9d0aa950359d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938217296-172.17.0.19-1599363818225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-6879e509-5a6a-4e80-8e5c-f096a597fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-92fd1094-ca1c-4fde-bf1c-c099dd9dd3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-a70fef2e-024f-4618-8edc-5357aeeadc38,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-80c92e9b-dd9a-4815-8237-0fe636e6946b,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e9632da0-2c1f-4508-8394-0b969e321534,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-116b236a-6953-4e9d-88ee-c0eb51b0707f,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-5e40d7a8-e915-4ddd-a6e6-6574ccb2c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-9eef6a66-9dd0-420d-9492-1b1c84d9da12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938217296-172.17.0.19-1599363818225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-6879e509-5a6a-4e80-8e5c-f096a597fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-92fd1094-ca1c-4fde-bf1c-c099dd9dd3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-a70fef2e-024f-4618-8edc-5357aeeadc38,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-80c92e9b-dd9a-4815-8237-0fe636e6946b,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-e9632da0-2c1f-4508-8394-0b969e321534,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-116b236a-6953-4e9d-88ee-c0eb51b0707f,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-5e40d7a8-e915-4ddd-a6e6-6574ccb2c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-9eef6a66-9dd0-420d-9492-1b1c84d9da12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061499755-172.17.0.19-1599363966017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46181,DS-fc09c593-1f94-4184-b6e0-c28ac2c53921,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-332447a2-0f36-4ee6-8f77-19aa18c5e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-05d6097e-9418-4cc0-8f84-56a08e84bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-70314d4f-44a6-44d2-b47b-3c51dbb11025,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-e4ac3cc0-f88c-4f71-b5f6-a28b29d2fb04,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-a831e811-fcd0-4658-ac09-272e69ebc404,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1a2eb881-ac9a-42dc-bba5-59111ffb3965,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-d81ae862-b736-41de-a81e-0ada9b6acec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061499755-172.17.0.19-1599363966017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46181,DS-fc09c593-1f94-4184-b6e0-c28ac2c53921,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-332447a2-0f36-4ee6-8f77-19aa18c5e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-05d6097e-9418-4cc0-8f84-56a08e84bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-70314d4f-44a6-44d2-b47b-3c51dbb11025,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-e4ac3cc0-f88c-4f71-b5f6-a28b29d2fb04,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-a831e811-fcd0-4658-ac09-272e69ebc404,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1a2eb881-ac9a-42dc-bba5-59111ffb3965,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-d81ae862-b736-41de-a81e-0ada9b6acec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893570962-172.17.0.19-1599364170651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-023a70ac-4e56-48a4-8450-c00869ec1fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b6aea4da-613d-4ea7-9eae-0ef95fdf5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-1313104a-9c39-4aaa-9467-ff4981e539ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-8c75ff44-e924-4fd2-beeb-6af75cf34b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-e116942f-010c-49e4-b606-0b8c3dcd5da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c3b31a7c-7c1d-4793-b9cd-91a6a9197a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-67437a5a-60ec-4c4a-b0e1-ba115b7ef6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-8fcc2e49-a495-46ff-88be-6c006e7a40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893570962-172.17.0.19-1599364170651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-023a70ac-4e56-48a4-8450-c00869ec1fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-b6aea4da-613d-4ea7-9eae-0ef95fdf5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-1313104a-9c39-4aaa-9467-ff4981e539ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-8c75ff44-e924-4fd2-beeb-6af75cf34b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-e116942f-010c-49e4-b606-0b8c3dcd5da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-c3b31a7c-7c1d-4793-b9cd-91a6a9197a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-67437a5a-60ec-4c4a-b0e1-ba115b7ef6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-8fcc2e49-a495-46ff-88be-6c006e7a40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893146340-172.17.0.19-1599364226341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-dd51d83d-c5d6-4e01-9815-973a9bd01f31,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-76c4de84-54ea-4977-8681-12a3e8931f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-37e2d933-0fe7-4b79-b813-03bb89675f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9354b347-f44a-4467-bffd-8effdddc9215,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-62c6ecac-e091-4848-aef4-7f96fa6f34dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-b29e14f0-6a93-41cc-87cf-49596b2ade01,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-5bb9ce52-a45e-4dc9-9582-67c49107ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5c4ef427-c906-4da3-bc6b-f2f707cc671a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893146340-172.17.0.19-1599364226341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-dd51d83d-c5d6-4e01-9815-973a9bd01f31,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-76c4de84-54ea-4977-8681-12a3e8931f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-37e2d933-0fe7-4b79-b813-03bb89675f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9354b347-f44a-4467-bffd-8effdddc9215,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-62c6ecac-e091-4848-aef4-7f96fa6f34dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-b29e14f0-6a93-41cc-87cf-49596b2ade01,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-5bb9ce52-a45e-4dc9-9582-67c49107ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5c4ef427-c906-4da3-bc6b-f2f707cc671a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801787887-172.17.0.19-1599364640103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-4ba88770-63a5-4084-933a-71284a423a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-98b90ebc-7994-4ebc-a453-7b0b88f36985,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-c443af14-e121-4ee6-99a9-030843558ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-823ab19d-e0a4-48b4-a585-1e5c07971f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e3b23bbd-3d8a-448b-90e0-c806aa2f006e,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-4c8c962e-992c-4a0d-be14-6c6c1daf2873,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-65f91d07-3b4d-40db-82d2-61f2fad406fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-d2c2c39d-a978-4fe0-95d7-c976e9b98574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801787887-172.17.0.19-1599364640103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-4ba88770-63a5-4084-933a-71284a423a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-98b90ebc-7994-4ebc-a453-7b0b88f36985,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-c443af14-e121-4ee6-99a9-030843558ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-823ab19d-e0a4-48b4-a585-1e5c07971f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e3b23bbd-3d8a-448b-90e0-c806aa2f006e,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-4c8c962e-992c-4a0d-be14-6c6c1daf2873,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-65f91d07-3b4d-40db-82d2-61f2fad406fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-d2c2c39d-a978-4fe0-95d7-c976e9b98574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4352
