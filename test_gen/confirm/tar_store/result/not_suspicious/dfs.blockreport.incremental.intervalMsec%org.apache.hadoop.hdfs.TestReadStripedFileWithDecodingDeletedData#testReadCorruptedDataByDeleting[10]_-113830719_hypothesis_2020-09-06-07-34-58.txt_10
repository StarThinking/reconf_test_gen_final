reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-de22fb73-fb01-4af1-8427-6061b8f7cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-476c46f9-01ca-4af9-979a-ab95f0921c60,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-fa578a67-ce99-4eb9-b6d1-9f4a441aa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d2c78c6b-4ee3-4c0c-9e6d-7074db2ac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-b6ce6e4d-bfbd-4743-9ff3-a815acc21e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-c2c6e9cd-a33a-4117-923e-582f45bade10,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-ac1edfe8-32fe-41ce-bed8-9668616eaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-24787a6b-27ff-4bb5-9ec4-75093d477cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-605b39b1-605b-4ff3-9e93-7279e023eadb,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-f67cefc4-575d-43c3-8c81-a7e961f9fc1f,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-f67cefc4-575d-43c3-8c81-a7e961f9fc1f,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-de22fb73-fb01-4af1-8427-6061b8f7cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-476c46f9-01ca-4af9-979a-ab95f0921c60,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-fa578a67-ce99-4eb9-b6d1-9f4a441aa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d2c78c6b-4ee3-4c0c-9e6d-7074db2ac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-b6ce6e4d-bfbd-4743-9ff3-a815acc21e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-c2c6e9cd-a33a-4117-923e-582f45bade10,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-ac1edfe8-32fe-41ce-bed8-9668616eaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-24787a6b-27ff-4bb5-9ec4-75093d477cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-605b39b1-605b-4ff3-9e93-7279e023eadb,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-f67cefc4-575d-43c3-8c81-a7e961f9fc1f,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-431229227-172.17.0.5-1599382598896:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-f67cefc4-575d-43c3-8c81-a7e961f9fc1f,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-35c592d3-f904-467b-b545-7d656d809ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-88dda98b-8e30-4ce0-aed5-af2b1ccf5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-315dd033-bb57-453b-a351-fa9950e6541b,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-d666b3d2-e66a-4ac0-a92c-d22247e66205,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-7e0a8178-5277-4df2-a275-2d94a56f177b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-a1168a94-dd89-4e8a-b291-bec96a169b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-f7582b81-b829-42b1-b8a6-773b6d99f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-62ae83e6-96c6-4244-ae39-bfc3d6d3b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-8bc4351e-2f70-46b1-a4fa-a22078b27df4,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b8c08184-c950-491a-abe4-8c222901984c,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b8c08184-c950-491a-abe4-8c222901984c,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-35c592d3-f904-467b-b545-7d656d809ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-88dda98b-8e30-4ce0-aed5-af2b1ccf5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-315dd033-bb57-453b-a351-fa9950e6541b,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-d666b3d2-e66a-4ac0-a92c-d22247e66205,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-7e0a8178-5277-4df2-a275-2d94a56f177b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-a1168a94-dd89-4e8a-b291-bec96a169b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-f7582b81-b829-42b1-b8a6-773b6d99f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-62ae83e6-96c6-4244-ae39-bfc3d6d3b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-8bc4351e-2f70-46b1-a4fa-a22078b27df4,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b8c08184-c950-491a-abe4-8c222901984c,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1954695571-172.17.0.5-1599382697241:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-b8c08184-c950-491a-abe4-8c222901984c,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-febafdf5-93f7-4720-adcc-834a91f41beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-53029143-ae77-4179-a85c-d5c5d2352083,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-30ea348b-8428-4cd4-b0a0-b5ffe062b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-ced64f25-936b-403b-9d44-cbe44c2cd672,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-7daa8ccd-e185-4b42-bebb-66e63439c497,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-5e50ea3a-4cc6-49ac-b18b-e8a6e88b15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-be9a31d7-5872-43d1-b4f9-03034a5fc7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-a580dcc5-efa3-473b-88e2-d53889e8b32a,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-137ec917-0d04-43d2-b498-ea27d6de569c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-4c14ad29-6083-4ae6-983d-b4dd0df7f010,DISK]]; indices=[7]}];  lastLocatedBlock=LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-4c14ad29-6083-4ae6-983d-b4dd0df7f010,DISK]]; indices=[7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-febafdf5-93f7-4720-adcc-834a91f41beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-53029143-ae77-4179-a85c-d5c5d2352083,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-30ea348b-8428-4cd4-b0a0-b5ffe062b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-ced64f25-936b-403b-9d44-cbe44c2cd672,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-7daa8ccd-e185-4b42-bebb-66e63439c497,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-5e50ea3a-4cc6-49ac-b18b-e8a6e88b15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-be9a31d7-5872-43d1-b4f9-03034a5fc7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-a580dcc5-efa3-473b-88e2-d53889e8b32a,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-137ec917-0d04-43d2-b498-ea27d6de569c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-4c14ad29-6083-4ae6-983d-b4dd0df7f010,DISK]]; indices=[7]}];  lastLocatedBlock=LocatedStripedBlock{BP-779837253-172.17.0.5-1599382879126:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-4c14ad29-6083-4ae6-983d-b4dd0df7f010,DISK]]; indices=[7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-64af838d-f83a-49b4-85db-83705ac0561b,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ae151763-3e1b-4b6a-8017-aecdcc41adc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-b933622f-ce37-4634-9221-a31c598ebf83,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f0758ea7-dbf1-4278-bb77-a7750328fe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-8531e118-693d-47c6-b767-0021acdac0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-8f76ec40-1278-4427-a92c-d7e32e07ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-4353939e-94ef-4cc5-8858-21d2848dc280,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-3b95bb03-f913-472d-a732-a364f25f0734,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-e5daeae7-fe6c-40da-9b16-5f83853df9df,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-bd8b5fab-ba8f-4eca-b8c6-41a044900f17,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-bd8b5fab-ba8f-4eca-b8c6-41a044900f17,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-64af838d-f83a-49b4-85db-83705ac0561b,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ae151763-3e1b-4b6a-8017-aecdcc41adc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-b933622f-ce37-4634-9221-a31c598ebf83,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f0758ea7-dbf1-4278-bb77-a7750328fe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-8531e118-693d-47c6-b767-0021acdac0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-8f76ec40-1278-4427-a92c-d7e32e07ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-4353939e-94ef-4cc5-8858-21d2848dc280,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-3b95bb03-f913-472d-a732-a364f25f0734,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-e5daeae7-fe6c-40da-9b16-5f83853df9df,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-bd8b5fab-ba8f-4eca-b8c6-41a044900f17,DISK]]; indices=[6]}];  lastLocatedBlock=LocatedStripedBlock{BP-1090344448-172.17.0.5-1599383251061:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-bd8b5fab-ba8f-4eca-b8c6-41a044900f17,DISK]]; indices=[6]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-7be277d4-d8bd-4615-943e-4d3363227cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-a8a0792e-8564-4dbb-b708-e998a08b48f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-af9c8078-6da4-478a-a3ea-81b5cf1b16d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-36d7b138-5a94-4616-89e1-1d7712534de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-50bd4935-c47d-45b3-bf37-a5243dd03f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f8f3aa16-1c96-4d73-89be-8f10fc24cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-0916fe27-f9fc-467c-ab1f-4b12cbb9e142,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-6807f0b4-b5e8-4f50-a55a-578ce94f66b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-825bdf56-bca7-4823-8881-a17b00678d03,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-acb0eaa7-e78c-4bdb-a57e-892ad7ea5879,DISK]]; indices=[0]}];  lastLocatedBlock=LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-acb0eaa7-e78c-4bdb-a57e-892ad7ea5879,DISK]]; indices=[0]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=123, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-7be277d4-d8bd-4615-943e-4d3363227cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-a8a0792e-8564-4dbb-b708-e998a08b48f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-af9c8078-6da4-478a-a3ea-81b5cf1b16d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-36d7b138-5a94-4616-89e1-1d7712534de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-50bd4935-c47d-45b3-bf37-a5243dd03f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f8f3aa16-1c96-4d73-89be-8f10fc24cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-0916fe27-f9fc-467c-ab1f-4b12cbb9e142,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-6807f0b4-b5e8-4f50-a55a-578ce94f66b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-825bdf56-bca7-4823-8881-a17b00678d03,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-acb0eaa7-e78c-4bdb-a57e-892ad7ea5879,DISK]]; indices=[0]}];  lastLocatedBlock=LocatedStripedBlock{BP-580402164-172.17.0.5-1599384554922:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-acb0eaa7-e78c-4bdb-a57e-892ad7ea5879,DISK]]; indices=[0]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[10]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 9132
