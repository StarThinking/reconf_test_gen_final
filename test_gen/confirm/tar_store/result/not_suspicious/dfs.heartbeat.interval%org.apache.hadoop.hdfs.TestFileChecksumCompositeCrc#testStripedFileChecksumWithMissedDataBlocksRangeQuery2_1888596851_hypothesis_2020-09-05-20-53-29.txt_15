reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944080616-172.17.0.3-1599339371105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-747bfd07-4459-42e8-b2a2-2858e29c61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-ce42c8ca-fc2a-49c0-9dbb-cf4dd010cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-2ea32a55-cd97-4a6b-8051-4a5f3564e683,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-bc5ac3f7-e194-4421-94b6-1ac8823a7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-09097543-133d-4a79-a652-9139633516d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-7b83f0de-2f68-4490-a6af-9aa6bba77cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-71fc3df3-8b04-4cee-adf4-47acd71a3509,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-a44feb42-c55a-46c5-83e6-83c928baf528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944080616-172.17.0.3-1599339371105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-747bfd07-4459-42e8-b2a2-2858e29c61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-ce42c8ca-fc2a-49c0-9dbb-cf4dd010cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-2ea32a55-cd97-4a6b-8051-4a5f3564e683,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-bc5ac3f7-e194-4421-94b6-1ac8823a7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-09097543-133d-4a79-a652-9139633516d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-7b83f0de-2f68-4490-a6af-9aa6bba77cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-71fc3df3-8b04-4cee-adf4-47acd71a3509,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-a44feb42-c55a-46c5-83e6-83c928baf528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200222819-172.17.0.3-1599339499786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-04d1303e-579d-4ccc-a4ab-2e1609fe2898,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7c9e9615-9378-4d9b-bbd4-92fedcd1760a,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-cdf7760c-86cb-47ae-a6c0-a7b2fe900a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-ce65413f-c83d-458a-b530-115a2d53456e,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-29dbdcf0-c806-4f95-a061-dab76dc047d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-032b776d-0ae9-49be-88d0-23c78ac6bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26d2311f-5513-48db-9b78-15debd499cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-28f6fce5-5d08-44a3-8436-da13a7693cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200222819-172.17.0.3-1599339499786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-04d1303e-579d-4ccc-a4ab-2e1609fe2898,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7c9e9615-9378-4d9b-bbd4-92fedcd1760a,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-cdf7760c-86cb-47ae-a6c0-a7b2fe900a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-ce65413f-c83d-458a-b530-115a2d53456e,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-29dbdcf0-c806-4f95-a061-dab76dc047d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-032b776d-0ae9-49be-88d0-23c78ac6bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-26d2311f-5513-48db-9b78-15debd499cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-28f6fce5-5d08-44a3-8436-da13a7693cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069173659-172.17.0.3-1599339533631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44618,DS-65627f93-75a0-4790-93f7-d8cf8bd3a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-1a08c4b2-96dc-453c-8632-25354df7d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-0e73b680-f15e-4726-a16c-b9d6af07206f,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-fb9cb8b9-ed08-4bc8-8e33-14c54d3cf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-6fb115fb-a422-4620-9857-cb52d50c0607,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-da5eb720-1e1e-4754-a2de-b0183a101da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-080d27d3-4857-45e0-b5f2-d9651c658adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-6c62ce2e-0526-4c5d-9335-4ba95619d5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069173659-172.17.0.3-1599339533631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44618,DS-65627f93-75a0-4790-93f7-d8cf8bd3a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-1a08c4b2-96dc-453c-8632-25354df7d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-0e73b680-f15e-4726-a16c-b9d6af07206f,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-fb9cb8b9-ed08-4bc8-8e33-14c54d3cf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-6fb115fb-a422-4620-9857-cb52d50c0607,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-da5eb720-1e1e-4754-a2de-b0183a101da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-080d27d3-4857-45e0-b5f2-d9651c658adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-6c62ce2e-0526-4c5d-9335-4ba95619d5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973761967-172.17.0.3-1599339671847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-6a0e2a09-a0be-4ddc-b84e-80e46c34dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-5c844b69-e215-4bdf-9341-b1fd2366c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-5ff288b2-f76f-4cc7-a935-5e2a7a85ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-4ac5d5da-83e0-4240-b047-6abd9c6e5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-9601a337-bfe6-4739-81ec-52f33bd0f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-90e60144-9302-4aa4-9afd-2a25e3ed04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-5394b394-7d37-45b6-86ba-15c991c0e794,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-7fd820ea-d745-49ab-8232-93226bc56c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973761967-172.17.0.3-1599339671847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35652,DS-6a0e2a09-a0be-4ddc-b84e-80e46c34dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-5c844b69-e215-4bdf-9341-b1fd2366c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-5ff288b2-f76f-4cc7-a935-5e2a7a85ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-4ac5d5da-83e0-4240-b047-6abd9c6e5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-9601a337-bfe6-4739-81ec-52f33bd0f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-90e60144-9302-4aa4-9afd-2a25e3ed04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-5394b394-7d37-45b6-86ba-15c991c0e794,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-7fd820ea-d745-49ab-8232-93226bc56c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407751527-172.17.0.3-1599340047080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-714cf3c4-c9ef-4944-b0c2-e9344d34774a,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-c9c45cc4-087a-4eb1-9326-05840127ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-25769e93-570d-4230-b47d-947e87efe15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-e19b5c32-e13a-4387-95eb-2d8ab18f8377,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-1213daba-70b5-43f8-82f4-374bf5036c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ba679533-daa2-4fd8-983c-6d1f8f16f478,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-2e2fc210-dc0b-48db-9dff-f84ff5797445,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-8ae0c2c8-7265-47fb-acb5-57caf63eb486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407751527-172.17.0.3-1599340047080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-714cf3c4-c9ef-4944-b0c2-e9344d34774a,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-c9c45cc4-087a-4eb1-9326-05840127ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-25769e93-570d-4230-b47d-947e87efe15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-e19b5c32-e13a-4387-95eb-2d8ab18f8377,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-1213daba-70b5-43f8-82f4-374bf5036c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ba679533-daa2-4fd8-983c-6d1f8f16f478,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-2e2fc210-dc0b-48db-9dff-f84ff5797445,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-8ae0c2c8-7265-47fb-acb5-57caf63eb486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927711690-172.17.0.3-1599340481463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-32a1b022-58c0-47c7-8f02-84a4ff84686d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-1eb19bf3-98d3-4630-a9c1-53143bb55ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-fe9dce90-a67f-4949-98cf-552718cc3bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-8cd9903a-3e8b-4a2c-80c6-759cc416e211,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-d65b1937-89f2-41e9-a63d-bca955f4e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-f210e47d-763d-4e60-9a67-7df94f1e1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-bfdbfc24-0ee7-476d-b98f-3814132cc41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-58d88b56-b6df-4dc8-898d-ef32dff50257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927711690-172.17.0.3-1599340481463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-32a1b022-58c0-47c7-8f02-84a4ff84686d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-1eb19bf3-98d3-4630-a9c1-53143bb55ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-fe9dce90-a67f-4949-98cf-552718cc3bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-8cd9903a-3e8b-4a2c-80c6-759cc416e211,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-d65b1937-89f2-41e9-a63d-bca955f4e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-f210e47d-763d-4e60-9a67-7df94f1e1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-bfdbfc24-0ee7-476d-b98f-3814132cc41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-58d88b56-b6df-4dc8-898d-ef32dff50257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264035435-172.17.0.3-1599340927271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-d7a51a38-5f78-4439-af20-4c306c57bc48,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-411aa29f-952e-420a-80a1-2d8d0241b670,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-4cab3898-a9ea-459a-962b-4d26c2288749,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-227eeda4-dee0-443d-a0c5-14374746cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-f7f2b100-0110-4224-bb8d-080c7b08c070,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-a1446acd-1896-4630-bd82-f409642276fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-3903891f-b30c-41f1-9edb-3720764e09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-e90a3b62-0607-4621-a599-43d0f38226c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264035435-172.17.0.3-1599340927271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-d7a51a38-5f78-4439-af20-4c306c57bc48,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-411aa29f-952e-420a-80a1-2d8d0241b670,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-4cab3898-a9ea-459a-962b-4d26c2288749,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-227eeda4-dee0-443d-a0c5-14374746cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-f7f2b100-0110-4224-bb8d-080c7b08c070,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-a1446acd-1896-4630-bd82-f409642276fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-3903891f-b30c-41f1-9edb-3720764e09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-e90a3b62-0607-4621-a599-43d0f38226c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461820103-172.17.0.3-1599341033835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42879,DS-af487900-b08e-4ac4-a534-63f5b2ca1449,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-9b84bc39-bee9-4827-b9f5-d49d99d70036,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-3c192f88-6a90-479f-b339-3c98466bb33f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-61bb464b-a5cb-4878-9fc7-031d4e98f364,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-4ba09500-3420-4395-b975-142b9c787a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-dc7f5c97-2630-4c88-9389-8d315fe2c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-20b3d41c-20b1-46f1-9620-769ad4dc84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-4b2f2538-66b4-4f4f-824c-2af0b02bb8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461820103-172.17.0.3-1599341033835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42879,DS-af487900-b08e-4ac4-a534-63f5b2ca1449,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-9b84bc39-bee9-4827-b9f5-d49d99d70036,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-3c192f88-6a90-479f-b339-3c98466bb33f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-61bb464b-a5cb-4878-9fc7-031d4e98f364,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-4ba09500-3420-4395-b975-142b9c787a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-dc7f5c97-2630-4c88-9389-8d315fe2c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-20b3d41c-20b1-46f1-9620-769ad4dc84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-4b2f2538-66b4-4f4f-824c-2af0b02bb8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142963874-172.17.0.3-1599341150628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-e5e2ca0c-5cb2-45fb-97e8-048774b1c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-c0f4465a-f116-4c06-8659-d953ab68f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-89b1641a-3947-4d1b-b708-7aec2c061121,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-eea3ebae-eef5-43e4-8e42-b6b02f6a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-cec28da3-d4cd-4312-92af-79629d9bbd31,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-dabe4faf-65e2-4556-9362-9a3d3d3f68d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-8c772828-b953-44fd-be5b-0424a81fcb63,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-052d61d5-f962-426f-9a29-5c31c03c69bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142963874-172.17.0.3-1599341150628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-e5e2ca0c-5cb2-45fb-97e8-048774b1c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-c0f4465a-f116-4c06-8659-d953ab68f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-89b1641a-3947-4d1b-b708-7aec2c061121,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-eea3ebae-eef5-43e4-8e42-b6b02f6a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-cec28da3-d4cd-4312-92af-79629d9bbd31,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-dabe4faf-65e2-4556-9362-9a3d3d3f68d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-8c772828-b953-44fd-be5b-0424a81fcb63,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-052d61d5-f962-426f-9a29-5c31c03c69bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663814715-172.17.0.3-1599341241374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-078061ef-aa48-462a-a0c9-7f807cef007f,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-1ca1b9c9-389a-4cdd-a9ab-e099e649c454,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-6d52ee68-113c-4603-bb39-702553077f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-1147d447-360f-43fc-a780-4e49c05dee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-8a185381-a511-4984-89aa-001550a7783e,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-a26e3eff-1258-4955-88ad-bb3c329b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-7417b6bd-df63-4b86-a0cf-1affb8c9d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-7187dba3-d769-4141-aa18-c572358f51d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663814715-172.17.0.3-1599341241374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-078061ef-aa48-462a-a0c9-7f807cef007f,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-1ca1b9c9-389a-4cdd-a9ab-e099e649c454,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-6d52ee68-113c-4603-bb39-702553077f39,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-1147d447-360f-43fc-a780-4e49c05dee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-8a185381-a511-4984-89aa-001550a7783e,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-a26e3eff-1258-4955-88ad-bb3c329b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-7417b6bd-df63-4b86-a0cf-1affb8c9d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-7187dba3-d769-4141-aa18-c572358f51d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123845981-172.17.0.3-1599341435352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-58e63e52-0d36-414b-aca6-6aabbd76683e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-0bfc3cb9-fa34-4331-a6cb-d8326cb7a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-af3233c7-81a0-4f29-8fe9-a6ca3f446588,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-16f27d97-e0bd-46ca-bbed-d2f25d4a966b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-49ca9241-a259-4ec0-8371-6c3f5b6ac250,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-c2387b38-d973-434e-8fd2-50201ca58037,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-891c7742-6104-4379-b398-44fa6f0ed2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-58eb8ab8-a685-4bec-bc7b-a80bbcd51e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123845981-172.17.0.3-1599341435352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-58e63e52-0d36-414b-aca6-6aabbd76683e,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-0bfc3cb9-fa34-4331-a6cb-d8326cb7a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-af3233c7-81a0-4f29-8fe9-a6ca3f446588,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-16f27d97-e0bd-46ca-bbed-d2f25d4a966b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-49ca9241-a259-4ec0-8371-6c3f5b6ac250,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-c2387b38-d973-434e-8fd2-50201ca58037,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-891c7742-6104-4379-b398-44fa6f0ed2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-58eb8ab8-a685-4bec-bc7b-a80bbcd51e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122262363-172.17.0.3-1599341653757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-4c853723-d9ff-4364-882d-9c3ca25b02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-ba38aa12-b974-4758-880a-a2af85009ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-b04dc332-ee8e-4bd5-b4c2-4b122fa661fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-739885ce-e800-4602-a29f-2468ce2762bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-26c4fe0b-5422-4396-960b-536d8e993c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-d7ddca56-6403-4116-83c4-a09b7fd3d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-d11b9180-f3b6-468b-8b28-56b57cd9e81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-b1583d4c-3c6a-4006-a444-ffde759350b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122262363-172.17.0.3-1599341653757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-4c853723-d9ff-4364-882d-9c3ca25b02e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-ba38aa12-b974-4758-880a-a2af85009ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-b04dc332-ee8e-4bd5-b4c2-4b122fa661fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-739885ce-e800-4602-a29f-2468ce2762bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-26c4fe0b-5422-4396-960b-536d8e993c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-d7ddca56-6403-4116-83c4-a09b7fd3d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-d11b9180-f3b6-468b-8b28-56b57cd9e81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-b1583d4c-3c6a-4006-a444-ffde759350b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074362894-172.17.0.3-1599342394071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-f224695b-1488-4481-baf6-bf9b6a7931e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-5b4feb56-b884-4838-b183-68f99d9d434b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-c32bfc02-148e-41bb-934f-ebfea36e6717,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-737433c2-f8f0-4f85-8e73-a35baec221e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-76a8d2d2-261b-45a1-9145-a46f18f76141,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-513826c4-cc85-40d0-865e-70518304c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-98d0b4c9-cc4a-409c-931d-17d0d04de41d,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-1378d0b1-12fd-4cd8-8f3e-e55b4fe4e8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074362894-172.17.0.3-1599342394071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-f224695b-1488-4481-baf6-bf9b6a7931e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-5b4feb56-b884-4838-b183-68f99d9d434b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-c32bfc02-148e-41bb-934f-ebfea36e6717,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-737433c2-f8f0-4f85-8e73-a35baec221e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-76a8d2d2-261b-45a1-9145-a46f18f76141,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-513826c4-cc85-40d0-865e-70518304c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-98d0b4c9-cc4a-409c-931d-17d0d04de41d,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-1378d0b1-12fd-4cd8-8f3e-e55b4fe4e8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400277242-172.17.0.3-1599342464219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40681,DS-2b7d304d-4cd8-46b2-abab-ccc600545192,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-6774bef4-1998-4635-aae1-08c4a50f60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-bed0213f-fc68-48bd-8ece-bbfbc5a266ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-230ff1ec-1649-4a26-bfe1-2e877d895026,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-26ce6b62-3eb7-4e7a-9f20-212f971ed225,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-50b75c17-4eb3-4a9a-a2d6-91dd93cba8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1cd99eef-c5c3-4f3b-aec5-dbe98badda65,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-779ef31c-6543-4756-ac8c-ec984bd46b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400277242-172.17.0.3-1599342464219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40681,DS-2b7d304d-4cd8-46b2-abab-ccc600545192,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-6774bef4-1998-4635-aae1-08c4a50f60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-bed0213f-fc68-48bd-8ece-bbfbc5a266ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-230ff1ec-1649-4a26-bfe1-2e877d895026,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-26ce6b62-3eb7-4e7a-9f20-212f971ed225,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-50b75c17-4eb3-4a9a-a2d6-91dd93cba8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1cd99eef-c5c3-4f3b-aec5-dbe98badda65,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-779ef31c-6543-4756-ac8c-ec984bd46b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480543802-172.17.0.3-1599342788941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-35d0559a-6054-4ff5-8f6c-d24d0a8e0697,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-94c9aeba-5695-416f-9571-bf7dbed3261d,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-56c42c1e-c434-4104-b3f6-d05615d990d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b610a7f5-d861-4171-b259-7fc79d0260ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-8e14becc-c427-4822-8c63-076adefe7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-f511702e-f41a-4b1f-8e43-e1384a9049dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ab293132-5ea8-400f-b26f-1cefc6806454,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-45e322b1-e5b7-4cbd-8911-af4f9e4c70db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480543802-172.17.0.3-1599342788941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-35d0559a-6054-4ff5-8f6c-d24d0a8e0697,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-94c9aeba-5695-416f-9571-bf7dbed3261d,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-56c42c1e-c434-4104-b3f6-d05615d990d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b610a7f5-d861-4171-b259-7fc79d0260ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-8e14becc-c427-4822-8c63-076adefe7eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-f511702e-f41a-4b1f-8e43-e1384a9049dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-ab293132-5ea8-400f-b26f-1cefc6806454,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-45e322b1-e5b7-4cbd-8911-af4f9e4c70db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040126852-172.17.0.3-1599343148902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-d610d6aa-f9af-41ec-8410-faf6857ba43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-c98d26b1-7562-4cc1-ab25-15cfc7035b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-5e810f0e-dcdb-422d-864c-c6391ce2b43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-d27cd01a-289f-4b42-a784-30e144ca5947,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4f2d5a2b-9ada-4525-9660-01a0b9dedf85,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-66abf7be-7543-41de-8fde-9aa3cfdd04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-f86aaac1-da44-4fc4-83be-4634dde8c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-d80f01a3-e72e-40f8-ac5d-3789990c7d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040126852-172.17.0.3-1599343148902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-d610d6aa-f9af-41ec-8410-faf6857ba43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-c98d26b1-7562-4cc1-ab25-15cfc7035b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-5e810f0e-dcdb-422d-864c-c6391ce2b43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-d27cd01a-289f-4b42-a784-30e144ca5947,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4f2d5a2b-9ada-4525-9660-01a0b9dedf85,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-66abf7be-7543-41de-8fde-9aa3cfdd04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-f86aaac1-da44-4fc4-83be-4634dde8c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-d80f01a3-e72e-40f8-ac5d-3789990c7d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975941038-172.17.0.3-1599343216413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-f109931e-d162-4945-bd15-aa419e90a716,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-189e41df-2e35-4f1a-9d4f-80f89108d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-de030a2f-e1e6-4d15-8dd4-7fba3a2d5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-b7eb3953-d9a6-481d-9210-798938e1608e,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-63244180-e543-4d95-86d1-beb4c4bc1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-5f0d96ac-d133-4636-8ea6-d399f18029d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-7e728e8d-4af3-48d9-908f-80cc308d19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-3e3b9e2c-0349-4ece-900b-3d03d8c0d28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975941038-172.17.0.3-1599343216413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37596,DS-f109931e-d162-4945-bd15-aa419e90a716,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-189e41df-2e35-4f1a-9d4f-80f89108d52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-de030a2f-e1e6-4d15-8dd4-7fba3a2d5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-b7eb3953-d9a6-481d-9210-798938e1608e,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-63244180-e543-4d95-86d1-beb4c4bc1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-5f0d96ac-d133-4636-8ea6-d399f18029d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-7e728e8d-4af3-48d9-908f-80cc308d19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-3e3b9e2c-0349-4ece-900b-3d03d8c0d28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311239756-172.17.0.3-1599343448348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-521d82bb-07c0-4929-86e2-6faa5ff8c945,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-5d27af79-1493-44a9-b282-cdaacbf24fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-a9b8a77f-0169-43d5-a56c-ca4225b39d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-8da386a9-b5c0-4ccf-a534-d38533cfe30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-2758136b-d94b-4f38-a350-8e3608c978ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-64a7897f-0145-455e-85ec-31afa3813ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-eba627f2-bac1-4eaa-aa38-6dc1e921f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-02e9623d-2386-4cc7-b7e6-c9fda72a3c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311239756-172.17.0.3-1599343448348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-521d82bb-07c0-4929-86e2-6faa5ff8c945,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-5d27af79-1493-44a9-b282-cdaacbf24fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-a9b8a77f-0169-43d5-a56c-ca4225b39d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-8da386a9-b5c0-4ccf-a534-d38533cfe30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-2758136b-d94b-4f38-a350-8e3608c978ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-64a7897f-0145-455e-85ec-31afa3813ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-eba627f2-bac1-4eaa-aa38-6dc1e921f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-02e9623d-2386-4cc7-b7e6-c9fda72a3c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274434326-172.17.0.3-1599343477820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-e905db12-5460-413a-b152-169cb4fd3207,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-e6ea8f34-b0a5-4bab-a81d-cf63feb9a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-cc594f72-c085-4d52-9805-b0a92762038e,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-528d45f6-a9c0-43c9-bfc0-5ff01780ecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-3a78454f-d39a-45cf-ac5c-d5e16c90983b,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-8e135e7b-2a67-4e3b-a5c8-011a39023341,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-5e295a56-40b5-4cac-9fdc-38403e207efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-a657517a-d621-4961-8855-71724a373c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274434326-172.17.0.3-1599343477820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-e905db12-5460-413a-b152-169cb4fd3207,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-e6ea8f34-b0a5-4bab-a81d-cf63feb9a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-cc594f72-c085-4d52-9805-b0a92762038e,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-528d45f6-a9c0-43c9-bfc0-5ff01780ecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-3a78454f-d39a-45cf-ac5c-d5e16c90983b,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-8e135e7b-2a67-4e3b-a5c8-011a39023341,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-5e295a56-40b5-4cac-9fdc-38403e207efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-a657517a-d621-4961-8855-71724a373c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325343587-172.17.0.3-1599343512808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-59f79f60-85bc-4dfd-a83c-7a529ea66f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-9b81316c-bbb4-48ed-b227-fed70d910e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-18a616da-fb5a-4ce9-948a-4a39131c673a,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-17afa1d2-7e09-4ecf-a4ad-5f18d8f2acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2098fc85-1d1c-4353-8503-a01dc1209c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-9a179525-75cd-455b-ba81-41e0f3a12078,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-74d3bc05-3ba0-40c5-97d1-b6180d909b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-48df4284-f5e5-4cf2-bf33-f378e5a7955c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325343587-172.17.0.3-1599343512808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-59f79f60-85bc-4dfd-a83c-7a529ea66f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-9b81316c-bbb4-48ed-b227-fed70d910e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-18a616da-fb5a-4ce9-948a-4a39131c673a,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-17afa1d2-7e09-4ecf-a4ad-5f18d8f2acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2098fc85-1d1c-4353-8503-a01dc1209c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-9a179525-75cd-455b-ba81-41e0f3a12078,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-74d3bc05-3ba0-40c5-97d1-b6180d909b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-48df4284-f5e5-4cf2-bf33-f378e5a7955c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993216048-172.17.0.3-1599343610524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-15553029-4882-44b6-bf84-b38f502c94e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-0b5985b7-92e1-4b50-8800-5c6099adbd45,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-d8186194-fa4a-4e0c-bc4f-ffe09e499dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-e8e03c98-c58c-47e2-98ac-f2a39bad4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-7e44b511-1e8a-45fd-b7ec-ab47079ea73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8683b15a-fe16-48d8-bf7b-a8b603164ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-cee00104-a175-4522-8ccb-33a55d6c4824,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-b4909da9-da81-47e0-a52a-95f723c0ebc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993216048-172.17.0.3-1599343610524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-15553029-4882-44b6-bf84-b38f502c94e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-0b5985b7-92e1-4b50-8800-5c6099adbd45,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-d8186194-fa4a-4e0c-bc4f-ffe09e499dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-e8e03c98-c58c-47e2-98ac-f2a39bad4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-7e44b511-1e8a-45fd-b7ec-ab47079ea73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8683b15a-fe16-48d8-bf7b-a8b603164ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-cee00104-a175-4522-8ccb-33a55d6c4824,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-b4909da9-da81-47e0-a52a-95f723c0ebc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187329399-172.17.0.3-1599343802729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-461d4bd8-b10c-4551-9829-8db71163baae,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-eafcc164-4e89-469e-a97a-1e9221296dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-800ec5ec-aa08-4e92-befa-23d0fd427ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-b20d8449-6228-40ff-ac1b-f7e35e70bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-28c04e83-5c78-4907-985a-57306cdbc138,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-72b3df1b-128f-4d5a-a7c8-4afc058e067d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-23eb936d-227c-47ec-9e00-c52e7a1bd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-2f021781-eca8-4f3f-b8a6-bac225f3cb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187329399-172.17.0.3-1599343802729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-461d4bd8-b10c-4551-9829-8db71163baae,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-eafcc164-4e89-469e-a97a-1e9221296dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-800ec5ec-aa08-4e92-befa-23d0fd427ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-b20d8449-6228-40ff-ac1b-f7e35e70bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-28c04e83-5c78-4907-985a-57306cdbc138,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-72b3df1b-128f-4d5a-a7c8-4afc058e067d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-23eb936d-227c-47ec-9e00-c52e7a1bd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-2f021781-eca8-4f3f-b8a6-bac225f3cb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5173
