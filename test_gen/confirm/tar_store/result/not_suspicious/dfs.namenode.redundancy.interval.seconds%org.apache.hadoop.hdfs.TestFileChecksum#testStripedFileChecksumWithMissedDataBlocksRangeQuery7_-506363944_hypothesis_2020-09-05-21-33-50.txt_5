reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020180822-172.17.0.21-1599341705769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36413,DS-d42861a0-8ef4-4ee4-a378-3a8ec7b3ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-7d60d87c-6cec-41a0-89b4-e48843cf8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-acdf8827-2fea-462d-9646-6a9848676a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-f25a9a4c-6bd4-4809-90bd-1c87bcb0262d,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-38c0792e-6099-4e72-bc86-f1d982ed6485,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-fc6da01d-c51d-4400-a04e-beb01b92e979,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-7f88ab29-b832-4d5c-b0a0-86e0dab8e392,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a7463d23-9139-4a14-938a-eea3207771d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020180822-172.17.0.21-1599341705769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36413,DS-d42861a0-8ef4-4ee4-a378-3a8ec7b3ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-7d60d87c-6cec-41a0-89b4-e48843cf8d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-acdf8827-2fea-462d-9646-6a9848676a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-f25a9a4c-6bd4-4809-90bd-1c87bcb0262d,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-38c0792e-6099-4e72-bc86-f1d982ed6485,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-fc6da01d-c51d-4400-a04e-beb01b92e979,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-7f88ab29-b832-4d5c-b0a0-86e0dab8e392,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a7463d23-9139-4a14-938a-eea3207771d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400214174-172.17.0.21-1599341739037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-b95b39f9-8304-4ba6-98c6-2cd5f4c3fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-cceca56f-fe22-4b92-b4ae-835035bb712c,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-59a27a6f-9ca8-4087-a5bf-b839c338fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-d7325d70-3666-452b-a30f-3f02f756234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-67a0c610-0cbd-4cc4-adbd-5ee7a84892ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-d26e020e-0b2a-4ef8-9ae5-63be139777a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-32598733-4b0a-438f-8f5f-d2f85d42aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-5f9f0433-96b5-4cb7-b494-50455498d5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400214174-172.17.0.21-1599341739037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37292,DS-b95b39f9-8304-4ba6-98c6-2cd5f4c3fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-cceca56f-fe22-4b92-b4ae-835035bb712c,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-59a27a6f-9ca8-4087-a5bf-b839c338fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-d7325d70-3666-452b-a30f-3f02f756234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-67a0c610-0cbd-4cc4-adbd-5ee7a84892ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-d26e020e-0b2a-4ef8-9ae5-63be139777a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-32598733-4b0a-438f-8f5f-d2f85d42aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-5f9f0433-96b5-4cb7-b494-50455498d5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526105989-172.17.0.21-1599341925816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-c6eaba0d-9945-49d2-a257-a3413cfeba75,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-8147b4ff-5cd1-44fb-8a06-2eb36a537724,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-9329b98b-1d7a-4038-a64f-6120a386f586,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-71c81716-5552-44d3-90f8-8a905fb46807,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-1257cb6d-237b-4633-97f2-fd3a64febaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-9cdfd80e-b236-4ed3-99e5-cd69eaf325ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4952d3b1-9e28-4c3b-a1d7-033e2b64bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-5eaa1dad-8243-4a92-b0d5-e55b4688ac2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526105989-172.17.0.21-1599341925816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-c6eaba0d-9945-49d2-a257-a3413cfeba75,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-8147b4ff-5cd1-44fb-8a06-2eb36a537724,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-9329b98b-1d7a-4038-a64f-6120a386f586,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-71c81716-5552-44d3-90f8-8a905fb46807,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-1257cb6d-237b-4633-97f2-fd3a64febaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-9cdfd80e-b236-4ed3-99e5-cd69eaf325ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4952d3b1-9e28-4c3b-a1d7-033e2b64bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-5eaa1dad-8243-4a92-b0d5-e55b4688ac2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039830711-172.17.0.21-1599342536781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-95589520-03c1-4ec9-a1fc-5f717944fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-4c889008-26b5-4842-8955-dd60e8661a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-8dd15af8-077b-44d3-a01e-999274b75b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-c3c44580-036e-4bf5-94b4-b0dc1aae14cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-006dbd39-b48c-4292-8e5d-18503efcd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-359e07fd-b331-40cd-aca6-ac040ce4093c,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-4cbaba1b-0e35-401e-8adf-86d4d92d0dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-e68c1b68-48c0-4be0-bb01-8dfc1658f594,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039830711-172.17.0.21-1599342536781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-95589520-03c1-4ec9-a1fc-5f717944fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-4c889008-26b5-4842-8955-dd60e8661a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-8dd15af8-077b-44d3-a01e-999274b75b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-c3c44580-036e-4bf5-94b4-b0dc1aae14cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-006dbd39-b48c-4292-8e5d-18503efcd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-359e07fd-b331-40cd-aca6-ac040ce4093c,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-4cbaba1b-0e35-401e-8adf-86d4d92d0dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-e68c1b68-48c0-4be0-bb01-8dfc1658f594,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999512276-172.17.0.21-1599342666380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-eaf1e549-d87f-45ae-90f3-2ac9fc4e7a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-8877ac29-8989-47d5-adf9-0df1b7727a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-43921a02-04f4-4469-b532-15e3c9b26f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-6b0c2465-ffd0-48af-bf81-510d5140c023,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-3a60ac1b-c776-4bcc-b536-418237329632,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-261e8fb3-2dee-4c6b-b0e7-9f6987904b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-73c98851-901e-44e8-b796-dfebffd16c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-d666d796-d2c2-455c-9edd-ecbd8142dc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999512276-172.17.0.21-1599342666380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-eaf1e549-d87f-45ae-90f3-2ac9fc4e7a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-8877ac29-8989-47d5-adf9-0df1b7727a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-43921a02-04f4-4469-b532-15e3c9b26f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-6b0c2465-ffd0-48af-bf81-510d5140c023,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-3a60ac1b-c776-4bcc-b536-418237329632,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-261e8fb3-2dee-4c6b-b0e7-9f6987904b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-73c98851-901e-44e8-b796-dfebffd16c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-d666d796-d2c2-455c-9edd-ecbd8142dc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531415564-172.17.0.21-1599343095575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-dd465e24-c31e-42c5-8436-781b3b1af971,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-09f493f2-ac79-4193-ace9-5eb2da25116d,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-a989c6da-fcd7-4407-a6af-f8e145fb277a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b2b3a52a-7ef8-4129-b680-ff9a137cf708,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-7772acf0-eb57-4aa6-9031-4cf323b6a022,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-026c1b61-7b42-4838-8b96-7e92c06ce88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-584bebff-504e-4ced-a6e4-f9e3ed30a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-87d45b98-297b-4424-a11b-cc796c73c738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531415564-172.17.0.21-1599343095575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-dd465e24-c31e-42c5-8436-781b3b1af971,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-09f493f2-ac79-4193-ace9-5eb2da25116d,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-a989c6da-fcd7-4407-a6af-f8e145fb277a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b2b3a52a-7ef8-4129-b680-ff9a137cf708,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-7772acf0-eb57-4aa6-9031-4cf323b6a022,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-026c1b61-7b42-4838-8b96-7e92c06ce88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-584bebff-504e-4ced-a6e4-f9e3ed30a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-87d45b98-297b-4424-a11b-cc796c73c738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905740562-172.17.0.21-1599343354297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-34815e88-63e0-4831-a2a7-b49150760ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-41c4bdd4-b8fe-4849-b202-a3bbc98e9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-e511e629-039f-489d-ada9-4a7c934e9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b3c7c4ac-86ab-449c-841e-705646921d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-8aa27b41-9901-4109-8b36-450b002edeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-6025fd77-32cd-4aaa-b207-8ade253bd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-08fc9510-bc0e-4086-a2a7-35c3a1210dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d43ef7b6-de72-4200-8a3a-ee55f5c69465,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905740562-172.17.0.21-1599343354297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-34815e88-63e0-4831-a2a7-b49150760ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-41c4bdd4-b8fe-4849-b202-a3bbc98e9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-e511e629-039f-489d-ada9-4a7c934e9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b3c7c4ac-86ab-449c-841e-705646921d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-8aa27b41-9901-4109-8b36-450b002edeec,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-6025fd77-32cd-4aaa-b207-8ade253bd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-08fc9510-bc0e-4086-a2a7-35c3a1210dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d43ef7b6-de72-4200-8a3a-ee55f5c69465,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107607807-172.17.0.21-1599343383892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-82b9e206-6ed0-4477-b5c5-fcd078e50de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-2260c1f7-465b-4a06-90f8-7d6c5dc86ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-be61a449-6d85-4b6f-9a2f-fc0a7272e62f,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-4e6c6549-7786-42e5-af0b-d24fec4a938b,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-04920056-164b-4c53-b22e-55aceffe55b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-5f66fb14-19e0-4411-b7e1-a0c84b861088,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-59013213-933c-4483-bfc6-ecdae5d8db38,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-fc26b336-37c3-49d2-bfba-6b3e33eda0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107607807-172.17.0.21-1599343383892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-82b9e206-6ed0-4477-b5c5-fcd078e50de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-2260c1f7-465b-4a06-90f8-7d6c5dc86ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-be61a449-6d85-4b6f-9a2f-fc0a7272e62f,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-4e6c6549-7786-42e5-af0b-d24fec4a938b,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-04920056-164b-4c53-b22e-55aceffe55b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-5f66fb14-19e0-4411-b7e1-a0c84b861088,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-59013213-933c-4483-bfc6-ecdae5d8db38,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-fc26b336-37c3-49d2-bfba-6b3e33eda0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211408712-172.17.0.21-1599343491789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-eb51c88b-30f6-42e7-beb1-93d0d48ee12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-d69c5bb9-227b-4a43-a807-48c1cf9233a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-bdb64876-779e-414f-b4b9-41009d174419,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-d6d41f31-a3e9-4499-ae5a-2c307faea0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-eb9e3aac-cea0-4202-84d2-66f1816a0970,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-51cbebf1-be2f-42a9-86ac-d38a889cd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ba3b0e8c-260d-43a3-8ca3-92ce232f52d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-b3de9442-5c70-4276-8645-0e885c15c403,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211408712-172.17.0.21-1599343491789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-eb51c88b-30f6-42e7-beb1-93d0d48ee12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-d69c5bb9-227b-4a43-a807-48c1cf9233a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-bdb64876-779e-414f-b4b9-41009d174419,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-d6d41f31-a3e9-4499-ae5a-2c307faea0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-eb9e3aac-cea0-4202-84d2-66f1816a0970,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-51cbebf1-be2f-42a9-86ac-d38a889cd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ba3b0e8c-260d-43a3-8ca3-92ce232f52d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-b3de9442-5c70-4276-8645-0e885c15c403,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649552204-172.17.0.21-1599343859363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-c564d38e-edb5-442b-b3e4-631b67064134,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-2c35cd77-4c49-4e36-a29f-1731950bdd36,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0679533b-7a0c-40d1-944d-56a4e6c0dae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-56396dd6-a4ed-495f-81c9-a4c3be7481a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-a8dc5b2c-910f-458f-94bf-64a951ff23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-a5ad12c9-e976-49bd-b986-146e25c41570,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-51bd2690-0ce9-4a97-bc13-7dad9bf40e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-e8c50f96-db3c-4f03-a3d0-cf14665d87b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649552204-172.17.0.21-1599343859363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-c564d38e-edb5-442b-b3e4-631b67064134,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-2c35cd77-4c49-4e36-a29f-1731950bdd36,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-0679533b-7a0c-40d1-944d-56a4e6c0dae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-56396dd6-a4ed-495f-81c9-a4c3be7481a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-a8dc5b2c-910f-458f-94bf-64a951ff23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-a5ad12c9-e976-49bd-b986-146e25c41570,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-51bd2690-0ce9-4a97-bc13-7dad9bf40e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-e8c50f96-db3c-4f03-a3d0-cf14665d87b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617111327-172.17.0.21-1599343998794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-2f1e0895-9dc5-4a68-910a-af21871def3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-9ee87556-a9b0-4363-b0f0-c72406550ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-154e61fe-9b20-4c54-970f-19dfa11d2883,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-d8f4cfb0-4166-494c-a735-4f503ce18052,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-a43134d9-a6d8-44ae-8440-bbda9c888d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-a19ad85d-6796-47ba-8fa7-7a64859b4f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-7e73bc06-2b28-44ec-8e72-778d2e95188c,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-73ab4622-af2a-47da-a692-84ccd87d3e31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617111327-172.17.0.21-1599343998794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-2f1e0895-9dc5-4a68-910a-af21871def3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-9ee87556-a9b0-4363-b0f0-c72406550ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-154e61fe-9b20-4c54-970f-19dfa11d2883,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-d8f4cfb0-4166-494c-a735-4f503ce18052,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-a43134d9-a6d8-44ae-8440-bbda9c888d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-a19ad85d-6796-47ba-8fa7-7a64859b4f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-7e73bc06-2b28-44ec-8e72-778d2e95188c,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-73ab4622-af2a-47da-a692-84ccd87d3e31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179601601-172.17.0.21-1599344079834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-d24d932b-5ed7-4946-a890-ba5f3f460dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-ee47d9c3-67af-4ff1-9632-da6e12cd116e,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-d1892cba-caa6-4563-9306-099e7a43ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-f7d11f75-3808-4a50-8c5b-a49bfddc3761,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-01eaa78c-7926-44ce-8fdf-ca58f141271e,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-12273206-a1d5-4f47-844b-e4bd71fcdff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9787dcde-e258-4a9a-bd5c-b6243f1509b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-c5a0d0ca-b300-484b-a5b9-38e002aad0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179601601-172.17.0.21-1599344079834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-d24d932b-5ed7-4946-a890-ba5f3f460dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-ee47d9c3-67af-4ff1-9632-da6e12cd116e,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-d1892cba-caa6-4563-9306-099e7a43ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-f7d11f75-3808-4a50-8c5b-a49bfddc3761,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-01eaa78c-7926-44ce-8fdf-ca58f141271e,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-12273206-a1d5-4f47-844b-e4bd71fcdff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9787dcde-e258-4a9a-bd5c-b6243f1509b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-c5a0d0ca-b300-484b-a5b9-38e002aad0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365204387-172.17.0.21-1599344519141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-0be5af64-4aa4-49ef-8787-28b7b81c28a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-12b7f0fb-b854-44b6-8673-97e35c0950ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-823e1a9b-9f56-4825-94d9-43db723e7916,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-aa23a2ce-8e51-4d41-ae28-d5f8722f4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-7abcfc0f-0dd6-4180-a82c-258c4670b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2499dc33-fb86-4076-8ec0-d07d5ca6d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-349b669d-6413-4d30-a901-456cf35f398e,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-ef041e6b-6d5f-4ce0-945b-d7dfeca6ab60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365204387-172.17.0.21-1599344519141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-0be5af64-4aa4-49ef-8787-28b7b81c28a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-12b7f0fb-b854-44b6-8673-97e35c0950ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-823e1a9b-9f56-4825-94d9-43db723e7916,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-aa23a2ce-8e51-4d41-ae28-d5f8722f4fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-7abcfc0f-0dd6-4180-a82c-258c4670b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2499dc33-fb86-4076-8ec0-d07d5ca6d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-349b669d-6413-4d30-a901-456cf35f398e,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-ef041e6b-6d5f-4ce0-945b-d7dfeca6ab60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838778480-172.17.0.21-1599344618606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-aaf9503d-2d2b-454a-9ee4-08087963386e,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-09399e5d-febd-473d-8d52-ee27d3aa4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-045c2a64-000e-4cd0-a786-3e335f3fc266,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-781b23f3-3376-4828-ade5-d3707ee5f5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-fb9088fd-dabc-4cc7-baad-0e507ba6f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-c70c6cc1-78e8-4bd0-8a7f-1213716033b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7a787783-c3da-4d88-8b34-4de22877bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-bfe6dcaa-1ebe-4b5c-8b40-44ab204caf96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838778480-172.17.0.21-1599344618606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-aaf9503d-2d2b-454a-9ee4-08087963386e,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-09399e5d-febd-473d-8d52-ee27d3aa4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-045c2a64-000e-4cd0-a786-3e335f3fc266,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-781b23f3-3376-4828-ade5-d3707ee5f5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-fb9088fd-dabc-4cc7-baad-0e507ba6f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-c70c6cc1-78e8-4bd0-8a7f-1213716033b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7a787783-c3da-4d88-8b34-4de22877bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-bfe6dcaa-1ebe-4b5c-8b40-44ab204caf96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667580257-172.17.0.21-1599344891920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-7cc3e58c-ebb8-4551-86ef-6af43b4335ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-5724dce2-df47-4d44-a0f5-443d6751cb13,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-f44ceaac-04ca-49e1-ac69-9fddc4a5e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-a0f67768-78cb-499d-aa70-61cd5e16aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b5f75220-fa56-4d92-a190-2db849ed4421,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-ccec1f00-8ffe-4bc6-b3bf-cc71ad58b872,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b698ce53-3064-4a22-8c90-64fadc5919b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5fe657cf-5af5-45b7-b07b-a5351f45458b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667580257-172.17.0.21-1599344891920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-7cc3e58c-ebb8-4551-86ef-6af43b4335ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-5724dce2-df47-4d44-a0f5-443d6751cb13,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-f44ceaac-04ca-49e1-ac69-9fddc4a5e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-a0f67768-78cb-499d-aa70-61cd5e16aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b5f75220-fa56-4d92-a190-2db849ed4421,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-ccec1f00-8ffe-4bc6-b3bf-cc71ad58b872,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b698ce53-3064-4a22-8c90-64fadc5919b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-5fe657cf-5af5-45b7-b07b-a5351f45458b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530171387-172.17.0.21-1599344988737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-1dee3690-baaa-4f97-8033-d0920a48e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-298bd2a0-58da-4c6b-9497-eff299958c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-6fa1317b-333f-48e5-b461-819ae71eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-60f82254-38d2-4003-b4b0-f5e2dcb304f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-36004fdb-eeda-4bd1-acee-5c8627652b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-d19aebd5-a138-45e4-88f7-f1a8b092c856,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-cd818cb4-1e4b-4646-bc98-404ef7bfc50f,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-4b9ae522-bd74-4015-bd25-5515db1c0ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530171387-172.17.0.21-1599344988737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-1dee3690-baaa-4f97-8033-d0920a48e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-298bd2a0-58da-4c6b-9497-eff299958c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-6fa1317b-333f-48e5-b461-819ae71eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-60f82254-38d2-4003-b4b0-f5e2dcb304f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-36004fdb-eeda-4bd1-acee-5c8627652b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-d19aebd5-a138-45e4-88f7-f1a8b092c856,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-cd818cb4-1e4b-4646-bc98-404ef7bfc50f,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-4b9ae522-bd74-4015-bd25-5515db1c0ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900092387-172.17.0.21-1599345040604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-bc838b61-2e52-4848-9216-2aa16951201d,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-f713aeec-2b8b-410b-b4d9-3dcaeeea2282,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-573b8cab-359f-41d3-9042-675b367f5357,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-5f85ad87-5ec0-4064-b50e-12328c0f5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-c7f61005-8d09-4d8c-9012-f61e374e5cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1addea37-880a-4cbd-a1ad-479d833aa2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-ea0c47c7-88bd-410e-bd3d-aa51ad2fc6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-61524fbd-ef63-4fc3-b871-6c6387f068dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900092387-172.17.0.21-1599345040604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-bc838b61-2e52-4848-9216-2aa16951201d,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-f713aeec-2b8b-410b-b4d9-3dcaeeea2282,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-573b8cab-359f-41d3-9042-675b367f5357,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-5f85ad87-5ec0-4064-b50e-12328c0f5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-c7f61005-8d09-4d8c-9012-f61e374e5cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1addea37-880a-4cbd-a1ad-479d833aa2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-ea0c47c7-88bd-410e-bd3d-aa51ad2fc6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-61524fbd-ef63-4fc3-b871-6c6387f068dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188054573-172.17.0.21-1599345089487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43704,DS-d0136703-ce2a-4a3e-a4ee-3cfe400de100,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-0eecb912-3728-47bb-a97d-23fbfff3b983,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-58f29658-0249-4b23-b27a-b5eca1b35037,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-11bfc780-2b0c-40c4-8473-25662bd8eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-03b23309-70c3-4bb2-b309-c3a82c258010,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-0531acad-a808-451a-a176-0e9901773729,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-305f875b-8692-4d94-8226-74ca64f07f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-fd673167-b081-4527-ae98-a5f970142ffb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188054573-172.17.0.21-1599345089487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43704,DS-d0136703-ce2a-4a3e-a4ee-3cfe400de100,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-0eecb912-3728-47bb-a97d-23fbfff3b983,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-58f29658-0249-4b23-b27a-b5eca1b35037,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-11bfc780-2b0c-40c4-8473-25662bd8eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-03b23309-70c3-4bb2-b309-c3a82c258010,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-0531acad-a808-451a-a176-0e9901773729,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-305f875b-8692-4d94-8226-74ca64f07f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-fd673167-b081-4527-ae98-a5f970142ffb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351818717-172.17.0.21-1599345155804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-86d93e15-8c7c-4c42-8400-61c0ac498d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b53d530b-7e3c-4cb1-a5ec-2fc90a62f92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-799c83ca-18ea-4bb8-a1d6-303bec4ef7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-8579e62c-a2e6-49b5-a622-d1a1888884b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-3a8e182d-0460-4bc9-9394-1f3febce85a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-eb488570-3417-4d80-916c-59a359fdfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-4b8925ee-30ab-4da8-800b-99a2406463b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-173f8083-d11e-445d-b660-87bd4146bc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351818717-172.17.0.21-1599345155804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-86d93e15-8c7c-4c42-8400-61c0ac498d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b53d530b-7e3c-4cb1-a5ec-2fc90a62f92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-799c83ca-18ea-4bb8-a1d6-303bec4ef7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-8579e62c-a2e6-49b5-a622-d1a1888884b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-3a8e182d-0460-4bc9-9394-1f3febce85a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-eb488570-3417-4d80-916c-59a359fdfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-4b8925ee-30ab-4da8-800b-99a2406463b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-173f8083-d11e-445d-b660-87bd4146bc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617748165-172.17.0.21-1599345283173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40134,DS-fa0c27df-85df-4abd-82ec-7a230a6166cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-7430f0b4-f504-4e3b-b986-61ee26fd1ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-cd71b624-e09c-4ffe-8ac3-e3ff1e083279,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-d81dbed5-c315-44ae-b04f-3acf03907c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-3a555ab2-dd20-4fca-ad8e-91735eb8c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-0e77d55c-def0-4c29-8c1c-5c5406f8b524,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-7a2ac38d-f0b8-4357-95b5-47e68decdf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-4af6a0ed-a4bb-4574-a322-345bcbd2a30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617748165-172.17.0.21-1599345283173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40134,DS-fa0c27df-85df-4abd-82ec-7a230a6166cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-7430f0b4-f504-4e3b-b986-61ee26fd1ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-cd71b624-e09c-4ffe-8ac3-e3ff1e083279,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-d81dbed5-c315-44ae-b04f-3acf03907c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-3a555ab2-dd20-4fca-ad8e-91735eb8c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-0e77d55c-def0-4c29-8c1c-5c5406f8b524,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-7a2ac38d-f0b8-4357-95b5-47e68decdf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-4af6a0ed-a4bb-4574-a322-345bcbd2a30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878800604-172.17.0.21-1599346039856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-1442d157-5708-48cf-ba39-da471824116c,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e28fb197-753b-40eb-807f-bf3620095c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-1442f3f0-20a7-4bf4-99b0-005a96c0c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0424f48d-f081-426a-9517-687284b8a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-813ffe31-3e81-4660-9241-4e55ec502427,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-695e6a00-36ac-4e42-8f5e-61509dcfbb65,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-380db5d3-5f09-4c44-ac40-9fc0d4ee0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-7a324ef7-2b73-4db0-b25e-5f7017a2b361,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878800604-172.17.0.21-1599346039856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-1442d157-5708-48cf-ba39-da471824116c,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e28fb197-753b-40eb-807f-bf3620095c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-1442f3f0-20a7-4bf4-99b0-005a96c0c26d,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0424f48d-f081-426a-9517-687284b8a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-813ffe31-3e81-4660-9241-4e55ec502427,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-695e6a00-36ac-4e42-8f5e-61509dcfbb65,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-380db5d3-5f09-4c44-ac40-9fc0d4ee0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-7a324ef7-2b73-4db0-b25e-5f7017a2b361,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3s
v2: 1s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971069357-172.17.0.21-1599346070031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-fa00b4c0-9a02-4bc0-9f9b-18f1c8449804,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-7b60debe-a4a2-4ebd-bddb-abaf99a5c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-5672b27a-a710-49e7-9f9c-0e46160020a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-9c5a619a-f3c7-4642-8438-e14dd454eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-fdb1f792-b041-4b0a-84bb-0d37f278d878,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f599cdcf-9a93-4310-b197-6ebf97685c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-5bc9ba31-3bbc-4ecc-bf1c-8ae1cbdbab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-3faffca5-f630-4094-8dfb-5917b429014d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971069357-172.17.0.21-1599346070031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-fa00b4c0-9a02-4bc0-9f9b-18f1c8449804,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-7b60debe-a4a2-4ebd-bddb-abaf99a5c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-5672b27a-a710-49e7-9f9c-0e46160020a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-9c5a619a-f3c7-4642-8438-e14dd454eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-fdb1f792-b041-4b0a-84bb-0d37f278d878,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f599cdcf-9a93-4310-b197-6ebf97685c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-5bc9ba31-3bbc-4ecc-bf1c-8ae1cbdbab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-3faffca5-f630-4094-8dfb-5917b429014d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4618
