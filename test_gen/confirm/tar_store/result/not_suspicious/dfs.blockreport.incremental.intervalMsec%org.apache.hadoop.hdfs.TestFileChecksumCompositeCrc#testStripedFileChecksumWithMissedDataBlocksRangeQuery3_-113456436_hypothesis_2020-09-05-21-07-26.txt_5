reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176047078-172.17.0.17-1599340095576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-7b53515d-0d6e-4776-86c4-cf8e5e057759,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-faaaa564-193c-4f2f-aa08-9ec2dcbcb13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-bdc76781-9acf-4ddd-b50f-12c48697858b,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-6e7a688f-48cd-49d1-84c7-e9be2869de10,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d77ffcff-e51f-4344-a2ce-3a7140f6bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-7b0f61c4-3060-4764-80eb-c2ddec3d807e,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-00faacda-52ed-4897-8bdf-8b21b2ea5d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-b91b6c44-d4e2-41a2-9dba-ccf9a8c7463c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176047078-172.17.0.17-1599340095576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-7b53515d-0d6e-4776-86c4-cf8e5e057759,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-faaaa564-193c-4f2f-aa08-9ec2dcbcb13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-bdc76781-9acf-4ddd-b50f-12c48697858b,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-6e7a688f-48cd-49d1-84c7-e9be2869de10,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d77ffcff-e51f-4344-a2ce-3a7140f6bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-7b0f61c4-3060-4764-80eb-c2ddec3d807e,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-00faacda-52ed-4897-8bdf-8b21b2ea5d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-b91b6c44-d4e2-41a2-9dba-ccf9a8c7463c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303641832-172.17.0.17-1599340429768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-7e02eda2-9dd2-4759-9ff2-87571e95263d,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-0c745b6a-6d9f-483f-b0b6-983fd5bbac38,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-2dfe1e99-5140-4ccd-a334-b88da893659c,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-7ff3c2af-1cd9-466d-9b46-01a27bca0356,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-a31fb9cb-08b9-4cac-9956-9c871a32f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-af5a2577-3cad-4e82-9b89-3c27606d116e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-f01c4ff4-1c4a-45e9-ac8c-fcdb81f89b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-cce903df-45b6-4351-9243-5f4fc37ba9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303641832-172.17.0.17-1599340429768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-7e02eda2-9dd2-4759-9ff2-87571e95263d,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-0c745b6a-6d9f-483f-b0b6-983fd5bbac38,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-2dfe1e99-5140-4ccd-a334-b88da893659c,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-7ff3c2af-1cd9-466d-9b46-01a27bca0356,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-a31fb9cb-08b9-4cac-9956-9c871a32f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-af5a2577-3cad-4e82-9b89-3c27606d116e,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-f01c4ff4-1c4a-45e9-ac8c-fcdb81f89b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-cce903df-45b6-4351-9243-5f4fc37ba9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375228473-172.17.0.17-1599340469233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-20158069-e1ab-46e9-aea9-6417d571dc41,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-9b904b55-2f9e-440f-b821-619ff9ae5067,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-f3918598-b8c3-49da-8f7d-f94f4edd8454,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-465adc92-204d-4535-9bd9-89b7aa55544a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-cf3081ed-a7bd-494c-8610-f4bec68f3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-18b83536-9758-4c6d-a9db-c50b8f615777,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8f6ae666-b686-4201-9c42-ca513cc87f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-0bbc27ca-49f4-4e60-8f12-3a4f08a08ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375228473-172.17.0.17-1599340469233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36339,DS-20158069-e1ab-46e9-aea9-6417d571dc41,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-9b904b55-2f9e-440f-b821-619ff9ae5067,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-f3918598-b8c3-49da-8f7d-f94f4edd8454,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-465adc92-204d-4535-9bd9-89b7aa55544a,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-cf3081ed-a7bd-494c-8610-f4bec68f3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-18b83536-9758-4c6d-a9db-c50b8f615777,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8f6ae666-b686-4201-9c42-ca513cc87f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-0bbc27ca-49f4-4e60-8f12-3a4f08a08ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031738505-172.17.0.17-1599340791724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-d9956d9f-534b-447e-8988-eb160caf4a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-d9ce2b90-800b-4cea-b8a2-cd43e0ca493c,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-7e4559ec-35be-43a3-a75a-15e57d00c5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-5ae63d2c-7453-4014-abc5-6e425471c819,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-d80d3e2a-aeec-4f5e-9220-57deee884289,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-1f143a1b-04d6-41f4-a609-8377ce380e34,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-0848299f-945b-40ba-8af0-7797b555bdec,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-41416d9c-8a17-4e71-b770-36814991f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031738505-172.17.0.17-1599340791724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-d9956d9f-534b-447e-8988-eb160caf4a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-d9ce2b90-800b-4cea-b8a2-cd43e0ca493c,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-7e4559ec-35be-43a3-a75a-15e57d00c5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-5ae63d2c-7453-4014-abc5-6e425471c819,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-d80d3e2a-aeec-4f5e-9220-57deee884289,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-1f143a1b-04d6-41f4-a609-8377ce380e34,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-0848299f-945b-40ba-8af0-7797b555bdec,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-41416d9c-8a17-4e71-b770-36814991f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545189549-172.17.0.17-1599341212293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-626e9728-ee25-451f-ad62-274200a9b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-5d4e93c9-4031-4b6d-8707-a83ef51395d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-71d3a5fa-ffe9-4f46-b2f8-11895c7f54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0bb419de-b7d1-4e50-a3a1-66adeec26e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-f340520d-96ea-4eb5-ab2b-7cf3ac76e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-2bc53cdb-5f51-41df-bc14-0400e9496be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-2d4f5d4b-ca7a-4857-b9b3-91a81b43e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-ebbaf1c2-2be5-4f34-b4cc-545a02675d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545189549-172.17.0.17-1599341212293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46399,DS-626e9728-ee25-451f-ad62-274200a9b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-5d4e93c9-4031-4b6d-8707-a83ef51395d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-71d3a5fa-ffe9-4f46-b2f8-11895c7f54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-0bb419de-b7d1-4e50-a3a1-66adeec26e94,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-f340520d-96ea-4eb5-ab2b-7cf3ac76e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-2bc53cdb-5f51-41df-bc14-0400e9496be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-2d4f5d4b-ca7a-4857-b9b3-91a81b43e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-ebbaf1c2-2be5-4f34-b4cc-545a02675d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710198260-172.17.0.17-1599341299266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-a0b5b6cd-0666-4e7b-8464-447937236e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-ebfd8ed4-a74c-41a7-aa63-8da25f5d00d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-95eeb489-6b66-4f25-8bd2-719e537bf3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c20a54f9-ca20-4ba3-b629-fbc0fd467656,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-6fe064ce-ee4f-4001-9e41-d787485be215,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c8ef098e-ad4f-4e1b-b6d4-2911baf548f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-57e9a6d1-6fb0-4d65-ae41-f648783fb3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-10b002ff-ee86-4899-9b36-1c9d3ec32a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710198260-172.17.0.17-1599341299266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-a0b5b6cd-0666-4e7b-8464-447937236e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-ebfd8ed4-a74c-41a7-aa63-8da25f5d00d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-95eeb489-6b66-4f25-8bd2-719e537bf3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c20a54f9-ca20-4ba3-b629-fbc0fd467656,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-6fe064ce-ee4f-4001-9e41-d787485be215,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c8ef098e-ad4f-4e1b-b6d4-2911baf548f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-57e9a6d1-6fb0-4d65-ae41-f648783fb3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-10b002ff-ee86-4899-9b36-1c9d3ec32a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215542554-172.17.0.17-1599341612865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45670,DS-5d996068-993a-4ea1-874e-38a633f64d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-6b932e66-b975-4577-ae4b-7541d409f817,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-d2b3c36d-1150-460a-b845-de1e93791011,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-98e34e13-362f-4eda-b062-51bbec7ada23,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-e419aeae-fd1e-44fc-99d6-71958701a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-8779423f-f3ab-4021-b79d-2ae345280fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-c999acab-d6bb-4de5-b01e-2a9633bcacc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-b29dcea8-cb87-4c9c-9b19-ab6645ed9f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215542554-172.17.0.17-1599341612865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45670,DS-5d996068-993a-4ea1-874e-38a633f64d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-6b932e66-b975-4577-ae4b-7541d409f817,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-d2b3c36d-1150-460a-b845-de1e93791011,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-98e34e13-362f-4eda-b062-51bbec7ada23,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-e419aeae-fd1e-44fc-99d6-71958701a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-8779423f-f3ab-4021-b79d-2ae345280fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-c999acab-d6bb-4de5-b01e-2a9633bcacc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-b29dcea8-cb87-4c9c-9b19-ab6645ed9f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295535062-172.17.0.17-1599343026495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-dd65c500-c6ce-4ba4-9f6e-bda9c7645fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f5b6187b-4eea-48ab-be37-20e0999f3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-20c219f4-f56f-49a4-ab41-4cee78092ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-0a04eebb-9aa7-4e8f-b559-5f129da0a5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f820bfd9-655f-4d07-9ec6-e9b02aa0394f,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-3198cf53-c65d-4cd7-bf34-dba6fb05838f,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b736d72e-bc69-42d0-a30d-38bc210dac1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-37514422-56a1-4874-9d8a-65411e82bd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295535062-172.17.0.17-1599343026495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-dd65c500-c6ce-4ba4-9f6e-bda9c7645fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-f5b6187b-4eea-48ab-be37-20e0999f3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-20c219f4-f56f-49a4-ab41-4cee78092ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-0a04eebb-9aa7-4e8f-b559-5f129da0a5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f820bfd9-655f-4d07-9ec6-e9b02aa0394f,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-3198cf53-c65d-4cd7-bf34-dba6fb05838f,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b736d72e-bc69-42d0-a30d-38bc210dac1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-37514422-56a1-4874-9d8a-65411e82bd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303866315-172.17.0.17-1599343617711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-beb507a5-3ae5-45b9-be40-cf15cb0b870a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-fbda1a49-de0d-4ba8-979e-8ebb1be7ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-62f7765c-cb92-4566-a330-241cea5f5868,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2d0c7d16-f45d-4e7c-a969-a8f7c000d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-065eb80f-b191-47c4-8cd1-e722c48905b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a23ab417-17ab-45ab-8266-9f2b31df98f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-9142cbc9-4caf-4fb9-8dcb-21d21faef989,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-9526dfe3-6dbd-4a4d-ad54-bdfd37f2b598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303866315-172.17.0.17-1599343617711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-beb507a5-3ae5-45b9-be40-cf15cb0b870a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-fbda1a49-de0d-4ba8-979e-8ebb1be7ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-62f7765c-cb92-4566-a330-241cea5f5868,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2d0c7d16-f45d-4e7c-a969-a8f7c000d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-065eb80f-b191-47c4-8cd1-e722c48905b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a23ab417-17ab-45ab-8266-9f2b31df98f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-9142cbc9-4caf-4fb9-8dcb-21d21faef989,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-9526dfe3-6dbd-4a4d-ad54-bdfd37f2b598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332992482-172.17.0.17-1599344335163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38284,DS-9ff72a1b-f46d-4627-a270-79bc9f6efbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-d66cebd2-059b-48fc-895f-0a9973f4039b,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-115a5b1e-682f-4ea1-b3c5-0ec61ea74a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-957c61e9-eca7-4381-8071-c1c04f8f7413,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cba74081-0c37-46ba-9389-26921b0519e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fbb03bb6-d95d-4850-8a83-73fb7efe776f,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-15fc36b7-844d-4349-91b6-3a6ba30df960,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-51fdc004-981b-4636-8a30-0cec42248453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332992482-172.17.0.17-1599344335163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38284,DS-9ff72a1b-f46d-4627-a270-79bc9f6efbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-d66cebd2-059b-48fc-895f-0a9973f4039b,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-115a5b1e-682f-4ea1-b3c5-0ec61ea74a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-957c61e9-eca7-4381-8071-c1c04f8f7413,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cba74081-0c37-46ba-9389-26921b0519e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fbb03bb6-d95d-4850-8a83-73fb7efe776f,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-15fc36b7-844d-4349-91b6-3a6ba30df960,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-51fdc004-981b-4636-8a30-0cec42248453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591990830-172.17.0.17-1599344759618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-1400f666-15bc-49c5-a0d0-9283b2430224,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f542fb46-b7e4-42de-98c5-1ba8bd8a9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-9faaf1db-bcf1-4728-8b61-63331d97b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-3f315483-a26d-4527-a378-16f6ff3d8432,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-108b66ea-36f6-4e57-9965-036734ab82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-f9948855-73bf-44f7-8260-e81c0fe78c91,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-3d5cbd18-1b05-4d9f-a6fa-797efcc7b72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-bf50466e-b981-4b1e-ab33-ce8718bfb634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591990830-172.17.0.17-1599344759618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-1400f666-15bc-49c5-a0d0-9283b2430224,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f542fb46-b7e4-42de-98c5-1ba8bd8a9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-9faaf1db-bcf1-4728-8b61-63331d97b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-3f315483-a26d-4527-a378-16f6ff3d8432,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-108b66ea-36f6-4e57-9965-036734ab82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-f9948855-73bf-44f7-8260-e81c0fe78c91,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-3d5cbd18-1b05-4d9f-a6fa-797efcc7b72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-bf50466e-b981-4b1e-ab33-ce8718bfb634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5459
