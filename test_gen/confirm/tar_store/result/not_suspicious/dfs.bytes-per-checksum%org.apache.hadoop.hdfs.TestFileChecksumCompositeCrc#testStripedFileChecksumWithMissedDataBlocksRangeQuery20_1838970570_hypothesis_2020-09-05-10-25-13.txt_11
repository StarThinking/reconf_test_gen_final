reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169794309-172.17.0.13-1599301669951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-47f61dd6-52aa-4970-8825-f1abbe11fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-d84cf02b-4436-4ce3-9064-204c2270233b,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-e9235311-e661-4528-870b-3475d3dc0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-892172cc-a474-4f46-8b50-1f0582c80527,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-92fa4490-2a4d-41c2-aeb3-fcd985551869,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-771b0037-9f6a-4a0a-b49a-d583d846094b,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-22923b81-e9e0-46ea-a1c8-470a61040f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-48165178-0900-4db7-9457-8a92fa479faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169794309-172.17.0.13-1599301669951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-47f61dd6-52aa-4970-8825-f1abbe11fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-d84cf02b-4436-4ce3-9064-204c2270233b,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-e9235311-e661-4528-870b-3475d3dc0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-892172cc-a474-4f46-8b50-1f0582c80527,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-92fa4490-2a4d-41c2-aeb3-fcd985551869,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-771b0037-9f6a-4a0a-b49a-d583d846094b,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-22923b81-e9e0-46ea-a1c8-470a61040f17,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-48165178-0900-4db7-9457-8a92fa479faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310711047-172.17.0.13-1599301728765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39414,DS-78bbfaec-a90f-43aa-8f6c-599a248e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-42287639-c87e-4e45-b9a6-5476550368bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-9d6b1f39-50aa-4643-b6fc-84aad4d66fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-4b91c46d-77f8-4d13-aa6c-19c57ac67485,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-2a9bf2d1-979d-4893-a81d-45e753b55bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-cfa17e69-7894-49a8-92a4-6303296fd71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-74c63a71-5358-4d7c-950c-447800cadd25,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-e68be7d0-3042-443d-a9c8-81a8efeb0baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310711047-172.17.0.13-1599301728765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39414,DS-78bbfaec-a90f-43aa-8f6c-599a248e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-42287639-c87e-4e45-b9a6-5476550368bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-9d6b1f39-50aa-4643-b6fc-84aad4d66fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-4b91c46d-77f8-4d13-aa6c-19c57ac67485,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-2a9bf2d1-979d-4893-a81d-45e753b55bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-cfa17e69-7894-49a8-92a4-6303296fd71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-74c63a71-5358-4d7c-950c-447800cadd25,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-e68be7d0-3042-443d-a9c8-81a8efeb0baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940959407-172.17.0.13-1599302784637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-556d183e-821b-448e-a2d3-a2bf2af30354,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-3df92b75-1cad-4765-a723-7370aaf0aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-caf7ac38-1a4d-4063-9e96-c91d1b5706f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-496ce93d-970f-4513-b7e1-54a4f006bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-897b527d-25b6-4904-9075-492d73c08a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-b803d6ba-6608-4cd0-950c-4432d7751397,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-f2049004-1a85-415f-9b72-ef92becc2f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5c85756f-0669-4f11-9089-97ba6141ea14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940959407-172.17.0.13-1599302784637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-556d183e-821b-448e-a2d3-a2bf2af30354,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-3df92b75-1cad-4765-a723-7370aaf0aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-caf7ac38-1a4d-4063-9e96-c91d1b5706f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-496ce93d-970f-4513-b7e1-54a4f006bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-897b527d-25b6-4904-9075-492d73c08a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-b803d6ba-6608-4cd0-950c-4432d7751397,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-f2049004-1a85-415f-9b72-ef92becc2f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5c85756f-0669-4f11-9089-97ba6141ea14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874153042-172.17.0.13-1599303622101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-5334e0b3-cc02-41e0-9069-ee21276765ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-7542c90e-b5ce-4e7e-9b47-7790aa3d5803,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-0ab249fb-5eff-4fbe-8392-c47d52ecf720,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-98d684ea-2a9a-41dc-82d9-dc7c7c8ade4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-d9adc1e0-c401-43e7-b01f-f39648e0efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-3a693d62-fa77-489d-bd9b-150f02926f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-846d7adc-fbe4-4bcf-87b9-579daa6ddea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e9e62a0d-1ff7-44d3-bf49-be423fab25f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874153042-172.17.0.13-1599303622101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-5334e0b3-cc02-41e0-9069-ee21276765ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-7542c90e-b5ce-4e7e-9b47-7790aa3d5803,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-0ab249fb-5eff-4fbe-8392-c47d52ecf720,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-98d684ea-2a9a-41dc-82d9-dc7c7c8ade4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-d9adc1e0-c401-43e7-b01f-f39648e0efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-3a693d62-fa77-489d-bd9b-150f02926f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-846d7adc-fbe4-4bcf-87b9-579daa6ddea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-e9e62a0d-1ff7-44d3-bf49-be423fab25f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434765855-172.17.0.13-1599303740298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-2baae3de-f4d0-44bb-b20c-bc7bc891a341,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-fe1bd43f-d57e-43a2-93c4-51639f8e7073,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-f0cfd08e-c05d-4aaa-8209-1ab0972b7380,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-069aa593-73ac-44fc-9b1f-65ccda391139,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7a3f86c4-c399-4338-8a69-810f140168c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-af89ca46-bf3e-405a-b778-67f9a7b4b341,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-547e62c9-0986-4469-aa4b-f1dbf2b7abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-5b47a133-4be2-4809-82c8-b2b7113b5df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434765855-172.17.0.13-1599303740298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-2baae3de-f4d0-44bb-b20c-bc7bc891a341,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-fe1bd43f-d57e-43a2-93c4-51639f8e7073,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-f0cfd08e-c05d-4aaa-8209-1ab0972b7380,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-069aa593-73ac-44fc-9b1f-65ccda391139,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7a3f86c4-c399-4338-8a69-810f140168c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-af89ca46-bf3e-405a-b778-67f9a7b4b341,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-547e62c9-0986-4469-aa4b-f1dbf2b7abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-5b47a133-4be2-4809-82c8-b2b7113b5df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536279133-172.17.0.13-1599303825048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-096ec988-5581-4117-8c16-dbf73d88309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-595b76fc-8991-4cad-85f2-fcdbef79dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4b4eacdd-a716-4810-9345-c530f88561c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-409a5927-8e4c-4a87-8cc6-4c30a4bc590e,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-9ab5148f-8b5b-4154-a7de-9b56f3ad3539,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-f85dedaf-3d08-4781-9c10-4ee33b841c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-4ddc9f05-b94a-49a5-b8b5-206ac8315bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-3647e74d-fb52-4f55-b07d-11aad87e515a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536279133-172.17.0.13-1599303825048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-096ec988-5581-4117-8c16-dbf73d88309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-595b76fc-8991-4cad-85f2-fcdbef79dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4b4eacdd-a716-4810-9345-c530f88561c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-409a5927-8e4c-4a87-8cc6-4c30a4bc590e,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-9ab5148f-8b5b-4154-a7de-9b56f3ad3539,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-f85dedaf-3d08-4781-9c10-4ee33b841c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-4ddc9f05-b94a-49a5-b8b5-206ac8315bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-3647e74d-fb52-4f55-b07d-11aad87e515a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530839430-172.17.0.13-1599304018479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-bb666add-b055-4767-9f27-53ad6504be98,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-8dcbc3c1-bfb8-4ff4-b073-a8f119bc8896,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-d2a06e84-8b99-4acc-9d6d-6318474a5614,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-96cb0d7d-734c-4111-a593-e9146dbc4b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-daec13ad-42d3-4db0-b1af-264184777888,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-32c0c36c-5caa-4256-8c8b-899282587c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-8ca5ca22-ca80-45d8-822b-f4352c934e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-66145733-d91b-4564-8948-e4e71cfd6016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530839430-172.17.0.13-1599304018479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-bb666add-b055-4767-9f27-53ad6504be98,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-8dcbc3c1-bfb8-4ff4-b073-a8f119bc8896,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-d2a06e84-8b99-4acc-9d6d-6318474a5614,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-96cb0d7d-734c-4111-a593-e9146dbc4b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-daec13ad-42d3-4db0-b1af-264184777888,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-32c0c36c-5caa-4256-8c8b-899282587c46,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-8ca5ca22-ca80-45d8-822b-f4352c934e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-66145733-d91b-4564-8948-e4e71cfd6016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816669831-172.17.0.13-1599304043847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-2558f52f-f443-44ab-b7c2-660bf6afc02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-2c664213-3ed9-4f0a-96d4-7781e13747e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-7c2dbbd1-c3f0-4032-ae2a-9aa6666eaf27,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-662b2ef1-7504-4f96-9eb9-0fe4cd39b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-23c8c5ac-36f4-4dfb-b3e4-840cca1b9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-901a3eae-cce4-4a13-a95a-275878375691,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-34171844-97e4-4194-9160-4c0f16497dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-da62d221-549e-4ebe-b82a-0e364ffc8e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816669831-172.17.0.13-1599304043847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37022,DS-2558f52f-f443-44ab-b7c2-660bf6afc02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-2c664213-3ed9-4f0a-96d4-7781e13747e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-7c2dbbd1-c3f0-4032-ae2a-9aa6666eaf27,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-662b2ef1-7504-4f96-9eb9-0fe4cd39b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-23c8c5ac-36f4-4dfb-b3e4-840cca1b9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-901a3eae-cce4-4a13-a95a-275878375691,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-34171844-97e4-4194-9160-4c0f16497dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-da62d221-549e-4ebe-b82a-0e364ffc8e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643247744-172.17.0.13-1599305374510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-64119b25-7e0a-494c-b192-618e047e0478,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-227862ad-6509-4934-a8f7-24ef79977cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-22ed56bd-35ba-49b7-ad51-e5d9a2d3f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-92c67213-fcfe-4c04-9c63-76d57653f377,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-259d973e-4726-4ebe-868f-6c720bafe016,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-74c9ff89-bd33-4c65-a7bf-6d72147b7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-54c6ca01-af23-412e-aac3-f74a1747840a,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-027db8f3-0991-4f5a-8f30-7d7d95f9139a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643247744-172.17.0.13-1599305374510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-64119b25-7e0a-494c-b192-618e047e0478,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-227862ad-6509-4934-a8f7-24ef79977cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-22ed56bd-35ba-49b7-ad51-e5d9a2d3f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-92c67213-fcfe-4c04-9c63-76d57653f377,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-259d973e-4726-4ebe-868f-6c720bafe016,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-74c9ff89-bd33-4c65-a7bf-6d72147b7b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-54c6ca01-af23-412e-aac3-f74a1747840a,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-027db8f3-0991-4f5a-8f30-7d7d95f9139a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4298
