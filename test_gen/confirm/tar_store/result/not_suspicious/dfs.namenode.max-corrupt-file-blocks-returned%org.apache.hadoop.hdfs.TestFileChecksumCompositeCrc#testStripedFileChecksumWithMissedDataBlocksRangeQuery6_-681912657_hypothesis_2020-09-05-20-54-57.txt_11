reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991525041-172.17.0.21-1599339534339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35584,DS-8f6e509d-3beb-43cb-a028-cf17d2b59f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-91fe343c-bc38-44b1-b3ed-63869aa321d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-7c694b05-1d50-4b53-91d4-e4fa107dd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-2abebabe-527b-4be6-85ed-c9e3967a085e,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-c2d9c1ce-d94e-4b2a-bc34-6703d09a12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-7f89017c-7927-4459-af62-1862256568bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-3c8ed65a-e4a0-49bf-bd78-2bd8ff476a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e5db2462-b75d-423b-8d48-9849960521e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991525041-172.17.0.21-1599339534339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35584,DS-8f6e509d-3beb-43cb-a028-cf17d2b59f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-91fe343c-bc38-44b1-b3ed-63869aa321d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-7c694b05-1d50-4b53-91d4-e4fa107dd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-2abebabe-527b-4be6-85ed-c9e3967a085e,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-c2d9c1ce-d94e-4b2a-bc34-6703d09a12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-7f89017c-7927-4459-af62-1862256568bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-3c8ed65a-e4a0-49bf-bd78-2bd8ff476a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e5db2462-b75d-423b-8d48-9849960521e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020909992-172.17.0.21-1599339579190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-9f719fcd-d3bd-4c69-ae4a-ac8b262faf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-6a196521-c6a1-4e45-acd2-4c4eec051c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-c9648f95-0f08-4c54-85e6-1b4ca42f7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-22b08e3d-f3d0-43e4-b168-60cc297eedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-b8172f87-01a7-488d-8ce0-1e798119e7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-dac6de56-751e-4b32-ab05-0e1cfd90b125,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-244198d9-c02b-4bf9-9412-2d7fc7d5e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-9e166a12-8937-4fa9-9d1d-30f2069775a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020909992-172.17.0.21-1599339579190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-9f719fcd-d3bd-4c69-ae4a-ac8b262faf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-6a196521-c6a1-4e45-acd2-4c4eec051c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-c9648f95-0f08-4c54-85e6-1b4ca42f7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-22b08e3d-f3d0-43e4-b168-60cc297eedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-b8172f87-01a7-488d-8ce0-1e798119e7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-dac6de56-751e-4b32-ab05-0e1cfd90b125,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-244198d9-c02b-4bf9-9412-2d7fc7d5e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-9e166a12-8937-4fa9-9d1d-30f2069775a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028745961-172.17.0.21-1599339610998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-99b5f480-2f75-46a3-bbe6-ba477633863a,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-831ad2ae-0a5f-418d-bc17-0e8f0eb33f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-8b1befb4-d06d-4a4d-ad61-d3deffe88023,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-ae6ed588-899c-469a-a911-0f516a35dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-2f613f4a-4cf1-43ce-b970-641cb930755c,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f0f26c0c-f7a9-4666-ac5a-dca1130f1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-be3d9760-408f-4f96-86bb-425eb53dec56,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-74da888e-4b32-4387-9f61-61a258a1e106,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028745961-172.17.0.21-1599339610998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-99b5f480-2f75-46a3-bbe6-ba477633863a,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-831ad2ae-0a5f-418d-bc17-0e8f0eb33f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-8b1befb4-d06d-4a4d-ad61-d3deffe88023,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-ae6ed588-899c-469a-a911-0f516a35dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-2f613f4a-4cf1-43ce-b970-641cb930755c,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-f0f26c0c-f7a9-4666-ac5a-dca1130f1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-be3d9760-408f-4f96-86bb-425eb53dec56,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-74da888e-4b32-4387-9f61-61a258a1e106,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408485406-172.17.0.21-1599339803157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-9fe7538e-a2a9-4c1e-84a2-e404c1bb4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-d74bf398-dcde-4240-8600-644c37627fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-0a34f60d-3d7f-4499-b67d-0b0abc778571,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-f1ab1dd7-6cf0-40fb-a383-22266422c367,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-b062c34c-9a93-473f-99ef-f41c4a62f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-a47662b1-bfce-48a0-b051-53f2a95b4220,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-b2388b56-9bfa-421b-a4db-14d37834afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-455a1bdd-2e73-4a74-ae10-21585f110a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408485406-172.17.0.21-1599339803157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33092,DS-9fe7538e-a2a9-4c1e-84a2-e404c1bb4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-d74bf398-dcde-4240-8600-644c37627fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-0a34f60d-3d7f-4499-b67d-0b0abc778571,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-f1ab1dd7-6cf0-40fb-a383-22266422c367,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-b062c34c-9a93-473f-99ef-f41c4a62f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-a47662b1-bfce-48a0-b051-53f2a95b4220,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-b2388b56-9bfa-421b-a4db-14d37834afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-455a1bdd-2e73-4a74-ae10-21585f110a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953215368-172.17.0.21-1599340279070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36227,DS-9ce3f48b-8f96-4e23-8ab6-2bb9c48035fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-46cfdb99-0c38-46cd-9f2f-355077f3a990,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8d0c876a-30e8-4a63-848a-6aa7320b9581,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-f18b9bfa-de02-44e3-a904-f9c0282de587,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-3e86970e-4157-4a8a-a2d1-c6477618a430,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-b032fa2b-e83f-467e-a252-bb180f2d22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-d423e3c1-331b-424e-ad0a-e5cd564e0d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-15735f61-9871-4adf-aa04-03c659b0af1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953215368-172.17.0.21-1599340279070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36227,DS-9ce3f48b-8f96-4e23-8ab6-2bb9c48035fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-46cfdb99-0c38-46cd-9f2f-355077f3a990,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8d0c876a-30e8-4a63-848a-6aa7320b9581,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-f18b9bfa-de02-44e3-a904-f9c0282de587,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-3e86970e-4157-4a8a-a2d1-c6477618a430,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-b032fa2b-e83f-467e-a252-bb180f2d22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-d423e3c1-331b-424e-ad0a-e5cd564e0d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-15735f61-9871-4adf-aa04-03c659b0af1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109449582-172.17.0.21-1599340399902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35498,DS-b31b1168-eb07-4556-af22-693d5872acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-e1a15937-084e-4ca1-816c-434418cda474,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4db9b234-5662-483c-8a42-ee04baa2939d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-33a244be-8e8d-4259-a86a-e3d21cef6ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-8f7e7b45-8828-4f76-a8fa-4e6a08a5940f,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-5c870d0f-1d7d-4cf6-b191-5af0150ff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-10e09277-bcdc-47a2-ae0b-b9310212319d,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-add643ec-0f7f-470c-b18a-6593b5e7f70a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109449582-172.17.0.21-1599340399902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35498,DS-b31b1168-eb07-4556-af22-693d5872acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-e1a15937-084e-4ca1-816c-434418cda474,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4db9b234-5662-483c-8a42-ee04baa2939d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-33a244be-8e8d-4259-a86a-e3d21cef6ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-8f7e7b45-8828-4f76-a8fa-4e6a08a5940f,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-5c870d0f-1d7d-4cf6-b191-5af0150ff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-10e09277-bcdc-47a2-ae0b-b9310212319d,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-add643ec-0f7f-470c-b18a-6593b5e7f70a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384328096-172.17.0.21-1599340469216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37375,DS-679f20c3-6676-4746-893b-6fde1ae42991,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-4b018032-2646-4b2b-8458-8f2fc0a0abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-cccedd18-adbc-4567-a58e-1d0ba94c616e,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-dfa09671-fdb7-4d57-a7d9-72c601ca01ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-ccd18935-ac33-484d-abb8-1f5e6e3b67f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-11b00f0b-06c4-4e15-b64d-a17b0eddd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-85659108-271d-4ffa-8c34-4db386a4b302,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0323cd03-9e63-4239-81d8-8a34908bc463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384328096-172.17.0.21-1599340469216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37375,DS-679f20c3-6676-4746-893b-6fde1ae42991,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-4b018032-2646-4b2b-8458-8f2fc0a0abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-cccedd18-adbc-4567-a58e-1d0ba94c616e,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-dfa09671-fdb7-4d57-a7d9-72c601ca01ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-ccd18935-ac33-484d-abb8-1f5e6e3b67f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-11b00f0b-06c4-4e15-b64d-a17b0eddd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-85659108-271d-4ffa-8c34-4db386a4b302,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0323cd03-9e63-4239-81d8-8a34908bc463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900507402-172.17.0.21-1599340503871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-50f4fc5f-8709-4055-b917-ba59e7d3d469,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-89a7fb71-2961-4018-bcc4-509ab5118e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-7dd5f354-92a5-4d7e-972b-bf93aa4dfa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-ed1d2365-3fad-42c7-8ceb-624703862f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-3d2041c3-b24e-4cd9-851a-b85dc76d98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0e76df4b-82f3-4c85-8eb3-1eeefce779e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-f37d2afa-7a8c-4b64-9a9e-ef168ec3063b,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-eb5965b2-55b6-45c9-bcc7-9e4bf4e452ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900507402-172.17.0.21-1599340503871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-50f4fc5f-8709-4055-b917-ba59e7d3d469,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-89a7fb71-2961-4018-bcc4-509ab5118e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-7dd5f354-92a5-4d7e-972b-bf93aa4dfa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-ed1d2365-3fad-42c7-8ceb-624703862f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-3d2041c3-b24e-4cd9-851a-b85dc76d98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0e76df4b-82f3-4c85-8eb3-1eeefce779e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-f37d2afa-7a8c-4b64-9a9e-ef168ec3063b,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-eb5965b2-55b6-45c9-bcc7-9e4bf4e452ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219919276-172.17.0.21-1599340540117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-b7831a45-e870-43d4-8812-fa8047b716ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-404d2d28-cd8d-4b21-9dae-7ce4af659a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-e671f41c-7f2a-45b2-b944-e44f6ecccf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-da517382-7077-4d19-959d-10033932ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-780dc28e-bd19-48db-9d8e-252079bd4913,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2e6f6032-7ada-4915-9914-6edeae22f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-6ad000c1-99c6-4e14-b34e-011fbd43e462,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-7d5d2ef0-9b03-4af5-84c4-740721e20866,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219919276-172.17.0.21-1599340540117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-b7831a45-e870-43d4-8812-fa8047b716ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-404d2d28-cd8d-4b21-9dae-7ce4af659a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-e671f41c-7f2a-45b2-b944-e44f6ecccf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-da517382-7077-4d19-959d-10033932ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-780dc28e-bd19-48db-9d8e-252079bd4913,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2e6f6032-7ada-4915-9914-6edeae22f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-6ad000c1-99c6-4e14-b34e-011fbd43e462,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-7d5d2ef0-9b03-4af5-84c4-740721e20866,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946572651-172.17.0.21-1599340794434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-ec8567c4-423d-4cb5-bfa1-b56e8f121ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-36e1410f-85a9-4740-b3db-d45954aaf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-ce2a34de-6fec-4d7e-ac52-b859c468e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-28ff643b-3207-4f4d-98aa-00f35b1a238d,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-1235a642-aefa-46c7-8415-983a1b90dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-225ee06e-98d0-4bf4-8bc3-83b0818b2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-3fe41909-a0c2-40b4-b650-0aba57dc1421,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-1a15d210-7644-446d-a70b-0b25f6c9e8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946572651-172.17.0.21-1599340794434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36851,DS-ec8567c4-423d-4cb5-bfa1-b56e8f121ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-36e1410f-85a9-4740-b3db-d45954aaf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-ce2a34de-6fec-4d7e-ac52-b859c468e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-28ff643b-3207-4f4d-98aa-00f35b1a238d,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-1235a642-aefa-46c7-8415-983a1b90dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-225ee06e-98d0-4bf4-8bc3-83b0818b2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-3fe41909-a0c2-40b4-b650-0aba57dc1421,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-1a15d210-7644-446d-a70b-0b25f6c9e8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21752684-172.17.0.21-1599340868829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-16764f2e-7cda-427d-8055-f273fd9263d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-4aec761a-da0d-43ef-a65b-299a6d1d69c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-be6dbff9-78cc-455f-8d43-843a9065860e,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-2cf1d354-7d7d-41f0-869c-a93a5192c778,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-85b1c2e4-5f38-43a2-9ece-7deb2450bf14,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-bc7e3b5c-687a-4f06-9787-ecf68fe4ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-92b66c84-7407-4e8f-87ea-45b8e24c9209,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-577c86e0-a02d-4e81-8abf-e8e2a71a8a08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21752684-172.17.0.21-1599340868829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-16764f2e-7cda-427d-8055-f273fd9263d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-4aec761a-da0d-43ef-a65b-299a6d1d69c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-be6dbff9-78cc-455f-8d43-843a9065860e,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-2cf1d354-7d7d-41f0-869c-a93a5192c778,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-85b1c2e4-5f38-43a2-9ece-7deb2450bf14,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-bc7e3b5c-687a-4f06-9787-ecf68fe4ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-92b66c84-7407-4e8f-87ea-45b8e24c9209,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-577c86e0-a02d-4e81-8abf-e8e2a71a8a08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249034837-172.17.0.21-1599340976337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-da84298e-870e-40b6-81bf-3e1c279a3f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-00f2c568-454a-48ec-bc51-57ed3a74e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8ab7a952-6199-4d8d-8eb8-bf3cce5eb36b,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-6cba23a6-0505-4a5f-a846-400831d171df,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-a0691d33-0fd1-47e1-bb89-702be14a4fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-53c890f1-86e4-4c72-a22b-cbe6adf7b218,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0df3f3f8-25e7-46ce-935a-7c1c5af6a828,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-0babfcf8-b325-4438-886e-3cda6c6dabb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249034837-172.17.0.21-1599340976337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-da84298e-870e-40b6-81bf-3e1c279a3f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-00f2c568-454a-48ec-bc51-57ed3a74e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8ab7a952-6199-4d8d-8eb8-bf3cce5eb36b,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-6cba23a6-0505-4a5f-a846-400831d171df,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-a0691d33-0fd1-47e1-bb89-702be14a4fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-53c890f1-86e4-4c72-a22b-cbe6adf7b218,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0df3f3f8-25e7-46ce-935a-7c1c5af6a828,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-0babfcf8-b325-4438-886e-3cda6c6dabb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353454581-172.17.0.21-1599341242719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-62dbdf1c-e605-4ab7-a48b-7dae5d79ba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-90ae96ab-429f-422c-9701-10843cd2b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-73e820bd-ac2f-4a64-abbe-f9a8a9c2c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-3150a508-a421-4ac2-b2e3-7a65bb5eb142,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-653a4772-2d05-4ec0-b979-117e63f8f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-fcfb54e1-b51c-4c36-a804-e471b9f56a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-af8a445c-935a-48dd-b154-cd632cae4312,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7bd025c0-8a9a-4ec3-9ae2-703cee8fc7e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353454581-172.17.0.21-1599341242719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-62dbdf1c-e605-4ab7-a48b-7dae5d79ba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-90ae96ab-429f-422c-9701-10843cd2b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-73e820bd-ac2f-4a64-abbe-f9a8a9c2c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-3150a508-a421-4ac2-b2e3-7a65bb5eb142,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-653a4772-2d05-4ec0-b979-117e63f8f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-fcfb54e1-b51c-4c36-a804-e471b9f56a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-af8a445c-935a-48dd-b154-cd632cae4312,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7bd025c0-8a9a-4ec3-9ae2-703cee8fc7e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13695194-172.17.0.21-1599341336939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-08f620d5-d79c-4c43-b38b-e8761a990122,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-87a0c4cd-e8b5-4c57-ac91-9c79545eafab,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-505c7ac8-c243-4a21-93b2-7309790d76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-adbf460a-1c05-4b78-a345-9c37c94fc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-379752d2-60d5-4d79-86f1-3d9098eff1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6c3b17ef-85a7-4e36-921b-d9edd54c93d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-8f9bc2fd-c728-494b-9bd3-caee7c6a2032,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-1a430f1e-999f-48f0-9910-f4d4ff9c6839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13695194-172.17.0.21-1599341336939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-08f620d5-d79c-4c43-b38b-e8761a990122,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-87a0c4cd-e8b5-4c57-ac91-9c79545eafab,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-505c7ac8-c243-4a21-93b2-7309790d76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-adbf460a-1c05-4b78-a345-9c37c94fc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-379752d2-60d5-4d79-86f1-3d9098eff1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6c3b17ef-85a7-4e36-921b-d9edd54c93d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-8f9bc2fd-c728-494b-9bd3-caee7c6a2032,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-1a430f1e-999f-48f0-9910-f4d4ff9c6839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822534227-172.17.0.21-1599341613283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-9ad0e9a6-e004-4a9a-97aa-f4c815e53911,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-0cb7e330-82a8-4fdd-8d90-c6dbdfeb2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-a16c7410-5f28-4017-9f8a-933c7c50e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b394d280-9547-4869-8858-329171b97c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-b32943c9-9e8f-4c65-ac4c-b3493a10f316,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-eb7c7423-721d-4c44-a755-4ac77f3bc9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-c64de69f-c76e-43dd-a705-39dc2985c444,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-2a852cf5-e85e-4d52-a28e-e6c7c570fdee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822534227-172.17.0.21-1599341613283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46214,DS-9ad0e9a6-e004-4a9a-97aa-f4c815e53911,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-0cb7e330-82a8-4fdd-8d90-c6dbdfeb2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-a16c7410-5f28-4017-9f8a-933c7c50e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b394d280-9547-4869-8858-329171b97c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-b32943c9-9e8f-4c65-ac4c-b3493a10f316,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-eb7c7423-721d-4c44-a755-4ac77f3bc9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-c64de69f-c76e-43dd-a705-39dc2985c444,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-2a852cf5-e85e-4d52-a28e-e6c7c570fdee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063820411-172.17.0.21-1599341712045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-f0e7c10d-a14a-4106-afb2-c5656811086a,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-5ad58738-8eba-4056-b976-94ef2deb5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-3e27e830-dcf9-4df0-997e-ac35d831b794,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-cfad07f8-72b9-4263-b27c-95322bba70d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-4127aaff-1452-4ca0-9e3c-a5761774f211,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5186bdd6-6271-4743-8d7a-c5e58b1438a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-6bc18a46-c080-4448-9f93-cf037be57c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-28b277da-ed16-4b5d-8c29-78ab37d53ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063820411-172.17.0.21-1599341712045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-f0e7c10d-a14a-4106-afb2-c5656811086a,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-5ad58738-8eba-4056-b976-94ef2deb5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-3e27e830-dcf9-4df0-997e-ac35d831b794,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-cfad07f8-72b9-4263-b27c-95322bba70d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-4127aaff-1452-4ca0-9e3c-a5761774f211,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5186bdd6-6271-4743-8d7a-c5e58b1438a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-6bc18a46-c080-4448-9f93-cf037be57c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-28b277da-ed16-4b5d-8c29-78ab37d53ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546187681-172.17.0.21-1599341751403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44749,DS-dd8d0377-f953-4ff0-b53d-06d0cbd1cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-d64c5eeb-1adb-4e04-b42a-7f0d7a5defed,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ef6e1fde-1429-4c94-a421-cb172b7484ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-208e009a-1bfe-4372-b0df-a1237bc18bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a21f9f73-c60f-403f-a29c-066e262aa61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-ec723ceb-9d30-4d23-8eb7-910ce95231d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-49569994-9d23-4a4c-9956-32e274cc2106,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-5e57f1dd-b9ae-4d74-bfda-b5f114a282eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546187681-172.17.0.21-1599341751403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44749,DS-dd8d0377-f953-4ff0-b53d-06d0cbd1cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-d64c5eeb-1adb-4e04-b42a-7f0d7a5defed,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ef6e1fde-1429-4c94-a421-cb172b7484ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-208e009a-1bfe-4372-b0df-a1237bc18bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a21f9f73-c60f-403f-a29c-066e262aa61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-ec723ceb-9d30-4d23-8eb7-910ce95231d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-49569994-9d23-4a4c-9956-32e274cc2106,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-5e57f1dd-b9ae-4d74-bfda-b5f114a282eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391054351-172.17.0.21-1599341787471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-3002fbc2-c7ee-4a5a-9375-e0cdffdda654,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-7295734b-8801-4d7c-9dba-35fe58d69368,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-da39a0ff-5b78-461a-bd33-25bf2470697f,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c861841d-6a1c-4aad-9767-84894b4739fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c1a60002-79d5-4e8e-8e76-9ba2161399c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-43ae3a2e-392c-45f7-9f39-0d1f263897e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c1f4f1aa-dee2-48bf-965b-803056a61d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-6291bc63-80ef-40c8-b368-040ef93d7b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391054351-172.17.0.21-1599341787471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-3002fbc2-c7ee-4a5a-9375-e0cdffdda654,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-7295734b-8801-4d7c-9dba-35fe58d69368,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-da39a0ff-5b78-461a-bd33-25bf2470697f,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c861841d-6a1c-4aad-9767-84894b4739fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c1a60002-79d5-4e8e-8e76-9ba2161399c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-43ae3a2e-392c-45f7-9f39-0d1f263897e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c1f4f1aa-dee2-48bf-965b-803056a61d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-6291bc63-80ef-40c8-b368-040ef93d7b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928618942-172.17.0.21-1599341901672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-628194a7-b827-40d9-a38e-c3df99948b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-2ef9b048-8051-456a-bb0c-9e8ad5e16f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-2217f3d4-82f3-47be-afe2-9dc16b18a014,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-465cb188-347d-4bf4-9fb2-600c897e13da,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-576c1629-ee3c-47ff-b5df-73de6178c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-55485578-bd03-46fe-94ef-0019361dbb21,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-9e84ec8a-a93d-421f-bee8-3e9f58c97484,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4780c5f6-7e3e-40e3-ab02-6eeaa2f776f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928618942-172.17.0.21-1599341901672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-628194a7-b827-40d9-a38e-c3df99948b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-2ef9b048-8051-456a-bb0c-9e8ad5e16f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-2217f3d4-82f3-47be-afe2-9dc16b18a014,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-465cb188-347d-4bf4-9fb2-600c897e13da,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-576c1629-ee3c-47ff-b5df-73de6178c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-55485578-bd03-46fe-94ef-0019361dbb21,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-9e84ec8a-a93d-421f-bee8-3e9f58c97484,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4780c5f6-7e3e-40e3-ab02-6eeaa2f776f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872958585-172.17.0.21-1599341933388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-a6c0a530-7c5a-4ba7-83de-eb955325193b,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-5027e70f-3ad6-45a4-a9df-7b0379a8739a,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-553f1211-cd3c-4132-a3bf-f3dc41d92233,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6de04a8e-f565-491b-b08b-b11799501993,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-4b9055e5-978f-4413-b4fe-6ae7306e1579,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-4996595b-50a7-4a47-aef1-397bb8ec22aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-f263c737-afc3-436c-b221-b5ae7e52309d,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-c84f38bf-776f-4dbd-8e21-ea5439012bab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872958585-172.17.0.21-1599341933388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-a6c0a530-7c5a-4ba7-83de-eb955325193b,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-5027e70f-3ad6-45a4-a9df-7b0379a8739a,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-553f1211-cd3c-4132-a3bf-f3dc41d92233,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6de04a8e-f565-491b-b08b-b11799501993,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-4b9055e5-978f-4413-b4fe-6ae7306e1579,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-4996595b-50a7-4a47-aef1-397bb8ec22aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-f263c737-afc3-436c-b221-b5ae7e52309d,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-c84f38bf-776f-4dbd-8e21-ea5439012bab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239083307-172.17.0.21-1599342011931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-d751b481-2282-4f09-864e-1a22c5a58596,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-f5afcde8-cb4c-4e25-8dc3-20434a413f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-4eeae888-ff0e-4fb0-bdf6-523e72c683ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-def6bca2-b232-4017-ac11-63e34302f9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-eabc6884-c8ba-4eb5-bb16-3ac9fe76f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-d72776a7-b160-404f-b9a3-adf0e8ce1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-3bf0f700-f445-4b08-9d00-0d1c52ac78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-7b8f7367-03d1-4319-a5b7-4c5e4f7a160c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239083307-172.17.0.21-1599342011931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-d751b481-2282-4f09-864e-1a22c5a58596,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-f5afcde8-cb4c-4e25-8dc3-20434a413f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-4eeae888-ff0e-4fb0-bdf6-523e72c683ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-def6bca2-b232-4017-ac11-63e34302f9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-eabc6884-c8ba-4eb5-bb16-3ac9fe76f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-d72776a7-b160-404f-b9a3-adf0e8ce1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-3bf0f700-f445-4b08-9d00-0d1c52ac78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-7b8f7367-03d1-4319-a5b7-4c5e4f7a160c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048422932-172.17.0.21-1599342204571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-61b07c71-14b0-4dcc-b855-bddf5097ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-87954532-ff1a-4a83-871a-4aa76e5ea17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-7fd970f5-5a2d-485e-bf26-499ae742887e,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-e7a85997-504c-436b-820c-8e037d147374,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-85b7c19c-8e91-425e-b6cf-83f905f26017,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-8cfb2c0e-c7a6-42be-8585-653a78e90978,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-78e096e7-8b0a-442c-9d21-67152bf62a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-099bb57b-2442-4d6e-8c21-a6481270c365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048422932-172.17.0.21-1599342204571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-61b07c71-14b0-4dcc-b855-bddf5097ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-87954532-ff1a-4a83-871a-4aa76e5ea17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-7fd970f5-5a2d-485e-bf26-499ae742887e,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-e7a85997-504c-436b-820c-8e037d147374,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-85b7c19c-8e91-425e-b6cf-83f905f26017,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-8cfb2c0e-c7a6-42be-8585-653a78e90978,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-78e096e7-8b0a-442c-9d21-67152bf62a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-099bb57b-2442-4d6e-8c21-a6481270c365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418578980-172.17.0.21-1599342383571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-8da57f61-1eac-4092-963b-cc47cafafd72,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7699c5d8-a43e-4910-b2bc-fec6f30f2684,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-54debd31-3b09-4fbd-8b60-76ffd760539c,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-854cd53a-08ec-408d-a5e9-96ce5f225287,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-369b7893-96cf-40d0-b7f8-bf3d180b95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-8d9a700a-053d-49d0-ad8c-80d2c91cf2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-016ad4a9-3193-457b-a258-aa735e1c6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-1c990590-8456-4eb4-b269-724e22bd0e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418578980-172.17.0.21-1599342383571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-8da57f61-1eac-4092-963b-cc47cafafd72,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7699c5d8-a43e-4910-b2bc-fec6f30f2684,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-54debd31-3b09-4fbd-8b60-76ffd760539c,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-854cd53a-08ec-408d-a5e9-96ce5f225287,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-369b7893-96cf-40d0-b7f8-bf3d180b95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-8d9a700a-053d-49d0-ad8c-80d2c91cf2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-016ad4a9-3193-457b-a258-aa735e1c6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-1c990590-8456-4eb4-b269-724e22bd0e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876748856-172.17.0.21-1599342469055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-2a595d4f-c48d-4a2e-813d-f38949d63272,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-6960ebb7-3dce-4d96-b000-ed49888b2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-edd0007a-2c39-4609-8369-caf6ee9c2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-13d179d8-69e7-478a-968d-e6250ffc7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-cc5777a6-500b-4ca6-9edb-158b9c52fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-acc08828-51d5-4020-a661-0ea858fd3a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-0a7de180-aecb-4915-9fa1-cc63734a9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-debf3578-a9a4-48ee-b45b-c0c058389bb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876748856-172.17.0.21-1599342469055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-2a595d4f-c48d-4a2e-813d-f38949d63272,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-6960ebb7-3dce-4d96-b000-ed49888b2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-edd0007a-2c39-4609-8369-caf6ee9c2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-13d179d8-69e7-478a-968d-e6250ffc7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-cc5777a6-500b-4ca6-9edb-158b9c52fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-acc08828-51d5-4020-a661-0ea858fd3a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-0a7de180-aecb-4915-9fa1-cc63734a9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-debf3578-a9a4-48ee-b45b-c0c058389bb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752303621-172.17.0.21-1599342647374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-25852b73-cb54-4f7e-8cd1-d77e0319d659,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-40398b41-fe56-49e7-84ea-bb5ea7882f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-13ca4b09-bcc4-41d1-b504-7f1130127704,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-5f5ac720-497f-40e4-817b-7e3801ed5be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-0ed9d9fd-403d-422b-a145-3ee095036f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-c89b4dc4-2c57-4225-aae1-2a302f201146,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-8204e59e-656e-4554-887a-10de8739af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4d269384-23aa-4f92-b3c8-d46781ee9cb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752303621-172.17.0.21-1599342647374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-25852b73-cb54-4f7e-8cd1-d77e0319d659,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-40398b41-fe56-49e7-84ea-bb5ea7882f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-13ca4b09-bcc4-41d1-b504-7f1130127704,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-5f5ac720-497f-40e4-817b-7e3801ed5be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-0ed9d9fd-403d-422b-a145-3ee095036f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-c89b4dc4-2c57-4225-aae1-2a302f201146,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-8204e59e-656e-4554-887a-10de8739af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4d269384-23aa-4f92-b3c8-d46781ee9cb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425843685-172.17.0.21-1599342848870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-50b5b2ba-cd3a-4c8c-90f1-0a551b40d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-a1ed7b5c-b179-491e-8a9b-cf756df55820,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-96b6f30d-d9dd-4d74-a304-ab999b236770,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-67c56538-75d0-4387-b7ce-ec1851b04677,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-2ecbc0b0-5891-40ef-9618-f23febf4b789,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-817c36f5-0ac2-410f-8bfa-eca925ed8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-5aab6ca2-f310-4a51-89d0-8f795af699cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-94a294d3-2e11-4aef-aff2-0558634c2fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425843685-172.17.0.21-1599342848870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-50b5b2ba-cd3a-4c8c-90f1-0a551b40d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-a1ed7b5c-b179-491e-8a9b-cf756df55820,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-96b6f30d-d9dd-4d74-a304-ab999b236770,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-67c56538-75d0-4387-b7ce-ec1851b04677,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-2ecbc0b0-5891-40ef-9618-f23febf4b789,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-817c36f5-0ac2-410f-8bfa-eca925ed8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-5aab6ca2-f310-4a51-89d0-8f795af699cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-94a294d3-2e11-4aef-aff2-0558634c2fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409572425-172.17.0.21-1599343288182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-48d66120-ad77-48cd-9178-2a4a0ac86596,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-59888f7e-e799-446b-9359-3d78198bb14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-5955e279-42c5-4feb-8ab8-7345fd30bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-d5e44c6a-0721-43ec-865c-b912b9964685,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-3b020310-dd85-4a79-b525-5f248f33c584,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-fec26623-8173-42ec-9787-460cacc148b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bf573ad3-212f-4b09-a3f4-1a7004d7b336,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-5b633537-1934-473a-8a83-c2767b7ad46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409572425-172.17.0.21-1599343288182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38919,DS-48d66120-ad77-48cd-9178-2a4a0ac86596,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-59888f7e-e799-446b-9359-3d78198bb14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-5955e279-42c5-4feb-8ab8-7345fd30bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-d5e44c6a-0721-43ec-865c-b912b9964685,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-3b020310-dd85-4a79-b525-5f248f33c584,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-fec26623-8173-42ec-9787-460cacc148b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bf573ad3-212f-4b09-a3f4-1a7004d7b336,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-5b633537-1934-473a-8a83-c2767b7ad46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505545087-172.17.0.21-1599343514490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41478,DS-5aef677a-5f62-40d1-ab04-fcd3f7d759a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-37287e1e-bd22-452f-b916-5784b2318bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-c198f39d-070b-4ada-8de3-4010f2e6a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-34ecc714-534f-4bc9-9523-03c38abc6231,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c0aff45f-ca83-4aca-8f02-f486763e63de,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-93a92fee-737c-43dd-82ca-46bebc08e123,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-04c5517d-d8fa-4aee-8afd-8064dcd0201f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-8493c833-2022-44f9-b4b2-5a58fdc1141a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505545087-172.17.0.21-1599343514490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41478,DS-5aef677a-5f62-40d1-ab04-fcd3f7d759a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-37287e1e-bd22-452f-b916-5784b2318bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-c198f39d-070b-4ada-8de3-4010f2e6a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-34ecc714-534f-4bc9-9523-03c38abc6231,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c0aff45f-ca83-4aca-8f02-f486763e63de,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-93a92fee-737c-43dd-82ca-46bebc08e123,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-04c5517d-d8fa-4aee-8afd-8064dcd0201f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-8493c833-2022-44f9-b4b2-5a58fdc1141a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148036466-172.17.0.21-1599343555356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-6b3d8018-93c1-479b-b998-6d6c056c1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-fbd67d36-2b7f-4e80-9bc7-f8a33219c609,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-667ebc1f-82d8-4158-890b-52ae7d0f57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-0c20a860-3a11-4645-823d-402ad897ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d685a82f-a3ad-473a-9240-c254246e7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-192aa4a7-6b35-4979-9ebe-a5b70fd91836,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-779b3355-5585-4359-8be3-0db7e61c6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-4a2f8b6f-aece-4e26-9295-69d296a09e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148036466-172.17.0.21-1599343555356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-6b3d8018-93c1-479b-b998-6d6c056c1be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-fbd67d36-2b7f-4e80-9bc7-f8a33219c609,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-667ebc1f-82d8-4158-890b-52ae7d0f57a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-0c20a860-3a11-4645-823d-402ad897ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-d685a82f-a3ad-473a-9240-c254246e7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-192aa4a7-6b35-4979-9ebe-a5b70fd91836,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-779b3355-5585-4359-8be3-0db7e61c6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-4a2f8b6f-aece-4e26-9295-69d296a09e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270145101-172.17.0.21-1599343628116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-f709daf8-4c58-4a72-ad4c-753e9e6fc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-e90b8a45-2ecc-4b96-99c0-b8647803dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-bcbb0faa-34b3-4fff-932f-67b93cd2d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-789588d7-2402-4fab-8c8f-8ca94da4901d,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-1630c582-1889-4538-903b-c078fec5e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-cca8b976-23b7-42a1-b7eb-c0f079483a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-b957fd21-7ef5-4219-9249-ba5588ad8e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-e6f5e5ff-bd2a-468d-be49-a4b95ae12184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270145101-172.17.0.21-1599343628116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-f709daf8-4c58-4a72-ad4c-753e9e6fc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-e90b8a45-2ecc-4b96-99c0-b8647803dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-bcbb0faa-34b3-4fff-932f-67b93cd2d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-789588d7-2402-4fab-8c8f-8ca94da4901d,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-1630c582-1889-4538-903b-c078fec5e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-cca8b976-23b7-42a1-b7eb-c0f079483a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-b957fd21-7ef5-4219-9249-ba5588ad8e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-e6f5e5ff-bd2a-468d-be49-a4b95ae12184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250619490-172.17.0.21-1599343703957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-fb4b4413-8554-4c60-a772-578790a02874,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cfcfc7a3-6a21-4bc3-8675-515f93463c54,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-09b4e372-5989-40c3-b8c6-935c1a5194cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-e6190642-0594-4985-9c96-d768aac1c207,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-02be60a7-1e83-4183-bc82-82ce692eb039,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c3cfa50f-121b-4908-9977-45bc283876b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-64b9865d-f928-4209-a9ac-a3f3065d6e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-9782203c-d97e-48ab-9f1d-b4558808bcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250619490-172.17.0.21-1599343703957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-fb4b4413-8554-4c60-a772-578790a02874,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cfcfc7a3-6a21-4bc3-8675-515f93463c54,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-09b4e372-5989-40c3-b8c6-935c1a5194cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-e6190642-0594-4985-9c96-d768aac1c207,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-02be60a7-1e83-4183-bc82-82ce692eb039,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c3cfa50f-121b-4908-9977-45bc283876b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-64b9865d-f928-4209-a9ac-a3f3065d6e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-9782203c-d97e-48ab-9f1d-b4558808bcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239585509-172.17.0.21-1599343777887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-ea8b518b-1de3-494f-8677-d7d178aadd75,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-f459b75e-86c6-418b-9993-871fa8e0c628,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-1f239578-cfc8-4b8a-b8c7-e331ac07fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-0559788a-65fc-46fb-a8ab-b124d8119b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-7b796561-06b0-4a53-891d-45e9cc405b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c1338387-2e0a-44ed-a3fb-f88c8179ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-9d110f40-28bf-46ea-9cc7-67c00d018e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-ff9e54c1-7155-477c-ab4a-af3c7de4dacb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239585509-172.17.0.21-1599343777887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-ea8b518b-1de3-494f-8677-d7d178aadd75,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-f459b75e-86c6-418b-9993-871fa8e0c628,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-1f239578-cfc8-4b8a-b8c7-e331ac07fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-0559788a-65fc-46fb-a8ab-b124d8119b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-7b796561-06b0-4a53-891d-45e9cc405b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-c1338387-2e0a-44ed-a3fb-f88c8179ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-9d110f40-28bf-46ea-9cc7-67c00d018e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-ff9e54c1-7155-477c-ab4a-af3c7de4dacb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174858462-172.17.0.21-1599343892490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-e29b8dc9-eac2-45a9-8724-a409bbab5506,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-6c204deb-3694-4f6a-863c-39c31494981a,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ebe69fd7-c93e-43ff-bff9-e87f57d078aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-a4d32ae3-2515-494e-aa2d-a7591d1da411,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-c8f4b649-5bfb-4f9a-b2fa-74343293739f,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-e426783f-cb96-44df-aca0-f53a4403f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-749322c8-eb41-475f-9f19-52419eaaa705,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-543fb8a3-91fe-4d0a-899e-b7acfc1a9056,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174858462-172.17.0.21-1599343892490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-e29b8dc9-eac2-45a9-8724-a409bbab5506,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-6c204deb-3694-4f6a-863c-39c31494981a,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ebe69fd7-c93e-43ff-bff9-e87f57d078aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-a4d32ae3-2515-494e-aa2d-a7591d1da411,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-c8f4b649-5bfb-4f9a-b2fa-74343293739f,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-e426783f-cb96-44df-aca0-f53a4403f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-749322c8-eb41-475f-9f19-52419eaaa705,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-543fb8a3-91fe-4d0a-899e-b7acfc1a9056,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602049294-172.17.0.21-1599344060116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-0000ec10-064e-4386-947b-6fb4958d2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-1f19cf8d-fa06-4802-a221-c89a527d229b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-74307ee3-d491-403f-8c05-1d4649f10ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-fd2c649b-eee2-46c0-9545-617ec2c1f12f,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-30c982f9-c8b9-42d1-add8-8272a408594e,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-77d1c208-a1e3-491e-a7da-2e85068daccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-3abd479f-e616-4c15-81bf-ea58dfe9480c,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-f0e9181e-8d04-4712-afcc-a770b8bea5ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602049294-172.17.0.21-1599344060116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-0000ec10-064e-4386-947b-6fb4958d2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-1f19cf8d-fa06-4802-a221-c89a527d229b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-74307ee3-d491-403f-8c05-1d4649f10ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-fd2c649b-eee2-46c0-9545-617ec2c1f12f,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-30c982f9-c8b9-42d1-add8-8272a408594e,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-77d1c208-a1e3-491e-a7da-2e85068daccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-3abd479f-e616-4c15-81bf-ea58dfe9480c,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-f0e9181e-8d04-4712-afcc-a770b8bea5ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833872695-172.17.0.21-1599344291766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-0033f8ef-ce61-45b5-96cb-b2da5fdf1aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-5feca08e-4c9a-4d93-8a5a-6666e0d3f862,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-e4422d34-ff6b-4cd8-8a0f-3c449b28ba41,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ca1872fe-e20f-47bf-94c5-244ea1d98f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3e1ea511-81c8-483d-94ad-0bc439cc2c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-9a897054-745c-41ce-937d-93696a5fac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-eb150ce5-56f1-44fe-9bea-bf78f7bfb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-763073b4-9bc1-441c-8472-99dbd4ea3e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833872695-172.17.0.21-1599344291766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-0033f8ef-ce61-45b5-96cb-b2da5fdf1aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-5feca08e-4c9a-4d93-8a5a-6666e0d3f862,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-e4422d34-ff6b-4cd8-8a0f-3c449b28ba41,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ca1872fe-e20f-47bf-94c5-244ea1d98f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3e1ea511-81c8-483d-94ad-0bc439cc2c75,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-9a897054-745c-41ce-937d-93696a5fac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-eb150ce5-56f1-44fe-9bea-bf78f7bfb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-763073b4-9bc1-441c-8472-99dbd4ea3e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5420
