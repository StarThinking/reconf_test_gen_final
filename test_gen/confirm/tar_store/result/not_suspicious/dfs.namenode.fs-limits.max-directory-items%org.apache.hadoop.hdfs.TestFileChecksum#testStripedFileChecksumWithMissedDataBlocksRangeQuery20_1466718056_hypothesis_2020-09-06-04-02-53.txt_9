reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780096534-172.17.0.8-1599365188788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-0a199724-155a-450f-bfda-e8dcba9699f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-afca8d65-7980-47fc-9cd1-4158afb22bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-3533f843-d2cd-4bb0-984b-9545552b98ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1a93085b-9369-437f-b2c0-e5c143d56325,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-527286d9-9413-4c96-927a-fd34689586d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-9f7f3992-b401-44a3-a5cf-f2f7653f7775,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-fc8a4562-0ac5-4483-84e7-ec65ba9c46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-69069da5-f263-4d61-be37-c0b695d03774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780096534-172.17.0.8-1599365188788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-0a199724-155a-450f-bfda-e8dcba9699f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-afca8d65-7980-47fc-9cd1-4158afb22bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-3533f843-d2cd-4bb0-984b-9545552b98ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1a93085b-9369-437f-b2c0-e5c143d56325,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-527286d9-9413-4c96-927a-fd34689586d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-9f7f3992-b401-44a3-a5cf-f2f7653f7775,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-fc8a4562-0ac5-4483-84e7-ec65ba9c46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-69069da5-f263-4d61-be37-c0b695d03774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793626662-172.17.0.8-1599365464447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37341,DS-ac1445a3-ad77-4d1d-a3cd-1f37849af57b,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-d9e57f41-8411-4d18-8bc2-b11643876903,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-faeadd95-6817-42df-9c01-7721bb00fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-bc3d9aec-c84f-40bb-bd21-eee205a2a594,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-3e2ef221-92d9-4bfc-9ea9-d254f071441b,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-05627847-4ae4-4f93-a3ce-31e3de87daea,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-76c55f65-aaf2-40b9-9f88-5a3dfffd89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-93f8cf5b-8d0c-475d-84a1-ddc4da8b61a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793626662-172.17.0.8-1599365464447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37341,DS-ac1445a3-ad77-4d1d-a3cd-1f37849af57b,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-d9e57f41-8411-4d18-8bc2-b11643876903,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-faeadd95-6817-42df-9c01-7721bb00fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-bc3d9aec-c84f-40bb-bd21-eee205a2a594,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-3e2ef221-92d9-4bfc-9ea9-d254f071441b,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-05627847-4ae4-4f93-a3ce-31e3de87daea,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-76c55f65-aaf2-40b9-9f88-5a3dfffd89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-93f8cf5b-8d0c-475d-84a1-ddc4da8b61a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791064824-172.17.0.8-1599365495918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-a7589b43-8276-4079-9d23-432c71c1465b,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-9a52c501-2e1b-4132-9bba-cd5303ca00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-0a85d0ea-4bdb-4edc-93f9-09edf240002b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-472669b6-8db3-4f52-bd47-d9ca75c5def1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-855f4904-ce92-4566-a87a-4b205b06ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-6c64d287-ebff-4b3b-ba74-628ded01f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-af5b26ab-0c97-4284-99f2-aeb429a6d1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-616ae337-456c-4896-b1b7-c9e45851eb12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791064824-172.17.0.8-1599365495918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-a7589b43-8276-4079-9d23-432c71c1465b,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-9a52c501-2e1b-4132-9bba-cd5303ca00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-0a85d0ea-4bdb-4edc-93f9-09edf240002b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-472669b6-8db3-4f52-bd47-d9ca75c5def1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-855f4904-ce92-4566-a87a-4b205b06ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-6c64d287-ebff-4b3b-ba74-628ded01f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-af5b26ab-0c97-4284-99f2-aeb429a6d1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-616ae337-456c-4896-b1b7-c9e45851eb12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035295526-172.17.0.8-1599365742520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-e26b567d-b03c-42be-9477-e76f16f53b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-43002e61-e6eb-40f5-bf1b-08bdf7fdec69,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e9c88e12-1ff0-4186-ae49-75cbe4c6aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-d1037763-6496-4076-8f80-e865e04d825b,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-b01c90e0-488c-41a0-8307-4374f838fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-2879cf19-f371-4190-bade-c27fe88b7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-ad86ca22-31a3-4036-bfd2-b323e184d094,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-8e3069cd-9065-4fbd-a2f8-55ff23956126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035295526-172.17.0.8-1599365742520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-e26b567d-b03c-42be-9477-e76f16f53b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-43002e61-e6eb-40f5-bf1b-08bdf7fdec69,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e9c88e12-1ff0-4186-ae49-75cbe4c6aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-d1037763-6496-4076-8f80-e865e04d825b,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-b01c90e0-488c-41a0-8307-4374f838fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-2879cf19-f371-4190-bade-c27fe88b7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-ad86ca22-31a3-4036-bfd2-b323e184d094,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-8e3069cd-9065-4fbd-a2f8-55ff23956126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454977368-172.17.0.8-1599365780491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-34a4c9b1-feb8-4b35-a722-dcfa7282b176,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-774177b1-432f-4279-b252-f0e6b2ee00ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-01772014-4153-4c99-ac30-59c58f3c954c,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-9333806f-272c-4d04-a070-36cdfee23127,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-67dd9160-a1be-4aa7-8237-7c436515579f,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-6ac43c10-1f98-4c77-b973-b7b441a786f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-6b2102cd-1af9-4b7b-9e98-b7d6f0408680,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-303a6adb-214b-431b-82fb-8f59e48df112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454977368-172.17.0.8-1599365780491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-34a4c9b1-feb8-4b35-a722-dcfa7282b176,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-774177b1-432f-4279-b252-f0e6b2ee00ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-01772014-4153-4c99-ac30-59c58f3c954c,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-9333806f-272c-4d04-a070-36cdfee23127,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-67dd9160-a1be-4aa7-8237-7c436515579f,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-6ac43c10-1f98-4c77-b973-b7b441a786f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-6b2102cd-1af9-4b7b-9e98-b7d6f0408680,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-303a6adb-214b-431b-82fb-8f59e48df112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119699401-172.17.0.8-1599365970169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-65e8833f-3ab3-4a04-9ff8-a9434ec00a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e7290c07-6b16-4310-b44a-027475d3fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-324d10e2-3f3f-442d-ad06-dc8a48fa68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-2d114da8-3549-47d0-be79-75e7106d44c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-4a711e49-52d1-4141-9ca4-0beabbf9eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-a4b30855-c920-4f5d-9031-32d0f9d6d969,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-461502e5-c844-4cde-8f8b-d938feec58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a3ffeca3-3a2f-4a0b-a45c-b3b2eb3b93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119699401-172.17.0.8-1599365970169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-65e8833f-3ab3-4a04-9ff8-a9434ec00a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-e7290c07-6b16-4310-b44a-027475d3fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-324d10e2-3f3f-442d-ad06-dc8a48fa68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-2d114da8-3549-47d0-be79-75e7106d44c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-4a711e49-52d1-4141-9ca4-0beabbf9eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-a4b30855-c920-4f5d-9031-32d0f9d6d969,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-461502e5-c844-4cde-8f8b-d938feec58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a3ffeca3-3a2f-4a0b-a45c-b3b2eb3b93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092378993-172.17.0.8-1599367374995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-d7f18832-b092-45c7-95af-c7b0406caea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-365a2c58-0766-4c8b-97d2-bbe170187451,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-4547ce3b-18cc-4b76-bcda-272b5a718e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-0921589a-ab75-49f2-8921-93f4e10d4470,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-75f9350f-70c8-4be8-8cbb-c6d9df5d5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-71f406b5-3008-4c19-b812-ffb88df80dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-e4297126-8265-4a12-8195-9ae2697b8801,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-141a63ad-2c14-4e49-962c-a7a3b7b224fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092378993-172.17.0.8-1599367374995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-d7f18832-b092-45c7-95af-c7b0406caea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-365a2c58-0766-4c8b-97d2-bbe170187451,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-4547ce3b-18cc-4b76-bcda-272b5a718e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-0921589a-ab75-49f2-8921-93f4e10d4470,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-75f9350f-70c8-4be8-8cbb-c6d9df5d5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-71f406b5-3008-4c19-b812-ffb88df80dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-e4297126-8265-4a12-8195-9ae2697b8801,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-141a63ad-2c14-4e49-962c-a7a3b7b224fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113705191-172.17.0.8-1599367559392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-cc30a809-2e47-485a-9ea4-45c8068aa7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-4737bc5f-d3e2-44fd-be8a-d99438279200,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-2382d779-083c-4370-becc-bb546b9a328a,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-125c8ef1-0c9f-4d49-86f6-80c2e2631cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-3bd8b93a-fe61-4000-9837-74b0fd79f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-51057c1f-df2c-4d50-839b-cceb654c16a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-922b2e75-4ef2-4b6c-9a87-c362140cbeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-07628ae9-8052-4505-8abe-596a4d521d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113705191-172.17.0.8-1599367559392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-cc30a809-2e47-485a-9ea4-45c8068aa7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-4737bc5f-d3e2-44fd-be8a-d99438279200,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-2382d779-083c-4370-becc-bb546b9a328a,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-125c8ef1-0c9f-4d49-86f6-80c2e2631cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-3bd8b93a-fe61-4000-9837-74b0fd79f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-51057c1f-df2c-4d50-839b-cceb654c16a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-922b2e75-4ef2-4b6c-9a87-c362140cbeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-07628ae9-8052-4505-8abe-596a4d521d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446334698-172.17.0.8-1599367635617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-70186738-d42b-4de2-af7a-9b30c26131fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-46563437-6b0f-4011-a3f0-f66f4d783c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-eadbfe6b-ec74-48cd-b3cd-5caafbee0a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-098eff48-32ff-4d9d-b557-54011fcfeaed,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-83566189-2533-4cd2-8c97-f49053718859,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-78406923-4312-4845-b30c-43c6be935999,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-232e4125-2aef-48e4-aab6-c1f8392c99e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-022b5269-49fd-457b-8692-3971f20b109c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446334698-172.17.0.8-1599367635617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-70186738-d42b-4de2-af7a-9b30c26131fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-46563437-6b0f-4011-a3f0-f66f4d783c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-eadbfe6b-ec74-48cd-b3cd-5caafbee0a31,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-098eff48-32ff-4d9d-b557-54011fcfeaed,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-83566189-2533-4cd2-8c97-f49053718859,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-78406923-4312-4845-b30c-43c6be935999,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-232e4125-2aef-48e4-aab6-c1f8392c99e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-022b5269-49fd-457b-8692-3971f20b109c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470397661-172.17.0.8-1599368314256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-df4fe33a-d017-4c00-8eef-83e7cf67c35b,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-bd28e5eb-7322-4061-a396-bbba2447173e,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-02ab069b-f3d7-41b8-81b6-e2014536d090,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-691352f6-765e-431e-86ab-3d92200181f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-c7fa6028-b6c1-492a-b77b-beaa9ad7df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-dd0ec6a7-1e26-4ed3-a339-59fb27be7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-87643e0b-7890-40e1-bb61-9b1dad12f35d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-53701d55-80c7-4ea8-86c8-4f330179c3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470397661-172.17.0.8-1599368314256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-df4fe33a-d017-4c00-8eef-83e7cf67c35b,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-bd28e5eb-7322-4061-a396-bbba2447173e,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-02ab069b-f3d7-41b8-81b6-e2014536d090,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-691352f6-765e-431e-86ab-3d92200181f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-c7fa6028-b6c1-492a-b77b-beaa9ad7df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-dd0ec6a7-1e26-4ed3-a339-59fb27be7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-87643e0b-7890-40e1-bb61-9b1dad12f35d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-53701d55-80c7-4ea8-86c8-4f330179c3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001362688-172.17.0.8-1599368430391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-c50d8a07-00f9-45ae-8520-eff705e795c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-6126cc6f-6cbd-416e-a281-8456c5f713ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-8498ad6d-d466-4c9f-91ca-4e845e7a91b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1f07b1be-bf8e-47ef-8277-b505646ad574,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-b4dd18cd-dfcf-4ef6-9da6-a0b4eb2d94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-4277e2e6-42a7-47b4-9e52-49accd35d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-12f935dc-593f-4b18-b550-562da204d143,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-b31c6a6f-c563-4a95-a510-14904abb903e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001362688-172.17.0.8-1599368430391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-c50d8a07-00f9-45ae-8520-eff705e795c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-6126cc6f-6cbd-416e-a281-8456c5f713ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-8498ad6d-d466-4c9f-91ca-4e845e7a91b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1f07b1be-bf8e-47ef-8277-b505646ad574,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-b4dd18cd-dfcf-4ef6-9da6-a0b4eb2d94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-4277e2e6-42a7-47b4-9e52-49accd35d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-12f935dc-593f-4b18-b550-562da204d143,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-b31c6a6f-c563-4a95-a510-14904abb903e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705449556-172.17.0.8-1599368506558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46470,DS-c30a51e1-8771-4582-9bba-db95458a80fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-f95d2151-d094-4353-b937-f7ed0df85a18,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-6ecab0bc-fd4b-412e-ac1c-eb62ff4bfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-b0ef4422-a7c2-4c88-96ba-312788b8caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-580ef7b6-ca56-4b5c-9a77-ec47a873bf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-fd1d26b4-c4aa-4ffd-bd2d-afa02a9bef63,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c17bf6da-a2dc-4236-a163-d5a067a914c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-d92cb01f-8455-41a1-8c34-1df9e486a968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705449556-172.17.0.8-1599368506558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46470,DS-c30a51e1-8771-4582-9bba-db95458a80fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-f95d2151-d094-4353-b937-f7ed0df85a18,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-6ecab0bc-fd4b-412e-ac1c-eb62ff4bfcea,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-b0ef4422-a7c2-4c88-96ba-312788b8caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-580ef7b6-ca56-4b5c-9a77-ec47a873bf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-fd1d26b4-c4aa-4ffd-bd2d-afa02a9bef63,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c17bf6da-a2dc-4236-a163-d5a067a914c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-d92cb01f-8455-41a1-8c34-1df9e486a968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483446223-172.17.0.8-1599368610169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-b26beaae-f590-48dc-a287-06e5b54a5360,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-17f1e56f-6b1f-4cde-8539-3339c68c12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-e33949e0-fbc1-4e16-9b7d-35a14281dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-284f4966-0ae6-4e73-88a6-1d1435073778,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-77f204e9-5d45-494b-8709-2eea3352b396,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-5e014898-f74a-4afd-8d46-b231b9f2ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-6a08ce9e-c0e9-43f2-851f-5da1e8f9d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-33aac620-484a-4fc3-a2fc-67d683a9131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483446223-172.17.0.8-1599368610169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-b26beaae-f590-48dc-a287-06e5b54a5360,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-17f1e56f-6b1f-4cde-8539-3339c68c12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-e33949e0-fbc1-4e16-9b7d-35a14281dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-284f4966-0ae6-4e73-88a6-1d1435073778,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-77f204e9-5d45-494b-8709-2eea3352b396,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-5e014898-f74a-4afd-8d46-b231b9f2ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-6a08ce9e-c0e9-43f2-851f-5da1e8f9d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-33aac620-484a-4fc3-a2fc-67d683a9131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792735957-172.17.0.8-1599368757724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-4b0a7af9-b3a5-4d91-b32c-c77441fe63ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-0ba232e9-7fe9-4ae8-9556-a5876d62abce,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-0f019b50-d9f0-48dc-93de-8213da5230d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-94d74352-c3f3-489b-b189-04024774536e,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-e75f01ac-20a0-4ffc-b7cb-8c44e2a7580e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-4942cfc0-53b2-40ac-ad25-cbf09c15123f,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-47620fd6-5e71-48b4-b2e8-cfe2ca3a6c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-7b1d5914-ddcb-42fc-b791-75a5a978a495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792735957-172.17.0.8-1599368757724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-4b0a7af9-b3a5-4d91-b32c-c77441fe63ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-0ba232e9-7fe9-4ae8-9556-a5876d62abce,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-0f019b50-d9f0-48dc-93de-8213da5230d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-94d74352-c3f3-489b-b189-04024774536e,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-e75f01ac-20a0-4ffc-b7cb-8c44e2a7580e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-4942cfc0-53b2-40ac-ad25-cbf09c15123f,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-47620fd6-5e71-48b4-b2e8-cfe2ca3a6c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-7b1d5914-ddcb-42fc-b791-75a5a978a495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861233169-172.17.0.8-1599369229364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-ccf6e167-f794-43a8-a16c-ea3308cf0ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a7160233-d25d-4eae-84f5-48792e0b48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-cee0793c-3144-469f-a940-689232e4fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-3c28c033-78ed-4aac-8fba-f746f3a01ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-002a4dbf-165b-4e1e-9e21-b2e85d831247,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-89583959-331c-41f5-8cbd-dee775c5255b,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c19161f5-f2fc-4276-98fb-458384b79ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-00125aaa-39a5-465e-a2b3-149fa6197661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861233169-172.17.0.8-1599369229364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-ccf6e167-f794-43a8-a16c-ea3308cf0ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-a7160233-d25d-4eae-84f5-48792e0b48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-cee0793c-3144-469f-a940-689232e4fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-3c28c033-78ed-4aac-8fba-f746f3a01ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-002a4dbf-165b-4e1e-9e21-b2e85d831247,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-89583959-331c-41f5-8cbd-dee775c5255b,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c19161f5-f2fc-4276-98fb-458384b79ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-00125aaa-39a5-465e-a2b3-149fa6197661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860471847-172.17.0.8-1599369569793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-97356fd4-14e9-4cfe-8854-127f4148100d,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b6a11adf-9b78-47e7-9517-964526cec724,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-750ba136-7b9b-42d4-bfb7-ea5e9b639922,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-ae164153-2dde-49ff-9f9f-1b3aa0aac977,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-5666bfe5-9eee-4df7-ba20-f062c192a2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-af8e32fe-1baf-492d-a7cb-216d98695d43,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-898e258d-f403-411d-a4fd-ade5eced0ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-7efa62fc-aff9-43b3-8fe1-5d16380c557f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860471847-172.17.0.8-1599369569793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-97356fd4-14e9-4cfe-8854-127f4148100d,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-b6a11adf-9b78-47e7-9517-964526cec724,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-750ba136-7b9b-42d4-bfb7-ea5e9b639922,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-ae164153-2dde-49ff-9f9f-1b3aa0aac977,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-5666bfe5-9eee-4df7-ba20-f062c192a2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-af8e32fe-1baf-492d-a7cb-216d98695d43,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-898e258d-f403-411d-a4fd-ade5eced0ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-7efa62fc-aff9-43b3-8fe1-5d16380c557f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587330681-172.17.0.8-1599369641133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-34e0bcb5-b2e9-4ee5-aeb9-ff52de32aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-3430de4c-3227-4bf3-8a25-26c8b9e4d483,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-5035d99c-bae2-4ee1-8cbf-7d430203001a,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-0da299c6-25e9-4bc0-a65f-015ccd1289fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-b9a8b2f9-473d-4508-be57-4f7a00725941,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-8c3ae681-912f-4a13-8162-f374e7b03327,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-e210731d-0767-475b-a707-9cee667a3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-9ed25795-9892-4f4b-a581-232aa8a2388b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587330681-172.17.0.8-1599369641133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-34e0bcb5-b2e9-4ee5-aeb9-ff52de32aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-3430de4c-3227-4bf3-8a25-26c8b9e4d483,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-5035d99c-bae2-4ee1-8cbf-7d430203001a,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-0da299c6-25e9-4bc0-a65f-015ccd1289fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-b9a8b2f9-473d-4508-be57-4f7a00725941,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-8c3ae681-912f-4a13-8162-f374e7b03327,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-e210731d-0767-475b-a707-9cee667a3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-9ed25795-9892-4f4b-a581-232aa8a2388b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064207541-172.17.0.8-1599369744225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-8c19df74-0969-4949-a373-b150540f0161,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-a561bb3a-49a8-4fb5-b861-d10eb00f5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7037bc0c-a2c7-43bf-beda-393523273947,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-c2494c83-3829-45cc-87ae-f52ba148398d,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-76cc081d-2868-487a-bd18-7c4fec083f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d77ce067-5f36-49cb-b960-fbbe0edd14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-b7cca840-8d17-4f0a-b955-bccd58691b30,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-1339d28c-ea8d-4b0d-8725-06535daae7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064207541-172.17.0.8-1599369744225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-8c19df74-0969-4949-a373-b150540f0161,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-a561bb3a-49a8-4fb5-b861-d10eb00f5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7037bc0c-a2c7-43bf-beda-393523273947,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-c2494c83-3829-45cc-87ae-f52ba148398d,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-76cc081d-2868-487a-bd18-7c4fec083f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d77ce067-5f36-49cb-b960-fbbe0edd14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-b7cca840-8d17-4f0a-b955-bccd58691b30,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-1339d28c-ea8d-4b0d-8725-06535daae7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4966
