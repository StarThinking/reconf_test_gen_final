reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198406386-172.17.0.13-1599300852543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-2c2343f2-cd9a-4c25-820d-1a909d64f64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-7b5a3809-0c8b-4090-8f46-8bbd7a2c82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e063f161-4e9a-4c41-bc29-293d6cb437e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-859e469c-ce4f-480c-8907-1947059e265c,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-d4d821b3-1d7f-4ac8-becc-a9eb3b826cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-0078656a-6369-493f-bf37-014b0b602b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-9aacb8cb-95c5-47b1-9397-7eaaba93d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-fcf4413c-f554-4ede-9d28-4f69d5bbee92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198406386-172.17.0.13-1599300852543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-2c2343f2-cd9a-4c25-820d-1a909d64f64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-7b5a3809-0c8b-4090-8f46-8bbd7a2c82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e063f161-4e9a-4c41-bc29-293d6cb437e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-859e469c-ce4f-480c-8907-1947059e265c,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-d4d821b3-1d7f-4ac8-becc-a9eb3b826cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-0078656a-6369-493f-bf37-014b0b602b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-9aacb8cb-95c5-47b1-9397-7eaaba93d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-fcf4413c-f554-4ede-9d28-4f69d5bbee92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050893604-172.17.0.13-1599300933559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32911,DS-04adb805-0996-4a66-8dd2-09097e06ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-8cfd65e0-8cec-4966-b8a7-d1aab444ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-3d78250c-baea-45c2-b498-ce31e3c18e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-64ccc12e-0253-45d0-b1c2-53ccb03d1cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-0b731aa4-448b-479b-a956-fbc85d5d359a,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-2960b64c-6810-4958-9261-a7ac69013eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6386c30b-1922-4017-8b53-1e8774e83e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-b4bbc7f6-8a1e-406e-89e5-4190d49016ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050893604-172.17.0.13-1599300933559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32911,DS-04adb805-0996-4a66-8dd2-09097e06ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-8cfd65e0-8cec-4966-b8a7-d1aab444ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-3d78250c-baea-45c2-b498-ce31e3c18e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-64ccc12e-0253-45d0-b1c2-53ccb03d1cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-0b731aa4-448b-479b-a956-fbc85d5d359a,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-2960b64c-6810-4958-9261-a7ac69013eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6386c30b-1922-4017-8b53-1e8774e83e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-b4bbc7f6-8a1e-406e-89e5-4190d49016ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305844724-172.17.0.13-1599301014857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-e61d42df-a0b8-48bc-9d76-b4bea9711a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-e49d042a-fdb2-4734-bf98-a5f02734eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-dc7c516d-d22b-4d3d-ba5f-372c9dba26de,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-a89e12c4-348d-471b-900c-1e93952b83c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-4ee3f39d-74e5-43fa-a6a0-f4ab4046fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-19026dc6-d3e2-438a-8862-7f747ea5b0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-f0492581-5949-4efa-834e-a5849ed05075,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-2dca1378-cb5a-4b53-ad55-3ac2f9680619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305844724-172.17.0.13-1599301014857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-e61d42df-a0b8-48bc-9d76-b4bea9711a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-e49d042a-fdb2-4734-bf98-a5f02734eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-dc7c516d-d22b-4d3d-ba5f-372c9dba26de,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-a89e12c4-348d-471b-900c-1e93952b83c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-4ee3f39d-74e5-43fa-a6a0-f4ab4046fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-19026dc6-d3e2-438a-8862-7f747ea5b0be,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-f0492581-5949-4efa-834e-a5849ed05075,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-2dca1378-cb5a-4b53-ad55-3ac2f9680619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191133701-172.17.0.13-1599301097605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-ab10649d-c5d0-4769-a9c3-b102668efa13,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-49fafa7f-38c8-4855-ae40-c0aecb0ba2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-b4e1b9c9-3b71-40d8-97d3-7ef67c7768ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-71385bf8-7d32-41f7-b504-484b581121bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-16630f42-a460-42ab-9e3f-b45294ba25f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-ac795a0f-1119-48ea-bffe-e6f065ed1041,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-4ca2144b-ed18-4d1e-98f1-47bf6014f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-d505b977-41c8-49c5-b4de-cfd4ba950f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191133701-172.17.0.13-1599301097605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-ab10649d-c5d0-4769-a9c3-b102668efa13,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-49fafa7f-38c8-4855-ae40-c0aecb0ba2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-b4e1b9c9-3b71-40d8-97d3-7ef67c7768ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-71385bf8-7d32-41f7-b504-484b581121bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-16630f42-a460-42ab-9e3f-b45294ba25f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-ac795a0f-1119-48ea-bffe-e6f065ed1041,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-4ca2144b-ed18-4d1e-98f1-47bf6014f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-d505b977-41c8-49c5-b4de-cfd4ba950f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110372611-172.17.0.13-1599301278625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-1d393f84-a88b-40a3-899c-0a47e78cf444,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-514fa4ba-0ca2-495b-a780-ef5d87cb75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-27ea181f-cb31-4f97-b1cf-4b2ea8a8c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-db94bd97-da7d-453e-88c5-eb5a439f400d,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-ad35067c-255a-4122-bb5b-f01943f1e559,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-4fc724ac-c583-4d76-9462-d37ceab465a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-b9e277a8-ac0b-4b16-bea2-5e45fea40fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-57db3848-348f-45fa-857d-d9b3566f7978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110372611-172.17.0.13-1599301278625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44169,DS-1d393f84-a88b-40a3-899c-0a47e78cf444,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-514fa4ba-0ca2-495b-a780-ef5d87cb75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-27ea181f-cb31-4f97-b1cf-4b2ea8a8c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-db94bd97-da7d-453e-88c5-eb5a439f400d,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-ad35067c-255a-4122-bb5b-f01943f1e559,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-4fc724ac-c583-4d76-9462-d37ceab465a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-b9e277a8-ac0b-4b16-bea2-5e45fea40fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-57db3848-348f-45fa-857d-d9b3566f7978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200425159-172.17.0.13-1599301369201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-bf3a42a7-22ca-4a71-97c4-cacd7820dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-6556ada6-214a-41c5-bdf9-149fe2a540a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-ed8f3424-0ea9-4d8a-ba02-9a87ae965344,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-8e74a558-c575-440a-9a40-029dc951623b,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-8d802844-46db-4de5-949a-e6419033a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-67f04d4c-69ee-425a-a422-d0d15eeac342,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-924c153a-a3ab-41f3-8d47-6b2c14a02fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-90f176af-c7be-4696-bfe1-23a3fd77dd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200425159-172.17.0.13-1599301369201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-bf3a42a7-22ca-4a71-97c4-cacd7820dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-6556ada6-214a-41c5-bdf9-149fe2a540a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-ed8f3424-0ea9-4d8a-ba02-9a87ae965344,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-8e74a558-c575-440a-9a40-029dc951623b,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-8d802844-46db-4de5-949a-e6419033a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-67f04d4c-69ee-425a-a422-d0d15eeac342,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-924c153a-a3ab-41f3-8d47-6b2c14a02fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-90f176af-c7be-4696-bfe1-23a3fd77dd73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18295122-172.17.0.13-1599301458601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-231171cf-772b-4157-a7c1-fb24993f4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-8da32b55-36ab-409e-9039-1d396b1213a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-66137317-ea02-4540-9f87-0b6ef630e0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-3d118959-fa65-4354-a9de-ede7a5d67d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-ba648e76-600e-4530-848c-56d53c88a767,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-fea633ab-6f40-4bc6-829c-31edbfab9dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-975fe6dc-0a8f-4a4a-83b2-f7158aad16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-34bec3b7-608e-4f0c-b068-8fb041a7e55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18295122-172.17.0.13-1599301458601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-231171cf-772b-4157-a7c1-fb24993f4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-8da32b55-36ab-409e-9039-1d396b1213a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-66137317-ea02-4540-9f87-0b6ef630e0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-3d118959-fa65-4354-a9de-ede7a5d67d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-ba648e76-600e-4530-848c-56d53c88a767,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-fea633ab-6f40-4bc6-829c-31edbfab9dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-975fe6dc-0a8f-4a4a-83b2-f7158aad16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-34bec3b7-608e-4f0c-b068-8fb041a7e55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320439656-172.17.0.13-1599301939183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35558,DS-0e9c7282-6fe5-47cd-b415-bf5c9ab0a659,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-df51c33f-7707-4890-b34c-e49fee31e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-da0b286f-0c88-48ab-9e27-c9fd7c695440,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-815d6909-62c4-4929-9bbc-1002b4c60e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-c00e61a8-253d-4061-b491-c67d0b8efb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-ddd1523f-810c-4b74-80a1-be00ab6e8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-fea67391-c288-4232-ade5-52eac21e89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-c7fb7e6c-4e09-4e3f-8030-fa911bdad315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320439656-172.17.0.13-1599301939183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35558,DS-0e9c7282-6fe5-47cd-b415-bf5c9ab0a659,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-df51c33f-7707-4890-b34c-e49fee31e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-da0b286f-0c88-48ab-9e27-c9fd7c695440,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-815d6909-62c4-4929-9bbc-1002b4c60e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-c00e61a8-253d-4061-b491-c67d0b8efb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-ddd1523f-810c-4b74-80a1-be00ab6e8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-fea67391-c288-4232-ade5-52eac21e89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-c7fb7e6c-4e09-4e3f-8030-fa911bdad315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088779466-172.17.0.13-1599302085074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41267,DS-b0c79dd4-9ec8-49af-90d6-42549898afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-c9ad67c7-f531-42f2-9684-27dae4d84220,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-c0bc6d26-ae32-4a04-b4f1-3081db363ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-2281d0d7-fa82-4f5b-8698-a2816fe05bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-83e04e65-a197-4be7-8350-185ff3ebebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-601e06fc-ad87-420c-b191-1209de79911d,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-20541b63-24f4-448b-89ad-e8e93927a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-6764b244-c651-4cdc-bac2-99b0888bb9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088779466-172.17.0.13-1599302085074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41267,DS-b0c79dd4-9ec8-49af-90d6-42549898afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-c9ad67c7-f531-42f2-9684-27dae4d84220,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-c0bc6d26-ae32-4a04-b4f1-3081db363ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-2281d0d7-fa82-4f5b-8698-a2816fe05bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-83e04e65-a197-4be7-8350-185ff3ebebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-601e06fc-ad87-420c-b191-1209de79911d,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-20541b63-24f4-448b-89ad-e8e93927a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-6764b244-c651-4cdc-bac2-99b0888bb9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945146011-172.17.0.13-1599302115858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41170,DS-186f47fd-3b86-43a8-9907-51a0e552cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3af48a37-9bd5-4d91-ae02-dba0363dec24,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-a56baf29-36c4-49e9-9455-2ffb4473cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-759bf37b-afb7-453b-93e3-789fd15b4db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-52c5523e-2af3-4726-a932-cecc89adeaba,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-d1814375-f059-478d-94da-fb6b9258c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-c8c9d77c-aa8a-4da1-84ef-58c47a5221b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-0df55143-268f-48fe-92cd-4727f25bef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945146011-172.17.0.13-1599302115858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41170,DS-186f47fd-3b86-43a8-9907-51a0e552cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3af48a37-9bd5-4d91-ae02-dba0363dec24,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-a56baf29-36c4-49e9-9455-2ffb4473cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-759bf37b-afb7-453b-93e3-789fd15b4db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-52c5523e-2af3-4726-a932-cecc89adeaba,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-d1814375-f059-478d-94da-fb6b9258c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-c8c9d77c-aa8a-4da1-84ef-58c47a5221b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-0df55143-268f-48fe-92cd-4727f25bef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684741201-172.17.0.13-1599302168307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-cab376a7-858d-4dde-8267-f1be798b95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a506e776-cf6f-4cec-b51c-67c6da61a311,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-b42e4e56-512c-44da-b0e9-683d65b92715,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-10ff3b5c-3910-4227-9d97-c1a4d9d812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-dd188fe3-3423-460f-a74d-4137df275e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6e8c8164-da8b-4567-b04e-785652fcf776,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-206317da-2b74-4900-845c-15a5a0f1d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-f910f8c4-56a7-4fdf-b560-7d05e3f22e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684741201-172.17.0.13-1599302168307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-cab376a7-858d-4dde-8267-f1be798b95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a506e776-cf6f-4cec-b51c-67c6da61a311,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-b42e4e56-512c-44da-b0e9-683d65b92715,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-10ff3b5c-3910-4227-9d97-c1a4d9d812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-dd188fe3-3423-460f-a74d-4137df275e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6e8c8164-da8b-4567-b04e-785652fcf776,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-206317da-2b74-4900-845c-15a5a0f1d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-f910f8c4-56a7-4fdf-b560-7d05e3f22e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290890130-172.17.0.13-1599302220399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-15eb71d1-5146-411d-b698-30c996f89b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-0b29d9ce-462d-4bac-bebf-e7bf23edd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-8ac47efe-06f5-4a8f-abc4-ad38440537d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-7147a1d0-1e09-4404-a1b9-0dc7d9e3cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-e4aa2f7e-cb5b-445e-a128-282a735e2653,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-b5e6af08-30e0-4fc0-b242-d93c1377e365,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-dd239606-8fce-4a90-ab87-66108af98fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-ec23509f-48ef-4324-8a5b-6a6624346b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290890130-172.17.0.13-1599302220399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-15eb71d1-5146-411d-b698-30c996f89b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-0b29d9ce-462d-4bac-bebf-e7bf23edd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-8ac47efe-06f5-4a8f-abc4-ad38440537d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-7147a1d0-1e09-4404-a1b9-0dc7d9e3cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-e4aa2f7e-cb5b-445e-a128-282a735e2653,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-b5e6af08-30e0-4fc0-b242-d93c1377e365,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-dd239606-8fce-4a90-ab87-66108af98fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-ec23509f-48ef-4324-8a5b-6a6624346b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491317053-172.17.0.13-1599302379235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-7d772930-d8f8-4f52-87d9-5006b5a1c343,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-7947bcfb-da35-4fb1-9135-a12b1d651784,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-5728dc81-852f-461a-b955-843bcbd73f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-03f7f019-2a2f-4dbf-8d34-4cc81e5d0f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-b27fed47-c500-4c5a-bfd5-661f9a947948,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-8afe2b40-9485-4358-b9cc-2fca62b65aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-680bec1f-84bc-4a89-ba48-adfc3a690bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-a7968c2c-89cf-41eb-b18a-9a7badbc900d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491317053-172.17.0.13-1599302379235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41393,DS-7d772930-d8f8-4f52-87d9-5006b5a1c343,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-7947bcfb-da35-4fb1-9135-a12b1d651784,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-5728dc81-852f-461a-b955-843bcbd73f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-03f7f019-2a2f-4dbf-8d34-4cc81e5d0f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-b27fed47-c500-4c5a-bfd5-661f9a947948,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-8afe2b40-9485-4358-b9cc-2fca62b65aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-680bec1f-84bc-4a89-ba48-adfc3a690bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-a7968c2c-89cf-41eb-b18a-9a7badbc900d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324384252-172.17.0.13-1599302430405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-61e9ca90-f0ee-4fb3-a7b7-43584d0858b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-cb60a242-42ea-4e21-86ba-bd18df6ddcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-b475b2a8-0525-47c0-8c77-5f9bd67c5341,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c358cfc7-59ec-422c-a0b3-a300545f9f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-63ac62e5-c659-4a77-ab83-bc68148eb42d,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-65efe36f-65c6-4805-b3e2-d39ec0a71b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-6669eaa5-15e2-445f-9670-227bb4cae2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-6e12cfc1-3ccc-4c54-a773-c1e6d7de3be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324384252-172.17.0.13-1599302430405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-61e9ca90-f0ee-4fb3-a7b7-43584d0858b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-cb60a242-42ea-4e21-86ba-bd18df6ddcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-b475b2a8-0525-47c0-8c77-5f9bd67c5341,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c358cfc7-59ec-422c-a0b3-a300545f9f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-63ac62e5-c659-4a77-ab83-bc68148eb42d,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-65efe36f-65c6-4805-b3e2-d39ec0a71b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-6669eaa5-15e2-445f-9670-227bb4cae2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-6e12cfc1-3ccc-4c54-a773-c1e6d7de3be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054256693-172.17.0.13-1599302953471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-dc5a6e1f-df0f-46af-b875-e5cab9ad944a,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4a9aae6b-3401-4c91-a17e-b439a030af40,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8ff95edd-881c-436c-8692-7dfaeb5c9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3e914b74-3637-407a-a2fa-c9f80a6a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-5afc0a91-16ba-4cbf-bf20-cf0252dba1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-24dc7fa1-8a69-461a-a4cb-e8db4bea064b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-26ae1c13-7f5f-493f-ae5d-e9cee1adc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-942c5284-2e13-42bb-a407-d67320c3bc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054256693-172.17.0.13-1599302953471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-dc5a6e1f-df0f-46af-b875-e5cab9ad944a,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4a9aae6b-3401-4c91-a17e-b439a030af40,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8ff95edd-881c-436c-8692-7dfaeb5c9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3e914b74-3637-407a-a2fa-c9f80a6a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-5afc0a91-16ba-4cbf-bf20-cf0252dba1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-24dc7fa1-8a69-461a-a4cb-e8db4bea064b,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-26ae1c13-7f5f-493f-ae5d-e9cee1adc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-942c5284-2e13-42bb-a407-d67320c3bc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159287087-172.17.0.13-1599303006893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-ac6fae71-d29e-4af9-93b1-1ddcf3da1783,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-4dbefbb6-b903-47e8-9df2-36e071f18dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-57134928-33ad-452a-af93-dd70a8c9c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-a0d877c9-60cb-4188-80a3-81472203b308,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-eea9ef59-9e83-4b60-93e5-5eb1d2b90890,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-8dc1dace-bc8b-4a4f-add1-326963dd7cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-5db57b04-583f-4d30-a5cc-799cb1f8e341,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8ae9f998-2c44-45ce-b15c-2370b5e7d662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159287087-172.17.0.13-1599303006893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-ac6fae71-d29e-4af9-93b1-1ddcf3da1783,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-4dbefbb6-b903-47e8-9df2-36e071f18dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-57134928-33ad-452a-af93-dd70a8c9c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-a0d877c9-60cb-4188-80a3-81472203b308,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-eea9ef59-9e83-4b60-93e5-5eb1d2b90890,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-8dc1dace-bc8b-4a4f-add1-326963dd7cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-5db57b04-583f-4d30-a5cc-799cb1f8e341,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8ae9f998-2c44-45ce-b15c-2370b5e7d662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728933986-172.17.0.13-1599303931091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-e88f1021-2418-4823-a449-ed5d9b656a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-0f775b77-093e-43ae-9033-1b8ab8cb55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-747fddbf-324c-4ff7-98b0-0be78bf693b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-79e6dadf-df01-4783-a9a5-11aa6a849b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fb10625f-dc57-4bfb-821c-e1c96a0b1994,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e51b74d6-a1c8-4295-a22b-341636155682,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-06151f3e-cf9d-42c9-ab37-0c95730ef640,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-603bbb77-b51f-4c90-ba88-203e50e26842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728933986-172.17.0.13-1599303931091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-e88f1021-2418-4823-a449-ed5d9b656a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-0f775b77-093e-43ae-9033-1b8ab8cb55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-747fddbf-324c-4ff7-98b0-0be78bf693b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-79e6dadf-df01-4783-a9a5-11aa6a849b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fb10625f-dc57-4bfb-821c-e1c96a0b1994,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e51b74d6-a1c8-4295-a22b-341636155682,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-06151f3e-cf9d-42c9-ab37-0c95730ef640,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-603bbb77-b51f-4c90-ba88-203e50e26842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.checksum.type
component: hdfs:NameNode
v1: CRC32
v2: CRC32C
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380076361-172.17.0.13-1599304584409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-916cb8ec-02b4-4b94-aa45-1a75d59bd437,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-7f2c39af-9264-4c11-aaf6-ad41479ee6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-5ebac641-1928-42ce-a281-da113763b020,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-1a9e40ca-310f-4e47-9859-56d55f7f6e01,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-048146b0-5741-4b4f-bda1-f0d6532d30dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-c4f50bd6-043c-4570-9349-233bae54d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-8f8ebd0f-8e74-491c-8484-6413c46364bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e3d0d67c-02f8-466a-ba71-d3295698099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380076361-172.17.0.13-1599304584409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-916cb8ec-02b4-4b94-aa45-1a75d59bd437,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-7f2c39af-9264-4c11-aaf6-ad41479ee6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-5ebac641-1928-42ce-a281-da113763b020,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-1a9e40ca-310f-4e47-9859-56d55f7f6e01,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-048146b0-5741-4b4f-bda1-f0d6532d30dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-c4f50bd6-043c-4570-9349-233bae54d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-8f8ebd0f-8e74-491c-8484-6413c46364bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e3d0d67c-02f8-466a-ba71-d3295698099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4245
