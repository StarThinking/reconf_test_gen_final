reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443013045-172.17.0.18-1599372069597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-222ecb3f-5c30-4104-97bd-e0a5060f053c,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f1446f71-7723-4baf-b734-3e85ce52c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-b6e977fc-fbb3-4d9c-bb50-940002985e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-11569fcb-5fb7-496d-8b17-a535aa833471,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54990fb4-b5ec-451a-b823-ab4ce550cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-3481ebb3-4486-43ae-be31-ba4ccfee6c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-18566c4e-95dd-43b8-84d7-2ad3ebdb9298,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-2d6bbea3-73f4-46f4-a417-b02495abd1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443013045-172.17.0.18-1599372069597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-222ecb3f-5c30-4104-97bd-e0a5060f053c,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f1446f71-7723-4baf-b734-3e85ce52c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-b6e977fc-fbb3-4d9c-bb50-940002985e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-11569fcb-5fb7-496d-8b17-a535aa833471,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54990fb4-b5ec-451a-b823-ab4ce550cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-3481ebb3-4486-43ae-be31-ba4ccfee6c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-18566c4e-95dd-43b8-84d7-2ad3ebdb9298,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-2d6bbea3-73f4-46f4-a417-b02495abd1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155178368-172.17.0.18-1599372103858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-6ee7e9db-4b4b-458c-bb53-06825181baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-7b7b9472-3322-49f3-853c-dc1d455a83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8020831c-9ca7-4b6a-a907-0b236367c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-dcce8120-69ee-4abd-ae34-d956ab29f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-338d6417-b78f-471c-83d6-a740263282ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-196f363a-a37b-4e41-ac23-9d505250b949,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ece4f211-c13f-4ae8-af7b-e4176490cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-96052e4c-5705-462a-a10d-e11f5ac40f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155178368-172.17.0.18-1599372103858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-6ee7e9db-4b4b-458c-bb53-06825181baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-7b7b9472-3322-49f3-853c-dc1d455a83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8020831c-9ca7-4b6a-a907-0b236367c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-dcce8120-69ee-4abd-ae34-d956ab29f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-338d6417-b78f-471c-83d6-a740263282ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-196f363a-a37b-4e41-ac23-9d505250b949,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ece4f211-c13f-4ae8-af7b-e4176490cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-96052e4c-5705-462a-a10d-e11f5ac40f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435269693-172.17.0.18-1599372216502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-f3670911-d1f4-421a-b219-7840cb39846b,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-5baa6f60-4235-4d0e-bfa3-560ff8e8c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-07a1e0b9-6631-4022-913c-bfe3d5f6505e,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-ea0815c2-07fe-42ac-9de8-4f0f808928af,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-dd0cb23a-8103-4ff7-b0f4-0c7815caa5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6be8f9a1-bb49-4008-a996-30596b05e117,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-adfba876-439c-458b-b880-ecbd8ab879dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-07454252-23d1-41b2-8989-d9e91c582738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435269693-172.17.0.18-1599372216502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-f3670911-d1f4-421a-b219-7840cb39846b,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-5baa6f60-4235-4d0e-bfa3-560ff8e8c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-07a1e0b9-6631-4022-913c-bfe3d5f6505e,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-ea0815c2-07fe-42ac-9de8-4f0f808928af,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-dd0cb23a-8103-4ff7-b0f4-0c7815caa5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6be8f9a1-bb49-4008-a996-30596b05e117,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-adfba876-439c-458b-b880-ecbd8ab879dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-07454252-23d1-41b2-8989-d9e91c582738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604398531-172.17.0.18-1599372251238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-f7d196d8-88cb-459d-9508-c668150f8fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-b9c6c389-499d-4832-a9f9-ad1f8cc8065c,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-b19c5801-66e8-46a4-b300-53eda15969fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9e3d2f71-dfe5-4826-b763-75f0db39ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-7b30d07c-d79b-427f-a0d0-4cb905d12462,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-c5c9cabd-65b1-4910-9728-308e7777e016,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-7eb15e7a-9fbb-4e4e-9654-e8609527db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-f055b0ca-2479-4949-9f7f-c124627701d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604398531-172.17.0.18-1599372251238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-f7d196d8-88cb-459d-9508-c668150f8fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-b9c6c389-499d-4832-a9f9-ad1f8cc8065c,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-b19c5801-66e8-46a4-b300-53eda15969fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9e3d2f71-dfe5-4826-b763-75f0db39ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-7b30d07c-d79b-427f-a0d0-4cb905d12462,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-c5c9cabd-65b1-4910-9728-308e7777e016,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-7eb15e7a-9fbb-4e4e-9654-e8609527db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-f055b0ca-2479-4949-9f7f-c124627701d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677717560-172.17.0.18-1599372427361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-a313aa55-2bba-4ee8-9a0a-5a8fd643373b,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-e47e693c-2b13-41c4-8ef6-3bc79045cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-4ba7caaa-e4b0-4fb6-a8ca-8b4988c876c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-27133c00-4fbf-4da3-8c5b-1a29b4cb58fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-d8a2803a-7446-49fc-a2a3-e71294ead616,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d616df3b-1152-439a-964a-bdb2f4e445df,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-5b280e33-612e-429c-80f8-8534986e2f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-b37db9e5-9073-4c14-940f-5d00271bf74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677717560-172.17.0.18-1599372427361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-a313aa55-2bba-4ee8-9a0a-5a8fd643373b,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-e47e693c-2b13-41c4-8ef6-3bc79045cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-4ba7caaa-e4b0-4fb6-a8ca-8b4988c876c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-27133c00-4fbf-4da3-8c5b-1a29b4cb58fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-d8a2803a-7446-49fc-a2a3-e71294ead616,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d616df3b-1152-439a-964a-bdb2f4e445df,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-5b280e33-612e-429c-80f8-8534986e2f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-b37db9e5-9073-4c14-940f-5d00271bf74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663004973-172.17.0.18-1599373231763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-f5366114-db91-4f38-9c78-bc7fe04a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-c4c5a09c-d73f-4b02-ace7-dcf91675a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-73e7dbfd-4b00-4cdd-872b-b8c731806649,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-871b54a6-dfa7-4d86-8330-ef7cbc7d465d,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-1f4ca9eb-621b-455e-8e4e-dff56a29ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-33155643-b9a7-4201-8147-7d52ff0a17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-43e925e6-bace-46b5-9350-c8c4e24da62b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-17d38c3b-df8e-430f-9e62-dd6b563b7998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663004973-172.17.0.18-1599373231763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-f5366114-db91-4f38-9c78-bc7fe04a9c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-c4c5a09c-d73f-4b02-ace7-dcf91675a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-73e7dbfd-4b00-4cdd-872b-b8c731806649,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-871b54a6-dfa7-4d86-8330-ef7cbc7d465d,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-1f4ca9eb-621b-455e-8e4e-dff56a29ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-33155643-b9a7-4201-8147-7d52ff0a17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-43e925e6-bace-46b5-9350-c8c4e24da62b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-17d38c3b-df8e-430f-9e62-dd6b563b7998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166290006-172.17.0.18-1599373268651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-804a4a1e-5530-4fb5-843c-db05f5dc8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-9bd2db7f-a7ab-4be1-b670-dea7eeb760f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-875456c5-2470-47ec-928a-8ecba0a824fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1b7b8874-9ae3-4523-b3a0-8c8e1dec90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-c67c932d-290c-4084-abc2-d76f648a13fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-8486c757-e895-4d4f-90f4-c65740c20d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-a92988ca-10fd-49b1-8a65-611a2965e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-016cd75a-2fbf-4eb4-91a3-8e15485b026f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166290006-172.17.0.18-1599373268651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-804a4a1e-5530-4fb5-843c-db05f5dc8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-9bd2db7f-a7ab-4be1-b670-dea7eeb760f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-875456c5-2470-47ec-928a-8ecba0a824fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-1b7b8874-9ae3-4523-b3a0-8c8e1dec90c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-c67c932d-290c-4084-abc2-d76f648a13fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-8486c757-e895-4d4f-90f4-c65740c20d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-a92988ca-10fd-49b1-8a65-611a2965e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-016cd75a-2fbf-4eb4-91a3-8e15485b026f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255763396-172.17.0.18-1599373298737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33116,DS-5e8b9315-3179-444c-b41e-8388c6d5b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-345be0f5-9bc1-4104-9104-6b116e0a7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ed4709cc-31ed-4a32-af18-050b9db07247,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-0d6ea19b-44de-4503-aa48-1964127aeb88,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-79050f6c-575d-44c2-b398-be8370ee97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e3769081-16b9-4f4f-97e9-7ea9f21b3448,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e8e141da-17bd-4998-9ba0-4d8844c199cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a1564341-9d0b-4e0d-b7f7-cabadcf01a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255763396-172.17.0.18-1599373298737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33116,DS-5e8b9315-3179-444c-b41e-8388c6d5b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-345be0f5-9bc1-4104-9104-6b116e0a7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ed4709cc-31ed-4a32-af18-050b9db07247,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-0d6ea19b-44de-4503-aa48-1964127aeb88,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-79050f6c-575d-44c2-b398-be8370ee97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e3769081-16b9-4f4f-97e9-7ea9f21b3448,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-e8e141da-17bd-4998-9ba0-4d8844c199cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a1564341-9d0b-4e0d-b7f7-cabadcf01a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202224725-172.17.0.18-1599373745513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-aac67808-f6b7-4557-8d33-6301e9a3362e,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-0751062b-3d6b-45b6-baa9-105aa75618ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-7be1f97d-770f-4df4-9dbb-329f581b8f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-636cc7f2-2807-4944-9d51-4d870afff5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c360bea0-018f-4dc6-9bab-aeb8794ab411,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-957b509d-1668-47fa-b434-a388b0e8a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-ab9c4d63-0e6c-45f1-b68f-800e3222f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d1914657-efaa-4e70-a360-59279cca9113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202224725-172.17.0.18-1599373745513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-aac67808-f6b7-4557-8d33-6301e9a3362e,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-0751062b-3d6b-45b6-baa9-105aa75618ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-7be1f97d-770f-4df4-9dbb-329f581b8f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-636cc7f2-2807-4944-9d51-4d870afff5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c360bea0-018f-4dc6-9bab-aeb8794ab411,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-957b509d-1668-47fa-b434-a388b0e8a6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-ab9c4d63-0e6c-45f1-b68f-800e3222f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-d1914657-efaa-4e70-a360-59279cca9113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599661524-172.17.0.18-1599373862212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-a2f4e70b-7e78-4bad-9ef1-3edfce2d7731,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-954d63c7-6e21-4da1-a70b-53bd6e6bad00,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3fd386b9-01c4-4864-ad20-057ff05eac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-cbcb16c0-1329-4667-a2bf-dbab54e721bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-985d2146-b7bb-4728-9091-be05d2ccac33,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-6630147e-8393-4f58-8e64-0e97797741fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8bd252c3-b609-440f-9761-ac2cccc64be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5d1b62ef-8fc8-411d-a5f8-2abc6068766f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599661524-172.17.0.18-1599373862212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-a2f4e70b-7e78-4bad-9ef1-3edfce2d7731,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-954d63c7-6e21-4da1-a70b-53bd6e6bad00,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3fd386b9-01c4-4864-ad20-057ff05eac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-cbcb16c0-1329-4667-a2bf-dbab54e721bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-985d2146-b7bb-4728-9091-be05d2ccac33,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-6630147e-8393-4f58-8e64-0e97797741fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8bd252c3-b609-440f-9761-ac2cccc64be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5d1b62ef-8fc8-411d-a5f8-2abc6068766f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929765237-172.17.0.18-1599373896571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-fe825371-88b0-4f2d-b657-78585a406d14,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dd5a0a99-0999-4e0a-b5f8-475123408763,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-4a501fc2-c437-4908-9901-3d4ddbfb5bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-14b27a64-7e21-4f8b-9092-4dcd9511758e,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-4cb3c2e5-71ad-4968-a99f-3fe3b93d12e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-d74ed07a-e084-4f9d-b438-185eae7e2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-40b52984-55e5-450e-87ba-251b62bc4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-aafbd8ca-51bf-4d50-b19f-3afe30b4a6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929765237-172.17.0.18-1599373896571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-fe825371-88b0-4f2d-b657-78585a406d14,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dd5a0a99-0999-4e0a-b5f8-475123408763,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-4a501fc2-c437-4908-9901-3d4ddbfb5bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-14b27a64-7e21-4f8b-9092-4dcd9511758e,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-4cb3c2e5-71ad-4968-a99f-3fe3b93d12e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-d74ed07a-e084-4f9d-b438-185eae7e2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-40b52984-55e5-450e-87ba-251b62bc4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-aafbd8ca-51bf-4d50-b19f-3afe30b4a6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689349160-172.17.0.18-1599374677933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44194,DS-3aeaa42b-31f8-486a-a2a1-974a2302becb,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b126e054-3e35-4583-a65a-8c0e41022f56,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-54442370-b0a3-4dd3-82d0-f9ee523f93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-77045a47-0e5f-460c-bd87-82304908aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-8be58a63-fac3-4df1-abe7-1dda78f66839,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-136464b0-76b4-45ea-9ea0-d622e36cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-796d98d9-07bf-42f9-8440-981846981206,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-d191d233-4f4a-4aa1-b5bd-327b01f14fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689349160-172.17.0.18-1599374677933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44194,DS-3aeaa42b-31f8-486a-a2a1-974a2302becb,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-b126e054-3e35-4583-a65a-8c0e41022f56,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-54442370-b0a3-4dd3-82d0-f9ee523f93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-77045a47-0e5f-460c-bd87-82304908aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-8be58a63-fac3-4df1-abe7-1dda78f66839,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-136464b0-76b4-45ea-9ea0-d622e36cfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-796d98d9-07bf-42f9-8440-981846981206,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-d191d233-4f4a-4aa1-b5bd-327b01f14fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36715247-172.17.0.18-1599374744956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-bbdd38ae-06ab-4cd4-9f8c-ab911ace3f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-9a037e73-c087-4d6e-8f07-ed1fb0a050cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-1e620bee-0ad9-4d5b-8b06-24da325130c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-61ecc0bc-9a45-40cf-89a9-d5ec5e36acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-a0bc1bdc-e7fa-474c-9a79-9d57366f0e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-f1983760-cd8f-4e63-b354-688356255c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-62de4db6-a0c4-429f-b579-339b845fcfec,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-c3e4f6c5-6d6c-431b-8d1f-41d6843440b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36715247-172.17.0.18-1599374744956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-bbdd38ae-06ab-4cd4-9f8c-ab911ace3f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-9a037e73-c087-4d6e-8f07-ed1fb0a050cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-1e620bee-0ad9-4d5b-8b06-24da325130c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-61ecc0bc-9a45-40cf-89a9-d5ec5e36acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-a0bc1bdc-e7fa-474c-9a79-9d57366f0e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-f1983760-cd8f-4e63-b354-688356255c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-62de4db6-a0c4-429f-b579-339b845fcfec,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-c3e4f6c5-6d6c-431b-8d1f-41d6843440b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918219778-172.17.0.18-1599374782703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-b5adda0e-1da4-4198-93bd-cb788bb8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-53500049-6031-4c8a-ab17-d351a9ee7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-815613d5-786a-4e30-afe0-f7ff61d47a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-5b69f226-01a6-422c-b182-48a86c6ef8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-07f37fa9-edef-4625-a016-362525027575,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-9edbfcc5-ea4a-4ae3-b642-996bdc16ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-29bcaa8e-a752-4202-a30f-3f2b591bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-cb2ea1bd-6a8e-4e13-88d4-8a2ac62529ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918219778-172.17.0.18-1599374782703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-b5adda0e-1da4-4198-93bd-cb788bb8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-53500049-6031-4c8a-ab17-d351a9ee7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-815613d5-786a-4e30-afe0-f7ff61d47a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-5b69f226-01a6-422c-b182-48a86c6ef8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-07f37fa9-edef-4625-a016-362525027575,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-9edbfcc5-ea4a-4ae3-b642-996bdc16ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-29bcaa8e-a752-4202-a30f-3f2b591bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-cb2ea1bd-6a8e-4e13-88d4-8a2ac62529ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114972045-172.17.0.18-1599375344615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-4ea0bafe-47c0-4d44-8cfe-e09a1c42c0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-bcf44f48-af20-42bf-ab0f-4f8aa08fa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-c2196b1f-4f0d-4cd3-bc3b-3fda4996cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-546858f3-b1cc-4d8f-a838-ce133cdf579d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-e0bc6f45-5258-46b6-9240-52b28a5bcd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-9f322e6f-7b32-4cfe-90a8-f357fcc6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-d8f1de16-fefd-4781-8cd2-130e91d1fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-3c72def6-0e70-4c32-9ad4-18c4a53a57bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114972045-172.17.0.18-1599375344615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-4ea0bafe-47c0-4d44-8cfe-e09a1c42c0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-bcf44f48-af20-42bf-ab0f-4f8aa08fa6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-c2196b1f-4f0d-4cd3-bc3b-3fda4996cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-546858f3-b1cc-4d8f-a838-ce133cdf579d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-e0bc6f45-5258-46b6-9240-52b28a5bcd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-9f322e6f-7b32-4cfe-90a8-f357fcc6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-d8f1de16-fefd-4781-8cd2-130e91d1fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-3c72def6-0e70-4c32-9ad4-18c4a53a57bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845761435-172.17.0.18-1599375374495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-1878dfbd-1f02-469b-a5e7-0558c7e2752a,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-361db122-c470-4f2a-a71c-1c1409c41693,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-f976aaba-344f-4b76-bb4b-c4885c8624c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-12837101-0e1a-4f8d-baff-8ae2b75eee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-e09830fe-0276-4b03-abf9-ccf564b2c831,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-bdd3e142-5616-4bda-85e5-1d96e566df79,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-52307caf-0144-4dd5-b1fa-970227a2f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-615f095d-635d-4020-8c63-f92be6a6a209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845761435-172.17.0.18-1599375374495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-1878dfbd-1f02-469b-a5e7-0558c7e2752a,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-361db122-c470-4f2a-a71c-1c1409c41693,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-f976aaba-344f-4b76-bb4b-c4885c8624c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-12837101-0e1a-4f8d-baff-8ae2b75eee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-e09830fe-0276-4b03-abf9-ccf564b2c831,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-bdd3e142-5616-4bda-85e5-1d96e566df79,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-52307caf-0144-4dd5-b1fa-970227a2f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-615f095d-635d-4020-8c63-f92be6a6a209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293447195-172.17.0.18-1599375641941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-56f98307-b334-4356-a730-1004959c23f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-306c7d5d-c890-4714-8ff7-2096d8f95760,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-3a755215-e82f-4c32-8bf6-88dbf045234e,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-d651c949-4320-4a6f-a3a3-3e57ee0404e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-be08c19d-bf38-4ae3-ba14-ab05191d2624,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-95195e90-98e2-4458-a196-336011b6ef72,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-61ffc08f-2736-40b7-adc4-1a963e952d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-fb151632-c879-4f5e-9873-020ccdb0daa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293447195-172.17.0.18-1599375641941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-56f98307-b334-4356-a730-1004959c23f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-306c7d5d-c890-4714-8ff7-2096d8f95760,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-3a755215-e82f-4c32-8bf6-88dbf045234e,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-d651c949-4320-4a6f-a3a3-3e57ee0404e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-be08c19d-bf38-4ae3-ba14-ab05191d2624,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-95195e90-98e2-4458-a196-336011b6ef72,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-61ffc08f-2736-40b7-adc4-1a963e952d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-fb151632-c879-4f5e-9873-020ccdb0daa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335390332-172.17.0.18-1599375776871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-213976a0-91a2-4bb9-9b97-3adb701138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-176f8eeb-7ac0-47de-9bcf-62e15d4222ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-2346f804-a002-4383-b006-2b2760168333,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-dfd90334-79e1-4c1e-8015-e238f88a07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-a9cef5c0-c4e7-4a64-9735-0083dce02fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-5e29b80c-a685-404d-b8f8-24b2e0baacc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-0bdf091e-024e-4299-8a04-f9a6232e8912,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-0eac6357-c550-4804-b708-241069cd9387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335390332-172.17.0.18-1599375776871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-213976a0-91a2-4bb9-9b97-3adb701138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-176f8eeb-7ac0-47de-9bcf-62e15d4222ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-2346f804-a002-4383-b006-2b2760168333,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-dfd90334-79e1-4c1e-8015-e238f88a07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-a9cef5c0-c4e7-4a64-9735-0083dce02fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-5e29b80c-a685-404d-b8f8-24b2e0baacc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-0bdf091e-024e-4299-8a04-f9a6232e8912,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-0eac6357-c550-4804-b708-241069cd9387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964640063-172.17.0.18-1599375841104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38141,DS-eeef4ba0-061d-46b5-b658-780a2fc97455,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7180698d-ba55-4931-ba5a-47548ecc29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-bccca306-122d-4e20-a9b6-66f1338a6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-10638487-d5b6-4018-996e-5164f8eeb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-8e72a766-f5f5-4e44-9874-3e9958d37e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-0f1dd46c-0239-42c9-9c99-c4e500181faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-06e23e51-9694-4ba0-9814-2aa7f3b06670,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-7511dbdf-98b1-48df-8c12-181cc67d9307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964640063-172.17.0.18-1599375841104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38141,DS-eeef4ba0-061d-46b5-b658-780a2fc97455,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7180698d-ba55-4931-ba5a-47548ecc29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-bccca306-122d-4e20-a9b6-66f1338a6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-10638487-d5b6-4018-996e-5164f8eeb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-8e72a766-f5f5-4e44-9874-3e9958d37e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-0f1dd46c-0239-42c9-9c99-c4e500181faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-06e23e51-9694-4ba0-9814-2aa7f3b06670,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-7511dbdf-98b1-48df-8c12-181cc67d9307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343672280-172.17.0.18-1599376375774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-532d262f-e5fe-47cb-9632-372842f48ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-a996ed30-dcb4-4f53-ac91-5e5046fc2e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-185e622d-dcc9-48a8-bf2c-515df5947661,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-eecb1de3-4053-45d7-924d-01a0a0c82381,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-51f179d6-2e4c-4159-8148-e8d98cebbf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d142300a-81c0-4212-9534-4e08cf4bd81c,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a2f9b0a3-dafc-493c-8aed-e0fde1a5f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-3804a587-103d-46d8-acf3-b2c614f73686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343672280-172.17.0.18-1599376375774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-532d262f-e5fe-47cb-9632-372842f48ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-a996ed30-dcb4-4f53-ac91-5e5046fc2e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-185e622d-dcc9-48a8-bf2c-515df5947661,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-eecb1de3-4053-45d7-924d-01a0a0c82381,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-51f179d6-2e4c-4159-8148-e8d98cebbf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d142300a-81c0-4212-9534-4e08cf4bd81c,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a2f9b0a3-dafc-493c-8aed-e0fde1a5f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-3804a587-103d-46d8-acf3-b2c614f73686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249540130-172.17.0.18-1599376646893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b1a257f4-77b4-4f19-8258-2a2174f040bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-4672c1a6-711b-4ac1-9a93-89c9ba309d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-fb832897-c2fc-423f-94dd-df84cd2e63ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-b5a54988-3d86-4460-b37f-eab0a4cddb05,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bd182229-945e-44c4-9105-ebfcf457ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-c5444e8d-be36-49fe-a345-cd2c872b3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-6802b24c-9647-42b1-a9e2-999c67573635,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-f599ed48-983e-441d-b3e5-6a092d3eff3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249540130-172.17.0.18-1599376646893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b1a257f4-77b4-4f19-8258-2a2174f040bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-4672c1a6-711b-4ac1-9a93-89c9ba309d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-fb832897-c2fc-423f-94dd-df84cd2e63ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-b5a54988-3d86-4460-b37f-eab0a4cddb05,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bd182229-945e-44c4-9105-ebfcf457ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-c5444e8d-be36-49fe-a345-cd2c872b3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-6802b24c-9647-42b1-a9e2-999c67573635,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-f599ed48-983e-441d-b3e5-6a092d3eff3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853602753-172.17.0.18-1599377109285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35049,DS-a734a663-cd14-4fff-b4a5-c3213bc50932,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-8f583ee8-2465-4395-a173-b4403359e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-945650e2-5ff5-422b-b047-aa19ab2e6f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e65a804c-9501-4490-b899-db448e83467f,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a66c23aa-564e-40ab-86b4-c0bcbd94c797,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-1d534cad-278e-48ba-bb93-429d8b819a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ccc61271-71ee-440e-aa4f-0ee1b226bd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-66bd833a-018b-433f-81b5-c1602d3a099b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853602753-172.17.0.18-1599377109285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35049,DS-a734a663-cd14-4fff-b4a5-c3213bc50932,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-8f583ee8-2465-4395-a173-b4403359e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-945650e2-5ff5-422b-b047-aa19ab2e6f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e65a804c-9501-4490-b899-db448e83467f,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a66c23aa-564e-40ab-86b4-c0bcbd94c797,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-1d534cad-278e-48ba-bb93-429d8b819a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ccc61271-71ee-440e-aa4f-0ee1b226bd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-66bd833a-018b-433f-81b5-c1602d3a099b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5186
