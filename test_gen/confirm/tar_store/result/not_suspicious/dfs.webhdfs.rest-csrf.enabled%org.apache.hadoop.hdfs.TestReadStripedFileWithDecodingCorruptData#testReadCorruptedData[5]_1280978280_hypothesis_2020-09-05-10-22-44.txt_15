reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=2, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-380774633-172.17.0.9-1599303119540:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-edbfb791-db3c-4b64-a0ab-b7aaff5d7da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-90c9533e-3961-4f35-82f7-f5ff60ba8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-573aa59f-e317-4210-867e-a6d023dfe584,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-263c9dee-3142-46f7-a273-bfab8da26581,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d0835e36-ebf4-4161-a1aa-b544748d7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b53815c0-edaa-4adc-9d99-28f274934edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d4a79d32-9f08-4b48-b54f-d88e233a2520,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c1eef5cd-b5f8-4e7c-b105-268ad3358144,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-380774633-172.17.0.9-1599303119540:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-edbfb791-db3c-4b64-a0ab-b7aaff5d7da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-90c9533e-3961-4f35-82f7-f5ff60ba8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-573aa59f-e317-4210-867e-a6d023dfe584,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-263c9dee-3142-46f7-a273-bfab8da26581,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d0835e36-ebf4-4161-a1aa-b544748d7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b53815c0-edaa-4adc-9d99-28f274934edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d4a79d32-9f08-4b48-b54f-d88e233a2520,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c1eef5cd-b5f8-4e7c-b105-268ad3358144,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=2, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-380774633-172.17.0.9-1599303119540:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-edbfb791-db3c-4b64-a0ab-b7aaff5d7da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-90c9533e-3961-4f35-82f7-f5ff60ba8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-573aa59f-e317-4210-867e-a6d023dfe584,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-263c9dee-3142-46f7-a273-bfab8da26581,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d0835e36-ebf4-4161-a1aa-b544748d7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b53815c0-edaa-4adc-9d99-28f274934edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d4a79d32-9f08-4b48-b54f-d88e233a2520,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c1eef5cd-b5f8-4e7c-b105-268ad3358144,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-380774633-172.17.0.9-1599303119540:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-edbfb791-db3c-4b64-a0ab-b7aaff5d7da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-90c9533e-3961-4f35-82f7-f5ff60ba8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-573aa59f-e317-4210-867e-a6d023dfe584,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-263c9dee-3142-46f7-a273-bfab8da26581,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d0835e36-ebf4-4161-a1aa-b544748d7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b53815c0-edaa-4adc-9d99-28f274934edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d4a79d32-9f08-4b48-b54f-d88e233a2520,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c1eef5cd-b5f8-4e7c-b105-268ad3358144,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:378)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=3, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-251200514-172.17.0.9-1599303219505:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-470bc610-7072-4fc8-82c4-64230ee6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-794bd4af-9ba9-4743-8a5d-00bf53025ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-a77e8f5b-6818-461f-9b44-523fd9959e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-8f794653-b32b-43d3-b3c6-d1436bb27cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-fa25f386-a296-44bc-8961-4d9e2b758f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-a3c2e71f-f7c6-4bb7-bcfa-0defb308d995,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-86df5d2c-299a-4958-923e-6421d5fc4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c487c46-1673-43c0-a1b3-da0e86037436,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-251200514-172.17.0.9-1599303219505:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-470bc610-7072-4fc8-82c4-64230ee6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-794bd4af-9ba9-4743-8a5d-00bf53025ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-a77e8f5b-6818-461f-9b44-523fd9959e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-8f794653-b32b-43d3-b3c6-d1436bb27cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-fa25f386-a296-44bc-8961-4d9e2b758f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-a3c2e71f-f7c6-4bb7-bcfa-0defb308d995,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-86df5d2c-299a-4958-923e-6421d5fc4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c487c46-1673-43c0-a1b3-da0e86037436,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=3, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-251200514-172.17.0.9-1599303219505:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-470bc610-7072-4fc8-82c4-64230ee6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-794bd4af-9ba9-4743-8a5d-00bf53025ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-a77e8f5b-6818-461f-9b44-523fd9959e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-8f794653-b32b-43d3-b3c6-d1436bb27cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-fa25f386-a296-44bc-8961-4d9e2b758f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-a3c2e71f-f7c6-4bb7-bcfa-0defb308d995,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-86df5d2c-299a-4958-923e-6421d5fc4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c487c46-1673-43c0-a1b3-da0e86037436,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-251200514-172.17.0.9-1599303219505:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-470bc610-7072-4fc8-82c4-64230ee6f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-794bd4af-9ba9-4743-8a5d-00bf53025ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-a77e8f5b-6818-461f-9b44-523fd9959e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-8f794653-b32b-43d3-b3c6-d1436bb27cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-fa25f386-a296-44bc-8961-4d9e2b758f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-a3c2e71f-f7c6-4bb7-bcfa-0defb308d995,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-86df5d2c-299a-4958-923e-6421d5fc4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c487c46-1673-43c0-a1b3-da0e86037436,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:378)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2227)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 9958
