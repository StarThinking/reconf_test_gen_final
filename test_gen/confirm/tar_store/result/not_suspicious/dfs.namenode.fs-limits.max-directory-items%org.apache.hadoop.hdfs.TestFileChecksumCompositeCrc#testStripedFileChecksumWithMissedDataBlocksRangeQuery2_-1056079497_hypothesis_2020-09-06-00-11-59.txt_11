reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285366695-172.17.0.4-1599351275889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-9ca15b05-c656-4539-838f-6ab068cadf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3bb56229-2530-4eb3-963a-c4d32e5de811,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-385c6118-5506-47ee-b38d-05ffacc75800,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-065e138e-9433-467b-81bf-b7e88dcd4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-23a2776b-1386-408c-9759-48b2bd91ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-f2d21989-acaa-400d-9e74-e23d749a16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-b86d5505-65b7-499f-a32e-fdfe26a33088,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-9aaeb105-e0af-4aaf-8514-aa086b669f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285366695-172.17.0.4-1599351275889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-9ca15b05-c656-4539-838f-6ab068cadf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3bb56229-2530-4eb3-963a-c4d32e5de811,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-385c6118-5506-47ee-b38d-05ffacc75800,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-065e138e-9433-467b-81bf-b7e88dcd4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-23a2776b-1386-408c-9759-48b2bd91ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-f2d21989-acaa-400d-9e74-e23d749a16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-b86d5505-65b7-499f-a32e-fdfe26a33088,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-9aaeb105-e0af-4aaf-8514-aa086b669f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564665513-172.17.0.4-1599351428665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-d5aa2ed1-2d9f-48f4-a191-eb8926669356,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-0db4d0f8-7296-4647-8976-62c4b21fdb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-0c6766a7-c188-42bb-b0ec-302b57e22870,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-9b3159f5-d09c-4ea3-b991-e5d97b10c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-34068a24-2401-4f8c-ba97-63ec44a26dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-1951796e-e2ac-4af8-ab09-03bb1ec89c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-d1aa92ed-837e-4b9c-a1f1-1052879230fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-44340684-7d84-4b50-8641-80e5fcc837e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564665513-172.17.0.4-1599351428665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-d5aa2ed1-2d9f-48f4-a191-eb8926669356,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-0db4d0f8-7296-4647-8976-62c4b21fdb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-0c6766a7-c188-42bb-b0ec-302b57e22870,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-9b3159f5-d09c-4ea3-b991-e5d97b10c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-34068a24-2401-4f8c-ba97-63ec44a26dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-1951796e-e2ac-4af8-ab09-03bb1ec89c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-d1aa92ed-837e-4b9c-a1f1-1052879230fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-44340684-7d84-4b50-8641-80e5fcc837e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251737735-172.17.0.4-1599351649438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-60373423-e5cf-4817-b27c-14c02a76d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-63d20262-e35c-496d-b416-07c4ac98665a,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-fe8a882d-9b86-4f73-b1df-6d459c673ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-b101d326-2c35-413c-8863-0c912a2eee54,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-820b73ba-a968-4e74-b3d2-424ffbead06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-193b5e3c-dc27-4845-839b-6fdef020afae,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-949650cb-16fa-48a7-a00c-c30803454147,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e75f64f9-d2f7-42ad-8e3e-e9add02c2d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251737735-172.17.0.4-1599351649438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-60373423-e5cf-4817-b27c-14c02a76d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-63d20262-e35c-496d-b416-07c4ac98665a,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-fe8a882d-9b86-4f73-b1df-6d459c673ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-b101d326-2c35-413c-8863-0c912a2eee54,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-820b73ba-a968-4e74-b3d2-424ffbead06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-193b5e3c-dc27-4845-839b-6fdef020afae,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-949650cb-16fa-48a7-a00c-c30803454147,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e75f64f9-d2f7-42ad-8e3e-e9add02c2d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171520257-172.17.0.4-1599351767065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-d897efa7-796e-4ec1-90ed-f2e73c76e989,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-8dff213f-a0f4-49ab-b2d0-8f349ef2f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f7dbefbe-4e03-4824-a9b4-55e1b0160287,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-06d1261d-8bf9-41d9-bfee-13a37bcb4636,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-c8e55596-c868-4c6f-8482-b5f980a48472,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-7651b1cc-4f82-4e30-88aa-39c5f219fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-9a21b8e9-a892-4f02-9c10-fcd700bc0e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-e9d4a6c8-13aa-461f-ac7e-2b9e73b19c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171520257-172.17.0.4-1599351767065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-d897efa7-796e-4ec1-90ed-f2e73c76e989,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-8dff213f-a0f4-49ab-b2d0-8f349ef2f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f7dbefbe-4e03-4824-a9b4-55e1b0160287,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-06d1261d-8bf9-41d9-bfee-13a37bcb4636,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-c8e55596-c868-4c6f-8482-b5f980a48472,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-7651b1cc-4f82-4e30-88aa-39c5f219fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-9a21b8e9-a892-4f02-9c10-fcd700bc0e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-e9d4a6c8-13aa-461f-ac7e-2b9e73b19c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546168364-172.17.0.4-1599352270325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-15af960d-147a-40da-a4f6-6c3d531378a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-48456708-dc63-4b7a-828c-d6a5fea926c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-52c53f06-fcc7-4b9b-8eb4-6a4f7616178f,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-5101f8da-82f9-4180-8e3b-21015d6b8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-408b998f-1206-4b4a-b6a8-1e76b367d0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-d5bfe8e2-8371-4d9b-a0e2-6702b383ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-c02eb0b8-379d-47e1-93b7-9c729c3a5ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-68edf65a-f7d6-400f-be20-8de372d44dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546168364-172.17.0.4-1599352270325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-15af960d-147a-40da-a4f6-6c3d531378a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-48456708-dc63-4b7a-828c-d6a5fea926c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-52c53f06-fcc7-4b9b-8eb4-6a4f7616178f,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-5101f8da-82f9-4180-8e3b-21015d6b8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-408b998f-1206-4b4a-b6a8-1e76b367d0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-d5bfe8e2-8371-4d9b-a0e2-6702b383ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-c02eb0b8-379d-47e1-93b7-9c729c3a5ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-68edf65a-f7d6-400f-be20-8de372d44dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398025626-172.17.0.4-1599352854245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46043,DS-a414777c-5753-4b11-bf9a-4d90fd3b3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-d7272eaf-52e9-4664-abb5-d2005fb433c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-2ece794f-9071-4731-bb7f-0481b63853de,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-6ed7723f-8d29-4a59-83a7-aed23e4b274c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ed3364b3-8f6b-453c-a345-bd421194f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-d5985052-5262-4d9b-8f87-92baeb7219ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-e3af88dd-5070-46ad-aa24-b10967c2c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-fa7fd723-1019-4e1d-9060-f1936ccfc8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398025626-172.17.0.4-1599352854245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46043,DS-a414777c-5753-4b11-bf9a-4d90fd3b3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-d7272eaf-52e9-4664-abb5-d2005fb433c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-2ece794f-9071-4731-bb7f-0481b63853de,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-6ed7723f-8d29-4a59-83a7-aed23e4b274c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ed3364b3-8f6b-453c-a345-bd421194f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-d5985052-5262-4d9b-8f87-92baeb7219ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-e3af88dd-5070-46ad-aa24-b10967c2c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-fa7fd723-1019-4e1d-9060-f1936ccfc8d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545249687-172.17.0.4-1599353313324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-9aae9f0f-afb2-4719-91a0-1962046d645d,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-ab1f3553-2372-4e3f-91ae-52ee4531418d,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-a2979f59-2c54-4230-a9e1-fa1db3c2ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-dab25958-776c-4c83-94be-cdf6a15ca453,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-26f25341-92c1-4611-adfc-c047c1f4bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-39c7f43e-9fe0-4ae6-860d-7ff685de8876,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c28a4ba6-ca6a-44b8-9a47-94a21f787af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5e2af695-2b87-4102-ae5f-81cee2a17d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545249687-172.17.0.4-1599353313324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-9aae9f0f-afb2-4719-91a0-1962046d645d,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-ab1f3553-2372-4e3f-91ae-52ee4531418d,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-a2979f59-2c54-4230-a9e1-fa1db3c2ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-dab25958-776c-4c83-94be-cdf6a15ca453,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-26f25341-92c1-4611-adfc-c047c1f4bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-39c7f43e-9fe0-4ae6-860d-7ff685de8876,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c28a4ba6-ca6a-44b8-9a47-94a21f787af0,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-5e2af695-2b87-4102-ae5f-81cee2a17d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266122832-172.17.0.4-1599353410072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-3c2ba3ac-f48c-441a-a140-1ba1be78f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-9df124ac-c456-499e-a42b-d83ae7b63c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-19a78588-3241-4f61-ae82-776c53e41a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-16c0635b-fa22-494c-ab2c-cdaaef8bc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-4494098f-8eac-44cb-9e8a-6ebe949dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c8d0f96a-dc81-4cf8-a75e-74d3a26e47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-c1cb1f76-503b-4d2a-be7c-774cc629c6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-f5780019-094e-416f-be19-b354dc268a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266122832-172.17.0.4-1599353410072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-3c2ba3ac-f48c-441a-a140-1ba1be78f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-9df124ac-c456-499e-a42b-d83ae7b63c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-19a78588-3241-4f61-ae82-776c53e41a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-16c0635b-fa22-494c-ab2c-cdaaef8bc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-4494098f-8eac-44cb-9e8a-6ebe949dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c8d0f96a-dc81-4cf8-a75e-74d3a26e47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-c1cb1f76-503b-4d2a-be7c-774cc629c6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-f5780019-094e-416f-be19-b354dc268a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337689512-172.17.0.4-1599353471825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-fcd3cab9-0896-4c64-af73-28d735b4171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-67a6e273-acf1-4603-8fd7-04d59c7c98d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-06ec6399-5476-4d0a-822c-8b072e1ecd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-513b4d76-23d6-4f3a-a528-43bf95663624,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-9f6d19dd-ac85-4c3c-b7d7-d4f9242a5ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-b9a0bab9-bd3d-4548-8dd7-71ead03e124a,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a4dd04c0-46eb-4a41-b4ab-2690c09c0621,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-bffc54db-0dbf-4851-bb2d-bc790da6b325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337689512-172.17.0.4-1599353471825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-fcd3cab9-0896-4c64-af73-28d735b4171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-67a6e273-acf1-4603-8fd7-04d59c7c98d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-06ec6399-5476-4d0a-822c-8b072e1ecd82,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-513b4d76-23d6-4f3a-a528-43bf95663624,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-9f6d19dd-ac85-4c3c-b7d7-d4f9242a5ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-b9a0bab9-bd3d-4548-8dd7-71ead03e124a,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a4dd04c0-46eb-4a41-b4ab-2690c09c0621,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-bffc54db-0dbf-4851-bb2d-bc790da6b325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829997040-172.17.0.4-1599353757858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-069672e9-57fa-4dc4-aa22-cc3cd17804c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-46ccc0d0-dca7-450e-990a-19edc24791a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-45511401-16e4-4c07-9588-77d4051acd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2bda7706-9050-4c61-b3fd-8a350fe39d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-742a98a2-87e5-4301-ac32-12ab37bdcbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-89c46e1f-a5fe-4940-b995-e494b3f054a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-2f17f2af-bd07-4f49-b92d-d598f02c671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-2a9d84d1-5dc7-432b-8fe9-9b0cb36c7797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829997040-172.17.0.4-1599353757858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-069672e9-57fa-4dc4-aa22-cc3cd17804c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-46ccc0d0-dca7-450e-990a-19edc24791a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-45511401-16e4-4c07-9588-77d4051acd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2bda7706-9050-4c61-b3fd-8a350fe39d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-742a98a2-87e5-4301-ac32-12ab37bdcbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-89c46e1f-a5fe-4940-b995-e494b3f054a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-2f17f2af-bd07-4f49-b92d-d598f02c671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-2a9d84d1-5dc7-432b-8fe9-9b0cb36c7797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570661427-172.17.0.4-1599353822410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-7ef4f65b-f000-4aaa-b2ab-b24b0c1c8867,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-da9282ad-95e0-4c30-a288-e9ed3ac13162,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-f06baf0e-75e8-4b78-b9c9-c3bce8005f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-3818be97-9fd4-4185-b2d8-90ac8a9a0734,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-a7bd7913-ad42-4e40-b17f-a07fa1698752,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-edd93b66-a72e-4c31-aec1-0063cce7492d,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-3ea31576-d182-433c-b7e2-55c541611e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-1ea39962-368a-4bdd-9895-69d50f9389f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570661427-172.17.0.4-1599353822410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-7ef4f65b-f000-4aaa-b2ab-b24b0c1c8867,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-da9282ad-95e0-4c30-a288-e9ed3ac13162,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-f06baf0e-75e8-4b78-b9c9-c3bce8005f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-3818be97-9fd4-4185-b2d8-90ac8a9a0734,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-a7bd7913-ad42-4e40-b17f-a07fa1698752,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-edd93b66-a72e-4c31-aec1-0063cce7492d,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-3ea31576-d182-433c-b7e2-55c541611e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-1ea39962-368a-4bdd-9895-69d50f9389f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624592917-172.17.0.4-1599354101860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-80cd55d9-0a83-4ae2-b190-8115e5e798ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-98099b70-a228-49a5-9714-541d9b34e351,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-912fd00f-ae7c-46ab-a712-e96f8ce556aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-55a4d89a-5d09-49de-950e-f562ed0475f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-7e654dd4-908d-48ab-9fa3-5991303aa6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-369215d8-9e35-44d4-9c99-38460e2e6635,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-5e458500-bdb1-4efe-8d47-ff6b3a061a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-0d4934e9-f3ed-498d-8598-b8e9dd106b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624592917-172.17.0.4-1599354101860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-80cd55d9-0a83-4ae2-b190-8115e5e798ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-98099b70-a228-49a5-9714-541d9b34e351,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-912fd00f-ae7c-46ab-a712-e96f8ce556aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-55a4d89a-5d09-49de-950e-f562ed0475f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-7e654dd4-908d-48ab-9fa3-5991303aa6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-369215d8-9e35-44d4-9c99-38460e2e6635,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-5e458500-bdb1-4efe-8d47-ff6b3a061a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-0d4934e9-f3ed-498d-8598-b8e9dd106b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857964-172.17.0.4-1599354498448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-fdd5d44a-106e-44f2-9cb2-f3810851b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-940fc4aa-343c-4a7a-a6b2-059081dea4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e25138fb-2e1d-4343-a470-be412c8958eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-bea55170-f491-46b5-b832-2b2667d2f873,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-fb6c521d-aa19-4416-996e-200da3036f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-984d4c51-bd27-485b-920f-9a524b85b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-58a8a581-3366-45d2-aa50-6f8051856fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-b0e0389d-7172-446f-8af1-87b85b25ff7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857964-172.17.0.4-1599354498448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-fdd5d44a-106e-44f2-9cb2-f3810851b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-940fc4aa-343c-4a7a-a6b2-059081dea4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e25138fb-2e1d-4343-a470-be412c8958eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-bea55170-f491-46b5-b832-2b2667d2f873,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-fb6c521d-aa19-4416-996e-200da3036f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-984d4c51-bd27-485b-920f-9a524b85b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-58a8a581-3366-45d2-aa50-6f8051856fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-b0e0389d-7172-446f-8af1-87b85b25ff7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829893186-172.17.0.4-1599354763342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-f9026265-53fe-48e7-9c4e-7118f94cf222,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-3ed2d815-2d56-407e-b93f-a79d1043cd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-53e65919-4dac-45e0-b780-3883d3f58b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-87c0598a-ee3c-4973-a325-6da6c708ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-af2bf22a-3e1c-403d-a57e-a7cc460c2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-5f65c8f1-51ec-4f11-b805-fec6e7a88941,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-bb9dadb2-9180-4218-a868-e495a73336c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-b49a52eb-2c6a-4bf0-9fa8-dcd3f216b58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829893186-172.17.0.4-1599354763342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-f9026265-53fe-48e7-9c4e-7118f94cf222,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-3ed2d815-2d56-407e-b93f-a79d1043cd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-53e65919-4dac-45e0-b780-3883d3f58b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-87c0598a-ee3c-4973-a325-6da6c708ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-af2bf22a-3e1c-403d-a57e-a7cc460c2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-5f65c8f1-51ec-4f11-b805-fec6e7a88941,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-bb9dadb2-9180-4218-a868-e495a73336c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-b49a52eb-2c6a-4bf0-9fa8-dcd3f216b58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231846546-172.17.0.4-1599354956125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-fc9a1517-e951-4c5c-bd0c-9d919770edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-50623658-547b-46db-bdf6-bc92558757b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-5c7c991f-0729-4878-9b03-0cd71298b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f6f0a55a-5a28-4622-a067-67f815e36319,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-a1b90096-79fe-475f-b993-29dd547f6abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-e7a4cc47-50cd-438b-b790-59dab55a6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-4fc141cd-4a5c-4abf-a264-7a2adc6341e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-687b5821-9e2b-48d8-b3e1-db614822d6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231846546-172.17.0.4-1599354956125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-fc9a1517-e951-4c5c-bd0c-9d919770edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-50623658-547b-46db-bdf6-bc92558757b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-5c7c991f-0729-4878-9b03-0cd71298b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f6f0a55a-5a28-4622-a067-67f815e36319,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-a1b90096-79fe-475f-b993-29dd547f6abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-e7a4cc47-50cd-438b-b790-59dab55a6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-4fc141cd-4a5c-4abf-a264-7a2adc6341e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-687b5821-9e2b-48d8-b3e1-db614822d6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440604239-172.17.0.4-1599355118989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-41106803-29c3-49a2-be06-e89d80c8a070,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-0905da48-6cd8-423c-a903-ff7671f59f19,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-838c52a5-c4c5-4590-b997-d70a1d3f188d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1888ee25-10cb-46f4-ad64-99831a985175,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-a7821f74-7242-4d4f-a50a-f0dc726b65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-dfe30e84-c1ce-4a63-aa82-bf59f416064b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-8b25d0ad-32b0-4050-bfab-2278d95ec1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-7abae70f-33e8-4bad-acc4-73510f3c3fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440604239-172.17.0.4-1599355118989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-41106803-29c3-49a2-be06-e89d80c8a070,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-0905da48-6cd8-423c-a903-ff7671f59f19,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-838c52a5-c4c5-4590-b997-d70a1d3f188d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-1888ee25-10cb-46f4-ad64-99831a985175,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-a7821f74-7242-4d4f-a50a-f0dc726b65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-dfe30e84-c1ce-4a63-aa82-bf59f416064b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-8b25d0ad-32b0-4050-bfab-2278d95ec1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-7abae70f-33e8-4bad-acc4-73510f3c3fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176255741-172.17.0.4-1599355208148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-93bd26d8-1991-4f9a-937e-6f7c44691e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-931d04bc-b39a-4682-8c4c-455fc631e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-a21638d4-8675-4a2b-88fc-3ad0404e0452,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-99a6c7f3-5e6e-42ee-a3f4-3c9cd66fbc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-c49bb43e-b24b-4e90-b4ad-9aec33dcd526,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-f3822ece-d1fa-4dd5-87b9-bbcde3cf8f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-7f402e75-49df-43c8-a3c3-5559e488463b,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-b9686ccd-288d-4994-8915-efa5f88f9120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176255741-172.17.0.4-1599355208148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-93bd26d8-1991-4f9a-937e-6f7c44691e15,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-931d04bc-b39a-4682-8c4c-455fc631e96c,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-a21638d4-8675-4a2b-88fc-3ad0404e0452,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-99a6c7f3-5e6e-42ee-a3f4-3c9cd66fbc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-c49bb43e-b24b-4e90-b4ad-9aec33dcd526,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-f3822ece-d1fa-4dd5-87b9-bbcde3cf8f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-7f402e75-49df-43c8-a3c3-5559e488463b,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-b9686ccd-288d-4994-8915-efa5f88f9120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62202344-172.17.0.4-1599356136149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40427,DS-f234b9ff-44a9-43c0-aeee-cd544fee671a,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3fca272e-c850-4cfb-b612-0fb3b948d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-6d22624a-cfb4-4970-a083-b70c72fc8442,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-b041caf2-64a0-4800-8ea6-d8d6cb110758,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-498f7faf-ffb6-49c3-b860-a2158a19aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-52a0803c-572d-4f04-9180-653432d032bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-31b33b12-c601-4934-b8e3-a8a138f970ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-0b03817c-c705-4eb3-9bad-b34fb56a6308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62202344-172.17.0.4-1599356136149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40427,DS-f234b9ff-44a9-43c0-aeee-cd544fee671a,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3fca272e-c850-4cfb-b612-0fb3b948d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-6d22624a-cfb4-4970-a083-b70c72fc8442,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-b041caf2-64a0-4800-8ea6-d8d6cb110758,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-498f7faf-ffb6-49c3-b860-a2158a19aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-52a0803c-572d-4f04-9180-653432d032bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-31b33b12-c601-4934-b8e3-a8a138f970ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-0b03817c-c705-4eb3-9bad-b34fb56a6308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5139
