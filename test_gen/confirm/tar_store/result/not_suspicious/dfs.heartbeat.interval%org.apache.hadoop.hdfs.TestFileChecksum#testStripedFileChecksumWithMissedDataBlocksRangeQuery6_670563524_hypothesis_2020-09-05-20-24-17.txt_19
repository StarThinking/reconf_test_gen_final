reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451017736-172.17.0.11-1599337507113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-c8b95e89-4bc4-44e6-9fd0-d36b93c1827c,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-11c1fb81-57bb-40a2-9be9-4a6a506eb992,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-70f7bf6e-b523-4e4a-a55f-c791edc2a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-5505077b-4482-414f-ad6c-68b42dbf578e,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-23f02e74-5eec-4907-9d4f-cc16b90cbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-2377423c-735c-4bd2-a682-14861c811a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-5dcffc60-9d27-4cb5-91c9-cdb8cb9a145f,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-f956bf6e-c38a-418d-be65-080e183d1479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451017736-172.17.0.11-1599337507113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-c8b95e89-4bc4-44e6-9fd0-d36b93c1827c,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-11c1fb81-57bb-40a2-9be9-4a6a506eb992,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-70f7bf6e-b523-4e4a-a55f-c791edc2a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-5505077b-4482-414f-ad6c-68b42dbf578e,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-23f02e74-5eec-4907-9d4f-cc16b90cbaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-2377423c-735c-4bd2-a682-14861c811a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-5dcffc60-9d27-4cb5-91c9-cdb8cb9a145f,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-f956bf6e-c38a-418d-be65-080e183d1479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181237011-172.17.0.11-1599337536106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-be6a9c11-09dd-4c97-a549-0618a3b4fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-e5808809-e492-4c32-83c6-d4258ae5bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-41352943-7e31-415b-a95a-ad726d2f4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-f37aea12-7601-4d54-b4c6-ff81d67c7ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-428ac609-137e-4385-bcfe-c8e402d06334,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-a2a2f41e-4b02-4ef9-a06d-cdd442061982,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-70f1bbc9-48bf-48bd-a379-fc29d59dbcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-895028ff-c765-4e0c-a5c6-75685aff141e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181237011-172.17.0.11-1599337536106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-be6a9c11-09dd-4c97-a549-0618a3b4fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-e5808809-e492-4c32-83c6-d4258ae5bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-41352943-7e31-415b-a95a-ad726d2f4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-f37aea12-7601-4d54-b4c6-ff81d67c7ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-428ac609-137e-4385-bcfe-c8e402d06334,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-a2a2f41e-4b02-4ef9-a06d-cdd442061982,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-70f1bbc9-48bf-48bd-a379-fc29d59dbcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-895028ff-c765-4e0c-a5c6-75685aff141e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663847439-172.17.0.11-1599337807649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-cf5b94a1-48e1-42e4-9161-3c97f770473f,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-42b43e0b-6db5-4560-9b2c-219e8689f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-911027cd-b8a3-4521-a620-a94c33e6f5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a61bf897-d03a-4505-a95e-7de44c7616cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-5ccf8bd1-28bd-4f96-9a29-6e9b591e6623,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-21c5b882-dc36-49fd-bb48-ca2489116e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-189bbdeb-571c-4535-ab92-4e2a83677083,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-07c2e999-1bf5-4a8a-b2e4-902feebfa688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663847439-172.17.0.11-1599337807649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-cf5b94a1-48e1-42e4-9161-3c97f770473f,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-42b43e0b-6db5-4560-9b2c-219e8689f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-911027cd-b8a3-4521-a620-a94c33e6f5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a61bf897-d03a-4505-a95e-7de44c7616cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-5ccf8bd1-28bd-4f96-9a29-6e9b591e6623,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-21c5b882-dc36-49fd-bb48-ca2489116e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-189bbdeb-571c-4535-ab92-4e2a83677083,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-07c2e999-1bf5-4a8a-b2e4-902feebfa688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180453881-172.17.0.11-1599337842621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-8c3199ec-fd18-4af8-8231-273f67170e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-7c0f0a27-cdec-4c4b-89ea-5a908f6059b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-37092228-9c52-4258-b2c1-435ed116502b,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5be46447-e177-481b-b1bf-c35743043548,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-1765e89d-4d53-439f-a8df-fc91a7c223cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-93c31c50-5667-4af6-928d-325843135545,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-a2705c48-5ba6-4ce8-9fa2-27caba091885,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-93a003ba-7921-424b-8c0c-960edbad940c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180453881-172.17.0.11-1599337842621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-8c3199ec-fd18-4af8-8231-273f67170e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-7c0f0a27-cdec-4c4b-89ea-5a908f6059b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-37092228-9c52-4258-b2c1-435ed116502b,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5be46447-e177-481b-b1bf-c35743043548,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-1765e89d-4d53-439f-a8df-fc91a7c223cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-93c31c50-5667-4af6-928d-325843135545,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-a2705c48-5ba6-4ce8-9fa2-27caba091885,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-93a003ba-7921-424b-8c0c-960edbad940c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065839452-172.17.0.11-1599338061695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-98430b5f-0a7c-4908-b596-c005059cab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-d1dc744b-8bc4-4a0a-adcc-844b228c9a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-b3cfad09-e3b2-4201-a4cf-1c787b3f0361,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-76870b19-401b-4e4d-89e4-3f5332e8dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-59d9d48e-c4a6-405c-8dca-8039561306d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f6ba5726-ace2-47c0-9be0-1274d44997ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-472f5f47-905e-44ab-8ad3-cb490b3eb2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0d14e9f1-1c04-4449-9cc5-a084c9e919d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065839452-172.17.0.11-1599338061695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-98430b5f-0a7c-4908-b596-c005059cab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-d1dc744b-8bc4-4a0a-adcc-844b228c9a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-b3cfad09-e3b2-4201-a4cf-1c787b3f0361,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-76870b19-401b-4e4d-89e4-3f5332e8dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-59d9d48e-c4a6-405c-8dca-8039561306d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f6ba5726-ace2-47c0-9be0-1274d44997ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-472f5f47-905e-44ab-8ad3-cb490b3eb2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0d14e9f1-1c04-4449-9cc5-a084c9e919d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782943019-172.17.0.11-1599338209514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-f4b194aa-9418-43e0-9275-4353829e89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-0867b6f1-9fee-4eca-9954-f0954ffef89a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-2755d6a7-8cd4-4c0b-bc38-bea87dd003f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e4e7bae0-1bc8-448c-a0d3-8a3f76d20e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-1ab741ff-4c3f-42aa-ba29-ed3963631d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-9277952a-50d4-4f18-8f44-6087f1376a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-39bf5c85-256b-4670-8f64-c63c11c00b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-b9417158-5424-4f60-a849-750484776709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782943019-172.17.0.11-1599338209514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-f4b194aa-9418-43e0-9275-4353829e89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-0867b6f1-9fee-4eca-9954-f0954ffef89a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-2755d6a7-8cd4-4c0b-bc38-bea87dd003f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e4e7bae0-1bc8-448c-a0d3-8a3f76d20e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-1ab741ff-4c3f-42aa-ba29-ed3963631d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-9277952a-50d4-4f18-8f44-6087f1376a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-39bf5c85-256b-4670-8f64-c63c11c00b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-b9417158-5424-4f60-a849-750484776709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436914487-172.17.0.11-1599338324763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35476,DS-5a69f9ce-14ca-4469-a78e-87407f032142,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-8af98e77-21d3-4782-81b9-0c5549bb79ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d9ab5a17-b592-4ad5-8618-3c9a2b2fa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-3453ef78-377a-449e-89b2-2162438d7f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-01eca8f2-a99e-4e66-92c0-b7973378f204,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a9f4e204-a411-4fa8-a7a3-78a7534dc210,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-bbb08947-0b05-4a51-9cc4-f300ac4e1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-456791e8-a712-4cf4-96e6-b31319bb9f5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436914487-172.17.0.11-1599338324763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35476,DS-5a69f9ce-14ca-4469-a78e-87407f032142,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-8af98e77-21d3-4782-81b9-0c5549bb79ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-d9ab5a17-b592-4ad5-8618-3c9a2b2fa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-3453ef78-377a-449e-89b2-2162438d7f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-01eca8f2-a99e-4e66-92c0-b7973378f204,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a9f4e204-a411-4fa8-a7a3-78a7534dc210,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-bbb08947-0b05-4a51-9cc4-f300ac4e1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-456791e8-a712-4cf4-96e6-b31319bb9f5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257612501-172.17.0.11-1599338415088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-84a2c729-ddac-42cc-aca0-81f8e4f95648,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-623570ce-870e-4532-98a1-7e4ea620f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-63b07d6d-d473-4636-834a-efaddc52a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-99c281fd-3a1c-425c-b785-1990c5439a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-4dbfe7e9-fc9a-4753-8ee1-985e990b6063,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-cf325b5c-ac5d-4e88-835a-b79557a291ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-17a81b90-ca83-46c7-8379-e49a6bd19d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6e23e3ca-9b73-4c37-9a6d-05c1dd775b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257612501-172.17.0.11-1599338415088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-84a2c729-ddac-42cc-aca0-81f8e4f95648,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-623570ce-870e-4532-98a1-7e4ea620f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-63b07d6d-d473-4636-834a-efaddc52a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-99c281fd-3a1c-425c-b785-1990c5439a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-4dbfe7e9-fc9a-4753-8ee1-985e990b6063,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-cf325b5c-ac5d-4e88-835a-b79557a291ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-17a81b90-ca83-46c7-8379-e49a6bd19d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6e23e3ca-9b73-4c37-9a6d-05c1dd775b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171403773-172.17.0.11-1599338868424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-6cb907ae-3715-46ee-b995-47a8f353a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-d3cf1c6a-13cd-40de-aaac-902c011bf3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-4b414beb-02a0-458d-bacc-bd24dbd20d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-8f2c33f4-b136-4dea-920e-b072a9d23054,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3c8d44f0-27d3-41af-b0fe-ae14ccff6eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-1457d721-7f6a-4be8-9a41-e4980133bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-31521c91-476a-45c0-a0b7-71823e9f6813,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-cb338000-bea9-4067-81bd-dbd5cc6dd7cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171403773-172.17.0.11-1599338868424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-6cb907ae-3715-46ee-b995-47a8f353a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-d3cf1c6a-13cd-40de-aaac-902c011bf3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-4b414beb-02a0-458d-bacc-bd24dbd20d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-8f2c33f4-b136-4dea-920e-b072a9d23054,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3c8d44f0-27d3-41af-b0fe-ae14ccff6eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-1457d721-7f6a-4be8-9a41-e4980133bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-31521c91-476a-45c0-a0b7-71823e9f6813,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-cb338000-bea9-4067-81bd-dbd5cc6dd7cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084185448-172.17.0.11-1599338957770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-b87a6f15-1b4c-44aa-98c8-032511d7464d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-70cf44ac-1c73-4f46-8f64-68d3d26989ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-884aa393-5231-42f8-a3df-a283d7077af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-51ed0f0a-fc51-4b9b-b555-6548173866d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-85299e27-4b74-437f-a4b0-dea40368fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d073597b-0987-4f80-b35b-961f3240218d,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-15cdbd28-3245-49e6-88e2-cb36631211d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-42ee5b3f-9a99-44ce-a7e8-618836a76677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084185448-172.17.0.11-1599338957770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-b87a6f15-1b4c-44aa-98c8-032511d7464d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-70cf44ac-1c73-4f46-8f64-68d3d26989ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-884aa393-5231-42f8-a3df-a283d7077af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-51ed0f0a-fc51-4b9b-b555-6548173866d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-85299e27-4b74-437f-a4b0-dea40368fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d073597b-0987-4f80-b35b-961f3240218d,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-15cdbd28-3245-49e6-88e2-cb36631211d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-42ee5b3f-9a99-44ce-a7e8-618836a76677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436288788-172.17.0.11-1599339017242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-ffb311fc-00e4-4c23-8a89-73974af9f584,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-d7ac6462-1776-4102-bccb-b3a2c3317980,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-dacd29e9-636d-4b65-b33c-f0fd0e6b3440,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-d866f7ed-1e80-4cad-8851-2cdf5d96a9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-e92fc473-f703-4cb6-b2b1-c66323a76498,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-7c321020-9c46-4e4c-b127-a8158af2c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-1b894562-011e-4730-8082-a728dc02a6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-f702b4f9-6d28-450f-b648-b6527a86cadd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436288788-172.17.0.11-1599339017242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-ffb311fc-00e4-4c23-8a89-73974af9f584,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-d7ac6462-1776-4102-bccb-b3a2c3317980,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-dacd29e9-636d-4b65-b33c-f0fd0e6b3440,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-d866f7ed-1e80-4cad-8851-2cdf5d96a9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-e92fc473-f703-4cb6-b2b1-c66323a76498,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-7c321020-9c46-4e4c-b127-a8158af2c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-1b894562-011e-4730-8082-a728dc02a6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-f702b4f9-6d28-450f-b648-b6527a86cadd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373294796-172.17.0.11-1599339174467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-d9c7b584-14db-421e-bd54-41f8f6530397,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-0e19befb-4c0e-4ebd-9868-fa947a2eeead,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-1cc5be33-c896-47a0-9128-9b4bbcf59ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-d0a9ec4b-d0f1-46c1-9db2-2ef33564412b,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-acd45dfd-5174-44de-b41e-b4b34a33ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-6ff24a8a-ff81-4d89-bc48-a959f539f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-1e25a488-8e2a-4b47-86af-2fe05edc5e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-cf7dba61-394f-4052-ae9b-00259cb864a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373294796-172.17.0.11-1599339174467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-d9c7b584-14db-421e-bd54-41f8f6530397,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-0e19befb-4c0e-4ebd-9868-fa947a2eeead,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-1cc5be33-c896-47a0-9128-9b4bbcf59ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-d0a9ec4b-d0f1-46c1-9db2-2ef33564412b,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-acd45dfd-5174-44de-b41e-b4b34a33ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-6ff24a8a-ff81-4d89-bc48-a959f539f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-1e25a488-8e2a-4b47-86af-2fe05edc5e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-cf7dba61-394f-4052-ae9b-00259cb864a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905156548-172.17.0.11-1599339206920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-faa24d4d-300d-4ae3-be52-9763b37c4aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-ab61fc2a-f256-437b-98d1-7fff7eb5deb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-8adb854b-a2eb-4f22-8389-1014f6b18018,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-1c775737-7b60-4ac4-9fb0-213abac748e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-39a56574-926c-4887-94b9-8d764200d411,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-0995b2ef-cdd7-42c5-b6d9-351c7e5f4a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-683820f2-89a0-4082-9c8d-578bde0382d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-0c854975-5e13-4e5a-b0cb-c6ccf5e66d1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905156548-172.17.0.11-1599339206920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-faa24d4d-300d-4ae3-be52-9763b37c4aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-ab61fc2a-f256-437b-98d1-7fff7eb5deb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-8adb854b-a2eb-4f22-8389-1014f6b18018,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-1c775737-7b60-4ac4-9fb0-213abac748e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-39a56574-926c-4887-94b9-8d764200d411,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-0995b2ef-cdd7-42c5-b6d9-351c7e5f4a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-683820f2-89a0-4082-9c8d-578bde0382d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-0c854975-5e13-4e5a-b0cb-c6ccf5e66d1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418726105-172.17.0.11-1599339762454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42465,DS-69bca63c-2088-4e9b-95c1-f4f4db2e65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-dc67f685-6020-4a62-81b3-856862bc968b,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-43f54802-49b6-4a9d-be65-50b6166b56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-66158d46-e835-422a-ae26-d9a455bca6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-3d77763e-1c27-4794-9d4a-f3f095e15824,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-4e650944-181d-4f30-8799-9a3190bcf490,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-5e9fd71b-5299-45cb-8d54-c641591ba0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-58e2fe96-fd8f-4744-a7da-5ba38d40ec8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418726105-172.17.0.11-1599339762454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42465,DS-69bca63c-2088-4e9b-95c1-f4f4db2e65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-dc67f685-6020-4a62-81b3-856862bc968b,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-43f54802-49b6-4a9d-be65-50b6166b56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-66158d46-e835-422a-ae26-d9a455bca6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-3d77763e-1c27-4794-9d4a-f3f095e15824,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-4e650944-181d-4f30-8799-9a3190bcf490,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-5e9fd71b-5299-45cb-8d54-c641591ba0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-58e2fe96-fd8f-4744-a7da-5ba38d40ec8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238347103-172.17.0.11-1599339826621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-d282fb6c-97f1-46c9-8dba-edb1174495d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-06c5dbed-61fb-4353-9f87-4f282453abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-7feeedb6-1818-4376-8e96-66307c86754d,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-19e85908-93f9-480e-adb0-9e82b85f6462,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-e7ed7c98-3881-4136-b534-85c7ca442b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-095e1f92-301b-4464-913a-2e44afd69d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-3fac5603-9ec5-44c4-939c-641a1b269ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-6eea1be4-72e6-4314-ad37-4735c4870c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238347103-172.17.0.11-1599339826621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-d282fb6c-97f1-46c9-8dba-edb1174495d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-06c5dbed-61fb-4353-9f87-4f282453abb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-7feeedb6-1818-4376-8e96-66307c86754d,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-19e85908-93f9-480e-adb0-9e82b85f6462,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-e7ed7c98-3881-4136-b534-85c7ca442b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-095e1f92-301b-4464-913a-2e44afd69d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-3fac5603-9ec5-44c4-939c-641a1b269ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-6eea1be4-72e6-4314-ad37-4735c4870c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407831639-172.17.0.11-1599340098148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-2636eb60-2eb6-4a61-a6d1-5ee3cf2410b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-edd78732-c22b-4feb-87f3-8ce5f5222c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-bc948431-89a8-42c3-8a56-8b34e7f93e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-39388334-5698-4af0-9c6a-816f4b519f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-82e0013e-6670-428f-87f5-5340508cd09e,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-55bd606a-21fd-43aa-ab1b-6a34c51ddb43,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-47e3f0a2-a29f-4c98-80f2-edc07043b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-8b8c262f-fbe2-4a47-8c1e-262fe9396067,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407831639-172.17.0.11-1599340098148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-2636eb60-2eb6-4a61-a6d1-5ee3cf2410b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-edd78732-c22b-4feb-87f3-8ce5f5222c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-bc948431-89a8-42c3-8a56-8b34e7f93e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-39388334-5698-4af0-9c6a-816f4b519f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-82e0013e-6670-428f-87f5-5340508cd09e,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-55bd606a-21fd-43aa-ab1b-6a34c51ddb43,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-47e3f0a2-a29f-4c98-80f2-edc07043b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-8b8c262f-fbe2-4a47-8c1e-262fe9396067,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856965946-172.17.0.11-1599340555835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-1ace2844-347f-4aa4-94bc-113b13b01f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-76904af5-3e7d-405b-a412-f90d98aaf1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-6160b153-be61-43b1-8d0d-cca5d458082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-eeb05453-f5af-4a68-8b2b-a04938125e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-256f1d6f-3c00-471d-98f9-a1a429b74cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4312e40d-45c4-43e4-abdb-6e36ee3bb980,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-6a516aa8-7b63-44a3-8da9-ab0dec891ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-d1de1d07-24cf-4b2e-83c7-45627168ff6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856965946-172.17.0.11-1599340555835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-1ace2844-347f-4aa4-94bc-113b13b01f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-76904af5-3e7d-405b-a412-f90d98aaf1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-6160b153-be61-43b1-8d0d-cca5d458082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-eeb05453-f5af-4a68-8b2b-a04938125e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-256f1d6f-3c00-471d-98f9-a1a429b74cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4312e40d-45c4-43e4-abdb-6e36ee3bb980,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-6a516aa8-7b63-44a3-8da9-ab0dec891ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-d1de1d07-24cf-4b2e-83c7-45627168ff6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478351487-172.17.0.11-1599340743386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-d8a2cca8-865e-4f92-a8c4-1ef96b04d956,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-35ab6b57-b284-4209-bcb0-49cf62c1445c,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-3666c130-e49c-40ca-9f6c-7b5df343505f,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-ebdbf2c6-068b-4aef-a85c-aa38d3d06181,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-8536d46e-34a9-4059-9489-a94b98dad250,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-f0416ef8-ebb0-430e-854c-77a2224be808,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-44137b71-2071-4d84-b92c-914f6c877888,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-a8ec0b50-e665-450b-a1d5-039d2c011771,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478351487-172.17.0.11-1599340743386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-d8a2cca8-865e-4f92-a8c4-1ef96b04d956,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-35ab6b57-b284-4209-bcb0-49cf62c1445c,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-3666c130-e49c-40ca-9f6c-7b5df343505f,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-ebdbf2c6-068b-4aef-a85c-aa38d3d06181,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-8536d46e-34a9-4059-9489-a94b98dad250,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-f0416ef8-ebb0-430e-854c-77a2224be808,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-44137b71-2071-4d84-b92c-914f6c877888,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-a8ec0b50-e665-450b-a1d5-039d2c011771,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974421103-172.17.0.11-1599340771641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-ff751dbd-f03a-4c93-8f17-ac9ee0cb1aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-a146e73b-ee18-4160-b233-fd9aa096dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-27f5dd8e-704b-402e-99a6-ac5c8a05a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-87afdd73-b65e-4fdd-be24-7cf108cf4504,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-21962b9d-fa03-45ca-bb7f-f3efdc053896,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-4ef3dc27-7864-45d6-ae4f-592a6a1aa141,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-6059506e-6891-404e-80f2-794006af0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-7ea24968-6fd2-4459-a6f3-e653b1ebe36c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974421103-172.17.0.11-1599340771641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-ff751dbd-f03a-4c93-8f17-ac9ee0cb1aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-a146e73b-ee18-4160-b233-fd9aa096dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-27f5dd8e-704b-402e-99a6-ac5c8a05a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-87afdd73-b65e-4fdd-be24-7cf108cf4504,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-21962b9d-fa03-45ca-bb7f-f3efdc053896,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-4ef3dc27-7864-45d6-ae4f-592a6a1aa141,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-6059506e-6891-404e-80f2-794006af0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-7ea24968-6fd2-4459-a6f3-e653b1ebe36c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566011276-172.17.0.11-1599340829644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37245,DS-82cd46c5-1323-4361-b509-79a775d19c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-b7e12d17-cbbc-44b5-b481-260a426379fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-94c00656-780b-4220-9c1f-6401a2a9322d,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-f33c61ed-c46c-42ed-8773-c826473c74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-21fbc7ad-d3b9-44f8-abdf-f0ff9566d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-042f7d05-4ca2-4252-a1f7-ba7bef9b9329,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-6fa3a010-7434-4b12-8801-dbfebe46a485,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-cee6fe9c-85fd-49c6-acf3-5abbaaa0277a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566011276-172.17.0.11-1599340829644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37245,DS-82cd46c5-1323-4361-b509-79a775d19c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-b7e12d17-cbbc-44b5-b481-260a426379fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-94c00656-780b-4220-9c1f-6401a2a9322d,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-f33c61ed-c46c-42ed-8773-c826473c74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-21fbc7ad-d3b9-44f8-abdf-f0ff9566d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-042f7d05-4ca2-4252-a1f7-ba7bef9b9329,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-6fa3a010-7434-4b12-8801-dbfebe46a485,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-cee6fe9c-85fd-49c6-acf3-5abbaaa0277a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266473507-172.17.0.11-1599340928572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-58287189-04e2-4265-a8e8-e9faf13d3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-708ee7dd-0421-4766-a734-d2eee55cbac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1c8823de-0f33-4573-8592-bd0e697af204,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ab4ac683-635f-45ee-8480-69dc1dee36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-2a07b662-0746-41a3-9768-94d809892911,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-865300c4-495b-4e97-8ceb-6bc10b9cf40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-0043c3fc-e24c-4448-91bf-58ba9db1fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7a887726-fea2-471a-a697-df237777497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266473507-172.17.0.11-1599340928572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-58287189-04e2-4265-a8e8-e9faf13d3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-708ee7dd-0421-4766-a734-d2eee55cbac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-1c8823de-0f33-4573-8592-bd0e697af204,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-ab4ac683-635f-45ee-8480-69dc1dee36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-2a07b662-0746-41a3-9768-94d809892911,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-865300c4-495b-4e97-8ceb-6bc10b9cf40d,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-0043c3fc-e24c-4448-91bf-58ba9db1fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7a887726-fea2-471a-a697-df237777497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800948448-172.17.0.11-1599341029288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37987,DS-832ec246-da27-4c3d-90c5-3bef52782f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-6954fe0b-36fc-4cf9-85fd-371a1834603e,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-5feac6a3-11ab-4a53-aaa1-cde952ea0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-b1ffebed-f7ff-4a49-a4be-50d6fdc20ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-80f9b606-bf92-4dd6-9077-7c478c1212ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-4b4d5b61-9dcd-4b5b-b665-16a87ebac27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-95f5dac0-794e-443d-a290-d0e23da6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d7648824-6c29-4348-b4e8-0aa6c1691fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800948448-172.17.0.11-1599341029288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37987,DS-832ec246-da27-4c3d-90c5-3bef52782f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-6954fe0b-36fc-4cf9-85fd-371a1834603e,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-5feac6a3-11ab-4a53-aaa1-cde952ea0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-b1ffebed-f7ff-4a49-a4be-50d6fdc20ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-80f9b606-bf92-4dd6-9077-7c478c1212ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-4b4d5b61-9dcd-4b5b-b665-16a87ebac27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-95f5dac0-794e-443d-a290-d0e23da6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d7648824-6c29-4348-b4e8-0aa6c1691fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869850294-172.17.0.11-1599341090859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-6bb73e08-beb0-4c7c-ae5c-2f6d33f5973b,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-51f838ea-e1bb-4fb8-ab8a-694bd0766818,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-2a331b03-31d6-420f-ad58-5db3417c7061,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-941d3875-2523-4a22-b643-5955baeeb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-99d90ebd-1918-4193-8f85-641f543edbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-845e1407-0ab4-49c5-9357-26271806a796,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ab5cccf0-1d46-4da9-abd6-474613dc9226,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-2f853a29-5586-4591-ab99-420982ffbe6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869850294-172.17.0.11-1599341090859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-6bb73e08-beb0-4c7c-ae5c-2f6d33f5973b,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-51f838ea-e1bb-4fb8-ab8a-694bd0766818,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-2a331b03-31d6-420f-ad58-5db3417c7061,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-941d3875-2523-4a22-b643-5955baeeb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-99d90ebd-1918-4193-8f85-641f543edbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-845e1407-0ab4-49c5-9357-26271806a796,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ab5cccf0-1d46-4da9-abd6-474613dc9226,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-2f853a29-5586-4591-ab99-420982ffbe6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430745810-172.17.0.11-1599341270628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-396d3a24-2428-4e4f-9ca3-04e9e6b1d555,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d9cc6d35-0416-47ab-a7a0-391ccb2d4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-4eb4a2c4-ecf6-4d73-8f1c-d442de1b1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-23427c95-86ea-4655-8e58-367392530155,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-8244d939-616c-4fe2-a473-be85fb0b2b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-1cd59d48-bb5c-4bf7-bfad-b28dec827207,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-257d45aa-5045-4ff5-a11c-1693823e5347,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-a8ce824c-d149-4a1b-a7f4-8009aab32dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430745810-172.17.0.11-1599341270628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-396d3a24-2428-4e4f-9ca3-04e9e6b1d555,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d9cc6d35-0416-47ab-a7a0-391ccb2d4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-4eb4a2c4-ecf6-4d73-8f1c-d442de1b1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-23427c95-86ea-4655-8e58-367392530155,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-8244d939-616c-4fe2-a473-be85fb0b2b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-1cd59d48-bb5c-4bf7-bfad-b28dec827207,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-257d45aa-5045-4ff5-a11c-1693823e5347,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-a8ce824c-d149-4a1b-a7f4-8009aab32dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643177036-172.17.0.11-1599341298974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-7601bb58-ce4c-4a14-b4b3-ac26238d5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-557c9162-ad39-4c85-9b7b-cc84cc2fc9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-20b344b4-d9d4-4488-9e3e-bf14651b2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-28f6e5d5-8d09-4f12-ad4c-1772ee597eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-d001c6c8-e43c-4e4c-9ac8-aad3ce8a92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-6b2ec0ff-5f67-443f-844d-3d6b5decdd77,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-1054ca2b-26bf-4179-ae2c-db890267cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8dab02cb-8ef2-4e17-a343-d70412a14f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643177036-172.17.0.11-1599341298974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-7601bb58-ce4c-4a14-b4b3-ac26238d5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-557c9162-ad39-4c85-9b7b-cc84cc2fc9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-20b344b4-d9d4-4488-9e3e-bf14651b2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-28f6e5d5-8d09-4f12-ad4c-1772ee597eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-d001c6c8-e43c-4e4c-9ac8-aad3ce8a92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-6b2ec0ff-5f67-443f-844d-3d6b5decdd77,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-1054ca2b-26bf-4179-ae2c-db890267cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8dab02cb-8ef2-4e17-a343-d70412a14f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661809742-172.17.0.11-1599341834941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-273d0521-dd8b-422b-b2af-eaec026cb1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-428cc6f4-89fb-4b83-a2df-17ca81d5720f,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-faaf36c1-e8dd-4167-b431-bbb42ed217d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-238d4b97-e374-4531-8eb7-73f872becf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-228a38c2-aba6-48df-bec8-2dd91f15c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-3c225441-2eba-43c5-961e-80e36839acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-47ff5f47-7d75-466b-b250-7d31b90c91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-2925ced7-446d-47d4-a88c-fe04c88e1097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661809742-172.17.0.11-1599341834941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-273d0521-dd8b-422b-b2af-eaec026cb1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-428cc6f4-89fb-4b83-a2df-17ca81d5720f,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-faaf36c1-e8dd-4167-b431-bbb42ed217d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-238d4b97-e374-4531-8eb7-73f872becf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-228a38c2-aba6-48df-bec8-2dd91f15c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-3c225441-2eba-43c5-961e-80e36839acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-47ff5f47-7d75-466b-b250-7d31b90c91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-2925ced7-446d-47d4-a88c-fe04c88e1097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785754601-172.17.0.11-1599341890433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-79e2fe8c-322d-4ead-a59d-055b618e492e,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-fbaa06be-e545-46b3-b9bd-6748123bd336,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-bd78de2e-4b1c-48d4-8d9b-bc3d55960513,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-53fb88f4-05b1-4fe1-a1e5-7de854da7207,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-d711988c-66eb-4b67-91f8-21e6af81be25,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-5f043d56-a75d-4b54-bdae-cd3a182c2122,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-c454b63f-9043-4c25-b3b4-46f424afbbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-92764959-8e18-4c13-8750-b2ffbd08f5a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785754601-172.17.0.11-1599341890433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-79e2fe8c-322d-4ead-a59d-055b618e492e,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-fbaa06be-e545-46b3-b9bd-6748123bd336,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-bd78de2e-4b1c-48d4-8d9b-bc3d55960513,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-53fb88f4-05b1-4fe1-a1e5-7de854da7207,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-d711988c-66eb-4b67-91f8-21e6af81be25,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-5f043d56-a75d-4b54-bdae-cd3a182c2122,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-c454b63f-9043-4c25-b3b4-46f424afbbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-92764959-8e18-4c13-8750-b2ffbd08f5a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261339715-172.17.0.11-1599342042122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-2fc901c1-9228-4fa5-8be0-148b6bed022b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-53d9eaa3-1b4f-4a83-8ea2-418a11bd1c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-2f72e08d-cf4c-4971-969f-5c9983e22b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-70341e7a-444b-4ddb-80aa-e33a0f500bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-247c1c3e-779b-4651-b35e-400562ed8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a8df5271-18bd-4050-abaf-2ed893cd0370,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-53cc4e36-e43f-4c45-8807-fe8c4adbe88b,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-e32faa63-80fb-4504-b07d-1f3d4f0e9365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261339715-172.17.0.11-1599342042122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-2fc901c1-9228-4fa5-8be0-148b6bed022b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-53d9eaa3-1b4f-4a83-8ea2-418a11bd1c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-2f72e08d-cf4c-4971-969f-5c9983e22b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-70341e7a-444b-4ddb-80aa-e33a0f500bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-247c1c3e-779b-4651-b35e-400562ed8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a8df5271-18bd-4050-abaf-2ed893cd0370,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-53cc4e36-e43f-4c45-8807-fe8c4adbe88b,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-e32faa63-80fb-4504-b07d-1f3d4f0e9365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 4665
