reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539310900-172.17.0.17-1599335003847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-3b36f1f5-b441-467f-a142-f58378804289,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-cc51d8e5-72d0-417e-9608-017a5c6efc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-66b99280-eb98-44d1-a5b7-408211df0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-0ab00503-3b8a-451a-aee9-a327fabd7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-fa878451-09b6-4714-9681-29adf8af5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9d30f1f5-863b-4232-9b72-407723ac122d,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-3f8905ee-69ed-475a-b4f7-aae4bb4fbc96,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9356afc9-bdca-475f-b1a5-9ebe990ced47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539310900-172.17.0.17-1599335003847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-3b36f1f5-b441-467f-a142-f58378804289,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-cc51d8e5-72d0-417e-9608-017a5c6efc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-66b99280-eb98-44d1-a5b7-408211df0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-0ab00503-3b8a-451a-aee9-a327fabd7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-fa878451-09b6-4714-9681-29adf8af5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9d30f1f5-863b-4232-9b72-407723ac122d,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-3f8905ee-69ed-475a-b4f7-aae4bb4fbc96,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9356afc9-bdca-475f-b1a5-9ebe990ced47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373982863-172.17.0.17-1599335122776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-d6668b21-6838-4b01-9cc0-572d944592e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-91db6cd3-8e3a-4e5f-9450-5872aefe9f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-44171f31-aaa9-4e9d-9e4e-cb2a0dd8746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-15dbfba8-1636-4778-936f-78599489ad02,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-148b6629-fc1f-4ae8-a900-7b4dadd1a408,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-0bcc45f1-9db8-4fb4-b8c6-38d1274d364f,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-291ac9ca-6f19-47f8-929a-9e47d04776af,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-14cf2e1b-637d-4ece-9b2e-68bc6eccde2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373982863-172.17.0.17-1599335122776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-d6668b21-6838-4b01-9cc0-572d944592e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-91db6cd3-8e3a-4e5f-9450-5872aefe9f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-44171f31-aaa9-4e9d-9e4e-cb2a0dd8746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-15dbfba8-1636-4778-936f-78599489ad02,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-148b6629-fc1f-4ae8-a900-7b4dadd1a408,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-0bcc45f1-9db8-4fb4-b8c6-38d1274d364f,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-291ac9ca-6f19-47f8-929a-9e47d04776af,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-14cf2e1b-637d-4ece-9b2e-68bc6eccde2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772461230-172.17.0.17-1599335672084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-eba3a8be-7135-46fa-998c-ccbbe9551120,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-af479820-b7ea-43ef-a052-e3542a5ef1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-0c89b6e5-84a3-43c5-9782-3df64cbce2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-9ebe3861-ba30-4fc5-a703-a02d2b87fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-3e85321f-2908-41cb-af2f-da6ecf675789,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4f857b61-7754-4466-b5bd-993aaac6a887,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-25fb1fd5-65ce-452a-88e1-52f5a234e433,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-74c230e9-c1f7-4809-a4ab-9dd4179584a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772461230-172.17.0.17-1599335672084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-eba3a8be-7135-46fa-998c-ccbbe9551120,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-af479820-b7ea-43ef-a052-e3542a5ef1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-0c89b6e5-84a3-43c5-9782-3df64cbce2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-9ebe3861-ba30-4fc5-a703-a02d2b87fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-3e85321f-2908-41cb-af2f-da6ecf675789,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4f857b61-7754-4466-b5bd-993aaac6a887,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-25fb1fd5-65ce-452a-88e1-52f5a234e433,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-74c230e9-c1f7-4809-a4ab-9dd4179584a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626425030-172.17.0.17-1599335750674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-0782e520-50dc-4b56-b300-063627a3c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-26c933eb-9f45-4590-88c7-cda504a4062e,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-45468928-07cb-4cf2-befc-fa530bea3cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-96bc56dc-5490-4f3d-b350-69cd4c948148,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-ad6edfa6-adb0-4b9d-aae7-7c0711667a82,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-81ffa123-ddd1-465c-bd28-62f9559871ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1c5510d3-b3b4-41b2-900a-328ab39d2d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-92f00340-b73c-4d08-b2f4-9e1bf148a2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626425030-172.17.0.17-1599335750674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33557,DS-0782e520-50dc-4b56-b300-063627a3c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-26c933eb-9f45-4590-88c7-cda504a4062e,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-45468928-07cb-4cf2-befc-fa530bea3cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-96bc56dc-5490-4f3d-b350-69cd4c948148,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-ad6edfa6-adb0-4b9d-aae7-7c0711667a82,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-81ffa123-ddd1-465c-bd28-62f9559871ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1c5510d3-b3b4-41b2-900a-328ab39d2d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-92f00340-b73c-4d08-b2f4-9e1bf148a2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887695552-172.17.0.17-1599335884209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-2eabb16f-90a7-407b-a40c-2abbc8585339,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f088988b-bc25-4c07-9cc7-b5719e7028f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8094ef52-d03d-412f-ba6d-0fccbdda75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-a170212b-0b56-4bb1-be4a-38380f8d90db,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-b83fb0d0-a795-4ea5-afac-83da5b2d0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-92af6ba2-5448-44bd-9ab4-02e4afe29b85,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-74c8db51-14d4-459f-b9f4-65c893f0f392,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-149a8086-aa69-4194-8a12-798e0154bf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887695552-172.17.0.17-1599335884209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-2eabb16f-90a7-407b-a40c-2abbc8585339,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-f088988b-bc25-4c07-9cc7-b5719e7028f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-8094ef52-d03d-412f-ba6d-0fccbdda75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-a170212b-0b56-4bb1-be4a-38380f8d90db,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-b83fb0d0-a795-4ea5-afac-83da5b2d0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-92af6ba2-5448-44bd-9ab4-02e4afe29b85,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-74c8db51-14d4-459f-b9f4-65c893f0f392,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-149a8086-aa69-4194-8a12-798e0154bf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835091559-172.17.0.17-1599335961906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-26e42b20-2666-4f7c-9ee7-9004ae820aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-a146a80a-7c78-4305-8e86-4313c090f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-42ee39c2-4293-41e6-bd9a-f0d5c4a23c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-545aad2c-94af-4717-9785-24e496aaceac,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c4b5a2d2-c969-4300-a54a-7f73aad0757a,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-a777acc8-81e4-4059-aa1a-9b799fd1f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-4be8b396-7663-4572-a598-41832326db70,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ef219e4f-66e5-4b7c-96a9-07d5fc0b892c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835091559-172.17.0.17-1599335961906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-26e42b20-2666-4f7c-9ee7-9004ae820aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-a146a80a-7c78-4305-8e86-4313c090f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-42ee39c2-4293-41e6-bd9a-f0d5c4a23c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-545aad2c-94af-4717-9785-24e496aaceac,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-c4b5a2d2-c969-4300-a54a-7f73aad0757a,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-a777acc8-81e4-4059-aa1a-9b799fd1f3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-4be8b396-7663-4572-a598-41832326db70,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-ef219e4f-66e5-4b7c-96a9-07d5fc0b892c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646773978-172.17.0.17-1599336814176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46495,DS-1c26c57b-619c-4fdf-8f05-b4db0aefefda,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-532f0781-9674-4c7b-9daa-e322855c2f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-61b30967-f386-4492-a860-744a09ff50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-2bfc49bb-0884-401a-9124-0d20944a9e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-6d4a243b-4594-45c7-8362-1296c6f6b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-a46d2d2e-c454-4537-868b-16c191953161,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-693de15a-754d-4d7e-bdd0-6344d5d8c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-12408ed6-b8cd-4324-adec-77507b3f0fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646773978-172.17.0.17-1599336814176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46495,DS-1c26c57b-619c-4fdf-8f05-b4db0aefefda,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-532f0781-9674-4c7b-9daa-e322855c2f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-61b30967-f386-4492-a860-744a09ff50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-2bfc49bb-0884-401a-9124-0d20944a9e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-6d4a243b-4594-45c7-8362-1296c6f6b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-a46d2d2e-c454-4537-868b-16c191953161,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-693de15a-754d-4d7e-bdd0-6344d5d8c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-12408ed6-b8cd-4324-adec-77507b3f0fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63555669-172.17.0.17-1599337098304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-cdab5e16-9a05-4a98-a5f7-56c4b75ecef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-95ad712c-6cab-4f89-9eca-197428886cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-e67a5666-7741-42bf-a712-2a81f21975af,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-50aa0484-5933-43fc-85ac-c5fbd631e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-f6e2601c-8a65-4e7d-9531-3af8425c6c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e119925e-a63d-4253-b67c-7d44c4ba288f,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-0a3aabcd-016b-4301-bbf7-a7b4e23d506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-e863a7cc-b594-4dde-a86e-fafbb80754ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63555669-172.17.0.17-1599337098304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-cdab5e16-9a05-4a98-a5f7-56c4b75ecef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-95ad712c-6cab-4f89-9eca-197428886cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-e67a5666-7741-42bf-a712-2a81f21975af,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-50aa0484-5933-43fc-85ac-c5fbd631e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-f6e2601c-8a65-4e7d-9531-3af8425c6c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e119925e-a63d-4253-b67c-7d44c4ba288f,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-0a3aabcd-016b-4301-bbf7-a7b4e23d506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-e863a7cc-b594-4dde-a86e-fafbb80754ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49439253-172.17.0.17-1599337240257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-b786d483-bc94-49a3-8b71-6db0e91e2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-f0f89882-d222-44ed-9eb4-452072710eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-eb32cc88-6f3c-4a36-baae-f5792bd7e278,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b788ede7-b8a1-4f57-b450-1342d0bd70e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-09a28697-c491-4e87-b816-f062cf4cfe50,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-c57d44c3-6cd4-45c9-badc-5e99c5486bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-874ad607-fe5d-45a3-8aab-b32240746bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-62a7f51f-3dc5-4794-9060-e74b59739444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49439253-172.17.0.17-1599337240257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-b786d483-bc94-49a3-8b71-6db0e91e2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-f0f89882-d222-44ed-9eb4-452072710eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-eb32cc88-6f3c-4a36-baae-f5792bd7e278,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b788ede7-b8a1-4f57-b450-1342d0bd70e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-09a28697-c491-4e87-b816-f062cf4cfe50,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-c57d44c3-6cd4-45c9-badc-5e99c5486bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-874ad607-fe5d-45a3-8aab-b32240746bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-62a7f51f-3dc5-4794-9060-e74b59739444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446839312-172.17.0.17-1599337507864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-18183163-675d-4182-a052-17be03303bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-d91e85c2-c049-4def-9eeb-8e23d5a60022,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4613183d-20b3-476f-9c63-3babb859bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-a583c762-5c0e-40a1-a343-5fc367476428,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-a7d8d6ef-14a5-4441-bcc7-591442238ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-0097ee11-c12e-4be4-a14d-5fc393926a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-0c255924-f5f8-4de1-83f1-85727da09702,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-faeee7bc-36db-444d-ab1e-44657087b7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446839312-172.17.0.17-1599337507864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-18183163-675d-4182-a052-17be03303bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-d91e85c2-c049-4def-9eeb-8e23d5a60022,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4613183d-20b3-476f-9c63-3babb859bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-a583c762-5c0e-40a1-a343-5fc367476428,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-a7d8d6ef-14a5-4441-bcc7-591442238ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-0097ee11-c12e-4be4-a14d-5fc393926a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-0c255924-f5f8-4de1-83f1-85727da09702,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-faeee7bc-36db-444d-ab1e-44657087b7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239660134-172.17.0.17-1599337660330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-39bc13f1-4f5b-43f0-92b3-54c9c5b115fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-3ddc0435-a08d-45c7-929e-b8277bba3832,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-eb1e03b7-638d-4a32-beb5-36612c70ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-c9395c57-3eae-4725-97ef-10c725ace0de,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-0d25eda1-7656-4880-a6ca-06f2a233b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-f13f401d-09e1-47eb-aceb-d4379f70e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-2e36cd53-e052-42e3-ab6e-ecbeb51cecda,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-e8f44afc-0187-46c5-94cf-3f20a380f948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239660134-172.17.0.17-1599337660330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-39bc13f1-4f5b-43f0-92b3-54c9c5b115fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-3ddc0435-a08d-45c7-929e-b8277bba3832,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-eb1e03b7-638d-4a32-beb5-36612c70ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-c9395c57-3eae-4725-97ef-10c725ace0de,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-0d25eda1-7656-4880-a6ca-06f2a233b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-f13f401d-09e1-47eb-aceb-d4379f70e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-2e36cd53-e052-42e3-ab6e-ecbeb51cecda,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-e8f44afc-0187-46c5-94cf-3f20a380f948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842720817-172.17.0.17-1599338057205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-59139222-e193-4b88-ac86-80e553350389,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4f117eef-4c24-46f3-be0e-a7ab38a2d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-788cecca-ce07-405c-9dbe-35abc61c8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-960b36b2-b828-4f46-9f37-fab62350cb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-b3c63495-4256-40dc-9cab-29505862304c,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-1c9d303a-2cb3-48ee-b071-67c64f898cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9dc33c3c-5400-4aaa-acdf-70f8af70375d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-f6cfd47b-57c3-4bb5-8871-00d00b8fc90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842720817-172.17.0.17-1599338057205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-59139222-e193-4b88-ac86-80e553350389,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-4f117eef-4c24-46f3-be0e-a7ab38a2d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-788cecca-ce07-405c-9dbe-35abc61c8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-960b36b2-b828-4f46-9f37-fab62350cb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-b3c63495-4256-40dc-9cab-29505862304c,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-1c9d303a-2cb3-48ee-b071-67c64f898cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9dc33c3c-5400-4aaa-acdf-70f8af70375d,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-f6cfd47b-57c3-4bb5-8871-00d00b8fc90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923925103-172.17.0.17-1599338126229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35792,DS-1f3367a1-1382-458f-9821-713685fb2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-3b2ff278-337e-4f09-92a2-6d54725814c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-f8ed60f2-589d-488d-b92e-6720b77552ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-0f1e5331-eda4-477d-8a21-dae339c1c079,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-4dd983c3-ada7-4f6c-82c3-aa813dbb2930,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-50645a98-216e-42dd-aa94-11c0788adf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-fa776c58-f802-4768-bc40-c43140cb8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-086d39ef-904a-4450-9d83-c9899a279924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923925103-172.17.0.17-1599338126229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35792,DS-1f3367a1-1382-458f-9821-713685fb2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-3b2ff278-337e-4f09-92a2-6d54725814c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-f8ed60f2-589d-488d-b92e-6720b77552ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-0f1e5331-eda4-477d-8a21-dae339c1c079,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-4dd983c3-ada7-4f6c-82c3-aa813dbb2930,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-50645a98-216e-42dd-aa94-11c0788adf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-fa776c58-f802-4768-bc40-c43140cb8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-086d39ef-904a-4450-9d83-c9899a279924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275212998-172.17.0.17-1599338330890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-fc5d8083-d514-42f2-abf8-8e77b22b3547,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-1d624b6b-b281-4cef-b66e-b7cbe0650d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-bc572c11-d9b5-4d58-9617-3e1346ccbe85,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-80ed956a-c773-4b7c-88a5-ff9720240a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-8725ddec-1a40-4086-9862-5ee3ba6e91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-11d910fd-5519-4105-9d2e-1a0676b94edd,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-8885e2b6-4351-419a-9e49-00fa0208bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-dd7b5983-eb3b-40a4-b184-ad0198c2de79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275212998-172.17.0.17-1599338330890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-fc5d8083-d514-42f2-abf8-8e77b22b3547,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-1d624b6b-b281-4cef-b66e-b7cbe0650d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-bc572c11-d9b5-4d58-9617-3e1346ccbe85,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-80ed956a-c773-4b7c-88a5-ff9720240a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-8725ddec-1a40-4086-9862-5ee3ba6e91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-11d910fd-5519-4105-9d2e-1a0676b94edd,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-8885e2b6-4351-419a-9e49-00fa0208bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-dd7b5983-eb3b-40a4-b184-ad0198c2de79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038328033-172.17.0.17-1599338399311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37982,DS-4a3600d7-7695-4957-9542-0ca5febf0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-c9f9eb0e-c10b-4f90-941d-9b00da2c5ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-b7845540-c442-403d-8ef5-21cc1ce9463e,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-ee868b0e-0a28-401b-804d-7f63fbdbad25,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-cd16e42e-b5a9-46c1-a00f-21e713d160d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-87a37410-01df-47d1-a977-d017aff915ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4d3467c4-754e-41f6-9cf8-ced2d02ae911,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-48767591-0e47-4afa-9ab5-968d01826997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038328033-172.17.0.17-1599338399311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37982,DS-4a3600d7-7695-4957-9542-0ca5febf0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-c9f9eb0e-c10b-4f90-941d-9b00da2c5ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-b7845540-c442-403d-8ef5-21cc1ce9463e,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-ee868b0e-0a28-401b-804d-7f63fbdbad25,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-cd16e42e-b5a9-46c1-a00f-21e713d160d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-87a37410-01df-47d1-a977-d017aff915ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4d3467c4-754e-41f6-9cf8-ced2d02ae911,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-48767591-0e47-4afa-9ab5-968d01826997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059526501-172.17.0.17-1599338467318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-5c6ccdfe-9614-49a8-82c9-e53841338526,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-e4051752-ec46-4cae-bbc8-0d81348b3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-7c028010-4cc4-41be-975f-d6cd04ac3044,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f7ff21af-63ce-48ae-a4bd-fa67aa408b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-9325589c-d1ec-4c66-b6c2-fce3c40abe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-aedffb44-900d-4d4e-922a-03f4f600d763,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-18e49bfc-40cf-48e5-954e-521690fe50d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-b604bc57-3d2f-4f45-a7f5-6893ad414cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059526501-172.17.0.17-1599338467318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-5c6ccdfe-9614-49a8-82c9-e53841338526,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-e4051752-ec46-4cae-bbc8-0d81348b3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-7c028010-4cc4-41be-975f-d6cd04ac3044,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f7ff21af-63ce-48ae-a4bd-fa67aa408b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-9325589c-d1ec-4c66-b6c2-fce3c40abe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-aedffb44-900d-4d4e-922a-03f4f600d763,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-18e49bfc-40cf-48e5-954e-521690fe50d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-b604bc57-3d2f-4f45-a7f5-6893ad414cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871387988-172.17.0.17-1599338601380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-3472e24d-4489-4039-8825-a1d4151c52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-20526b7a-72a2-492c-9653-2b3f54d5a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-44982c63-688c-41b7-8b46-abbd1871670d,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-e891657b-471a-40d5-bdd0-d9306d10a149,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-270e41ef-6316-4f29-87bb-cfcd32bc3f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-c99e1120-ed7f-453e-83cc-9b83fd6977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-7e1d8001-2459-40c0-a0d8-4bb664b8155a,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-fe497516-5573-4397-be8c-47968559f423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871387988-172.17.0.17-1599338601380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-3472e24d-4489-4039-8825-a1d4151c52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-20526b7a-72a2-492c-9653-2b3f54d5a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-44982c63-688c-41b7-8b46-abbd1871670d,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-e891657b-471a-40d5-bdd0-d9306d10a149,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-270e41ef-6316-4f29-87bb-cfcd32bc3f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-c99e1120-ed7f-453e-83cc-9b83fd6977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-7e1d8001-2459-40c0-a0d8-4bb664b8155a,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-fe497516-5573-4397-be8c-47968559f423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869946766-172.17.0.17-1599338951143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-3ad83637-2109-4202-b128-8e89bfdba81e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-efa0c5b0-fdaa-4db1-af76-e3e1c853c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-28abdc90-f1a5-45ba-acf8-c9a01981b345,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-50dfb86a-04f7-4c2d-95d0-73cf70c86c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-664d57da-3371-4f40-99f7-7b3dfedf06c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-90176e2b-a9ed-490d-bb0c-78c130f41133,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-cd6dc25d-f80d-47c3-b246-46aefed4f691,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-646bbc5f-e6cc-4466-bec6-e1ca4781c232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869946766-172.17.0.17-1599338951143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-3ad83637-2109-4202-b128-8e89bfdba81e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-efa0c5b0-fdaa-4db1-af76-e3e1c853c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-28abdc90-f1a5-45ba-acf8-c9a01981b345,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-50dfb86a-04f7-4c2d-95d0-73cf70c86c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-664d57da-3371-4f40-99f7-7b3dfedf06c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-90176e2b-a9ed-490d-bb0c-78c130f41133,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-cd6dc25d-f80d-47c3-b246-46aefed4f691,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-646bbc5f-e6cc-4466-bec6-e1ca4781c232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246522065-172.17.0.17-1599339019654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-71cef718-accc-4ccb-b2e4-1b32479d6819,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-3a84d6ef-263d-4fc1-b601-2e4744aac8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-f22d52e8-dc35-4deb-884c-0d901fbaf77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-f975948b-7cf0-40c8-8d42-537ad05f27ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-e6b79f4b-93b5-401c-8db7-c2eb6c0aae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-6527e28d-7549-4344-af03-7529d3c0fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-0ac8fd99-a8fc-44c0-a084-73fde11cefd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-4de00bdf-3c27-4b50-854a-11d98afd912f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246522065-172.17.0.17-1599339019654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-71cef718-accc-4ccb-b2e4-1b32479d6819,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-3a84d6ef-263d-4fc1-b601-2e4744aac8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-f22d52e8-dc35-4deb-884c-0d901fbaf77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-f975948b-7cf0-40c8-8d42-537ad05f27ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-e6b79f4b-93b5-401c-8db7-c2eb6c0aae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-6527e28d-7549-4344-af03-7529d3c0fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-0ac8fd99-a8fc-44c0-a084-73fde11cefd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-4de00bdf-3c27-4b50-854a-11d98afd912f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550082889-172.17.0.17-1599339455974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34944,DS-2b48c0ed-4350-4fe5-84fe-4eff8dd43cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-983f8e0a-9e81-47bd-b730-e55de7122a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-b4c5a561-632d-4616-93a5-059d68287e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-f24187b4-42d4-4d34-921d-d11a88c1f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-c8f1206f-c2f0-41ec-82c9-11b261774299,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-2705cd7f-f5e8-4f98-8781-08bd1fba8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-4a37460e-8ab4-47e4-881e-b137e7a90254,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-3d3d849c-8880-4ffa-98ca-4ec355eae2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550082889-172.17.0.17-1599339455974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34944,DS-2b48c0ed-4350-4fe5-84fe-4eff8dd43cca,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-983f8e0a-9e81-47bd-b730-e55de7122a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-b4c5a561-632d-4616-93a5-059d68287e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-f24187b4-42d4-4d34-921d-d11a88c1f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-c8f1206f-c2f0-41ec-82c9-11b261774299,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-2705cd7f-f5e8-4f98-8781-08bd1fba8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-4a37460e-8ab4-47e4-881e-b137e7a90254,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-3d3d849c-8880-4ffa-98ca-4ec355eae2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5252
