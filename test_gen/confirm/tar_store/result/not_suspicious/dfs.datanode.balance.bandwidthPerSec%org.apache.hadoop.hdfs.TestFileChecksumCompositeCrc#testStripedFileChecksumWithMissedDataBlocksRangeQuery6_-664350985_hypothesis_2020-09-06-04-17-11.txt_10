reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248565674-172.17.0.10-1599365959345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-b95e8bbc-2133-4bd6-a3cd-90aef005d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-df2b3c35-bced-4275-bf34-7625c12ab902,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-c490ec8b-1c2f-4b8e-b564-33d5401c064e,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-33dd9687-d30f-428a-943a-21a8fc6f3901,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3c46ec53-ee7a-49de-bbbb-3e13e134cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b7f56070-55c2-45d5-b11c-a08f060c6202,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-45b54760-6b09-40fa-b50f-2ce5b1227ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-478d0ca6-1d52-449f-a5fa-3bb1df4cab77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248565674-172.17.0.10-1599365959345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-b95e8bbc-2133-4bd6-a3cd-90aef005d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-df2b3c35-bced-4275-bf34-7625c12ab902,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-c490ec8b-1c2f-4b8e-b564-33d5401c064e,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-33dd9687-d30f-428a-943a-21a8fc6f3901,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3c46ec53-ee7a-49de-bbbb-3e13e134cc21,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b7f56070-55c2-45d5-b11c-a08f060c6202,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-45b54760-6b09-40fa-b50f-2ce5b1227ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-478d0ca6-1d52-449f-a5fa-3bb1df4cab77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258320662-172.17.0.10-1599366159009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-c5f328eb-1aa5-4aa3-b049-dd09625f7e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bebab06a-7a1e-4e77-8f2d-71a8a8785316,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-d4bb8973-9b97-450a-a3e8-c72bab641a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0814f1de-6ca7-4c00-bf68-b5568a88aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0a1abde9-33ef-45be-87e8-e17063c00861,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-5dd7a66b-e086-46a5-9456-3235d45b0326,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-e931ba32-780a-45ff-9e22-4482be12212e,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-f29e813c-df81-4a4c-8c7b-dc2cebdb82bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258320662-172.17.0.10-1599366159009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-c5f328eb-1aa5-4aa3-b049-dd09625f7e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bebab06a-7a1e-4e77-8f2d-71a8a8785316,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-d4bb8973-9b97-450a-a3e8-c72bab641a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-0814f1de-6ca7-4c00-bf68-b5568a88aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0a1abde9-33ef-45be-87e8-e17063c00861,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-5dd7a66b-e086-46a5-9456-3235d45b0326,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-e931ba32-780a-45ff-9e22-4482be12212e,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-f29e813c-df81-4a4c-8c7b-dc2cebdb82bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047775885-172.17.0.10-1599366304098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-2ccd8fb5-8b3d-4d70-b616-af2508748cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-0dfda71c-37c6-49a7-a564-446fd7578125,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-10b9d814-3fbb-4730-a9eb-3d79085d0945,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-d7dc9fa1-80ff-4ddc-9128-00b2ec71723b,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-1d44b45a-99ee-4c97-a0b8-0db62098e070,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-c415bdd8-ae17-49e5-9f5e-71c82a8a46b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-ed647cc9-93bd-4c8e-8d83-69ccf55ba9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-0ee8727a-84b0-4ee0-8bcd-ddb301a31023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047775885-172.17.0.10-1599366304098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-2ccd8fb5-8b3d-4d70-b616-af2508748cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-0dfda71c-37c6-49a7-a564-446fd7578125,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-10b9d814-3fbb-4730-a9eb-3d79085d0945,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-d7dc9fa1-80ff-4ddc-9128-00b2ec71723b,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-1d44b45a-99ee-4c97-a0b8-0db62098e070,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-c415bdd8-ae17-49e5-9f5e-71c82a8a46b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-ed647cc9-93bd-4c8e-8d83-69ccf55ba9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-0ee8727a-84b0-4ee0-8bcd-ddb301a31023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529304373-172.17.0.10-1599366374743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-0d2aa00e-dad9-4d8a-bb8d-048768d11e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-ae3f19e3-786d-44e1-baec-596f959efbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-c82a8289-d028-4e82-974d-6edcac814a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-81deff33-bd9f-433c-bb70-7cfb5907e713,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-e435abd4-3ecc-4a86-8b5c-1948819ff47e,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-db89ed73-d368-4c90-ae23-676c721a3987,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-3e9eb7f5-69c2-49fa-9a42-9d18964beb07,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-3c217d29-b74d-4912-9f33-161a1a391926,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529304373-172.17.0.10-1599366374743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-0d2aa00e-dad9-4d8a-bb8d-048768d11e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-ae3f19e3-786d-44e1-baec-596f959efbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-c82a8289-d028-4e82-974d-6edcac814a73,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-81deff33-bd9f-433c-bb70-7cfb5907e713,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-e435abd4-3ecc-4a86-8b5c-1948819ff47e,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-db89ed73-d368-4c90-ae23-676c721a3987,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-3e9eb7f5-69c2-49fa-9a42-9d18964beb07,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-3c217d29-b74d-4912-9f33-161a1a391926,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503323727-172.17.0.10-1599366527065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-df02a641-a9ba-448c-b40e-ed8590fa3cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-173852e0-414c-40a1-beb0-3ea55e37ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-beacb380-2907-4d23-afe4-16950ace497b,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-fbf5b421-fa71-4844-9e10-cfc0a9010107,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-6ccc0374-2d97-42ab-8e8c-47d4efdce3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-b7729abb-ab71-4c0f-9062-96f82d77bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-50942e8a-5480-4417-9da4-ea431c52a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-8443592e-d169-4e22-9135-2a88106809c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503323727-172.17.0.10-1599366527065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-df02a641-a9ba-448c-b40e-ed8590fa3cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-173852e0-414c-40a1-beb0-3ea55e37ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-beacb380-2907-4d23-afe4-16950ace497b,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-fbf5b421-fa71-4844-9e10-cfc0a9010107,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-6ccc0374-2d97-42ab-8e8c-47d4efdce3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-b7729abb-ab71-4c0f-9062-96f82d77bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-50942e8a-5480-4417-9da4-ea431c52a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-8443592e-d169-4e22-9135-2a88106809c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226518617-172.17.0.10-1599366717375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-21a0dd0f-58eb-436c-a7ff-b6cde1d7bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-09b6998e-53b1-4e2c-80be-301aa978d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-ce1bc8b3-7dac-4e2f-8897-f851479093d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-a8c09f99-f78d-4ce8-9d41-fdab71035168,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-54625b9c-18c8-41c4-84a2-28b378c3fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-aa1006be-5c54-4228-881c-f847513cd717,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5d15017c-5b93-49ad-81a0-d26a3752bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-3a9a2d0a-9a2c-4a2c-906b-78eef666ff86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226518617-172.17.0.10-1599366717375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-21a0dd0f-58eb-436c-a7ff-b6cde1d7bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-09b6998e-53b1-4e2c-80be-301aa978d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-ce1bc8b3-7dac-4e2f-8897-f851479093d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-a8c09f99-f78d-4ce8-9d41-fdab71035168,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-54625b9c-18c8-41c4-84a2-28b378c3fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-aa1006be-5c54-4228-881c-f847513cd717,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-5d15017c-5b93-49ad-81a0-d26a3752bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-3a9a2d0a-9a2c-4a2c-906b-78eef666ff86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705302935-172.17.0.10-1599366804480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-91c6d798-a70d-48c8-8a16-7f28ee41a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-e078c89f-efb3-41b0-a241-5a0e51528a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5981383f-ec3e-45a9-a483-9f57f0fc1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-594b036b-632c-47cd-8fff-32c6810592cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-c5182384-22af-4dd5-bde1-a4ecdda1e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-d4be2876-6a5f-471f-a828-91f6ecf1624d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-06d96e20-b28e-45fc-a0b8-5e1b82d230f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-022e900d-92d0-4398-888e-a1fb21f977b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705302935-172.17.0.10-1599366804480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-91c6d798-a70d-48c8-8a16-7f28ee41a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-e078c89f-efb3-41b0-a241-5a0e51528a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5981383f-ec3e-45a9-a483-9f57f0fc1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-594b036b-632c-47cd-8fff-32c6810592cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-c5182384-22af-4dd5-bde1-a4ecdda1e5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-d4be2876-6a5f-471f-a828-91f6ecf1624d,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-06d96e20-b28e-45fc-a0b8-5e1b82d230f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-022e900d-92d0-4398-888e-a1fb21f977b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948193921-172.17.0.10-1599367034596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-45e2fd04-5f16-43d9-81a6-90e34721e000,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-51402d5b-e6e7-491a-b596-b36cf036cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-40825370-1131-47e7-aba7-8aa4951cf48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-54efd6e7-50fb-45e2-92cf-baf48b8c5a56,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-7b2087ae-8521-4697-9d76-2e8e9339b3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-84cc21a1-36b5-4bba-8fe2-bd723b79889a,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-02c28b94-2d31-4acc-ba0e-d7d13516b564,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-dda1adc0-7a9c-4e50-bcf2-1f7c7a2457c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948193921-172.17.0.10-1599367034596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-45e2fd04-5f16-43d9-81a6-90e34721e000,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-51402d5b-e6e7-491a-b596-b36cf036cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-40825370-1131-47e7-aba7-8aa4951cf48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-54efd6e7-50fb-45e2-92cf-baf48b8c5a56,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-7b2087ae-8521-4697-9d76-2e8e9339b3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-84cc21a1-36b5-4bba-8fe2-bd723b79889a,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-02c28b94-2d31-4acc-ba0e-d7d13516b564,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-dda1adc0-7a9c-4e50-bcf2-1f7c7a2457c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020760750-172.17.0.10-1599367190891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-07f1448f-d14c-4a38-82e5-ad4c34f37007,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-1ed47397-0a71-4d20-9bb4-fc31f7223b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-bdee1f30-c832-4869-810a-465057514425,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c6b5292c-bcd5-4838-bfc3-e6fcbe649476,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-08c5ef67-63ab-4d08-9e01-722ed288c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-0877f98b-3875-47af-97ec-644097d7f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-4d28d8e4-9641-48f8-9659-1820b146c904,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-a6ede5fe-8e57-411d-b8dc-4fbacce52979,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020760750-172.17.0.10-1599367190891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-07f1448f-d14c-4a38-82e5-ad4c34f37007,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-1ed47397-0a71-4d20-9bb4-fc31f7223b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-bdee1f30-c832-4869-810a-465057514425,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-c6b5292c-bcd5-4838-bfc3-e6fcbe649476,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-08c5ef67-63ab-4d08-9e01-722ed288c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-0877f98b-3875-47af-97ec-644097d7f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-4d28d8e4-9641-48f8-9659-1820b146c904,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-a6ede5fe-8e57-411d-b8dc-4fbacce52979,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993428066-172.17.0.10-1599367789776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-9e8da723-1e1a-46fc-b894-ae10b158e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-8500cd41-221c-4913-b5ea-a0772ea88299,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f892fe67-a55b-4ee4-9a17-97c80f1ed604,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-c6eef9bf-f2f7-4ae6-bccd-86f90c852f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-f79db9af-866d-4462-bb41-46f37577a305,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-be186ee5-aa91-4541-b358-3de9f10e3e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1a350a12-a0a1-4c6a-9507-b58bddeeddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-8030cd21-69b7-412d-84fc-639f31762e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993428066-172.17.0.10-1599367789776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-9e8da723-1e1a-46fc-b894-ae10b158e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-8500cd41-221c-4913-b5ea-a0772ea88299,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f892fe67-a55b-4ee4-9a17-97c80f1ed604,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-c6eef9bf-f2f7-4ae6-bccd-86f90c852f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-f79db9af-866d-4462-bb41-46f37577a305,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-be186ee5-aa91-4541-b358-3de9f10e3e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-1a350a12-a0a1-4c6a-9507-b58bddeeddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-8030cd21-69b7-412d-84fc-639f31762e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702697433-172.17.0.10-1599367872618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-281a4d7c-0400-46bf-811d-749af78c72ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-5aecede8-6367-4963-9430-fd3424417160,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-899cc7a6-5d0a-4fa1-84c7-02fe4ce73d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-b7a4acd3-7074-4166-a6b8-c1680c26c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a4c47e34-ccf8-4995-9885-f3a889fb1074,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-b92d44de-67fb-4628-94fc-4ce5b08757f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-439e1817-510e-43d5-a818-278307d70bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-8c7d90d3-0095-42c6-b7ab-92ed25665676,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702697433-172.17.0.10-1599367872618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-281a4d7c-0400-46bf-811d-749af78c72ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-5aecede8-6367-4963-9430-fd3424417160,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-899cc7a6-5d0a-4fa1-84c7-02fe4ce73d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-b7a4acd3-7074-4166-a6b8-c1680c26c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-a4c47e34-ccf8-4995-9885-f3a889fb1074,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-b92d44de-67fb-4628-94fc-4ce5b08757f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-439e1817-510e-43d5-a818-278307d70bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-8c7d90d3-0095-42c6-b7ab-92ed25665676,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324306097-172.17.0.10-1599368044125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-cd8218aa-b128-4884-a90d-07e030580245,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-5bd73d5b-eea7-44f4-a9e2-ef79a07e9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-066ebf72-6aeb-4c92-8f47-b77fb07150a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-bf18261b-e86e-4991-8ccc-1777b80eb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-125f0964-e98b-4dcc-b0ce-f0f9ec35daca,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-490d6420-2bdd-4934-b42a-15ab809094b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-3a1f8a30-0123-402f-9c09-5fd8fefdd35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-fa736ada-eba2-42b3-87ee-11c610a44553,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324306097-172.17.0.10-1599368044125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45054,DS-cd8218aa-b128-4884-a90d-07e030580245,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-5bd73d5b-eea7-44f4-a9e2-ef79a07e9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-066ebf72-6aeb-4c92-8f47-b77fb07150a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-bf18261b-e86e-4991-8ccc-1777b80eb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-125f0964-e98b-4dcc-b0ce-f0f9ec35daca,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-490d6420-2bdd-4934-b42a-15ab809094b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-3a1f8a30-0123-402f-9c09-5fd8fefdd35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-fa736ada-eba2-42b3-87ee-11c610a44553,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971567949-172.17.0.10-1599368083022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-2fb77577-64b3-47d8-8cba-f57fcaa39a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-7783ae2d-e5b5-4c40-a5e9-61ee321f67ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-3b70887f-caea-490c-9f70-f426caeed6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-b962a3b6-3b32-4f9c-aed4-92c58a33b765,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-ba11c7b5-17d3-4209-9617-a9c2c47c6113,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-00839ff1-e961-46e7-99e7-248814c85293,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-09bc98ef-af0e-4c2c-ba49-48971e808a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-121c1db2-4b9a-401b-a822-9f6c9856a391,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971567949-172.17.0.10-1599368083022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-2fb77577-64b3-47d8-8cba-f57fcaa39a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-7783ae2d-e5b5-4c40-a5e9-61ee321f67ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-3b70887f-caea-490c-9f70-f426caeed6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-b962a3b6-3b32-4f9c-aed4-92c58a33b765,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-ba11c7b5-17d3-4209-9617-a9c2c47c6113,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-00839ff1-e961-46e7-99e7-248814c85293,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-09bc98ef-af0e-4c2c-ba49-48971e808a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-121c1db2-4b9a-401b-a822-9f6c9856a391,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243286620-172.17.0.10-1599368154893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-f560130d-0ff7-45cf-a032-19a3c5c468be,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-13cf6955-9dc0-425d-af58-26a23b526ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-dbe630a9-b8d8-43bb-9da6-c6486218b59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ab907177-243a-4790-ba85-143193feb02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-ec116854-c3cd-4a61-85be-6ef1c3cc1f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-ecc038c4-f25d-4c93-97be-6a5579193ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-4bb9dd8f-ce7c-4097-a86b-529c9ea35cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c0b95df3-ea0c-4c34-bbce-334fe35b1612,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243286620-172.17.0.10-1599368154893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-f560130d-0ff7-45cf-a032-19a3c5c468be,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-13cf6955-9dc0-425d-af58-26a23b526ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-dbe630a9-b8d8-43bb-9da6-c6486218b59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ab907177-243a-4790-ba85-143193feb02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-ec116854-c3cd-4a61-85be-6ef1c3cc1f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-ecc038c4-f25d-4c93-97be-6a5579193ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-4bb9dd8f-ce7c-4097-a86b-529c9ea35cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-c0b95df3-ea0c-4c34-bbce-334fe35b1612,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235051459-172.17.0.10-1599368354184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-e411dbfb-6559-4f9c-baf8-da95892d788c,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-1a7e25f7-4c4f-45d2-9675-07b9e01f3bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-498907ab-368c-419b-b9a7-40aec2aa6afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-76c6890e-b444-47dd-a8e8-8e9c9ea3fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-693b1776-17d4-4f70-b68d-5539f72bd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-62ef8380-576b-4445-bde0-3c3f589dd426,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-0140a3ed-4883-4733-84b5-4133e91a05e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-8b2bda1a-3f72-4e99-bba7-b253203c6dbf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235051459-172.17.0.10-1599368354184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-e411dbfb-6559-4f9c-baf8-da95892d788c,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-1a7e25f7-4c4f-45d2-9675-07b9e01f3bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-498907ab-368c-419b-b9a7-40aec2aa6afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-76c6890e-b444-47dd-a8e8-8e9c9ea3fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-693b1776-17d4-4f70-b68d-5539f72bd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-62ef8380-576b-4445-bde0-3c3f589dd426,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-0140a3ed-4883-4733-84b5-4133e91a05e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-8b2bda1a-3f72-4e99-bba7-b253203c6dbf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348144109-172.17.0.10-1599368598001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-8fd702c9-c407-4160-927f-9cd881f4bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-86426d20-49f5-4138-ab29-b39c5971cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-c29d1ece-74bf-4e28-9657-903732b429e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-804de58a-bf4f-4071-8cda-168944748696,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-6b90b423-915b-4b49-bb3a-6120f5b58990,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-c503512b-b0fa-4dbf-bd6d-e4f33c84d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-6ef4ff7c-ea26-4fcc-9431-0ffe5499e767,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4f8a2cb7-74fb-42cc-92a3-cdc7b18b8566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348144109-172.17.0.10-1599368598001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-8fd702c9-c407-4160-927f-9cd881f4bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-86426d20-49f5-4138-ab29-b39c5971cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-c29d1ece-74bf-4e28-9657-903732b429e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-804de58a-bf4f-4071-8cda-168944748696,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-6b90b423-915b-4b49-bb3a-6120f5b58990,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-c503512b-b0fa-4dbf-bd6d-e4f33c84d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-6ef4ff7c-ea26-4fcc-9431-0ffe5499e767,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4f8a2cb7-74fb-42cc-92a3-cdc7b18b8566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584915522-172.17.0.10-1599368675424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-eb703f28-e0ef-4c69-b84c-0210afbb5904,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-83c8fb04-dfbd-4632-9a28-306ea11fb371,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-e8232089-7294-4987-97b7-073fa285f411,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-2fe0c766-0534-48c5-bba4-b98048d1dc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-74ca45e8-506a-47db-9dec-402a53259dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-bfd4ef38-1b31-4d08-a1f3-de3c44adc615,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-62eafbdb-8779-4332-961c-f755d2f69ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-2b5d5773-d68a-4fcb-9d64-607fd9105c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584915522-172.17.0.10-1599368675424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-eb703f28-e0ef-4c69-b84c-0210afbb5904,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-83c8fb04-dfbd-4632-9a28-306ea11fb371,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-e8232089-7294-4987-97b7-073fa285f411,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-2fe0c766-0534-48c5-bba4-b98048d1dc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-74ca45e8-506a-47db-9dec-402a53259dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-bfd4ef38-1b31-4d08-a1f3-de3c44adc615,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-62eafbdb-8779-4332-961c-f755d2f69ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-2b5d5773-d68a-4fcb-9d64-607fd9105c1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584645167-172.17.0.10-1599368825003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-51adcfa5-aa09-469f-ad4e-cf1f4ba77144,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-3d5e7219-53a4-44c0-b0f6-902552b1d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7de2396c-e23a-4660-ba49-295a31ef65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-5bfae056-e0e3-42df-8ed1-c13658851500,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-be5bf33a-e93e-4717-af7d-175b957cf1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-e7ed0fa5-2b4c-414b-a9f5-6a8417db375f,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-62768942-e6fc-4984-b9e9-5aac0c6a403c,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-5fee628c-425f-4b30-a41a-2e08b9dc32d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584645167-172.17.0.10-1599368825003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-51adcfa5-aa09-469f-ad4e-cf1f4ba77144,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-3d5e7219-53a4-44c0-b0f6-902552b1d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7de2396c-e23a-4660-ba49-295a31ef65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-5bfae056-e0e3-42df-8ed1-c13658851500,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-be5bf33a-e93e-4717-af7d-175b957cf1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-e7ed0fa5-2b4c-414b-a9f5-6a8417db375f,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-62768942-e6fc-4984-b9e9-5aac0c6a403c,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-5fee628c-425f-4b30-a41a-2e08b9dc32d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049852606-172.17.0.10-1599368903236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-827ca9e2-c1b7-4c4a-b879-259eedb7b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e0cc933b-624c-45b6-91b2-5c93f06aaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-156d6490-8173-4f14-a0f0-4d44b8d9c68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-957e01d9-3c83-4172-b25f-e54e349e0282,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-d767b4d0-bf3d-4027-b274-069165cfb243,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-d7c6ee1f-26f5-4f70-82d7-231ae999fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-c96eab26-aa75-463b-bbfb-a0a133d9a304,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-5c54b60c-4489-4fc9-b530-ef16b89c7112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049852606-172.17.0.10-1599368903236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-827ca9e2-c1b7-4c4a-b879-259eedb7b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e0cc933b-624c-45b6-91b2-5c93f06aaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-156d6490-8173-4f14-a0f0-4d44b8d9c68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-957e01d9-3c83-4172-b25f-e54e349e0282,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-d767b4d0-bf3d-4027-b274-069165cfb243,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-d7c6ee1f-26f5-4f70-82d7-231ae999fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-c96eab26-aa75-463b-bbfb-a0a133d9a304,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-5c54b60c-4489-4fc9-b530-ef16b89c7112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306286490-172.17.0.10-1599369267900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-b001eb0f-9cc5-46a6-ad63-c75d1ab955a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-57363c5f-f050-452b-9805-e5857fe365dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e4d66331-d7af-44e3-8dda-9c0de1684d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-39c5ea00-f88f-4a28-9813-a89b0bd33bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-9e335c78-c69b-4a79-aa4d-1273df32e9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-e3692f57-16b7-4d66-95c7-c932c276c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-f5d6d7e4-e1f5-4ae0-90ea-3a4228609d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-6ee99c14-ec9d-4aff-834b-ceb935140686,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306286490-172.17.0.10-1599369267900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-b001eb0f-9cc5-46a6-ad63-c75d1ab955a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-57363c5f-f050-452b-9805-e5857fe365dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-e4d66331-d7af-44e3-8dda-9c0de1684d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-39c5ea00-f88f-4a28-9813-a89b0bd33bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-9e335c78-c69b-4a79-aa4d-1273df32e9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-e3692f57-16b7-4d66-95c7-c932c276c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-f5d6d7e4-e1f5-4ae0-90ea-3a4228609d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-6ee99c14-ec9d-4aff-834b-ceb935140686,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151463169-172.17.0.10-1599369452063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-5689faf6-b11e-4266-9a1d-992800eebc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-83ab428d-60d2-4eec-8583-f801bdc96911,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-940e9213-5892-458d-86de-3ff96e33c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-b0015d4c-894c-47d9-9ffb-0e95803889dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-128581f9-d32b-406d-be3f-6e9b04c0371c,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0ee13df9-a622-4bb4-baca-f2ed50daa79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-4e8beb2e-2002-48a1-879b-36cd81611c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-c6b709f6-0805-4321-bed6-0ded2208e27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151463169-172.17.0.10-1599369452063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-5689faf6-b11e-4266-9a1d-992800eebc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-83ab428d-60d2-4eec-8583-f801bdc96911,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-940e9213-5892-458d-86de-3ff96e33c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-b0015d4c-894c-47d9-9ffb-0e95803889dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-128581f9-d32b-406d-be3f-6e9b04c0371c,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0ee13df9-a622-4bb4-baca-f2ed50daa79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-4e8beb2e-2002-48a1-879b-36cd81611c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-c6b709f6-0805-4321-bed6-0ded2208e27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321223909-172.17.0.10-1599369489143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-869e39a5-eae3-451f-a345-c5c7ef92f72a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a4750911-fa59-4a53-bf33-2aab24464fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-44fd563d-e691-45f2-a508-9491bf6bba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-ff204811-1b33-4ea5-81a4-84e18e59734b,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-e628ad70-f6fb-44d8-bf60-7c66b93911b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-ea59f799-b2fb-4345-8461-3a4872a9e961,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-11cb1be0-5bd8-489b-b5e3-5e03a51c709b,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-613742ba-758d-45c6-9015-7c0e102f2bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321223909-172.17.0.10-1599369489143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-869e39a5-eae3-451f-a345-c5c7ef92f72a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a4750911-fa59-4a53-bf33-2aab24464fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-44fd563d-e691-45f2-a508-9491bf6bba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-ff204811-1b33-4ea5-81a4-84e18e59734b,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-e628ad70-f6fb-44d8-bf60-7c66b93911b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-ea59f799-b2fb-4345-8461-3a4872a9e961,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-11cb1be0-5bd8-489b-b5e3-5e03a51c709b,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-613742ba-758d-45c6-9015-7c0e102f2bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725995996-172.17.0.10-1599369629538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-3c07203a-32f6-4867-b878-0c8809316260,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-be63a0ff-d876-49b9-b063-4e42c7941be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-c96684ec-3acd-46ae-a936-ef76903dd0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-20e80648-f10c-4cf0-98b5-705d5d2dfc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f4e81f72-4bf6-426d-99dc-c0054dd08209,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-2f665880-c8f9-4ecf-8a25-e59111d656c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-5576e6a1-dc7b-4b74-8656-46eef668057d,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-dcd16846-c019-40f4-8847-5e478580a813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725995996-172.17.0.10-1599369629538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-3c07203a-32f6-4867-b878-0c8809316260,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-be63a0ff-d876-49b9-b063-4e42c7941be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-c96684ec-3acd-46ae-a936-ef76903dd0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-20e80648-f10c-4cf0-98b5-705d5d2dfc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f4e81f72-4bf6-426d-99dc-c0054dd08209,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-2f665880-c8f9-4ecf-8a25-e59111d656c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-5576e6a1-dc7b-4b74-8656-46eef668057d,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-dcd16846-c019-40f4-8847-5e478580a813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503068428-172.17.0.10-1599369788806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-602a29f2-8bc5-4911-8948-78342d163202,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-fafad03a-dd99-416b-901d-02d29b6aaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-cf53020d-df5d-4d32-88be-b6f568c2d774,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-2bc375d3-3ee2-4676-9143-1cd76d85598d,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-e13e8fc5-bb2f-48f5-a61d-4e25a5961e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-f45f45c9-7c12-44e4-8b09-818f0d13ddc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-f3b4cb99-7dbb-4e7c-9b09-a19d0e1167f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f7a42d40-7ed1-49b2-bed2-6ba96c0b4bc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503068428-172.17.0.10-1599369788806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-602a29f2-8bc5-4911-8948-78342d163202,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-fafad03a-dd99-416b-901d-02d29b6aaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-cf53020d-df5d-4d32-88be-b6f568c2d774,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-2bc375d3-3ee2-4676-9143-1cd76d85598d,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-e13e8fc5-bb2f-48f5-a61d-4e25a5961e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-f45f45c9-7c12-44e4-8b09-818f0d13ddc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-f3b4cb99-7dbb-4e7c-9b09-a19d0e1167f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f7a42d40-7ed1-49b2-bed2-6ba96c0b4bc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664678778-172.17.0.10-1599370305918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-02cfb5f5-9536-4124-bd50-d86d1dae013d,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-9071d2b8-3bdb-4e91-8057-6b45c15daba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-08696381-d6eb-43a5-8e2f-28a999fdfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-129d6720-528f-4b11-80d4-fc367d6a9001,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-af887797-b7ce-427e-8275-2814d733bf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-f2472b00-c5bb-479f-9b25-01af38644dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-f5ea6531-529e-43d4-91ce-6395b4ea467a,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e328b692-b917-4301-872e-f6a6b6a76a98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664678778-172.17.0.10-1599370305918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-02cfb5f5-9536-4124-bd50-d86d1dae013d,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-9071d2b8-3bdb-4e91-8057-6b45c15daba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-08696381-d6eb-43a5-8e2f-28a999fdfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-129d6720-528f-4b11-80d4-fc367d6a9001,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-af887797-b7ce-427e-8275-2814d733bf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-f2472b00-c5bb-479f-9b25-01af38644dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-f5ea6531-529e-43d4-91ce-6395b4ea467a,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-e328b692-b917-4301-872e-f6a6b6a76a98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963149020-172.17.0.10-1599370858205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-3e8c214f-2b4d-4880-890a-84502973075e,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a4e88adc-4dd8-422a-8828-a0ac88381bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-21d3ecb7-c408-42d1-8a17-36ed512f464c,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-d04dd996-5b84-4008-b258-3b20453907f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-7b2c06a8-b20e-4143-9a7c-79d3140e5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-5eb6f6a6-b51d-4a57-abbe-4c39a5ea0777,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-11888a02-d2c5-470c-a1e4-abd8f3a5e1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a4060af0-4a85-42b5-b439-1214141ecd4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963149020-172.17.0.10-1599370858205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-3e8c214f-2b4d-4880-890a-84502973075e,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a4e88adc-4dd8-422a-8828-a0ac88381bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-21d3ecb7-c408-42d1-8a17-36ed512f464c,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-d04dd996-5b84-4008-b258-3b20453907f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-7b2c06a8-b20e-4143-9a7c-79d3140e5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-5eb6f6a6-b51d-4a57-abbe-4c39a5ea0777,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-11888a02-d2c5-470c-a1e4-abd8f3a5e1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-a4060af0-4a85-42b5-b439-1214141ecd4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015789513-172.17.0.10-1599371288889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-c3457f2a-7555-427b-a262-55e01be815c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-b4d576e3-7777-45aa-8970-5bb25a3842ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-6af0acb7-3790-440c-8d8f-fd90742e23f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-234be0a4-6749-4cd4-9154-7b915cb5eff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-25a8ece2-763b-431a-b6ef-b46cca362141,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-ac8b3e0e-964a-4f37-aa01-d017ec90a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-052769e7-15db-40b5-b873-9264303a17cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-a7752198-18ce-4b02-ab30-96557bc27766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015789513-172.17.0.10-1599371288889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-c3457f2a-7555-427b-a262-55e01be815c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-b4d576e3-7777-45aa-8970-5bb25a3842ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-6af0acb7-3790-440c-8d8f-fd90742e23f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-234be0a4-6749-4cd4-9154-7b915cb5eff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-25a8ece2-763b-431a-b6ef-b46cca362141,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-ac8b3e0e-964a-4f37-aa01-d017ec90a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-052769e7-15db-40b5-b873-9264303a17cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-a7752198-18ce-4b02-ab30-96557bc27766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010737804-172.17.0.10-1599371429872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-797634c3-ecfb-430a-a5a0-4b4f52dfb904,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-03e4ea19-adad-40ad-9900-35fdeedb5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7f03fc77-3c4c-4c05-87bd-4fbfd0df4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-0aabddd5-e95c-4ca2-88bd-478fe1fd13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-7697f6a8-ff37-44ca-b55f-497d0ad87c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-fa8a69ab-1ead-46e4-bc50-bc7598f5f133,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-5855dd44-9a2f-4b0d-a923-3a59292d3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5516e5a6-9a5d-4dcd-a432-5263b8dd429d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010737804-172.17.0.10-1599371429872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-797634c3-ecfb-430a-a5a0-4b4f52dfb904,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-03e4ea19-adad-40ad-9900-35fdeedb5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7f03fc77-3c4c-4c05-87bd-4fbfd0df4d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-0aabddd5-e95c-4ca2-88bd-478fe1fd13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-7697f6a8-ff37-44ca-b55f-497d0ad87c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-fa8a69ab-1ead-46e4-bc50-bc7598f5f133,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-5855dd44-9a2f-4b0d-a923-3a59292d3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5516e5a6-9a5d-4dcd-a432-5263b8dd429d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165931521-172.17.0.10-1599371463461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-e1c9efde-f038-4dd4-a107-0b29c2693dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-fcc66496-a448-4788-b28d-3370faa8d7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-f4b5967f-8e17-447c-85ef-636d5f0ec8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-5ee5601e-582b-4e2b-9be5-e0da3440ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-62733c49-78be-4ed0-b535-d89c38f4fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-c894116c-31f9-45c8-901f-04a2201ff1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4fe2621a-4cef-4e8e-aec0-4db41020e3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-1c332126-15de-4b73-bdb3-310130415bfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165931521-172.17.0.10-1599371463461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-e1c9efde-f038-4dd4-a107-0b29c2693dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-fcc66496-a448-4788-b28d-3370faa8d7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-f4b5967f-8e17-447c-85ef-636d5f0ec8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-5ee5601e-582b-4e2b-9be5-e0da3440ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-62733c49-78be-4ed0-b535-d89c38f4fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-c894116c-31f9-45c8-901f-04a2201ff1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4fe2621a-4cef-4e8e-aec0-4db41020e3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-1c332126-15de-4b73-bdb3-310130415bfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5731
