reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544507099-172.17.0.17-1599358832890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-c6c6503a-1844-4b0f-b686-3d24beb9201e,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-4f91fb85-704f-492f-8666-11df0fdfa066,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-b25a297a-4842-4061-811b-6a0645860363,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-b1739aa7-70fb-4d5b-a385-d291b9aa99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-266feed2-60dc-4700-828f-3c9be541ba20,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-1269f7d4-1e78-4b84-ac6a-116c5955d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-bc99334e-3634-40f7-97cb-60087c857526,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-3bd026c4-2359-4bf6-a46e-e057e306c0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544507099-172.17.0.17-1599358832890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-c6c6503a-1844-4b0f-b686-3d24beb9201e,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-4f91fb85-704f-492f-8666-11df0fdfa066,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-b25a297a-4842-4061-811b-6a0645860363,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-b1739aa7-70fb-4d5b-a385-d291b9aa99c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-266feed2-60dc-4700-828f-3c9be541ba20,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-1269f7d4-1e78-4b84-ac6a-116c5955d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-bc99334e-3634-40f7-97cb-60087c857526,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-3bd026c4-2359-4bf6-a46e-e057e306c0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916871278-172.17.0.17-1599359896755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39134,DS-f97bfb4d-c45b-4eb3-a34c-23372119caac,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-051b1723-10a7-48cc-9d01-697ef53230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-abbcb3e5-189d-47c0-bb9e-f4169a307fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-8d88c3c5-f0b4-409d-a50d-46b92f569b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-6b557aa7-7ae8-41b4-8bdc-3970cfbd569f,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-26dcd5fd-9cc2-4f7f-9bd3-451d3633d630,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-275a085d-173d-43b1-b363-4eaa17bd17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-8f35f818-b3df-46c4-8355-95bddbb88cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916871278-172.17.0.17-1599359896755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39134,DS-f97bfb4d-c45b-4eb3-a34c-23372119caac,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-051b1723-10a7-48cc-9d01-697ef53230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-abbcb3e5-189d-47c0-bb9e-f4169a307fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-8d88c3c5-f0b4-409d-a50d-46b92f569b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-6b557aa7-7ae8-41b4-8bdc-3970cfbd569f,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-26dcd5fd-9cc2-4f7f-9bd3-451d3633d630,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-275a085d-173d-43b1-b363-4eaa17bd17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-8f35f818-b3df-46c4-8355-95bddbb88cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530100251-172.17.0.17-1599360320087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-6732da14-c243-413d-9fdf-93eb5efc35db,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-06d2fc13-81ba-4ee9-98e7-400fc5c0bd83,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-c6628237-939d-45ee-9d1d-6ea4ac24d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-c009f65a-e6ab-40d7-a0a9-305ce4d4848c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-93a92ca2-668d-418c-9e0c-2c00d2f0ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-493ea73b-26d4-4b43-b75c-e99e9796f025,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-0dd2c7fa-f2e7-45ea-b340-13f972fa085d,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-24ad95aa-5968-4129-a69f-597eb0ca5435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530100251-172.17.0.17-1599360320087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-6732da14-c243-413d-9fdf-93eb5efc35db,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-06d2fc13-81ba-4ee9-98e7-400fc5c0bd83,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-c6628237-939d-45ee-9d1d-6ea4ac24d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-c009f65a-e6ab-40d7-a0a9-305ce4d4848c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-93a92ca2-668d-418c-9e0c-2c00d2f0ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-493ea73b-26d4-4b43-b75c-e99e9796f025,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-0dd2c7fa-f2e7-45ea-b340-13f972fa085d,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-24ad95aa-5968-4129-a69f-597eb0ca5435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559286228-172.17.0.17-1599360489238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36016,DS-6f7806ec-4882-4dd8-93d9-f7d2e7e13a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-0fbfcb7c-7e77-4da1-81fc-31d198d77490,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-c782981d-134b-40d7-b205-280fffc45b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-52a58b8a-cfda-434e-8666-b561e30891be,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-47672be0-f4a2-4542-bd8c-c39bbf7969ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-4bd4b7c6-cacc-4842-9d63-2b0eae039996,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-07fa83c8-34cd-4558-b229-d307faf5b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c3a95bb4-6738-4204-b78a-86d4f96d991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559286228-172.17.0.17-1599360489238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36016,DS-6f7806ec-4882-4dd8-93d9-f7d2e7e13a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-0fbfcb7c-7e77-4da1-81fc-31d198d77490,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-c782981d-134b-40d7-b205-280fffc45b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-52a58b8a-cfda-434e-8666-b561e30891be,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-47672be0-f4a2-4542-bd8c-c39bbf7969ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-4bd4b7c6-cacc-4842-9d63-2b0eae039996,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-07fa83c8-34cd-4558-b229-d307faf5b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c3a95bb4-6738-4204-b78a-86d4f96d991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427241943-172.17.0.17-1599360588203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-d098c0ec-c154-4c97-a8a7-c1d196545ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-66186c88-164c-4709-b94e-1c9e37bafc25,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-343de527-e0d3-4095-9a6f-4b8050c37a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-612e908b-4fff-4e91-8cc8-7d448812ccf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-4f49810a-20e0-4d00-8af6-0ada7b69c8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-20ade44b-a4ed-415d-9009-9e6db3888ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-2977557f-c65a-42f6-be8b-9d66e4ed830f,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-6509015c-5189-4148-b288-5fa288c91eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427241943-172.17.0.17-1599360588203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-d098c0ec-c154-4c97-a8a7-c1d196545ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-66186c88-164c-4709-b94e-1c9e37bafc25,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-343de527-e0d3-4095-9a6f-4b8050c37a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-612e908b-4fff-4e91-8cc8-7d448812ccf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-4f49810a-20e0-4d00-8af6-0ada7b69c8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-20ade44b-a4ed-415d-9009-9e6db3888ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-2977557f-c65a-42f6-be8b-9d66e4ed830f,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-6509015c-5189-4148-b288-5fa288c91eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121311132-172.17.0.17-1599361218311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-708e472d-51f4-4a16-aa08-2d14c069f120,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-4ab48f94-7d3c-48fa-8b83-02a6d73313ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-3b7c07c7-5285-47e2-9828-52a558ececfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-72b00f90-f2a5-4a7e-b438-60e0238d0318,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-0b48262b-7b9e-4157-a887-483d69055f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f0c38032-5a60-4226-9752-1cf20611b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-5b4d4c9c-88e9-4743-ab8c-2e14836d5086,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-5f7ae89a-28fc-4a07-a0bf-012b693537cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121311132-172.17.0.17-1599361218311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-708e472d-51f4-4a16-aa08-2d14c069f120,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-4ab48f94-7d3c-48fa-8b83-02a6d73313ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-3b7c07c7-5285-47e2-9828-52a558ececfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-72b00f90-f2a5-4a7e-b438-60e0238d0318,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-0b48262b-7b9e-4157-a887-483d69055f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f0c38032-5a60-4226-9752-1cf20611b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-5b4d4c9c-88e9-4743-ab8c-2e14836d5086,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-5f7ae89a-28fc-4a07-a0bf-012b693537cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700408315-172.17.0.17-1599361246889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-3d7db165-6083-4d34-bfd6-6fd664231dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-341afb6c-c3b2-4838-8d6a-3219eeb36366,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-09d3a91d-d1e4-4edb-af24-e051b57bd95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-8c7e28f5-74f3-4e85-9806-7b3d410982ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-9f3c26ae-5091-4e4c-a6f1-78ab8fadf265,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-bb37877d-b604-464d-828a-578044e8a676,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-c87ae667-d938-4c66-890f-f162df73cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-2eea8dee-17ba-4299-b2f5-29e7eab0369a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700408315-172.17.0.17-1599361246889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-3d7db165-6083-4d34-bfd6-6fd664231dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-341afb6c-c3b2-4838-8d6a-3219eeb36366,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-09d3a91d-d1e4-4edb-af24-e051b57bd95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-8c7e28f5-74f3-4e85-9806-7b3d410982ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-9f3c26ae-5091-4e4c-a6f1-78ab8fadf265,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-bb37877d-b604-464d-828a-578044e8a676,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-c87ae667-d938-4c66-890f-f162df73cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-2eea8dee-17ba-4299-b2f5-29e7eab0369a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828587256-172.17.0.17-1599361379207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-dfa2c388-0e40-456a-b913-f9c341d46f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-67bafb6a-019d-44ca-a005-03669ecb14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-875f7b2f-c5c2-4a21-a93a-d8e9faaf2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-e72a5430-ddc4-4626-be21-f7f4e6cac459,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b76d3eba-ec83-4ecc-aca3-b03dfb5bc2df,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-53890196-2df3-4853-9c1f-a2cf43305c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-0128266b-6e56-4564-9ae3-8286b357b612,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-1440893e-3741-4b66-8b93-c1abe18c4c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828587256-172.17.0.17-1599361379207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-dfa2c388-0e40-456a-b913-f9c341d46f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-67bafb6a-019d-44ca-a005-03669ecb14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-875f7b2f-c5c2-4a21-a93a-d8e9faaf2a52,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-e72a5430-ddc4-4626-be21-f7f4e6cac459,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b76d3eba-ec83-4ecc-aca3-b03dfb5bc2df,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-53890196-2df3-4853-9c1f-a2cf43305c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-0128266b-6e56-4564-9ae3-8286b357b612,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-1440893e-3741-4b66-8b93-c1abe18c4c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597448368-172.17.0.17-1599361653832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-d8c33d4f-c06f-43e2-ab75-b3aef1f806e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-26e3f9ed-cd6d-4cd8-9919-13ccef87ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-c5bfd749-9574-4c90-8e34-431ed7d3036c,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-f717078a-58fb-4174-896a-23f74e11d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-544cfcdc-6549-466c-ac6a-feb56615e754,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-5c715aaf-c6fe-4eb3-8739-79191263c179,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f3a40248-daea-4b26-9199-a87e2b579015,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-cf9d88eb-92b9-4109-bc93-d3f540806274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597448368-172.17.0.17-1599361653832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43059,DS-d8c33d4f-c06f-43e2-ab75-b3aef1f806e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-26e3f9ed-cd6d-4cd8-9919-13ccef87ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-c5bfd749-9574-4c90-8e34-431ed7d3036c,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-f717078a-58fb-4174-896a-23f74e11d52e,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-544cfcdc-6549-466c-ac6a-feb56615e754,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-5c715aaf-c6fe-4eb3-8739-79191263c179,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f3a40248-daea-4b26-9199-a87e2b579015,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-cf9d88eb-92b9-4109-bc93-d3f540806274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670895393-172.17.0.17-1599361974890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-6b0082df-a340-4b03-ba40-e1833e7b6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0a18d312-33e5-40b4-8417-ab0b6624f735,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-b5651f1a-eafe-4c3f-a61b-813cbf17c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-d186fde1-dc76-446b-b66b-d2285fd4623d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-603034a8-7ec9-4ead-81fd-a7d3965fc805,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-eb37d50f-2368-4fe2-927a-9a96ce7a3a73,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-fd018bc9-a1a5-451e-8a22-5660a6039f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-ee174eda-7993-4c0d-bd4f-ec67f460ff56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670895393-172.17.0.17-1599361974890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-6b0082df-a340-4b03-ba40-e1833e7b6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0a18d312-33e5-40b4-8417-ab0b6624f735,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-b5651f1a-eafe-4c3f-a61b-813cbf17c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-d186fde1-dc76-446b-b66b-d2285fd4623d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-603034a8-7ec9-4ead-81fd-a7d3965fc805,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-eb37d50f-2368-4fe2-927a-9a96ce7a3a73,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-fd018bc9-a1a5-451e-8a22-5660a6039f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-ee174eda-7993-4c0d-bd4f-ec67f460ff56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357309966-172.17.0.17-1599362977537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-373add39-f620-4d85-96cd-44e5f5711be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2ed5db2a-f332-4fb3-ac47-37f1f31f270d,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-28620bf4-6cd8-4505-bc2f-7ad8490bd33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-547f7559-cca7-470f-97a4-2257ea63b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-74b9261e-904e-4b9f-8a45-54f64ff1c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-0bb95e3b-dcf6-4643-87cb-b10fc1cc80a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-86054d08-12ba-4ef2-ab58-9f0a6ad48257,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-37a9344a-76b2-4d60-baf4-f43e8fb1cd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357309966-172.17.0.17-1599362977537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-373add39-f620-4d85-96cd-44e5f5711be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2ed5db2a-f332-4fb3-ac47-37f1f31f270d,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-28620bf4-6cd8-4505-bc2f-7ad8490bd33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-547f7559-cca7-470f-97a4-2257ea63b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-74b9261e-904e-4b9f-8a45-54f64ff1c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-0bb95e3b-dcf6-4643-87cb-b10fc1cc80a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-86054d08-12ba-4ef2-ab58-9f0a6ad48257,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-37a9344a-76b2-4d60-baf4-f43e8fb1cd92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5103
