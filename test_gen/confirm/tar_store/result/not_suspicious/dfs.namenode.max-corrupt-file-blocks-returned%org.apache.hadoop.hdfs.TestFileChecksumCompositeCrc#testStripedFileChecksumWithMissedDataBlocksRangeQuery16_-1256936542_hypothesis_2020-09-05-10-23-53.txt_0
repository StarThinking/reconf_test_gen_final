reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484462766-172.17.0.10-1599301966156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-39397da1-f46a-4d9f-b5db-ba72210d8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-5428834d-29b7-449d-815f-ffdb6ce4f288,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-20d05f04-cc8c-4661-b832-850849931259,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0f10b6a3-aee8-49f1-bb70-a96d22c433f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-693d851d-e146-4ff2-8b17-eb239d57a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-57133187-b8d2-4faa-951b-01ae9fa4ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-fd7357e4-aceb-4ddf-b93e-43035748e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-3443dea8-dd43-44eb-8813-ee127728c991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484462766-172.17.0.10-1599301966156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-39397da1-f46a-4d9f-b5db-ba72210d8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-5428834d-29b7-449d-815f-ffdb6ce4f288,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-20d05f04-cc8c-4661-b832-850849931259,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0f10b6a3-aee8-49f1-bb70-a96d22c433f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-693d851d-e146-4ff2-8b17-eb239d57a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-57133187-b8d2-4faa-951b-01ae9fa4ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-fd7357e4-aceb-4ddf-b93e-43035748e6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-3443dea8-dd43-44eb-8813-ee127728c991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239072175-172.17.0.10-1599302582835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-1d6368a3-0eb4-46df-ab10-66cc5d3ce733,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9eb11a66-afe5-4186-944d-8033010d060c,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-a0d902dc-e0cc-4e1d-b994-d76664fc9815,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-2438ff69-e37b-43e0-b57b-220963329164,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-38351d38-67b5-41a0-b8da-5b7c40138c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-3ffac1d2-c188-44ab-8485-094c6da65278,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-9749b0c3-61a3-41db-9476-bafde3bbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-555b73dc-9a8a-41c7-8ffd-41c1f1e317bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239072175-172.17.0.10-1599302582835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-1d6368a3-0eb4-46df-ab10-66cc5d3ce733,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9eb11a66-afe5-4186-944d-8033010d060c,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-a0d902dc-e0cc-4e1d-b994-d76664fc9815,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-2438ff69-e37b-43e0-b57b-220963329164,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-38351d38-67b5-41a0-b8da-5b7c40138c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-3ffac1d2-c188-44ab-8485-094c6da65278,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-9749b0c3-61a3-41db-9476-bafde3bbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-555b73dc-9a8a-41c7-8ffd-41c1f1e317bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64964184-172.17.0.10-1599302885317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-5149a2a4-5cd1-4064-ad2d-72ded4f4095a,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-83e8eef6-8cf2-4ca3-bc76-f7387efd9095,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-c664d17e-98ee-414f-8a7e-d88114a473fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-8f5503d9-83c9-4c88-9b5a-ed58d8a06691,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-6b859e20-3ccd-4a05-81d8-77b3fcc4c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ce89db5b-e7e7-4fbe-837a-3e8bd6081f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-3de2cba1-3c8f-410c-ae2b-e8ab572a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-4ff67e7f-bc49-4807-a915-e56bb76f0cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64964184-172.17.0.10-1599302885317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-5149a2a4-5cd1-4064-ad2d-72ded4f4095a,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-83e8eef6-8cf2-4ca3-bc76-f7387efd9095,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-c664d17e-98ee-414f-8a7e-d88114a473fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-8f5503d9-83c9-4c88-9b5a-ed58d8a06691,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-6b859e20-3ccd-4a05-81d8-77b3fcc4c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-ce89db5b-e7e7-4fbe-837a-3e8bd6081f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-3de2cba1-3c8f-410c-ae2b-e8ab572a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-4ff67e7f-bc49-4807-a915-e56bb76f0cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192132447-172.17.0.10-1599302964174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-62fdfc0d-21f1-4a87-a17d-f40bf919749a,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-c5fd8164-1623-47c4-b8a5-5c49c7ee9866,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-38208d6e-5ac8-4398-920f-889705e65dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-be7094dc-d6a8-4050-9ece-6f105fd3ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-3794c8eb-134f-4080-b67d-af2294d3c4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-f9d66e39-0774-4c88-b002-ccbe71a1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-16593e0e-55b0-413f-a073-985c3305af93,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-313021d6-ebd6-457d-b367-657de569e199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192132447-172.17.0.10-1599302964174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-62fdfc0d-21f1-4a87-a17d-f40bf919749a,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-c5fd8164-1623-47c4-b8a5-5c49c7ee9866,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-38208d6e-5ac8-4398-920f-889705e65dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-be7094dc-d6a8-4050-9ece-6f105fd3ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-3794c8eb-134f-4080-b67d-af2294d3c4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-f9d66e39-0774-4c88-b002-ccbe71a1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-16593e0e-55b0-413f-a073-985c3305af93,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-313021d6-ebd6-457d-b367-657de569e199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092309227-172.17.0.10-1599303029220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-0cd15e6b-a803-4a25-a8bf-5235a92fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-7906c5cb-b83c-4ca8-aade-8c2ba8a2707e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-9d4a9806-5731-4ad5-bc5e-a93c2da832f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-95ffb57e-87da-4355-83d0-fa4a93f17630,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-6d3bde67-777b-400a-b8e0-e10cebd16ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-10794d3b-37bd-4bf5-863e-4b742fe134df,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-c3aefc0b-69d7-4546-ba4c-cfa0b1837764,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-2e0519cc-c519-4530-a5f9-ab03d3035735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092309227-172.17.0.10-1599303029220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-0cd15e6b-a803-4a25-a8bf-5235a92fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-7906c5cb-b83c-4ca8-aade-8c2ba8a2707e,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-9d4a9806-5731-4ad5-bc5e-a93c2da832f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-95ffb57e-87da-4355-83d0-fa4a93f17630,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-6d3bde67-777b-400a-b8e0-e10cebd16ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-10794d3b-37bd-4bf5-863e-4b742fe134df,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-c3aefc0b-69d7-4546-ba4c-cfa0b1837764,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-2e0519cc-c519-4530-a5f9-ab03d3035735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642110742-172.17.0.10-1599303218964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-47c04cf0-269e-40d7-80ad-7d89aef52114,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-97c0ed63-6f0c-4be0-bd17-6bd93c96c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e8fbc0ff-0728-4b13-9ce5-db3e2dd7bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-d0ce95e6-c700-4c39-8a1e-aa14d7e37b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-9fdab3af-4025-430f-9982-70943ee5f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-c2bce77e-4464-4652-83dc-423caa149ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-305e6fc3-9678-4fe0-9fd6-93752fcb5808,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-ae03dcde-2a5a-40d4-9232-0b7499e0c59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642110742-172.17.0.10-1599303218964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-47c04cf0-269e-40d7-80ad-7d89aef52114,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-97c0ed63-6f0c-4be0-bd17-6bd93c96c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-e8fbc0ff-0728-4b13-9ce5-db3e2dd7bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-d0ce95e6-c700-4c39-8a1e-aa14d7e37b15,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-9fdab3af-4025-430f-9982-70943ee5f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-c2bce77e-4464-4652-83dc-423caa149ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-305e6fc3-9678-4fe0-9fd6-93752fcb5808,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-ae03dcde-2a5a-40d4-9232-0b7499e0c59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519784954-172.17.0.10-1599303298194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-6595b268-6f33-434d-89d3-8dff65ae98c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-02815735-6720-48cb-bb5e-ee15f0590fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-f303cfa4-d1f2-4f73-bd51-25b023c69472,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-490e2829-ef13-4404-90dd-38f30436c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-866d67a1-e225-49eb-9293-16ea4a990a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-a4dda573-dfb2-46f7-98af-d8f2fe27c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-8a4ce525-c347-4176-bad2-c9a3ca2d0919,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-dac79e4b-8ea9-477a-84ed-f86a2ea2eb6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519784954-172.17.0.10-1599303298194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-6595b268-6f33-434d-89d3-8dff65ae98c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-02815735-6720-48cb-bb5e-ee15f0590fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-f303cfa4-d1f2-4f73-bd51-25b023c69472,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-490e2829-ef13-4404-90dd-38f30436c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-866d67a1-e225-49eb-9293-16ea4a990a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-a4dda573-dfb2-46f7-98af-d8f2fe27c6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-8a4ce525-c347-4176-bad2-c9a3ca2d0919,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-dac79e4b-8ea9-477a-84ed-f86a2ea2eb6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694365347-172.17.0.10-1599303503045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-92e62ba0-46cb-4dff-9b01-872356dcf820,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-a220364f-2c09-47d9-b180-8a10e8793522,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-30e110a4-6edd-4f93-8b33-141c3ab36830,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-cc1d9684-86ed-46f3-838e-7f105c295b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-24221555-4131-4d10-868a-3b7f3c371eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-4affa9ed-c495-4ca6-a355-364eaf0449eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-80d25851-3113-4d3c-b836-897b580e5276,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2cf0b324-7cdb-49ea-88f8-fa2c42920dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694365347-172.17.0.10-1599303503045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-92e62ba0-46cb-4dff-9b01-872356dcf820,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-a220364f-2c09-47d9-b180-8a10e8793522,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-30e110a4-6edd-4f93-8b33-141c3ab36830,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-cc1d9684-86ed-46f3-838e-7f105c295b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-24221555-4131-4d10-868a-3b7f3c371eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-4affa9ed-c495-4ca6-a355-364eaf0449eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-80d25851-3113-4d3c-b836-897b580e5276,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2cf0b324-7cdb-49ea-88f8-fa2c42920dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328223876-172.17.0.10-1599303571825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36948,DS-55579bcc-34c1-467b-96ef-5ce8d3b823fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-41707c9c-14ee-4a81-a2c4-e2641ccc65bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-a55d70f0-d4f5-47c8-b672-667935264d75,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-9dd37c8c-be17-4b68-ac49-d0f9ca309ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-ff1c83be-2f37-411d-84f9-09ec63dada72,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-7443d8b3-cdae-4e14-a2de-efd39bd8ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-d152b879-3747-4aca-a1f5-ee498036c031,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-388ed01a-a670-4a15-816c-800f9620eda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328223876-172.17.0.10-1599303571825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36948,DS-55579bcc-34c1-467b-96ef-5ce8d3b823fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-41707c9c-14ee-4a81-a2c4-e2641ccc65bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-a55d70f0-d4f5-47c8-b672-667935264d75,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-9dd37c8c-be17-4b68-ac49-d0f9ca309ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-ff1c83be-2f37-411d-84f9-09ec63dada72,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-7443d8b3-cdae-4e14-a2de-efd39bd8ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-d152b879-3747-4aca-a1f5-ee498036c031,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-388ed01a-a670-4a15-816c-800f9620eda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929409715-172.17.0.10-1599303608516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-8144385e-cccc-40d2-b698-124557e54ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-780b9eb6-65dc-4f1c-bfa9-5403551119b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-1b34d79c-5f3e-45ff-90ee-673f498b584f,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-cf464e1e-2bc3-421c-88ee-36574614c8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-d490c52d-3583-4b6d-9e32-246ed6695066,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-6f4f2b55-2e1f-44ee-b2a4-7d7c7ddb8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ba608575-b592-4a0b-8ce4-fa0a0578646a,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-eb5ed39b-c850-405c-9bed-04793655953f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929409715-172.17.0.10-1599303608516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-8144385e-cccc-40d2-b698-124557e54ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-780b9eb6-65dc-4f1c-bfa9-5403551119b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-1b34d79c-5f3e-45ff-90ee-673f498b584f,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-cf464e1e-2bc3-421c-88ee-36574614c8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-d490c52d-3583-4b6d-9e32-246ed6695066,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-6f4f2b55-2e1f-44ee-b2a4-7d7c7ddb8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ba608575-b592-4a0b-8ce4-fa0a0578646a,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-eb5ed39b-c850-405c-9bed-04793655953f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058306806-172.17.0.10-1599303777703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-e42bc769-651e-49bb-b7bd-5e9742555f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-7a871b55-c7fb-4e81-a0a3-cfe08eeccf99,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-74aa6bf9-5912-4335-afcc-172bae2da309,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-15e22e9c-2a3f-48cd-8c98-22824d3fc883,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-61689fd5-6b14-4fc7-85e9-fb6266749056,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a048f9de-d886-4669-94fd-5c2c75160d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-18e5e810-58e4-44fe-a027-da1aeef7903e,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-9231e201-e2c7-46cf-8cf9-7621d896396b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058306806-172.17.0.10-1599303777703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-e42bc769-651e-49bb-b7bd-5e9742555f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-7a871b55-c7fb-4e81-a0a3-cfe08eeccf99,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-74aa6bf9-5912-4335-afcc-172bae2da309,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-15e22e9c-2a3f-48cd-8c98-22824d3fc883,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-61689fd5-6b14-4fc7-85e9-fb6266749056,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a048f9de-d886-4669-94fd-5c2c75160d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-18e5e810-58e4-44fe-a027-da1aeef7903e,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-9231e201-e2c7-46cf-8cf9-7621d896396b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945216594-172.17.0.10-1599304025799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-a4fd73a6-5021-4052-85bb-bfd97a004dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-611d7df1-cfab-4346-8aa9-fda0f9cec749,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-bf5d26ed-ed35-44bb-aa42-d5fd4c62cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-a4408ac9-5a5e-41ca-b941-263f1bd816d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-3b51193b-5238-4dcd-9e6c-6e78091c4533,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-9e3aeb1d-023c-4067-b8d7-90a650a5a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-9a9d0a24-49f2-4d68-b239-b8cdbf4d1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-135225e2-b13f-4d5b-8258-fec3506f48e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945216594-172.17.0.10-1599304025799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-a4fd73a6-5021-4052-85bb-bfd97a004dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-611d7df1-cfab-4346-8aa9-fda0f9cec749,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-bf5d26ed-ed35-44bb-aa42-d5fd4c62cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-a4408ac9-5a5e-41ca-b941-263f1bd816d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-3b51193b-5238-4dcd-9e6c-6e78091c4533,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-9e3aeb1d-023c-4067-b8d7-90a650a5a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-9a9d0a24-49f2-4d68-b239-b8cdbf4d1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-135225e2-b13f-4d5b-8258-fec3506f48e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253525204-172.17.0.10-1599304135843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-f010f9ae-f7b5-401a-8731-751ff5cc7b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-93365dd9-78e0-4b82-b8a9-6a20db6a2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-acb601a5-e969-4730-9212-bdedb58ab714,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-aadc8128-5e2a-4a1f-b257-4b814f415892,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-076a0cd5-5366-46e4-bc49-06db1f330f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d771ba09-e1d8-47e7-9767-28d9d6cb65db,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-73c28c42-685e-4a62-b0b4-f9e0ad391c33,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-ff05a76f-935f-4787-88d6-cae2ae76288e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253525204-172.17.0.10-1599304135843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-f010f9ae-f7b5-401a-8731-751ff5cc7b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-93365dd9-78e0-4b82-b8a9-6a20db6a2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-acb601a5-e969-4730-9212-bdedb58ab714,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-aadc8128-5e2a-4a1f-b257-4b814f415892,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-076a0cd5-5366-46e4-bc49-06db1f330f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d771ba09-e1d8-47e7-9767-28d9d6cb65db,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-73c28c42-685e-4a62-b0b4-f9e0ad391c33,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-ff05a76f-935f-4787-88d6-cae2ae76288e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589497176-172.17.0.10-1599304176308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-27acbd33-acd5-48b2-abbe-3595fe2bf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-285c7534-8550-4e39-9616-0ef358e0faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-48e9a664-7360-4792-8c4f-e8157c949033,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-72e87b8e-873d-476c-bb78-38c9e35cd095,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-f1663b74-2dae-4a98-b9be-9d385a151e06,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-c8dd8350-e77d-4fc6-9a98-fbefaae17d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-3a0d1c2d-fc48-4167-81f6-fed408a26838,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-ff081c54-4096-42da-85f1-963176ba307e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589497176-172.17.0.10-1599304176308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36699,DS-27acbd33-acd5-48b2-abbe-3595fe2bf8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-285c7534-8550-4e39-9616-0ef358e0faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-48e9a664-7360-4792-8c4f-e8157c949033,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-72e87b8e-873d-476c-bb78-38c9e35cd095,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-f1663b74-2dae-4a98-b9be-9d385a151e06,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-c8dd8350-e77d-4fc6-9a98-fbefaae17d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-3a0d1c2d-fc48-4167-81f6-fed408a26838,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-ff081c54-4096-42da-85f1-963176ba307e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460406942-172.17.0.10-1599304316436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-360129a1-20ac-4140-a59f-2ddc21f1dff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-103c7fe9-d572-4acb-b5ec-2b1f454640aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-1a67c663-9114-429d-a477-319ce62eb976,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-80bd419d-21c2-4442-9619-1f18eb53c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-39c8f056-22e6-4404-bd62-378f69184972,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-8504cb82-7b3d-428a-bf81-31a5081fa8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-ca69fe0f-5ae2-4732-958e-b7be35900d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-5fc54844-24ef-4079-808c-fdcc3fa0afc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460406942-172.17.0.10-1599304316436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-360129a1-20ac-4140-a59f-2ddc21f1dff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-103c7fe9-d572-4acb-b5ec-2b1f454640aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-1a67c663-9114-429d-a477-319ce62eb976,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-80bd419d-21c2-4442-9619-1f18eb53c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-39c8f056-22e6-4404-bd62-378f69184972,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-8504cb82-7b3d-428a-bf81-31a5081fa8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-ca69fe0f-5ae2-4732-958e-b7be35900d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-5fc54844-24ef-4079-808c-fdcc3fa0afc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409255108-172.17.0.10-1599304623164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-cb102700-44e5-4810-8c09-e72019c026f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-eb9a1f10-7584-4c83-81c9-3783e4f272ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b4ed0698-f8f5-4c6d-addf-a706b944233c,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-98a95bd8-cb05-4849-a98b-c34390f067de,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-ea2817e6-8b70-45ae-be96-4c5ac51f1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-b1eb4177-c4b3-46b1-9d91-b8e4bf0e4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-7b08eefe-1879-46f3-abd5-5570e002a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-35fd04cd-2413-41e3-9545-b489f7180b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409255108-172.17.0.10-1599304623164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-cb102700-44e5-4810-8c09-e72019c026f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-eb9a1f10-7584-4c83-81c9-3783e4f272ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b4ed0698-f8f5-4c6d-addf-a706b944233c,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-98a95bd8-cb05-4849-a98b-c34390f067de,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-ea2817e6-8b70-45ae-be96-4c5ac51f1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-b1eb4177-c4b3-46b1-9d91-b8e4bf0e4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-7b08eefe-1879-46f3-abd5-5570e002a9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-35fd04cd-2413-41e3-9545-b489f7180b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956602404-172.17.0.10-1599304785219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-ee6b7b3e-cdef-45a3-8515-3e6ac1cf961d,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-cbcddf68-580c-4a1a-9e4f-26f656fadc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ce50d290-ce5f-4367-b7c5-19016be9d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-4b59e99c-2375-432f-ab8a-e1272e6c8274,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-b3a4b434-ea20-4e04-810b-a3b32f0d8919,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c90f838b-61d8-42c0-b1fb-59ec9cd99956,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-9b6e918d-0255-47e9-a6a8-804df19deb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-c71dd7ee-411c-4653-899e-2687cecdc46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956602404-172.17.0.10-1599304785219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-ee6b7b3e-cdef-45a3-8515-3e6ac1cf961d,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-cbcddf68-580c-4a1a-9e4f-26f656fadc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ce50d290-ce5f-4367-b7c5-19016be9d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-4b59e99c-2375-432f-ab8a-e1272e6c8274,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-b3a4b434-ea20-4e04-810b-a3b32f0d8919,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c90f838b-61d8-42c0-b1fb-59ec9cd99956,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-9b6e918d-0255-47e9-a6a8-804df19deb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-c71dd7ee-411c-4653-899e-2687cecdc46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154902417-172.17.0.10-1599304907039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-e9fecb81-ad61-44ce-bfe9-d3a96b4856ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-1e21f1c0-9a11-4857-a76a-4eed2e32eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6e55efed-2e20-45d8-a037-1081954b41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-cab248e8-1e65-48df-8d9a-8296f92f18e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-794d5ddf-ad7f-4a7a-992f-b50ac2e75165,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-02ea7a6d-62f5-4e0e-973c-e1beb2fc1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-8a0c8b87-b188-4b57-8a01-b382da7c14e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-7cee5480-565a-4afd-a204-80f956888d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154902417-172.17.0.10-1599304907039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-e9fecb81-ad61-44ce-bfe9-d3a96b4856ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-1e21f1c0-9a11-4857-a76a-4eed2e32eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-6e55efed-2e20-45d8-a037-1081954b41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-cab248e8-1e65-48df-8d9a-8296f92f18e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-794d5ddf-ad7f-4a7a-992f-b50ac2e75165,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-02ea7a6d-62f5-4e0e-973c-e1beb2fc1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-8a0c8b87-b188-4b57-8a01-b382da7c14e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-7cee5480-565a-4afd-a204-80f956888d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974226065-172.17.0.10-1599305107907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36710,DS-73dd673f-99a0-46d2-97f9-24fe268a1696,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-1a1867fd-1323-46bf-83a7-7151dfa33d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-1fede422-ad85-451d-a972-ce6acc77f263,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ef8f4ab0-e3de-49c0-9d84-d2e3d99b4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-4f34de3a-674d-44d5-9193-5544770e6cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4d46c495-1347-4e8a-8459-5b5d2eb2d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-f3832676-2442-4987-90ec-a5fc98b2c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-2ff301e9-f1e3-4dc5-bda3-7d3e213fb439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-974226065-172.17.0.10-1599305107907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36710,DS-73dd673f-99a0-46d2-97f9-24fe268a1696,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-1a1867fd-1323-46bf-83a7-7151dfa33d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-1fede422-ad85-451d-a972-ce6acc77f263,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ef8f4ab0-e3de-49c0-9d84-d2e3d99b4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-4f34de3a-674d-44d5-9193-5544770e6cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4d46c495-1347-4e8a-8459-5b5d2eb2d22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-f3832676-2442-4987-90ec-a5fc98b2c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-2ff301e9-f1e3-4dc5-bda3-7d3e213fb439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556846681-172.17.0.10-1599305456906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-a12a2d97-4768-4e7d-b0b5-d1b24c27f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9c2f7819-7b64-4b5e-afab-fcb8cb1c1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b9aae284-9406-4c23-9449-89c2540709da,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-ff4deedf-6bbe-4a3d-b078-8682ba169398,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b53dc01f-296c-4b72-b45e-542228e8522a,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7200f24d-41be-4f27-88b9-d158e1ff526f,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-bdfde2bb-f180-406c-a576-0cde3a91b723,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-5e51b374-633d-40d7-8dc8-ff37456f47bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556846681-172.17.0.10-1599305456906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32843,DS-a12a2d97-4768-4e7d-b0b5-d1b24c27f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9c2f7819-7b64-4b5e-afab-fcb8cb1c1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b9aae284-9406-4c23-9449-89c2540709da,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-ff4deedf-6bbe-4a3d-b078-8682ba169398,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b53dc01f-296c-4b72-b45e-542228e8522a,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7200f24d-41be-4f27-88b9-d158e1ff526f,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-bdfde2bb-f180-406c-a576-0cde3a91b723,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-5e51b374-633d-40d7-8dc8-ff37456f47bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81763729-172.17.0.10-1599305535195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-7ee7d311-b5d4-44f3-be66-66c3f208cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-7f0195e2-53e7-4999-912e-5bf1a4202e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-722c3a4e-d92b-487c-bd24-4bb657254401,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-dcf7bde9-c848-44df-85e9-98e071ea45b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-31e0f5fd-f4cf-44be-bc28-b0c141119dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-74b55ef8-bcdd-4119-ac00-b887733d80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-a6d4c8c5-e5ae-4468-b5d6-a58278fdac03,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-a171bf92-0053-489a-b593-ce4831bb69b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81763729-172.17.0.10-1599305535195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-7ee7d311-b5d4-44f3-be66-66c3f208cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-7f0195e2-53e7-4999-912e-5bf1a4202e98,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-722c3a4e-d92b-487c-bd24-4bb657254401,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-dcf7bde9-c848-44df-85e9-98e071ea45b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-31e0f5fd-f4cf-44be-bc28-b0c141119dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-74b55ef8-bcdd-4119-ac00-b887733d80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-a6d4c8c5-e5ae-4468-b5d6-a58278fdac03,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-a171bf92-0053-489a-b593-ce4831bb69b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425351859-172.17.0.10-1599306191919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-55d17750-90ea-4b4e-9261-7786eab022b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-25584d0f-4eaa-411c-b3a1-66a48540001a,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8ef59237-be82-43c7-be2e-529564b0f142,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-d13aa8c1-0474-4647-893d-04a2f08ca1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-9729ef7b-301b-4f9a-8476-02518efc8981,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-07ef0335-a7c7-41b9-87da-344b5c9fefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-418c901f-c893-4943-8eef-17db9d6e9415,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-a8f57b6c-d1d2-49a1-b22e-21c198c253f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425351859-172.17.0.10-1599306191919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-55d17750-90ea-4b4e-9261-7786eab022b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-25584d0f-4eaa-411c-b3a1-66a48540001a,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8ef59237-be82-43c7-be2e-529564b0f142,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-d13aa8c1-0474-4647-893d-04a2f08ca1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-9729ef7b-301b-4f9a-8476-02518efc8981,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-07ef0335-a7c7-41b9-87da-344b5c9fefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-418c901f-c893-4943-8eef-17db9d6e9415,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-a8f57b6c-d1d2-49a1-b22e-21c198c253f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810401859-172.17.0.10-1599306385325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-c4ef9601-14e3-4d48-b9b2-a3409082581a,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d14c5894-4136-47c1-a221-e05ead96542e,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-db416202-dba6-46d8-8921-1dd2f3f810a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-a46c3031-a342-4a68-8099-d5093f5557c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-1d09618b-3955-4bcb-b563-7732f9775864,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-640e4a91-c9d0-464f-924e-fcb2e54896f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-abd97961-82ae-42f3-b8c4-224b215232e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-845214c4-196a-4d12-b228-979a9a8ce314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810401859-172.17.0.10-1599306385325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-c4ef9601-14e3-4d48-b9b2-a3409082581a,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d14c5894-4136-47c1-a221-e05ead96542e,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-db416202-dba6-46d8-8921-1dd2f3f810a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-a46c3031-a342-4a68-8099-d5093f5557c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-1d09618b-3955-4bcb-b563-7732f9775864,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-640e4a91-c9d0-464f-924e-fcb2e54896f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-abd97961-82ae-42f3-b8c4-224b215232e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-845214c4-196a-4d12-b228-979a9a8ce314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031943334-172.17.0.10-1599306887761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-054ef518-536e-4590-b1ca-3310bbed94a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-7eef0ef8-0a23-4d81-a67c-c00c4f0f5380,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-32b0278e-0e37-42a6-9abf-6d1a5e45262b,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-22b81aab-f496-4600-a7ac-d1edcbac1b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-a66ffbe7-2437-440d-9449-dd4a8e6a8fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-5dd13a2c-6211-4e8f-87f9-896a884de796,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-c0e66ed2-df7f-4ea3-9df4-d24d40acd427,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-5f60ae03-95ba-4248-bbe6-bda5fb962ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031943334-172.17.0.10-1599306887761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-054ef518-536e-4590-b1ca-3310bbed94a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-7eef0ef8-0a23-4d81-a67c-c00c4f0f5380,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-32b0278e-0e37-42a6-9abf-6d1a5e45262b,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-22b81aab-f496-4600-a7ac-d1edcbac1b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-a66ffbe7-2437-440d-9449-dd4a8e6a8fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-5dd13a2c-6211-4e8f-87f9-896a884de796,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-c0e66ed2-df7f-4ea3-9df4-d24d40acd427,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-5f60ae03-95ba-4248-bbe6-bda5fb962ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598716325-172.17.0.10-1599307009934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-0251cbaf-134d-4b6f-a144-d7f8d02a493e,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-443ef8af-4f3d-4283-9b9d-d1f3e6da05cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-370a85d8-4674-45c0-ab1d-11d0ee4aa7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-79b48912-fdbe-43fb-a256-ab5217703756,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-e6e7a9d8-aee6-4ee4-bcc5-10d2a8c5ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-f6c21777-f558-457f-9dd6-c531cb25c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-2ef26c12-8d13-4f3c-b24c-9db8a0c8da02,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-22725fb4-41d1-4b54-83a7-03c1b479adc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598716325-172.17.0.10-1599307009934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-0251cbaf-134d-4b6f-a144-d7f8d02a493e,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-443ef8af-4f3d-4283-9b9d-d1f3e6da05cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-370a85d8-4674-45c0-ab1d-11d0ee4aa7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-79b48912-fdbe-43fb-a256-ab5217703756,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-e6e7a9d8-aee6-4ee4-bcc5-10d2a8c5ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-f6c21777-f558-457f-9dd6-c531cb25c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-2ef26c12-8d13-4f3c-b24c-9db8a0c8da02,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-22725fb4-41d1-4b54-83a7-03c1b479adc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5759
