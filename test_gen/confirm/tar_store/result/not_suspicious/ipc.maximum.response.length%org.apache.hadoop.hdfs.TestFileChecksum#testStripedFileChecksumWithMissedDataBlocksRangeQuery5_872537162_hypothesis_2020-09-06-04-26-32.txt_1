reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027844392-172.17.0.5-1599366511462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-6140a5f2-1299-42ce-a76f-d6c29fc307d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-7e063b04-2b6c-4aac-9328-b9b2566e7f21,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-3c535627-c36b-49f9-9aea-83c36eb96ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-8922a66f-77ec-4ee9-bbbc-5b69a28a8c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-ba6b5db9-da78-48aa-9e23-7592927db577,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-62b58f88-5970-4c6c-8f93-6e595a0d2724,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-9a148ca2-ffc3-4ef0-b100-d54e3d4d3485,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-be5a1c74-ee96-45a9-9a22-d4172dc0e17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027844392-172.17.0.5-1599366511462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-6140a5f2-1299-42ce-a76f-d6c29fc307d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-7e063b04-2b6c-4aac-9328-b9b2566e7f21,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-3c535627-c36b-49f9-9aea-83c36eb96ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-8922a66f-77ec-4ee9-bbbc-5b69a28a8c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-ba6b5db9-da78-48aa-9e23-7592927db577,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-62b58f88-5970-4c6c-8f93-6e595a0d2724,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-9a148ca2-ffc3-4ef0-b100-d54e3d4d3485,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-be5a1c74-ee96-45a9-9a22-d4172dc0e17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65915397-172.17.0.5-1599366975191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-06204030-fd6f-4f11-b4f8-6ec3d5f8b515,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-6ca5945d-2f5d-4e4a-912c-a49091770521,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4bcec3bf-874f-482d-874e-d195db47ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-1273aab7-b3ec-4bf4-9b4a-235b186c77f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-2ff02911-44eb-4d7d-84c3-29deff4f004a,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-e09b83ac-9317-4e60-a3b1-5c9ba3288d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-2aa66fd2-5f47-4ca2-a4c4-694962cebe39,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-99460f80-764f-4f18-a1a7-2fa40a6d7930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65915397-172.17.0.5-1599366975191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-06204030-fd6f-4f11-b4f8-6ec3d5f8b515,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-6ca5945d-2f5d-4e4a-912c-a49091770521,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4bcec3bf-874f-482d-874e-d195db47ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-1273aab7-b3ec-4bf4-9b4a-235b186c77f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-2ff02911-44eb-4d7d-84c3-29deff4f004a,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-e09b83ac-9317-4e60-a3b1-5c9ba3288d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-2aa66fd2-5f47-4ca2-a4c4-694962cebe39,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-99460f80-764f-4f18-a1a7-2fa40a6d7930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275760243-172.17.0.5-1599367378420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-58b86f98-9445-4bbb-b244-991db3b01eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-0cd9cb2b-e919-4f88-b480-7ae899f09763,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-108e1942-b12e-48b5-a788-e0b43c91c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-ac9383d2-0f6f-4430-98ee-cf7c25cf9eec,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-3f7b59a4-658f-43a8-9ae5-30ee355d36f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-f0cd55bd-2134-47b7-86c9-5800b66dec7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-f449bb84-0e0d-45f9-b648-f237fc522a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-399556e7-717b-44cb-8897-291677b33a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275760243-172.17.0.5-1599367378420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-58b86f98-9445-4bbb-b244-991db3b01eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-0cd9cb2b-e919-4f88-b480-7ae899f09763,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-108e1942-b12e-48b5-a788-e0b43c91c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-ac9383d2-0f6f-4430-98ee-cf7c25cf9eec,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-3f7b59a4-658f-43a8-9ae5-30ee355d36f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-f0cd55bd-2134-47b7-86c9-5800b66dec7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-f449bb84-0e0d-45f9-b648-f237fc522a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-399556e7-717b-44cb-8897-291677b33a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899729244-172.17.0.5-1599367404361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-2b1396de-c18f-4dbd-b366-3de4228c4f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-eb348ef2-2215-4fd9-bfe8-9c5f65bd32a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-b382473f-0e75-4114-b842-c5e9d5c3786d,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-dd425ccb-313f-4cb6-89c4-5b4880a4befe,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-a3282b38-1dbb-4e31-88ae-f2d4539b678a,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-24763ed5-a3cf-4a15-8100-3b682f8369e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-efebe232-93dd-4bea-a5f9-1282964a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f36bed87-ea9a-4182-9cdc-fd9195416ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899729244-172.17.0.5-1599367404361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-2b1396de-c18f-4dbd-b366-3de4228c4f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-eb348ef2-2215-4fd9-bfe8-9c5f65bd32a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-b382473f-0e75-4114-b842-c5e9d5c3786d,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-dd425ccb-313f-4cb6-89c4-5b4880a4befe,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-a3282b38-1dbb-4e31-88ae-f2d4539b678a,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-24763ed5-a3cf-4a15-8100-3b682f8369e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-efebe232-93dd-4bea-a5f9-1282964a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f36bed87-ea9a-4182-9cdc-fd9195416ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548081417-172.17.0.5-1599367598212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-864a3820-f212-439e-83dc-c83dd06797b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e703b595-4c9d-4d69-aa88-690b3d7ce7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-5464872b-0910-4b3b-a89d-996c208c77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-32031dcd-7d0b-4c24-a319-aa05b0988995,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-ed9d66a2-3eaf-4f21-b3a4-bb1273b0ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-9d38850a-b6c5-4049-9d52-4bddf6c5db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-6fcb530d-c8fd-41ec-8f04-793361f1202c,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-a0ba2d6d-9cce-45ca-8a03-0fa797e25338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548081417-172.17.0.5-1599367598212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-864a3820-f212-439e-83dc-c83dd06797b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e703b595-4c9d-4d69-aa88-690b3d7ce7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-5464872b-0910-4b3b-a89d-996c208c77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-32031dcd-7d0b-4c24-a319-aa05b0988995,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-ed9d66a2-3eaf-4f21-b3a4-bb1273b0ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-9d38850a-b6c5-4049-9d52-4bddf6c5db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-6fcb530d-c8fd-41ec-8f04-793361f1202c,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-a0ba2d6d-9cce-45ca-8a03-0fa797e25338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085506185-172.17.0.5-1599367628376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-6dd14bf5-8fd7-4e3f-bb1e-4281a6e4e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4e32bac9-a844-4da7-af8d-5974897c9aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-fcd26ba4-acc5-46d5-9f6a-2114b486be71,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-7eba0090-c499-46b9-b2a0-10ff1c2b29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-8a36b2c7-1eeb-4be2-a4f8-ae27b751a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-cfc4625a-15dc-4e26-9973-297ee4c805a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-ee772a69-4202-4060-ab11-92ccbd9ef755,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-3192194c-f303-4670-8608-437f8e6b6683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085506185-172.17.0.5-1599367628376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-6dd14bf5-8fd7-4e3f-bb1e-4281a6e4e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-4e32bac9-a844-4da7-af8d-5974897c9aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-fcd26ba4-acc5-46d5-9f6a-2114b486be71,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-7eba0090-c499-46b9-b2a0-10ff1c2b29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-8a36b2c7-1eeb-4be2-a4f8-ae27b751a50b,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-cfc4625a-15dc-4e26-9973-297ee4c805a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-ee772a69-4202-4060-ab11-92ccbd9ef755,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-3192194c-f303-4670-8608-437f8e6b6683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206968630-172.17.0.5-1599367826597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-307ab333-60dd-450e-91cc-ce8971015ced,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-d68a55f7-2e1e-4a8a-8d0e-fc6875ac9cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-01b5d517-e1a9-4a46-ba13-250712ffbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-19f8f9f2-bb6a-4256-be29-120e52197a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-5543c982-b1ee-4f84-8679-9f7eb4f423dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2d876714-f25e-4375-8698-b292e9a6cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-50748da1-3b75-4195-8f41-790408981e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-0fe83dea-cc1a-4736-88bc-e3fc764f4d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206968630-172.17.0.5-1599367826597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-307ab333-60dd-450e-91cc-ce8971015ced,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-d68a55f7-2e1e-4a8a-8d0e-fc6875ac9cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-01b5d517-e1a9-4a46-ba13-250712ffbbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-19f8f9f2-bb6a-4256-be29-120e52197a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-5543c982-b1ee-4f84-8679-9f7eb4f423dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2d876714-f25e-4375-8698-b292e9a6cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-50748da1-3b75-4195-8f41-790408981e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-0fe83dea-cc1a-4736-88bc-e3fc764f4d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774762233-172.17.0.5-1599367920194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-062dd6ed-c644-42e5-b076-188c55d68484,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-0c01411c-e665-4930-808f-0ea1cf97b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-9a028038-d965-4986-b471-418571f690a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-0d057667-7ca2-41f7-9515-b61d9ebdc6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-12a26c65-8dff-4e31-826b-003d28785a14,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-7313f0bd-83e6-472c-8384-a2eb7fe93667,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b0376003-8a59-479e-9f3e-7fbc23765438,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-2ec4db29-7382-48ff-abd2-1b7fd685f121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774762233-172.17.0.5-1599367920194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-062dd6ed-c644-42e5-b076-188c55d68484,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-0c01411c-e665-4930-808f-0ea1cf97b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-9a028038-d965-4986-b471-418571f690a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-0d057667-7ca2-41f7-9515-b61d9ebdc6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-12a26c65-8dff-4e31-826b-003d28785a14,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-7313f0bd-83e6-472c-8384-a2eb7fe93667,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b0376003-8a59-479e-9f3e-7fbc23765438,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-2ec4db29-7382-48ff-abd2-1b7fd685f121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767425682-172.17.0.5-1599368205233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-288dd171-7532-42ea-8933-bd7f4e2c0241,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-28c92184-51d0-41d2-9cba-26d38f9af20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-92fc16d1-264d-4e7e-b39a-192f956fe236,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-aef416a7-8138-4b6d-bda9-9504d2148f02,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0985cef9-60e7-4d71-bc6c-22e853f9d073,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-df9e262c-cdf6-42a5-94ed-08e4844585e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-cb78c4dd-0556-42ca-8bd3-41d118c5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-717df28e-7cf1-4dfa-9b7e-24661515841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767425682-172.17.0.5-1599368205233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-288dd171-7532-42ea-8933-bd7f4e2c0241,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-28c92184-51d0-41d2-9cba-26d38f9af20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-92fc16d1-264d-4e7e-b39a-192f956fe236,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-aef416a7-8138-4b6d-bda9-9504d2148f02,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0985cef9-60e7-4d71-bc6c-22e853f9d073,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-df9e262c-cdf6-42a5-94ed-08e4844585e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-cb78c4dd-0556-42ca-8bd3-41d118c5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-717df28e-7cf1-4dfa-9b7e-24661515841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395985428-172.17.0.5-1599368346814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-ec029213-a1bd-4fee-98fc-f692bda381ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-19c569fc-b9df-40ce-898b-a773ec2c4b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-3ed5e95a-6eb7-4f2f-88e3-0b565cab78bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f409c061-ae7d-4724-b24c-d6bc1b336212,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-44bc42d8-fdd9-40ac-b0c2-2bca914d1008,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-f39c70a7-014d-4424-8a99-6f473cd6711e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-2b654649-806f-4bc2-8573-1b8e795ad993,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-5da3a28b-1629-4154-9645-7ba034587f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395985428-172.17.0.5-1599368346814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-ec029213-a1bd-4fee-98fc-f692bda381ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-19c569fc-b9df-40ce-898b-a773ec2c4b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-3ed5e95a-6eb7-4f2f-88e3-0b565cab78bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f409c061-ae7d-4724-b24c-d6bc1b336212,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-44bc42d8-fdd9-40ac-b0c2-2bca914d1008,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-f39c70a7-014d-4424-8a99-6f473cd6711e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-2b654649-806f-4bc2-8573-1b8e795ad993,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-5da3a28b-1629-4154-9645-7ba034587f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407231108-172.17.0.5-1599368581184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-ed74c223-a165-4685-8000-6cc7e5ddd352,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-a0d8b2a7-65e3-4c00-8611-2aa5c339f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-cb4d3ece-f498-421d-abd5-a343df3e0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d2456c8b-7829-4149-aab2-ea4bdfa42e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-3d4d8210-0150-4993-8c26-18a580efc8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-8079a900-3a20-4954-b4ce-e2a48ad8d350,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-b8bf196b-8d64-42fc-99e4-b741cf724cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-9568dbc2-8ed9-4519-b17e-2f991b226e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407231108-172.17.0.5-1599368581184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-ed74c223-a165-4685-8000-6cc7e5ddd352,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-a0d8b2a7-65e3-4c00-8611-2aa5c339f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-cb4d3ece-f498-421d-abd5-a343df3e0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d2456c8b-7829-4149-aab2-ea4bdfa42e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-3d4d8210-0150-4993-8c26-18a580efc8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-8079a900-3a20-4954-b4ce-e2a48ad8d350,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-b8bf196b-8d64-42fc-99e4-b741cf724cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-9568dbc2-8ed9-4519-b17e-2f991b226e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575663091-172.17.0.5-1599368703021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-7a9c50f8-83a8-4fd6-bd22-0c365c500df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-22548e17-e023-45a9-84a7-d83cdfc4c277,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-93c75b2b-0401-4f57-8c25-4ce87067e499,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d3f9ad64-ef39-4021-8c03-80a634341274,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-0e40604c-7918-4b38-af3b-d1e8bcc18ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-0915977a-ca5e-418f-aca1-655964f396e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d4e892bd-b471-443f-864d-bcae62c4b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-e8deab1e-61b0-4ade-84a2-730cd578c591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575663091-172.17.0.5-1599368703021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-7a9c50f8-83a8-4fd6-bd22-0c365c500df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-22548e17-e023-45a9-84a7-d83cdfc4c277,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-93c75b2b-0401-4f57-8c25-4ce87067e499,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d3f9ad64-ef39-4021-8c03-80a634341274,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-0e40604c-7918-4b38-af3b-d1e8bcc18ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-0915977a-ca5e-418f-aca1-655964f396e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d4e892bd-b471-443f-864d-bcae62c4b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-e8deab1e-61b0-4ade-84a2-730cd578c591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171864925-172.17.0.5-1599369157923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-8e7f8dce-d82d-4f1a-bc69-79acba57d289,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-4ec82d4a-8ff3-41c3-b0ff-d13fdba7bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-fef11fb4-e226-40c7-9153-b41460e4a888,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-a338841c-70e7-4586-b71f-ca15cc9f60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a64efa72-2a95-4e3c-9e52-78f016833d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-8355f81d-f04f-4f20-a44b-84c9445054fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-9887f850-ee17-4a1b-b1ae-e784c75426a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-a87f58f7-d931-4d1c-b351-f70ea51ae18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171864925-172.17.0.5-1599369157923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-8e7f8dce-d82d-4f1a-bc69-79acba57d289,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-4ec82d4a-8ff3-41c3-b0ff-d13fdba7bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-fef11fb4-e226-40c7-9153-b41460e4a888,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-a338841c-70e7-4586-b71f-ca15cc9f60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a64efa72-2a95-4e3c-9e52-78f016833d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-8355f81d-f04f-4f20-a44b-84c9445054fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-9887f850-ee17-4a1b-b1ae-e784c75426a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-a87f58f7-d931-4d1c-b351-f70ea51ae18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119803482-172.17.0.5-1599369227556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-0cedbcd9-9bea-4e78-978a-60202d4f93f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-359047fd-7b58-49ef-9e9d-b96be2b8f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-f031636e-0b00-49d7-8c38-dba35f4f1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-01cd38af-c765-42df-a332-b26205481c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-629e65a8-7d09-40c1-898c-bcf43d66029f,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-8176940e-93cd-46e1-b2d7-f8861dc3b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-af1d7110-be1d-49c3-bf58-9a0469c689d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-8fc8e80f-26fe-4419-8ec2-98b499e70a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119803482-172.17.0.5-1599369227556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-0cedbcd9-9bea-4e78-978a-60202d4f93f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-359047fd-7b58-49ef-9e9d-b96be2b8f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-f031636e-0b00-49d7-8c38-dba35f4f1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-01cd38af-c765-42df-a332-b26205481c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-629e65a8-7d09-40c1-898c-bcf43d66029f,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-8176940e-93cd-46e1-b2d7-f8861dc3b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-af1d7110-be1d-49c3-bf58-9a0469c689d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-8fc8e80f-26fe-4419-8ec2-98b499e70a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227099283-172.17.0.5-1599369416762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-bbc3235d-cb80-4347-b7ec-9d0396a28c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-4e0717e5-ab99-48bf-b5fb-79ed89ff5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-21866f1a-d5ad-489a-b560-0fc3f40e44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-3fdcd588-71c6-4bc2-b565-4ad96d567709,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-4299026b-66c6-4917-95d7-f134ab565395,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-3c34896d-8f17-40bc-a168-16a35809fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-0e009b63-199a-4b7c-bdc9-dac3566ecac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-2637b596-6ed8-4c0f-901f-c6e77ed18bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227099283-172.17.0.5-1599369416762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-bbc3235d-cb80-4347-b7ec-9d0396a28c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-4e0717e5-ab99-48bf-b5fb-79ed89ff5a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-21866f1a-d5ad-489a-b560-0fc3f40e44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-3fdcd588-71c6-4bc2-b565-4ad96d567709,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-4299026b-66c6-4917-95d7-f134ab565395,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-3c34896d-8f17-40bc-a168-16a35809fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-0e009b63-199a-4b7c-bdc9-dac3566ecac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-2637b596-6ed8-4c0f-901f-c6e77ed18bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477038201-172.17.0.5-1599369729778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-360762ba-bb7c-4a90-9d02-3888f841b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-58c957c6-e6bf-4f7f-9b58-4462a8e304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-780e0b95-07ad-4588-9f54-f13933e1275d,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-4a26411a-f604-42c1-a2b8-e4e1f85d95e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-9276c89d-78f0-47b7-b629-18f5b0266188,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-232135fb-ccd9-4bc3-b62b-19104c504ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-a283e535-82cd-412b-97a5-160a7812ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-06f43c6c-113f-411d-8d24-4a4209a1a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477038201-172.17.0.5-1599369729778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-360762ba-bb7c-4a90-9d02-3888f841b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-58c957c6-e6bf-4f7f-9b58-4462a8e304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-780e0b95-07ad-4588-9f54-f13933e1275d,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-4a26411a-f604-42c1-a2b8-e4e1f85d95e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-9276c89d-78f0-47b7-b629-18f5b0266188,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-232135fb-ccd9-4bc3-b62b-19104c504ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-a283e535-82cd-412b-97a5-160a7812ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-06f43c6c-113f-411d-8d24-4a4209a1a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326601923-172.17.0.5-1599369967028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38505,DS-d7dedfc9-6267-42cd-aed4-bee69da1e695,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-6925f6c8-b7d1-43f2-883f-0215bae125d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-c828fae4-9877-4572-a386-992e34174bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-e284f2b7-4740-400c-8736-a7688e5f545a,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7c0a4aa8-f349-4a1e-81e1-8ac57be7c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-88c4312f-8cd6-4060-b84d-18caf7a1ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-53f0e44e-4a84-4c31-b578-d6785cb1032e,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-13c95dc2-08c6-4893-8c71-24e5ee78829a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326601923-172.17.0.5-1599369967028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38505,DS-d7dedfc9-6267-42cd-aed4-bee69da1e695,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-6925f6c8-b7d1-43f2-883f-0215bae125d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-c828fae4-9877-4572-a386-992e34174bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-e284f2b7-4740-400c-8736-a7688e5f545a,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7c0a4aa8-f349-4a1e-81e1-8ac57be7c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-88c4312f-8cd6-4060-b84d-18caf7a1ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-53f0e44e-4a84-4c31-b578-d6785cb1032e,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-13c95dc2-08c6-4893-8c71-24e5ee78829a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825288261-172.17.0.5-1599370178622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-00d8b96b-7072-404f-a67e-c0ef137fca69,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-7c32a475-d424-4747-996a-8e027f32b847,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2a9df2ff-8237-4e00-bdfb-0d41b6cf3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-acc49aa7-08ce-4bca-921e-424b0cc2d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-571a169f-a4cc-40af-97b2-9a8b42ba63df,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-08ec5c27-a067-4d20-882d-4b6fae7ec140,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-62d726dc-5ff0-4e8c-b50f-0135523fb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-870f13e4-c2f0-4060-92cb-7af6a672c6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825288261-172.17.0.5-1599370178622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43427,DS-00d8b96b-7072-404f-a67e-c0ef137fca69,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-7c32a475-d424-4747-996a-8e027f32b847,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2a9df2ff-8237-4e00-bdfb-0d41b6cf3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-acc49aa7-08ce-4bca-921e-424b0cc2d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-571a169f-a4cc-40af-97b2-9a8b42ba63df,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-08ec5c27-a067-4d20-882d-4b6fae7ec140,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-62d726dc-5ff0-4e8c-b50f-0135523fb8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-870f13e4-c2f0-4060-92cb-7af6a672c6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004487173-172.17.0.5-1599370464027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-cf6bb9be-55cf-42af-9432-b8dc1187500b,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-027bfaa8-a800-485a-a2f1-2e14e1b56c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-17b71b91-bb16-4cfa-8e2c-2f70c4299a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-4ed5a1cf-434b-4f9f-a16d-bd70ffe25810,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-3af0457f-690a-4f75-858e-ca026d5f5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-06b5fd95-2336-4113-95b4-e261598b06aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-d8546c6d-9061-4cc1-88f2-1fbf82cff63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-3decb7fb-0dc6-40b9-96bf-429fb94b7b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004487173-172.17.0.5-1599370464027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-cf6bb9be-55cf-42af-9432-b8dc1187500b,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-027bfaa8-a800-485a-a2f1-2e14e1b56c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-17b71b91-bb16-4cfa-8e2c-2f70c4299a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-4ed5a1cf-434b-4f9f-a16d-bd70ffe25810,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-3af0457f-690a-4f75-858e-ca026d5f5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-06b5fd95-2336-4113-95b4-e261598b06aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-d8546c6d-9061-4cc1-88f2-1fbf82cff63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-3decb7fb-0dc6-40b9-96bf-429fb94b7b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819278882-172.17.0.5-1599370519354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-b013a8e4-38b4-4de2-9a09-b3ed51519183,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-a6ffda2b-e63c-4750-b090-bd651409371f,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ba780b3f-3d5c-4d0a-a264-8639bbc9a5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-d9ab1451-9f20-42ea-97d3-716493bce106,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-d7acaaea-d74a-48a0-8ecb-dd48bee9dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-5881e18b-3aee-4574-bbaa-f104025b9824,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-35704830-069a-4ded-a95d-926de0bc5860,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c26a6230-7aab-4b67-9427-9ea303774626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819278882-172.17.0.5-1599370519354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-b013a8e4-38b4-4de2-9a09-b3ed51519183,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-a6ffda2b-e63c-4750-b090-bd651409371f,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ba780b3f-3d5c-4d0a-a264-8639bbc9a5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-d9ab1451-9f20-42ea-97d3-716493bce106,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-d7acaaea-d74a-48a0-8ecb-dd48bee9dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-5881e18b-3aee-4574-bbaa-f104025b9824,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-35704830-069a-4ded-a95d-926de0bc5860,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-c26a6230-7aab-4b67-9427-9ea303774626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670734747-172.17.0.5-1599370643887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46593,DS-393830ca-1252-491f-86da-05ae0ad47f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-a9e4666b-15da-4a5c-99e5-2da8faf56c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-60f22be5-a5e5-4e20-84c3-ef6cb4dc35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-ed02e711-adf4-42b4-9c4f-a73d62eed310,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-65d34345-9611-4a03-91bc-301cf8c3c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-8e4f27d9-2e49-40a6-b052-85f41f07affa,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-3e6fa8e5-011c-40a0-87b7-22a63c134164,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-dbbc61a3-f551-4c2e-bef5-cf15ca1d5db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670734747-172.17.0.5-1599370643887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46593,DS-393830ca-1252-491f-86da-05ae0ad47f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-a9e4666b-15da-4a5c-99e5-2da8faf56c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-60f22be5-a5e5-4e20-84c3-ef6cb4dc35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-ed02e711-adf4-42b4-9c4f-a73d62eed310,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-65d34345-9611-4a03-91bc-301cf8c3c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-8e4f27d9-2e49-40a6-b052-85f41f07affa,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-3e6fa8e5-011c-40a0-87b7-22a63c134164,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-dbbc61a3-f551-4c2e-bef5-cf15ca1d5db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 32768
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472442015-172.17.0.5-1599370698624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45650,DS-1247a467-dbc7-4224-9017-5465b70eb2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-5ba39ea9-443f-404d-892b-560febc50fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-20b84004-239e-4e99-98d1-1de1c97916b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-c5e0fcd5-940a-4688-a935-97a2b4655805,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-26fd4ee7-aef8-4f20-82be-4a016afe5537,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-aa45b47c-ea50-45f7-a015-ba7269c85cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-87827960-ba73-4699-874a-a6e72cd3801d,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-c51fce6b-e32c-4149-8d05-1fc2558b9b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472442015-172.17.0.5-1599370698624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45650,DS-1247a467-dbc7-4224-9017-5465b70eb2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-5ba39ea9-443f-404d-892b-560febc50fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-20b84004-239e-4e99-98d1-1de1c97916b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-c5e0fcd5-940a-4688-a935-97a2b4655805,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-26fd4ee7-aef8-4f20-82be-4a016afe5537,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-aa45b47c-ea50-45f7-a015-ba7269c85cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-87827960-ba73-4699-874a-a6e72cd3801d,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-c51fce6b-e32c-4149-8d05-1fc2558b9b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4382
