reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307777644-172.17.0.4-1599366798387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-79f13bc9-c058-476c-bae7-4ce7a34040fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-0cdfc495-5b64-4199-b4ae-f7df32dc02da,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-8f4ff309-2b5b-4ea7-a1f1-6b47775bc626,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-d79ab296-df09-4420-b859-bf766c75b082,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fc55fc3f-14ce-4a26-a1fc-9d7a3a625ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-0854496b-89e0-4575-a135-f31edf8e5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-4542e25e-66d5-4093-aa2e-a5b7cef4b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-40b2debe-fb67-4a79-a2f1-f5af842d2b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307777644-172.17.0.4-1599366798387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43087,DS-79f13bc9-c058-476c-bae7-4ce7a34040fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-0cdfc495-5b64-4199-b4ae-f7df32dc02da,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-8f4ff309-2b5b-4ea7-a1f1-6b47775bc626,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-d79ab296-df09-4420-b859-bf766c75b082,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fc55fc3f-14ce-4a26-a1fc-9d7a3a625ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-0854496b-89e0-4575-a135-f31edf8e5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-4542e25e-66d5-4093-aa2e-a5b7cef4b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-40b2debe-fb67-4a79-a2f1-f5af842d2b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862980542-172.17.0.4-1599366833129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43580,DS-f547b27f-bb4e-4f5c-b9ca-b25002257e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-0fe6fd49-dcec-4ba5-b8d6-17d1240507bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-824cad73-2010-47e4-871e-d37284f0f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-2b2d17e8-2398-4503-92d1-561323306ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-f7d277ae-f657-4222-b57f-a65a24f539ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-99e28ee7-e34f-4f74-8b9d-c500fa17e99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c949453c-86a1-4fc5-92ea-ac3e74902b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-170d2a5c-4e05-46d5-9cca-73c85aeaec48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862980542-172.17.0.4-1599366833129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43580,DS-f547b27f-bb4e-4f5c-b9ca-b25002257e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-0fe6fd49-dcec-4ba5-b8d6-17d1240507bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-824cad73-2010-47e4-871e-d37284f0f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-2b2d17e8-2398-4503-92d1-561323306ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-f7d277ae-f657-4222-b57f-a65a24f539ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-99e28ee7-e34f-4f74-8b9d-c500fa17e99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c949453c-86a1-4fc5-92ea-ac3e74902b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-170d2a5c-4e05-46d5-9cca-73c85aeaec48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022680847-172.17.0.4-1599366946113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-db5b5f73-b9e0-464d-a2a4-f03e466e6f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-90dc34a3-62c4-488d-afd0-0d2c78db4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-54c0fec4-88a6-468e-92cf-074639839ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-40eea3a7-221e-4907-bced-213ac5721a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d1d7f8b1-52ea-4937-9186-d281a366481d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-cdf05069-1e6f-4e46-8888-f36c070218dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-8e9e953b-03ec-4c80-8631-31126698b969,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6c845bef-692c-4739-ac9e-8b2edffd0b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022680847-172.17.0.4-1599366946113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-db5b5f73-b9e0-464d-a2a4-f03e466e6f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-90dc34a3-62c4-488d-afd0-0d2c78db4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-54c0fec4-88a6-468e-92cf-074639839ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-40eea3a7-221e-4907-bced-213ac5721a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d1d7f8b1-52ea-4937-9186-d281a366481d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-cdf05069-1e6f-4e46-8888-f36c070218dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-8e9e953b-03ec-4c80-8631-31126698b969,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6c845bef-692c-4739-ac9e-8b2edffd0b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947886873-172.17.0.4-1599367043777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-d94b1450-6111-4bdf-a77c-8a23614f0215,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-38d45dd7-8458-435b-9053-61fdde16533f,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-a935fa08-4f0e-4b91-b8bf-9b2da24f84a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7ef60556-5af2-4c2e-9fb1-d60447caf86a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-43d00cf7-61fe-478a-8c7a-f0ce0c97c588,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-04fb5dcd-1c31-49f8-bc7f-b6da50e868a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-6271756f-8a4b-4165-99d7-f1c28f6bbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-e3e14ce3-3905-4af2-a808-1c844fb58045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947886873-172.17.0.4-1599367043777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-d94b1450-6111-4bdf-a77c-8a23614f0215,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-38d45dd7-8458-435b-9053-61fdde16533f,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-a935fa08-4f0e-4b91-b8bf-9b2da24f84a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7ef60556-5af2-4c2e-9fb1-d60447caf86a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-43d00cf7-61fe-478a-8c7a-f0ce0c97c588,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-04fb5dcd-1c31-49f8-bc7f-b6da50e868a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-6271756f-8a4b-4165-99d7-f1c28f6bbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-e3e14ce3-3905-4af2-a808-1c844fb58045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344735090-172.17.0.4-1599367159610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-85ebe432-9216-4c8f-918d-aeddf27197ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-80b52761-058d-435a-98d1-abf015c38e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-7e81e930-c44d-4307-a1e7-69da3026256b,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f75659c7-d448-4266-abfe-b72f851743df,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-cdd525fb-ac29-4bb0-9ff3-887c09a8328d,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-d2cf9f9d-7be3-49ea-9a42-fa5ca4bd1ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-802a7bca-6ccb-4960-8797-f4ebd55ef521,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-3641c6ee-c9e4-4205-8963-3cf87ce89cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344735090-172.17.0.4-1599367159610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-85ebe432-9216-4c8f-918d-aeddf27197ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-80b52761-058d-435a-98d1-abf015c38e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-7e81e930-c44d-4307-a1e7-69da3026256b,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f75659c7-d448-4266-abfe-b72f851743df,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-cdd525fb-ac29-4bb0-9ff3-887c09a8328d,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-d2cf9f9d-7be3-49ea-9a42-fa5ca4bd1ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-802a7bca-6ccb-4960-8797-f4ebd55ef521,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-3641c6ee-c9e4-4205-8963-3cf87ce89cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427137645-172.17.0.4-1599367348315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-ca7d4756-526d-402c-81d6-33848d30c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-6f729b82-2e17-4313-99ff-bce00ac3de60,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-a09cb69a-590d-4bc3-a51d-d081897422ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-35c93770-7bba-43f2-bc36-e5e0e4344e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-6cc3f2fb-f9c4-428b-9282-d2cd5c6e5c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-a14f8bf6-173f-472e-ad2a-aca63a49b479,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-551c37d9-02ad-4a7f-ab05-183a67372ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-15d8f453-f265-44ad-95a1-ac1f5fc0598a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427137645-172.17.0.4-1599367348315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-ca7d4756-526d-402c-81d6-33848d30c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-6f729b82-2e17-4313-99ff-bce00ac3de60,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-a09cb69a-590d-4bc3-a51d-d081897422ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-35c93770-7bba-43f2-bc36-e5e0e4344e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-6cc3f2fb-f9c4-428b-9282-d2cd5c6e5c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-a14f8bf6-173f-472e-ad2a-aca63a49b479,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-551c37d9-02ad-4a7f-ab05-183a67372ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-15d8f453-f265-44ad-95a1-ac1f5fc0598a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863885703-172.17.0.4-1599367466290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-90899021-357f-4757-a332-3b9f75c51fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-ce52c5b7-5d08-4915-a4a2-14fe43850094,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-d899c739-128c-4e3f-9391-fde392fec611,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-1c85bd77-1d77-4b80-b8bb-5c4ac4dfbb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c491a289-1a52-49d3-921c-745746231923,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2617144d-1054-46a0-be2a-43e0f99a0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-ecdfc3da-95f1-4bdb-89ed-9f1008b6db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-cdaee0a3-c6dd-4847-b35c-69071ddf1979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863885703-172.17.0.4-1599367466290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-90899021-357f-4757-a332-3b9f75c51fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-ce52c5b7-5d08-4915-a4a2-14fe43850094,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-d899c739-128c-4e3f-9391-fde392fec611,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-1c85bd77-1d77-4b80-b8bb-5c4ac4dfbb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c491a289-1a52-49d3-921c-745746231923,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2617144d-1054-46a0-be2a-43e0f99a0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-ecdfc3da-95f1-4bdb-89ed-9f1008b6db2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-cdaee0a3-c6dd-4847-b35c-69071ddf1979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441269866-172.17.0.4-1599367625846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-4c85162c-c411-4e9f-84df-69d9d0c22f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-dbf10a2b-7bda-4dc5-bc60-d6d77928b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-27395c41-9b89-4514-bfcd-b23f0c531197,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-2900b2df-bb3c-4832-95ba-e27b42c8c026,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-ceb43b7e-498b-44bc-9949-045dc336b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-21e2abbe-8c87-413f-b1d2-cd90a6a4cf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-1504aeb9-4e66-4eb8-913c-e945182fc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-201b6da1-df40-4d66-adc5-6cb04575de17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441269866-172.17.0.4-1599367625846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-4c85162c-c411-4e9f-84df-69d9d0c22f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-dbf10a2b-7bda-4dc5-bc60-d6d77928b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-27395c41-9b89-4514-bfcd-b23f0c531197,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-2900b2df-bb3c-4832-95ba-e27b42c8c026,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-ceb43b7e-498b-44bc-9949-045dc336b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-21e2abbe-8c87-413f-b1d2-cd90a6a4cf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-1504aeb9-4e66-4eb8-913c-e945182fc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-201b6da1-df40-4d66-adc5-6cb04575de17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889151594-172.17.0.4-1599367701190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-cbe9d470-2c74-4913-8762-8c9599f15f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-b85a12db-d344-4670-9e08-6a9cb8c658ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-ee809576-4e63-4dd0-beaf-c2752bd68280,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-32ef3c2a-fd8c-4b92-9804-b2ccc902c128,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-d1b6f7b5-e29c-4014-b20f-c99096117b70,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9336c1e6-84ab-481a-9a48-9f67806e963b,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-946c7019-14b0-4ac7-b0da-a445bb353611,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-063da90f-6447-41a7-aa3c-3a1878688b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889151594-172.17.0.4-1599367701190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-cbe9d470-2c74-4913-8762-8c9599f15f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-b85a12db-d344-4670-9e08-6a9cb8c658ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-ee809576-4e63-4dd0-beaf-c2752bd68280,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-32ef3c2a-fd8c-4b92-9804-b2ccc902c128,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-d1b6f7b5-e29c-4014-b20f-c99096117b70,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9336c1e6-84ab-481a-9a48-9f67806e963b,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-946c7019-14b0-4ac7-b0da-a445bb353611,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-063da90f-6447-41a7-aa3c-3a1878688b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233989914-172.17.0.4-1599368199564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-d32d7056-17f3-4a67-ad0e-292d6058e498,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-6c88b192-2070-4a56-8746-47f5c5134a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-40039f01-d8ce-4dcc-a326-67dfd2d4f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7b16f74a-d362-4ea0-a163-3f5a136fb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-459ee280-cc3d-44c8-9660-9c3a1b81fccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-1883e7b1-027a-47c7-a795-95c9cbc19bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-71ffe4aa-14b0-4e9e-a466-13e5b2cebbda,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-f55a6910-8e6b-49d0-9453-08bc5dbf9b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233989914-172.17.0.4-1599368199564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-d32d7056-17f3-4a67-ad0e-292d6058e498,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-6c88b192-2070-4a56-8746-47f5c5134a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-40039f01-d8ce-4dcc-a326-67dfd2d4f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7b16f74a-d362-4ea0-a163-3f5a136fb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-459ee280-cc3d-44c8-9660-9c3a1b81fccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-1883e7b1-027a-47c7-a795-95c9cbc19bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-71ffe4aa-14b0-4e9e-a466-13e5b2cebbda,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-f55a6910-8e6b-49d0-9453-08bc5dbf9b86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205712673-172.17.0.4-1599368928672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-0a06bc22-2c39-4fcd-986a-780871c9de1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-d1d54e7b-b2b8-4f39-a89f-caa4bbec4572,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-78f69fad-6d20-4ab4-a19f-6ef2a5bf703f,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-1e1367bd-6d04-411e-ac16-8b7b01bf66e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-b22001d1-1afc-4213-a11f-d275326cea04,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-3b2173bc-39a0-48b6-9ed2-b193a282f815,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9aa6c445-2f67-4f7b-a41b-5015fd6d5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-4a73b13d-edc4-4395-9de6-f3c86f4b81cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205712673-172.17.0.4-1599368928672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-0a06bc22-2c39-4fcd-986a-780871c9de1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-d1d54e7b-b2b8-4f39-a89f-caa4bbec4572,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-78f69fad-6d20-4ab4-a19f-6ef2a5bf703f,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-1e1367bd-6d04-411e-ac16-8b7b01bf66e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-b22001d1-1afc-4213-a11f-d275326cea04,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-3b2173bc-39a0-48b6-9ed2-b193a282f815,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9aa6c445-2f67-4f7b-a41b-5015fd6d5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-4a73b13d-edc4-4395-9de6-f3c86f4b81cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915121479-172.17.0.4-1599369228020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6ea0be10-6cb7-4352-93ca-9b43f551dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-c3dca118-9b74-4ae1-a3f8-71d9707f4799,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-058cc446-2980-4ac6-bba3-e4e167879278,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cc0497c2-efb8-4413-82b6-e50fc0d8743b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-44664aff-c75c-4d8f-9e51-5ef9fc04dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-227309d9-64ab-4818-b93b-9778555e8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-e551f067-d5be-4a4a-a58c-b79473caf396,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-e7e24cd8-5415-4b01-9f8c-ff7c7ee0d1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915121479-172.17.0.4-1599369228020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6ea0be10-6cb7-4352-93ca-9b43f551dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-c3dca118-9b74-4ae1-a3f8-71d9707f4799,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-058cc446-2980-4ac6-bba3-e4e167879278,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-cc0497c2-efb8-4413-82b6-e50fc0d8743b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-44664aff-c75c-4d8f-9e51-5ef9fc04dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-227309d9-64ab-4818-b93b-9778555e8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-e551f067-d5be-4a4a-a58c-b79473caf396,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-e7e24cd8-5415-4b01-9f8c-ff7c7ee0d1f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672459632-172.17.0.4-1599369951622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-a5be390c-08d7-4e23-8733-ebb3d15ced0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-93f0ca11-ac62-46bb-99f5-9fd524a1bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-2576472c-7f68-4d24-a687-6a975098eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-29116d43-1dd8-429c-b41c-feddd005372b,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-50f87d17-3db0-4c8b-90f5-746db0bbe5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-fe53bb00-df8e-494b-91ae-2dba95691ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-95611415-bda2-4c98-85cb-2a9256acf201,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-6c86d890-e034-4eb4-b688-bccea265df4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672459632-172.17.0.4-1599369951622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-a5be390c-08d7-4e23-8733-ebb3d15ced0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-93f0ca11-ac62-46bb-99f5-9fd524a1bba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-2576472c-7f68-4d24-a687-6a975098eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-29116d43-1dd8-429c-b41c-feddd005372b,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-50f87d17-3db0-4c8b-90f5-746db0bbe5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-fe53bb00-df8e-494b-91ae-2dba95691ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-95611415-bda2-4c98-85cb-2a9256acf201,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-6c86d890-e034-4eb4-b688-bccea265df4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194358995-172.17.0.4-1599370631607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-b38fecbd-3be4-40d3-a818-dea73067d117,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-9e3381ba-65bd-4c37-b2ab-8a3beaf075d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-efce9066-1aa0-4f62-89d1-155eb32a4841,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-6c995a17-5f70-4421-9824-348ebc84d193,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-3fda797a-bce4-4028-9630-90a3f9605731,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-96ce09e0-28f5-4dbd-aec1-e6347429e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-5307f4a8-4cac-43cc-b938-dea96cc709d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-88bbe7be-eeed-4bf5-adbc-8b620b66374d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194358995-172.17.0.4-1599370631607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-b38fecbd-3be4-40d3-a818-dea73067d117,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-9e3381ba-65bd-4c37-b2ab-8a3beaf075d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-efce9066-1aa0-4f62-89d1-155eb32a4841,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-6c995a17-5f70-4421-9824-348ebc84d193,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-3fda797a-bce4-4028-9630-90a3f9605731,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-96ce09e0-28f5-4dbd-aec1-e6347429e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-5307f4a8-4cac-43cc-b938-dea96cc709d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-88bbe7be-eeed-4bf5-adbc-8b620b66374d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164369641-172.17.0.4-1599370689600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-9304a33b-a6aa-478d-bc5c-527f8e345752,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-8804e15d-7749-49bf-8a0d-14acf5e0bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-04350aef-8c19-4bbd-903a-fa3e762cd563,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-d5b8a73c-f0e7-4077-b18a-81509eb17e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-7e85e307-000b-4c16-8cb9-7df6cd0ac62c,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-e8749511-b462-46c5-a9d2-658386b74e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-b237e0d0-7f36-4d27-b52f-33d966f96a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-efeb2191-2a6b-49b3-be06-c1640d1f711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164369641-172.17.0.4-1599370689600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-9304a33b-a6aa-478d-bc5c-527f8e345752,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-8804e15d-7749-49bf-8a0d-14acf5e0bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-04350aef-8c19-4bbd-903a-fa3e762cd563,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-d5b8a73c-f0e7-4077-b18a-81509eb17e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-7e85e307-000b-4c16-8cb9-7df6cd0ac62c,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-e8749511-b462-46c5-a9d2-658386b74e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-b237e0d0-7f36-4d27-b52f-33d966f96a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-efeb2191-2a6b-49b3-be06-c1640d1f711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471600623-172.17.0.4-1599370937709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41190,DS-3f32ee4c-9587-44c5-8d01-e13af10d6862,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-6e5fc72b-5087-41bf-b74b-d4bd6af79179,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-43bfa3ca-d872-4be3-8148-eb5d4e8267b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-4ee92dd1-f7c7-46a6-a053-1b077041d286,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-52f00bdc-1909-4191-94e1-052ba8aaac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-838e88ab-f9d7-49b1-a1f3-c2a2f3dbff32,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-d4e9b94f-2675-4745-9a3d-a921bf6aaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-5ab00340-cc2e-4892-9f1f-ce000b9fd23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471600623-172.17.0.4-1599370937709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41190,DS-3f32ee4c-9587-44c5-8d01-e13af10d6862,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-6e5fc72b-5087-41bf-b74b-d4bd6af79179,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-43bfa3ca-d872-4be3-8148-eb5d4e8267b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-4ee92dd1-f7c7-46a6-a053-1b077041d286,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-52f00bdc-1909-4191-94e1-052ba8aaac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-838e88ab-f9d7-49b1-a1f3-c2a2f3dbff32,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-d4e9b94f-2675-4745-9a3d-a921bf6aaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-5ab00340-cc2e-4892-9f1f-ce000b9fd23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4660
