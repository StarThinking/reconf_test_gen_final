reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958251274-172.17.0.15-1599363800310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-06f7f006-666c-4d88-8540-7449a29fba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-4b6e063b-8f12-4643-92b7-c4985b01004d,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-b82598a5-5228-42b7-b07b-fb661e5e24cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-d71d77fe-5a47-449f-ad62-b0869ba569e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-06ddc73c-26fd-42f8-b8d8-be6b346e36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-9b7c1a2a-c494-4e73-bb74-24f885d076ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-9c8e749e-bb10-41fb-9b1f-db0617922794,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1808daef-7461-44f8-801c-73080d223d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958251274-172.17.0.15-1599363800310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-06f7f006-666c-4d88-8540-7449a29fba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-4b6e063b-8f12-4643-92b7-c4985b01004d,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-b82598a5-5228-42b7-b07b-fb661e5e24cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-d71d77fe-5a47-449f-ad62-b0869ba569e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-06ddc73c-26fd-42f8-b8d8-be6b346e36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-9b7c1a2a-c494-4e73-bb74-24f885d076ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-9c8e749e-bb10-41fb-9b1f-db0617922794,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1808daef-7461-44f8-801c-73080d223d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372752703-172.17.0.15-1599363904857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-9bafbea3-1908-437b-b95d-362ab39d079f,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-b051d2c0-4a33-4b47-8171-2cd6d4292ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-a534e55f-71bc-4062-beb9-ff479ba349db,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-f311325b-3c0c-4f29-912b-ec44f87317b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-8e55f437-0a0f-4fc2-97cc-eaa203fc3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-82ec5e5f-f785-4e41-881d-a67cd81c8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-fa763167-620e-4c6f-8e3a-85a400cd2bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8974cb74-11a7-4047-af07-7a383f4afcbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372752703-172.17.0.15-1599363904857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-9bafbea3-1908-437b-b95d-362ab39d079f,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-b051d2c0-4a33-4b47-8171-2cd6d4292ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-a534e55f-71bc-4062-beb9-ff479ba349db,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-f311325b-3c0c-4f29-912b-ec44f87317b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-8e55f437-0a0f-4fc2-97cc-eaa203fc3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-82ec5e5f-f785-4e41-881d-a67cd81c8daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-fa763167-620e-4c6f-8e3a-85a400cd2bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8974cb74-11a7-4047-af07-7a383f4afcbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982709390-172.17.0.15-1599364168051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-87d0184e-db6c-42cd-8a5d-fc6dc836a244,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-46f92678-3bb4-4544-88a0-5b6a41422f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-2b991b9e-12b0-4374-b28f-5c4c8cdd7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-4eb19da5-b0bf-472c-8c91-5bbe577ff26c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-10250af8-a427-4772-b0a6-a314a1f53198,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-abdf0bb8-bec5-40a2-8374-65aab55e6ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-605c9c7c-79b3-408d-92b4-d9c64e43f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b025b82d-614a-4aea-8a28-18bce9fc9963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982709390-172.17.0.15-1599364168051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-87d0184e-db6c-42cd-8a5d-fc6dc836a244,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-46f92678-3bb4-4544-88a0-5b6a41422f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-2b991b9e-12b0-4374-b28f-5c4c8cdd7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-4eb19da5-b0bf-472c-8c91-5bbe577ff26c,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-10250af8-a427-4772-b0a6-a314a1f53198,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-abdf0bb8-bec5-40a2-8374-65aab55e6ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-605c9c7c-79b3-408d-92b4-d9c64e43f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b025b82d-614a-4aea-8a28-18bce9fc9963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749872762-172.17.0.15-1599365157009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-91d0754e-9997-4140-a828-ecfc47f2069b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-69f0b9c6-d071-44f8-b081-6b0fbf73402e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-620197f2-1141-4a13-ac35-b17b9963bd56,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2d9ba9cf-f66f-4958-95b4-93b479d3545e,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-432d0766-8288-497b-8445-b936a277c614,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-d3d581f4-d18a-4994-b179-568e23ea06df,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9f272ea7-9834-430e-a402-3c1a8411e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0d384e72-fbd4-47f4-b2f7-6a912dfa8957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749872762-172.17.0.15-1599365157009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-91d0754e-9997-4140-a828-ecfc47f2069b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-69f0b9c6-d071-44f8-b081-6b0fbf73402e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-620197f2-1141-4a13-ac35-b17b9963bd56,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2d9ba9cf-f66f-4958-95b4-93b479d3545e,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-432d0766-8288-497b-8445-b936a277c614,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-d3d581f4-d18a-4994-b179-568e23ea06df,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9f272ea7-9834-430e-a402-3c1a8411e2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0d384e72-fbd4-47f4-b2f7-6a912dfa8957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931869997-172.17.0.15-1599365195362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-9172a062-ed79-495a-a339-a24477c628f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-c6d08648-8c20-4b69-9f38-dcfc04fc3873,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8819686b-b743-4bc3-8e2f-0349b8cc079d,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-ada8aae7-8dab-455a-b3d5-69f5ec41463f,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-7bba26d5-8a88-40a1-944d-8ae4b045b850,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-5fc55864-1cfd-4e12-9cf5-63b2aa4aef71,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-7b5bf89b-326d-4d43-88c6-3c795edfbc05,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-844509c5-015a-4d9d-93ad-22a9f8d2989a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931869997-172.17.0.15-1599365195362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-9172a062-ed79-495a-a339-a24477c628f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-c6d08648-8c20-4b69-9f38-dcfc04fc3873,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-8819686b-b743-4bc3-8e2f-0349b8cc079d,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-ada8aae7-8dab-455a-b3d5-69f5ec41463f,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-7bba26d5-8a88-40a1-944d-8ae4b045b850,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-5fc55864-1cfd-4e12-9cf5-63b2aa4aef71,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-7b5bf89b-326d-4d43-88c6-3c795edfbc05,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-844509c5-015a-4d9d-93ad-22a9f8d2989a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083019666-172.17.0.15-1599365804206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-345d1e94-a288-48a3-b1af-cc1e073209d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-34a0ffaf-2f71-4e50-8cd1-dcea38b8e20e,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-02b61349-d026-4725-ab16-c3d510958e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-7706efb8-c121-4d2a-9504-1975986baacf,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-1104dee2-7aba-46eb-b948-902b14ec3960,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-08ba0ea2-384b-4da5-9e6b-856dd1911616,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-b90f6ad7-74aa-490c-b707-0f834a692f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-56aae2ff-de2d-4d26-8a0e-35139d33e450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083019666-172.17.0.15-1599365804206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-345d1e94-a288-48a3-b1af-cc1e073209d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-34a0ffaf-2f71-4e50-8cd1-dcea38b8e20e,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-02b61349-d026-4725-ab16-c3d510958e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-7706efb8-c121-4d2a-9504-1975986baacf,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-1104dee2-7aba-46eb-b948-902b14ec3960,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-08ba0ea2-384b-4da5-9e6b-856dd1911616,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-b90f6ad7-74aa-490c-b707-0f834a692f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-56aae2ff-de2d-4d26-8a0e-35139d33e450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413460371-172.17.0.15-1599367002551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-ab394124-ad81-4f4d-97ab-6aef79464e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-23103c37-7d60-4331-86f7-d03d6cda2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-4666d4fe-facf-4946-a794-1ec1f153d355,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-473231b2-48eb-4bc2-a007-dd4856a6f218,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-706d296b-4695-40f0-aa67-52c7e6fd820d,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-8b06aded-b32c-49ac-b424-3e86c1a28c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-53f8bd1b-d918-4fb4-84fd-973dcc333a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-8265addd-3e5a-40a7-953d-6d86b29dd48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413460371-172.17.0.15-1599367002551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-ab394124-ad81-4f4d-97ab-6aef79464e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-23103c37-7d60-4331-86f7-d03d6cda2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-4666d4fe-facf-4946-a794-1ec1f153d355,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-473231b2-48eb-4bc2-a007-dd4856a6f218,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-706d296b-4695-40f0-aa67-52c7e6fd820d,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-8b06aded-b32c-49ac-b424-3e86c1a28c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-53f8bd1b-d918-4fb4-84fd-973dcc333a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-8265addd-3e5a-40a7-953d-6d86b29dd48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480067408-172.17.0.15-1599367578145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-def62b8a-6b9c-426b-aa65-fef68c8f13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-8137a55e-8733-402f-9f08-80b306e58cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-becf4ac1-eed8-4b55-bf5a-7906973e30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c701ec85-cc8f-4d03-984d-712098a607a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-959228ef-f50f-44df-91e5-51d2fdb81530,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-285f4aeb-3313-411e-ad37-240c95919cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-d2a2eaad-ed8f-4742-a4b1-2b2792bb0259,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6774bcb3-58d8-4805-b349-6794dac32ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480067408-172.17.0.15-1599367578145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-def62b8a-6b9c-426b-aa65-fef68c8f13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-8137a55e-8733-402f-9f08-80b306e58cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-becf4ac1-eed8-4b55-bf5a-7906973e30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c701ec85-cc8f-4d03-984d-712098a607a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-959228ef-f50f-44df-91e5-51d2fdb81530,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-285f4aeb-3313-411e-ad37-240c95919cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-d2a2eaad-ed8f-4742-a4b1-2b2792bb0259,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-6774bcb3-58d8-4805-b349-6794dac32ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279136736-172.17.0.15-1599367647363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-ae9f461f-c6ad-46e6-b024-dc3f31ed9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-8fe229b0-a8d3-413d-b1d2-2430942ca779,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-4e5c1f04-c3f2-4c52-8c3e-9064d95fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-4c63a7f8-830c-4180-873f-9e24a4eea793,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ed2ab688-1431-4c49-b0c2-23687c8860dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-85a24f28-ce09-450f-9e71-ddfa85ebadaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-e1ba0e3b-fb3a-45eb-be32-fbc04c5298d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-1dbc0e2b-569b-4994-8ff9-1afc6891eb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279136736-172.17.0.15-1599367647363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-ae9f461f-c6ad-46e6-b024-dc3f31ed9c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-8fe229b0-a8d3-413d-b1d2-2430942ca779,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-4e5c1f04-c3f2-4c52-8c3e-9064d95fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-4c63a7f8-830c-4180-873f-9e24a4eea793,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ed2ab688-1431-4c49-b0c2-23687c8860dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-85a24f28-ce09-450f-9e71-ddfa85ebadaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-e1ba0e3b-fb3a-45eb-be32-fbc04c5298d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-1dbc0e2b-569b-4994-8ff9-1afc6891eb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764422225-172.17.0.15-1599367773488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-7cc74153-fd34-46d4-8f80-3fba6446566f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-6d0f1734-94d2-48d0-aa7c-5df31ddd0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-c7dbfa00-9b41-4ccb-8393-425bb670cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-a946a067-cb33-4be4-8c4c-9ea9d603d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-99cd5fb9-dac0-45d0-b01b-07502494aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-45c74d0c-7194-4a8f-9005-732c3aa256d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-1e2b2ae3-d390-4017-8a4f-6018446c6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-dfb5fc3f-f0a9-4d3f-95a6-ea312e85d6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764422225-172.17.0.15-1599367773488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-7cc74153-fd34-46d4-8f80-3fba6446566f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-6d0f1734-94d2-48d0-aa7c-5df31ddd0e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-c7dbfa00-9b41-4ccb-8393-425bb670cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-a946a067-cb33-4be4-8c4c-9ea9d603d98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-99cd5fb9-dac0-45d0-b01b-07502494aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-45c74d0c-7194-4a8f-9005-732c3aa256d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-1e2b2ae3-d390-4017-8a4f-6018446c6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-dfb5fc3f-f0a9-4d3f-95a6-ea312e85d6fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499238594-172.17.0.15-1599368021420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46506,DS-19196457-af99-4096-ad2f-79d440ba2f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-1aeed057-7ecc-42ff-be20-077b324abce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-b4b691cd-b2b8-4782-a112-f9c84594a75f,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b6797e4e-0428-46be-964c-79a5faee87bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-d89ad40a-c078-4a6f-a480-d4809904c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a1e5b88f-177f-42ff-bbfc-59cacb221408,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-e01faed5-af65-4017-8b3d-6dd3cecd41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9c01c05e-2665-40d8-a394-6b780dce79e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499238594-172.17.0.15-1599368021420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46506,DS-19196457-af99-4096-ad2f-79d440ba2f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-1aeed057-7ecc-42ff-be20-077b324abce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-b4b691cd-b2b8-4782-a112-f9c84594a75f,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b6797e4e-0428-46be-964c-79a5faee87bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-d89ad40a-c078-4a6f-a480-d4809904c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a1e5b88f-177f-42ff-bbfc-59cacb221408,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-e01faed5-af65-4017-8b3d-6dd3cecd41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9c01c05e-2665-40d8-a394-6b780dce79e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562494088-172.17.0.15-1599368260111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-3c2c8bd0-0506-4719-8e35-3cc03281b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-2da27a48-2c62-4483-b7f1-4b9dd9a1cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c1d3e764-7273-44f7-b5b8-ae41a09104c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-2e5f9ccc-2b59-4427-bc33-2513db03027d,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-86089cfa-86cf-4b0a-89ad-2730bd3390e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b1ad53e6-6c1b-4c2d-b00a-13419763fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-156e23f4-8373-4a70-8e0e-a85dab474a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-73214be9-d656-42b0-a0c9-7aa71530fab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562494088-172.17.0.15-1599368260111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-3c2c8bd0-0506-4719-8e35-3cc03281b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-2da27a48-2c62-4483-b7f1-4b9dd9a1cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c1d3e764-7273-44f7-b5b8-ae41a09104c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-2e5f9ccc-2b59-4427-bc33-2513db03027d,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-86089cfa-86cf-4b0a-89ad-2730bd3390e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b1ad53e6-6c1b-4c2d-b00a-13419763fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-156e23f4-8373-4a70-8e0e-a85dab474a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-73214be9-d656-42b0-a0c9-7aa71530fab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041852697-172.17.0.15-1599368864004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-9613f58f-1d88-4a6b-824a-fb5b466cb136,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-1470a3fb-3811-4c0e-a1ed-99a126270874,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-bad664df-8635-4615-9ddf-9f341e8ca8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-1b1d9766-c9a7-4635-8950-d5f69b909317,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-20abc858-49a9-4dd9-b7ab-913eafe69793,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5787e7cc-9f89-4a48-92a8-9d838fb6654a,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-d03d276a-9121-4517-b8d3-ba044ecc0739,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-76f42f0d-cd75-4101-9540-c910a73219fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041852697-172.17.0.15-1599368864004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-9613f58f-1d88-4a6b-824a-fb5b466cb136,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-1470a3fb-3811-4c0e-a1ed-99a126270874,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-bad664df-8635-4615-9ddf-9f341e8ca8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-1b1d9766-c9a7-4635-8950-d5f69b909317,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-20abc858-49a9-4dd9-b7ab-913eafe69793,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5787e7cc-9f89-4a48-92a8-9d838fb6654a,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-d03d276a-9121-4517-b8d3-ba044ecc0739,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-76f42f0d-cd75-4101-9540-c910a73219fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457827114-172.17.0.15-1599368899699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-00e0b2b8-d860-439e-8b79-c0e731128938,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-be8afcf4-40d3-45d5-8610-95134fbff187,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-fb91f417-ebf9-4459-8ebd-372750bbaf30,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-c6b7e452-99a3-462d-b188-b4c0b7ee1241,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-94e927c2-43a5-44ef-8f45-f592722b1b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-f164d960-d9a3-47b2-8768-8697302765ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-b948627c-4445-4586-b710-ee43fcabece7,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f1bedee4-35f5-4045-a5f3-cf15d73a04f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457827114-172.17.0.15-1599368899699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-00e0b2b8-d860-439e-8b79-c0e731128938,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-be8afcf4-40d3-45d5-8610-95134fbff187,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-fb91f417-ebf9-4459-8ebd-372750bbaf30,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-c6b7e452-99a3-462d-b188-b4c0b7ee1241,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-94e927c2-43a5-44ef-8f45-f592722b1b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-f164d960-d9a3-47b2-8768-8697302765ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-b948627c-4445-4586-b710-ee43fcabece7,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f1bedee4-35f5-4045-a5f3-cf15d73a04f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5329
