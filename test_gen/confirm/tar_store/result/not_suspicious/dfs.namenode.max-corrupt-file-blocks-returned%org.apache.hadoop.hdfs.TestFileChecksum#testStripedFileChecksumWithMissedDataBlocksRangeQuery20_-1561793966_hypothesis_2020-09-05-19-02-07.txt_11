reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114754747-172.17.0.3-1599332540271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-4746c569-8aa7-4413-9218-bd2026283196,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-dee28131-3ce0-4838-aa9f-176127210eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-4d364713-0640-4281-9ba6-90353d7f7893,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-205cbd12-6854-44e3-9aca-39e9c0c1541c,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-0a0e51c7-8634-41c6-9f60-c1692478ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-7d689938-9f5d-4960-bd7b-48ab15766375,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-97700c6f-97e6-4295-a34a-49908e0ff34b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-96fdc418-60ae-43b0-b4ec-c246563e484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114754747-172.17.0.3-1599332540271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40121,DS-4746c569-8aa7-4413-9218-bd2026283196,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-dee28131-3ce0-4838-aa9f-176127210eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-4d364713-0640-4281-9ba6-90353d7f7893,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-205cbd12-6854-44e3-9aca-39e9c0c1541c,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-0a0e51c7-8634-41c6-9f60-c1692478ae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-7d689938-9f5d-4960-bd7b-48ab15766375,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-97700c6f-97e6-4295-a34a-49908e0ff34b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-96fdc418-60ae-43b0-b4ec-c246563e484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965387218-172.17.0.3-1599332630233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-f0d623d3-c7de-4e2c-9b66-7672e231b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-dbc64d91-5b98-4858-9156-60818cf6fa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-6ad60e18-6cd5-4b37-bff4-4b17a1eb6c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-cccfd4c3-b780-4877-b239-57da07f5100a,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-a503ba17-4135-46e0-9fec-982ff0bde6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-847b0ab6-af08-4118-a22d-11fd5c0bac67,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-c071b004-d33e-47a9-bb88-2d03e280f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-41a1696c-4a77-4092-b63d-89e5b52c13af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965387218-172.17.0.3-1599332630233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-f0d623d3-c7de-4e2c-9b66-7672e231b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-dbc64d91-5b98-4858-9156-60818cf6fa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-6ad60e18-6cd5-4b37-bff4-4b17a1eb6c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-cccfd4c3-b780-4877-b239-57da07f5100a,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-a503ba17-4135-46e0-9fec-982ff0bde6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-847b0ab6-af08-4118-a22d-11fd5c0bac67,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-c071b004-d33e-47a9-bb88-2d03e280f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-41a1696c-4a77-4092-b63d-89e5b52c13af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038138403-172.17.0.3-1599333283624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-e8888852-13af-4d89-8891-3128c3047c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a0cc0101-a4bb-420d-bce0-684cf6d144a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-4ce65f98-5b99-4b6b-8576-92c0d78f00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-1afd2842-4adf-4680-a27e-5cbe7fca9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-b1952e23-9e61-4c69-b900-756721677b44,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-474665d2-a073-4bcf-89ac-01110d28a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-9c3e2282-933c-40f8-9e07-870ad4ee6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-b78d744f-318c-4d0a-a363-36203362a1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038138403-172.17.0.3-1599333283624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-e8888852-13af-4d89-8891-3128c3047c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a0cc0101-a4bb-420d-bce0-684cf6d144a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-4ce65f98-5b99-4b6b-8576-92c0d78f00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-1afd2842-4adf-4680-a27e-5cbe7fca9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-b1952e23-9e61-4c69-b900-756721677b44,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-474665d2-a073-4bcf-89ac-01110d28a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-9c3e2282-933c-40f8-9e07-870ad4ee6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-b78d744f-318c-4d0a-a363-36203362a1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414022509-172.17.0.3-1599333709868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36867,DS-331a33d0-5d80-4b7d-9ea6-45c28a1284e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-c1209170-3840-4744-a075-ef5721091d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-849c7951-5799-445d-9d92-43f290a65fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-d6624dc1-4647-431c-a141-2bd367e6da99,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-2b31207e-11ab-446a-9f6d-5d7c76cacac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c55c6f71-539d-40b9-a1bf-affe1403b3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-758e1270-4776-4a56-bef6-89dcc4e5394a,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-52370242-0cbd-4de6-b98c-907566597237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414022509-172.17.0.3-1599333709868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36867,DS-331a33d0-5d80-4b7d-9ea6-45c28a1284e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-c1209170-3840-4744-a075-ef5721091d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-849c7951-5799-445d-9d92-43f290a65fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-d6624dc1-4647-431c-a141-2bd367e6da99,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-2b31207e-11ab-446a-9f6d-5d7c76cacac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c55c6f71-539d-40b9-a1bf-affe1403b3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-758e1270-4776-4a56-bef6-89dcc4e5394a,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-52370242-0cbd-4de6-b98c-907566597237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245643639-172.17.0.3-1599334220627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42630,DS-b0d9e444-bb2c-4e97-85c3-dde6c60418db,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-c0791b16-1f71-4247-bbcb-273e904790b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-828af087-045e-4b62-bc7b-acdc3d5cf305,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-521ee243-3145-4a92-ab07-dda66dba823f,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7042d185-18c6-45cf-843c-a3ac901a5174,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-1454cba3-2015-429a-883d-453faad15707,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-28b58d80-4475-4f9b-b99b-309fa0bfd8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-268398d2-089b-4323-a3f5-5d03cfeceaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245643639-172.17.0.3-1599334220627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42630,DS-b0d9e444-bb2c-4e97-85c3-dde6c60418db,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-c0791b16-1f71-4247-bbcb-273e904790b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-828af087-045e-4b62-bc7b-acdc3d5cf305,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-521ee243-3145-4a92-ab07-dda66dba823f,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7042d185-18c6-45cf-843c-a3ac901a5174,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-1454cba3-2015-429a-883d-453faad15707,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-28b58d80-4475-4f9b-b99b-309fa0bfd8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-268398d2-089b-4323-a3f5-5d03cfeceaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921336248-172.17.0.3-1599334338103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44282,DS-f28e9eb6-d6e1-4c0e-9d73-7ddfcd9ef438,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f41639ec-1bbe-4cc2-9f02-5dd2db8ae6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-891f9841-950a-4263-b5b7-55b33ec784b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-d5c44f53-2068-4133-be56-de31b84797b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-3608c9b2-1f67-42a6-aa29-b5d5dfb98927,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-e37104c2-fb8e-475b-b24f-9661e0aa387c,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-1ad62a6d-f439-47db-8acb-22d1fb75421f,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-ad27a562-4456-4d3d-b50a-e6a214111194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921336248-172.17.0.3-1599334338103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44282,DS-f28e9eb6-d6e1-4c0e-9d73-7ddfcd9ef438,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f41639ec-1bbe-4cc2-9f02-5dd2db8ae6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-891f9841-950a-4263-b5b7-55b33ec784b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-d5c44f53-2068-4133-be56-de31b84797b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-3608c9b2-1f67-42a6-aa29-b5d5dfb98927,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-e37104c2-fb8e-475b-b24f-9661e0aa387c,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-1ad62a6d-f439-47db-8acb-22d1fb75421f,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-ad27a562-4456-4d3d-b50a-e6a214111194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338092517-172.17.0.3-1599334439971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-4f05846b-c67a-41b8-8972-c309d79b6d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-e94953f9-b3df-4ea2-8290-6e4a3ff074dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-534aa399-0fc9-4acc-aefc-56a43eeed89a,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-65ab4fcd-5843-42a7-ac33-97a8098e43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-d8addde2-590f-43f5-bd1d-b8c85385449e,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-4f3be2c3-07cd-4e89-8481-2c018fa6b601,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-4e1f8d10-c58d-4797-b125-9b016d4db422,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-ef9905dc-afeb-4050-9941-68d620713308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338092517-172.17.0.3-1599334439971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-4f05846b-c67a-41b8-8972-c309d79b6d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-e94953f9-b3df-4ea2-8290-6e4a3ff074dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-534aa399-0fc9-4acc-aefc-56a43eeed89a,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-65ab4fcd-5843-42a7-ac33-97a8098e43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-d8addde2-590f-43f5-bd1d-b8c85385449e,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-4f3be2c3-07cd-4e89-8481-2c018fa6b601,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-4e1f8d10-c58d-4797-b125-9b016d4db422,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-ef9905dc-afeb-4050-9941-68d620713308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339995058-172.17.0.3-1599334478665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43837,DS-c71aa4f4-b3dc-4b7a-8016-8b0cde51365d,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2e45e919-efa6-4964-bacd-413a58941e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-3c89e75b-6f3a-4f5c-8275-ba53239694c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e6ef9167-6cc3-4840-b1c6-f2dfcfcd0ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-d74fa402-a0fc-4246-8f6c-2e7cc2fe616e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-de12d349-04c4-48c8-8142-39510ac6b0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-d01e7441-6b7a-470f-891d-119289333a18,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-d1cf7c6d-b9fd-4462-a247-55d898cee5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339995058-172.17.0.3-1599334478665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43837,DS-c71aa4f4-b3dc-4b7a-8016-8b0cde51365d,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-2e45e919-efa6-4964-bacd-413a58941e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-3c89e75b-6f3a-4f5c-8275-ba53239694c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e6ef9167-6cc3-4840-b1c6-f2dfcfcd0ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-d74fa402-a0fc-4246-8f6c-2e7cc2fe616e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-de12d349-04c4-48c8-8142-39510ac6b0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-d01e7441-6b7a-470f-891d-119289333a18,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-d1cf7c6d-b9fd-4462-a247-55d898cee5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227974151-172.17.0.3-1599334639230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-ee67cf5f-476b-4332-bd1c-615793b363cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-d2cd897c-be0e-415f-bd64-a1313e2466c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-dcce1247-eb90-48bb-97fa-68db64a5fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-2e402555-30a8-475a-9ab0-4cffe846cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-ce1f2a2f-5b72-4b71-b8dc-48a9feee98f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-d249b574-d1c3-40bb-a567-6fd31af3ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-2327a2ca-2830-4253-b7f0-6cd5182773de,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2971d13a-5dd2-4ac0-8864-20775f40125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227974151-172.17.0.3-1599334639230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-ee67cf5f-476b-4332-bd1c-615793b363cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-d2cd897c-be0e-415f-bd64-a1313e2466c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-dcce1247-eb90-48bb-97fa-68db64a5fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-2e402555-30a8-475a-9ab0-4cffe846cbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-ce1f2a2f-5b72-4b71-b8dc-48a9feee98f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-d249b574-d1c3-40bb-a567-6fd31af3ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-2327a2ca-2830-4253-b7f0-6cd5182773de,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2971d13a-5dd2-4ac0-8864-20775f40125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125923089-172.17.0.3-1599334892952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-ed5f7638-9a30-4261-8e29-a4150d1449e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-dfd17e6f-8d3f-436c-a881-4844bb97b272,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-56efd4c0-6c05-4229-97e8-830452d71050,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0839253d-be93-4e80-bcfd-0084118aa8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-b6210da9-8670-4f55-904d-211bf1485c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-a460df52-069d-4411-a27f-16fe4daa91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-1c316229-fa2c-4c29-918b-ce46d162b618,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-67b38922-ab79-4bd3-83ac-0c8a356cc177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125923089-172.17.0.3-1599334892952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-ed5f7638-9a30-4261-8e29-a4150d1449e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-dfd17e6f-8d3f-436c-a881-4844bb97b272,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-56efd4c0-6c05-4229-97e8-830452d71050,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-0839253d-be93-4e80-bcfd-0084118aa8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-b6210da9-8670-4f55-904d-211bf1485c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-a460df52-069d-4411-a27f-16fe4daa91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-1c316229-fa2c-4c29-918b-ce46d162b618,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-67b38922-ab79-4bd3-83ac-0c8a356cc177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021695398-172.17.0.3-1599335048094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-046e04f1-e747-40fb-add3-9fd27ac9f828,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-33054a03-06ca-47cf-be39-8533d8e0c25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-00e43fa4-aeef-45ef-8e16-22b997cb06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-18a69850-42d5-4d6f-9c84-65c4fe46f034,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-7db294ca-fad8-4f98-86e0-50c3d120e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-a2626229-62f2-4f4f-9c35-a63ffd4df2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-7a13b08a-04e8-4c9e-a836-40807d48c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b4ac07a2-30bc-48e8-8e20-7a3f0611fa4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021695398-172.17.0.3-1599335048094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-046e04f1-e747-40fb-add3-9fd27ac9f828,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-33054a03-06ca-47cf-be39-8533d8e0c25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-00e43fa4-aeef-45ef-8e16-22b997cb06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-18a69850-42d5-4d6f-9c84-65c4fe46f034,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-7db294ca-fad8-4f98-86e0-50c3d120e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-a2626229-62f2-4f4f-9c35-a63ffd4df2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-7a13b08a-04e8-4c9e-a836-40807d48c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-b4ac07a2-30bc-48e8-8e20-7a3f0611fa4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797482033-172.17.0.3-1599335694473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-c7c89f3f-188d-4e36-b5e3-4306c293d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-a2b42d8a-e016-41f6-b9f3-e8bfe7189306,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-a885e7af-b4e6-4e8f-86e3-ee2504f3afe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-7792eb12-dadc-4305-9342-cf1f6eb82732,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-0d07a030-0065-49b5-a58e-65ac86d09cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e2f9531e-ec69-4e52-af71-e356e6fdd2da,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-40be9578-bd3a-4abe-89d4-f2cc110b9190,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-bcfba0f2-a300-4539-8f36-d6ffabb5f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797482033-172.17.0.3-1599335694473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-c7c89f3f-188d-4e36-b5e3-4306c293d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-a2b42d8a-e016-41f6-b9f3-e8bfe7189306,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-a885e7af-b4e6-4e8f-86e3-ee2504f3afe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-7792eb12-dadc-4305-9342-cf1f6eb82732,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-0d07a030-0065-49b5-a58e-65ac86d09cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e2f9531e-ec69-4e52-af71-e356e6fdd2da,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-40be9578-bd3a-4abe-89d4-f2cc110b9190,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-bcfba0f2-a300-4539-8f36-d6ffabb5f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896723036-172.17.0.3-1599335893573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-92983b8a-ca71-4b32-8f64-481b866fb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-7a810ee9-64d3-44b8-ae5b-9f7f8388cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-ccff6dba-aed6-4874-ad74-091464ce894a,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d9e99c11-f1b1-4ca1-b42d-e00c5976d73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-b92bfe92-0c8a-42d4-9adb-ccd737c93f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e38ee723-ab04-4c43-b379-cf7a8d54ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-3d49cedd-c426-4f38-b336-fd73a3bd2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-6feddce3-1865-4248-87c1-fe027fb35ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896723036-172.17.0.3-1599335893573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-92983b8a-ca71-4b32-8f64-481b866fb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-7a810ee9-64d3-44b8-ae5b-9f7f8388cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-ccff6dba-aed6-4874-ad74-091464ce894a,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d9e99c11-f1b1-4ca1-b42d-e00c5976d73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-b92bfe92-0c8a-42d4-9adb-ccd737c93f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e38ee723-ab04-4c43-b379-cf7a8d54ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-3d49cedd-c426-4f38-b336-fd73a3bd2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-6feddce3-1865-4248-87c1-fe027fb35ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301097240-172.17.0.3-1599336458412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-5694732f-7e7e-4226-8b03-340d91b1d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-350fbfdb-0f70-436c-9f82-4205b8abf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-7be241c0-36af-4c03-8783-2dbcd4e1cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-f48800de-11d3-4224-8cb8-74cca4c6885d,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-8d26ecbd-8b2c-464b-b4aa-9e705540395d,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-8e8092e6-4efc-48c5-a490-ca8606e095ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-b81ba994-2fe8-426f-be24-e537a6f53652,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-58fb1065-f264-41ec-8fa2-6b51bd42ec68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301097240-172.17.0.3-1599336458412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-5694732f-7e7e-4226-8b03-340d91b1d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-350fbfdb-0f70-436c-9f82-4205b8abf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-7be241c0-36af-4c03-8783-2dbcd4e1cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-f48800de-11d3-4224-8cb8-74cca4c6885d,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-8d26ecbd-8b2c-464b-b4aa-9e705540395d,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-8e8092e6-4efc-48c5-a490-ca8606e095ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-b81ba994-2fe8-426f-be24-e537a6f53652,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-58fb1065-f264-41ec-8fa2-6b51bd42ec68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26867119-172.17.0.3-1599337422028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-26128de2-f229-4c7a-9093-f0a8a99a0563,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-671ed399-5ccc-4b8d-b6e7-04ed778306b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-32abec14-b417-4ef5-8b5c-160b605375fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-e36cb541-ebb0-4d17-a58c-dd22a6643281,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-f548e99d-1cd5-4ddf-a899-c8ccde26c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-fa558bb0-f3e3-4ab9-8092-a7d11fc1390d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-aafdcc1b-9644-409d-9b61-b6a24aa569a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-5252e15a-4e8d-4256-8034-5c0d9e024731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26867119-172.17.0.3-1599337422028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-26128de2-f229-4c7a-9093-f0a8a99a0563,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-671ed399-5ccc-4b8d-b6e7-04ed778306b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-32abec14-b417-4ef5-8b5c-160b605375fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-e36cb541-ebb0-4d17-a58c-dd22a6643281,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-f548e99d-1cd5-4ddf-a899-c8ccde26c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-fa558bb0-f3e3-4ab9-8092-a7d11fc1390d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-aafdcc1b-9644-409d-9b61-b6a24aa569a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-5252e15a-4e8d-4256-8034-5c0d9e024731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4946
