reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589884250-172.17.0.9-1599348619568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-93fc14ff-6fcb-42ea-9841-4e384621f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-c07a5e5b-b4bb-42d2-90c4-21b0a0ae2326,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-47057597-a424-4d1f-ba9f-d24605cd8cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-4fcbd5af-29fb-45cf-b99c-6b73191a2731,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-0d417812-a12a-46b7-84ab-68e152362af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-8c7a203c-4557-48fe-8f30-3254de67529f,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-21a47e84-408e-4088-afd1-bcbd1195b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3007e39a-7c01-4f86-9163-a2a8dbb5387b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589884250-172.17.0.9-1599348619568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-93fc14ff-6fcb-42ea-9841-4e384621f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-c07a5e5b-b4bb-42d2-90c4-21b0a0ae2326,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-47057597-a424-4d1f-ba9f-d24605cd8cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-4fcbd5af-29fb-45cf-b99c-6b73191a2731,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-0d417812-a12a-46b7-84ab-68e152362af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-8c7a203c-4557-48fe-8f30-3254de67529f,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-21a47e84-408e-4088-afd1-bcbd1195b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-3007e39a-7c01-4f86-9163-a2a8dbb5387b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231962704-172.17.0.9-1599348781771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-f4a9508c-a9bb-4fc7-89e2-0d18d51c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bdebc28e-b639-4e5c-8ee6-e481c30ce96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-58555e82-a685-41b8-81ce-06a0fe159824,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-0bdb3524-9627-4a80-88e4-73cc9a153ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6c9772b5-0971-4223-9537-52c8b5094f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-8dedf506-8927-4df4-829d-3080e55660be,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-70755717-02d4-421d-8a60-2f707cbe487c,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-93780ab5-ef85-4ee1-992d-10623f58621b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231962704-172.17.0.9-1599348781771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-f4a9508c-a9bb-4fc7-89e2-0d18d51c84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bdebc28e-b639-4e5c-8ee6-e481c30ce96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-58555e82-a685-41b8-81ce-06a0fe159824,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-0bdb3524-9627-4a80-88e4-73cc9a153ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6c9772b5-0971-4223-9537-52c8b5094f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-8dedf506-8927-4df4-829d-3080e55660be,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-70755717-02d4-421d-8a60-2f707cbe487c,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-93780ab5-ef85-4ee1-992d-10623f58621b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609322654-172.17.0.9-1599348836928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-add3c4bf-0dcd-4756-a2f6-734e693f3779,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-59a75af0-b334-48a3-87f6-6ccab4c8783a,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-177c153d-d894-4b6c-9f31-2b05afdb5281,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-0fe322b1-30a6-43a9-987f-4c725ef0d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ec116336-3444-4696-bcd4-8837c7f1757c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-5be46d7c-2f37-41cb-a805-73ec8a5cd6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-b51794fe-7853-4b3c-aa5c-62a75414ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c8541cc7-7fd8-4fb2-a062-7eda5b46ac58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609322654-172.17.0.9-1599348836928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-add3c4bf-0dcd-4756-a2f6-734e693f3779,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-59a75af0-b334-48a3-87f6-6ccab4c8783a,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-177c153d-d894-4b6c-9f31-2b05afdb5281,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-0fe322b1-30a6-43a9-987f-4c725ef0d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ec116336-3444-4696-bcd4-8837c7f1757c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-5be46d7c-2f37-41cb-a805-73ec8a5cd6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-b51794fe-7853-4b3c-aa5c-62a75414ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-c8541cc7-7fd8-4fb2-a062-7eda5b46ac58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596582258-172.17.0.9-1599349260445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-dd417352-1c7c-4741-91d9-c6eb58a9b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-30b92ff7-3fdd-475d-8bc0-1ad6826b84cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-e4ef7749-05f5-4c4b-8f8d-99b2b45b1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-dac89584-e165-4adc-af5a-50dbf7061f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-9ee718ce-e069-4285-b48a-25f8135c68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-11f6cd60-2a0c-44a6-9d94-576a052746f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-08c75883-4cf6-481f-a1a4-714751568a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-33230f12-71d5-4237-af12-04cd05082890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596582258-172.17.0.9-1599349260445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-dd417352-1c7c-4741-91d9-c6eb58a9b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-30b92ff7-3fdd-475d-8bc0-1ad6826b84cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-e4ef7749-05f5-4c4b-8f8d-99b2b45b1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-dac89584-e165-4adc-af5a-50dbf7061f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-9ee718ce-e069-4285-b48a-25f8135c68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-11f6cd60-2a0c-44a6-9d94-576a052746f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-08c75883-4cf6-481f-a1a4-714751568a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-33230f12-71d5-4237-af12-04cd05082890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477852515-172.17.0.9-1599349797012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-4b752a27-ff3f-4723-9d46-4faa5872c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-e6537ead-23a0-4761-8069-aa08e742e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-51a76986-1201-4e57-8589-fd59a03a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d4e158b1-1c8c-4d43-b7cb-3bbe6d4139c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-1af247f0-3403-46a8-a9a1-fa63e3370d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-4c08ec49-3584-4a98-a4e7-4023d30e00b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-af21e6a8-ba7a-44ea-ae83-b058356d3cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-51bf14ab-de46-489d-8b78-59ef4db0075f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477852515-172.17.0.9-1599349797012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-4b752a27-ff3f-4723-9d46-4faa5872c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-e6537ead-23a0-4761-8069-aa08e742e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-51a76986-1201-4e57-8589-fd59a03a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d4e158b1-1c8c-4d43-b7cb-3bbe6d4139c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-1af247f0-3403-46a8-a9a1-fa63e3370d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-4c08ec49-3584-4a98-a4e7-4023d30e00b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-af21e6a8-ba7a-44ea-ae83-b058356d3cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-51bf14ab-de46-489d-8b78-59ef4db0075f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815829302-172.17.0.9-1599350149489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-87eb676b-1bd5-4bf4-832d-782e0792a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-02697a16-3669-46c7-aeae-73f56b973860,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-76ddf3ac-7f2a-403f-b145-6749b051e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-34c649e8-0fd4-48c9-9e9c-d8563cb47c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-2bc1a484-4779-49ac-8d13-c8e2c021e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-913be486-3db7-4e0f-91c5-ec3cf5c8215c,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-9fad7161-d168-4726-9b45-7e5c4dac3756,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-8fc7cf13-ce3f-4c08-bd39-06d424abab7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815829302-172.17.0.9-1599350149489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-87eb676b-1bd5-4bf4-832d-782e0792a60a,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-02697a16-3669-46c7-aeae-73f56b973860,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-76ddf3ac-7f2a-403f-b145-6749b051e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-34c649e8-0fd4-48c9-9e9c-d8563cb47c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-2bc1a484-4779-49ac-8d13-c8e2c021e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-913be486-3db7-4e0f-91c5-ec3cf5c8215c,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-9fad7161-d168-4726-9b45-7e5c4dac3756,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-8fc7cf13-ce3f-4c08-bd39-06d424abab7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076339484-172.17.0.9-1599350235947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-02d621be-f2b7-4cd0-9a0d-12092e66a264,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-54706377-5897-4594-99cb-b4c58a0b75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-43bf58f8-c432-42f8-9983-5be1d2e526cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-07f1a3e9-f0fe-48e1-9272-fc8cde3a98db,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-ca9f5765-06da-4ffe-ab42-8a5deb9522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-8d32317d-6a47-4c65-a43c-bde4e63ddf25,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-8b1142fb-fa3a-4604-a068-a238cbaf2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7f606843-6251-4c3e-b5f9-3da751d3d3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076339484-172.17.0.9-1599350235947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-02d621be-f2b7-4cd0-9a0d-12092e66a264,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-54706377-5897-4594-99cb-b4c58a0b75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-43bf58f8-c432-42f8-9983-5be1d2e526cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-07f1a3e9-f0fe-48e1-9272-fc8cde3a98db,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-ca9f5765-06da-4ffe-ab42-8a5deb9522c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-8d32317d-6a47-4c65-a43c-bde4e63ddf25,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-8b1142fb-fa3a-4604-a068-a238cbaf2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7f606843-6251-4c3e-b5f9-3da751d3d3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081855317-172.17.0.9-1599350790502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-21d04116-a47e-4c85-b3b1-73bde0b2fb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-ee719bcb-8692-42fe-a4b3-97480dedd7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-2248bffa-e19e-45f7-b797-c90b46f600b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-b1424e67-9f93-498d-803a-7d2dcb053d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-175861b7-9a2d-4b56-9c71-080285810753,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-2c3b66e1-ce0d-4f1a-8ef2-000ebd3c7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-9bdeadfe-5bb1-444f-af11-68039e7b0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-828198d3-73a3-4cae-8df3-f3e96fbf8ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081855317-172.17.0.9-1599350790502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-21d04116-a47e-4c85-b3b1-73bde0b2fb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-ee719bcb-8692-42fe-a4b3-97480dedd7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-2248bffa-e19e-45f7-b797-c90b46f600b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-b1424e67-9f93-498d-803a-7d2dcb053d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-175861b7-9a2d-4b56-9c71-080285810753,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-2c3b66e1-ce0d-4f1a-8ef2-000ebd3c7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-9bdeadfe-5bb1-444f-af11-68039e7b0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-828198d3-73a3-4cae-8df3-f3e96fbf8ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848597725-172.17.0.9-1599350955447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-a304aadc-93f0-4e5d-a919-53e552b8de95,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-34681e64-5513-4d3f-a153-f851e1532dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-3e8fc385-dd97-49b2-a765-b9b8a95dc817,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-72eba5fb-7082-494d-bcef-30938264e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-a03c317f-afea-41fa-a4a6-8a53b4e8d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-4622303a-2970-4b19-849a-79f0c1cef925,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-8ec66d29-2398-4e32-9358-0e9f26dde9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-4cf7bf1b-a76b-40c3-bb14-4377447a46ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848597725-172.17.0.9-1599350955447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-a304aadc-93f0-4e5d-a919-53e552b8de95,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-34681e64-5513-4d3f-a153-f851e1532dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-3e8fc385-dd97-49b2-a765-b9b8a95dc817,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-72eba5fb-7082-494d-bcef-30938264e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-a03c317f-afea-41fa-a4a6-8a53b4e8d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-4622303a-2970-4b19-849a-79f0c1cef925,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-8ec66d29-2398-4e32-9358-0e9f26dde9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-4cf7bf1b-a76b-40c3-bb14-4377447a46ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518320650-172.17.0.9-1599350981377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-3eaeae63-9e10-402d-8331-d2404019de36,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-4aa62c1c-dfe5-4674-a89b-6bdd3581b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-e3d3a754-609d-456f-81b9-baf10a01de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-ef7847f9-7b60-4ac5-934c-e15c4527b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-463a0e7f-9f80-40e6-a7b0-fa1993a9fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-5172cad8-8d05-4458-b450-02ee857f276f,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-39afd85f-d95b-4feb-ba98-e93ce06899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f90edeb5-bcf1-4ce6-8a5a-1ad5ab3a431f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518320650-172.17.0.9-1599350981377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36293,DS-3eaeae63-9e10-402d-8331-d2404019de36,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-4aa62c1c-dfe5-4674-a89b-6bdd3581b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-e3d3a754-609d-456f-81b9-baf10a01de7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-ef7847f9-7b60-4ac5-934c-e15c4527b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-463a0e7f-9f80-40e6-a7b0-fa1993a9fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-5172cad8-8d05-4458-b450-02ee857f276f,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-39afd85f-d95b-4feb-ba98-e93ce06899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f90edeb5-bcf1-4ce6-8a5a-1ad5ab3a431f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104971603-172.17.0.9-1599351218011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-690a8ba1-eefd-4121-9969-0b5f8b888721,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c0bcdd72-ee60-4b24-9da0-cb8d24f32c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-8ee11277-c17c-4eb0-99ef-9c02bc0c6672,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-4f2491cb-5d2c-4468-82a4-b75b3f98a271,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7f12a991-1c32-4459-a73f-0dd3c58bacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-1534511f-979b-4170-b7bd-619216f51f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-e29fb670-cd69-486c-98c3-171229e58225,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-f2b3486c-b590-41c4-bb13-644f6765edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104971603-172.17.0.9-1599351218011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38390,DS-690a8ba1-eefd-4121-9969-0b5f8b888721,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c0bcdd72-ee60-4b24-9da0-cb8d24f32c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-8ee11277-c17c-4eb0-99ef-9c02bc0c6672,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-4f2491cb-5d2c-4468-82a4-b75b3f98a271,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-7f12a991-1c32-4459-a73f-0dd3c58bacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-1534511f-979b-4170-b7bd-619216f51f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-e29fb670-cd69-486c-98c3-171229e58225,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-f2b3486c-b590-41c4-bb13-644f6765edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787620643-172.17.0.9-1599351273900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-cec32cba-a60c-411e-9754-d97a2ae99b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-8fb3a785-90d5-446e-8769-924c7a7e48e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-10dad2c4-2fa6-4c52-ba61-764d6d5e8885,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-4bd01e3f-9a5b-4c19-911d-96809c52e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-d1bb9a7d-e299-4239-b761-2e22d68b6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-f30bcd3d-ed99-4b52-981e-7aa14b33ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-3f9e1aeb-506a-43ec-bc07-77ca8420c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-47bc546a-abc5-4681-81ac-81679cd9a564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787620643-172.17.0.9-1599351273900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-cec32cba-a60c-411e-9754-d97a2ae99b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-8fb3a785-90d5-446e-8769-924c7a7e48e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-10dad2c4-2fa6-4c52-ba61-764d6d5e8885,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-4bd01e3f-9a5b-4c19-911d-96809c52e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-d1bb9a7d-e299-4239-b761-2e22d68b6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-f30bcd3d-ed99-4b52-981e-7aa14b33ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-3f9e1aeb-506a-43ec-bc07-77ca8420c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-47bc546a-abc5-4681-81ac-81679cd9a564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117183958-172.17.0.9-1599351537037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-59ce0f3e-e082-401a-85c2-d36ab748a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-be8aaf3c-ead0-4c25-b2d0-092e01246f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-99dad141-44a8-473e-b51c-ebd93f814557,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-891c72e7-ad9b-4049-b4b4-99f96d5fff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-44ddd046-34e2-4303-a0c2-0f6a50e5a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-40378d69-6705-4229-b59f-6a7cc17fce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-d566f08d-2322-4332-97b4-4e46ca8618b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-e2d465cf-7f7b-43ce-a512-ce6153312704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117183958-172.17.0.9-1599351537037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-59ce0f3e-e082-401a-85c2-d36ab748a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-be8aaf3c-ead0-4c25-b2d0-092e01246f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-99dad141-44a8-473e-b51c-ebd93f814557,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-891c72e7-ad9b-4049-b4b4-99f96d5fff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-44ddd046-34e2-4303-a0c2-0f6a50e5a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-40378d69-6705-4229-b59f-6a7cc17fce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-d566f08d-2322-4332-97b4-4e46ca8618b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-e2d465cf-7f7b-43ce-a512-ce6153312704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756059345-172.17.0.9-1599351598160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-534494c0-b207-4d02-9ac6-0e389f6e5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-0268adcc-758b-4ee1-b3ef-cb5c9411e683,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-2064d99a-1574-477a-844a-04c614b18ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-2ef3db6a-2514-47e6-98f5-90770f938fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-25c037b3-3173-45a3-be16-b9e69049c564,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-31653178-9986-46f8-ac8d-52f0d779b041,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-2c1dc0f4-8f5c-4344-81d2-7d1d9a728e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-75224d66-ba96-4ef3-9403-9a0b7ba6495c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756059345-172.17.0.9-1599351598160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-534494c0-b207-4d02-9ac6-0e389f6e5a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-0268adcc-758b-4ee1-b3ef-cb5c9411e683,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-2064d99a-1574-477a-844a-04c614b18ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-2ef3db6a-2514-47e6-98f5-90770f938fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-25c037b3-3173-45a3-be16-b9e69049c564,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-31653178-9986-46f8-ac8d-52f0d779b041,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-2c1dc0f4-8f5c-4344-81d2-7d1d9a728e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-75224d66-ba96-4ef3-9403-9a0b7ba6495c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633664881-172.17.0.9-1599352024666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-f55f5472-5f83-4e1d-8e7f-aa5c82b8289f,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-7d36e5b4-d0c1-4ff3-a45c-26c2ca7860b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-da4f4df7-3aff-4e8f-a360-5370b5dab1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-af90ae21-f19e-482a-b7b1-77217e977bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-542e35b3-2323-4bc7-b1a2-642f9e4e8f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-978e7c6b-ec9c-4472-a832-ac18f44a6945,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-08cfb102-413f-4348-bac7-f1a74f042fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0c336a3d-394a-4ebf-b8da-08d4c37f7e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633664881-172.17.0.9-1599352024666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-f55f5472-5f83-4e1d-8e7f-aa5c82b8289f,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-7d36e5b4-d0c1-4ff3-a45c-26c2ca7860b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-da4f4df7-3aff-4e8f-a360-5370b5dab1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-af90ae21-f19e-482a-b7b1-77217e977bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-542e35b3-2323-4bc7-b1a2-642f9e4e8f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-978e7c6b-ec9c-4472-a832-ac18f44a6945,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-08cfb102-413f-4348-bac7-f1a74f042fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0c336a3d-394a-4ebf-b8da-08d4c37f7e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639947901-172.17.0.9-1599352170653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-de3c4a46-68d1-4e1c-a053-86204855fdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-d20ce15f-7082-4417-8f73-933b8d2212fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-15514098-4047-4ac4-bbf5-acab3f9b6197,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-a554102e-2cbf-486a-96ba-2476873ee044,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3b472f50-80e9-4f00-9a18-717a14f59c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-43428930-4e55-4382-a51d-0b02ec713bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-3b8598e2-d764-4600-8f02-f4c310c05eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-2ab9121d-83f5-4d56-8bb5-5e6a5d06d636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639947901-172.17.0.9-1599352170653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-de3c4a46-68d1-4e1c-a053-86204855fdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-d20ce15f-7082-4417-8f73-933b8d2212fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-15514098-4047-4ac4-bbf5-acab3f9b6197,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-a554102e-2cbf-486a-96ba-2476873ee044,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3b472f50-80e9-4f00-9a18-717a14f59c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-43428930-4e55-4382-a51d-0b02ec713bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-3b8598e2-d764-4600-8f02-f4c310c05eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-2ab9121d-83f5-4d56-8bb5-5e6a5d06d636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089571804-172.17.0.9-1599352472040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-d3809f84-12f6-4538-b110-740060c92b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-36001e15-79f1-4d57-8a36-0c0b2eb192dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-bd3168e6-4c42-4fe0-b9f8-d2d1c7f601e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-7ec0d11e-2767-49eb-8d46-6ebd408f72fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-a03136fa-339e-468e-96a8-7a38e1505f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-b31d0161-2b0f-4fa8-98ce-43fc38102143,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-aae7e61f-5f95-4a68-a6e5-a673f72f2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-3ddc1436-9b6c-4d22-81a4-5084188fec67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089571804-172.17.0.9-1599352472040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-d3809f84-12f6-4538-b110-740060c92b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-36001e15-79f1-4d57-8a36-0c0b2eb192dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-bd3168e6-4c42-4fe0-b9f8-d2d1c7f601e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-7ec0d11e-2767-49eb-8d46-6ebd408f72fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-a03136fa-339e-468e-96a8-7a38e1505f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-b31d0161-2b0f-4fa8-98ce-43fc38102143,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-aae7e61f-5f95-4a68-a6e5-a673f72f2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-3ddc1436-9b6c-4d22-81a4-5084188fec67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506809858-172.17.0.9-1599352719848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-f57a8e55-b11c-44cd-8b78-350ca1684e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-7f2edc16-9ca1-4541-879d-f6068b9296de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-f45f175c-5546-4e44-b664-0706432d11b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9504b8ab-5b3e-45f8-8e7d-de78a5a04131,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-2ab30ac3-c8fe-45c6-82e5-3370f983dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-88bc9095-5556-4b3c-beca-9b96cc30d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-9fa7de08-7834-4f39-b536-2115738ad6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-0f417f4a-178b-4b6b-aa8e-c5277c8801b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506809858-172.17.0.9-1599352719848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-f57a8e55-b11c-44cd-8b78-350ca1684e24,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-7f2edc16-9ca1-4541-879d-f6068b9296de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-f45f175c-5546-4e44-b664-0706432d11b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9504b8ab-5b3e-45f8-8e7d-de78a5a04131,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-2ab30ac3-c8fe-45c6-82e5-3370f983dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-88bc9095-5556-4b3c-beca-9b96cc30d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-9fa7de08-7834-4f39-b536-2115738ad6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-0f417f4a-178b-4b6b-aa8e-c5277c8801b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415965682-172.17.0.9-1599352853932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-702b8c71-d81a-48bf-b798-ed96e8a9800f,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-faca50a0-36f8-4f34-9719-438ab64403b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-774e7f07-48f4-474f-a1d7-404a9222c187,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ac5de0ee-71ba-48d1-adb9-06ffc97349e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-55deea07-8612-4d82-adab-d1fa2eff457e,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-37b72bb5-13a9-440a-b98c-1bc9570059ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-7bceed2e-d501-4905-b9e7-d5d2aad08854,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a06c345b-acca-4ffd-8c31-4d175a37e323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415965682-172.17.0.9-1599352853932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-702b8c71-d81a-48bf-b798-ed96e8a9800f,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-faca50a0-36f8-4f34-9719-438ab64403b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-774e7f07-48f4-474f-a1d7-404a9222c187,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ac5de0ee-71ba-48d1-adb9-06ffc97349e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-55deea07-8612-4d82-adab-d1fa2eff457e,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-37b72bb5-13a9-440a-b98c-1bc9570059ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-7bceed2e-d501-4905-b9e7-d5d2aad08854,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a06c345b-acca-4ffd-8c31-4d175a37e323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4454
