reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109239290-172.17.0.6-1599313015323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-4760bf90-a74e-4667-9e92-5caa2441138d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-00b932e6-9b48-436e-b52b-205fb3bfd989,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-0fb4c439-4acc-4b40-b876-b8cc4242631b,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-da7cdd7c-ccfb-4d04-8f5c-7f0336e4dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-36e66069-e5be-44a0-9229-5f9a4fc3abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-5db82937-5f66-4d65-bcaa-9e37bca5b777,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-9c8a376f-560d-47f5-886b-a6cbe8d09129,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-a7b9edb8-3ba8-4309-b4f0-9286680d1ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109239290-172.17.0.6-1599313015323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-4760bf90-a74e-4667-9e92-5caa2441138d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-00b932e6-9b48-436e-b52b-205fb3bfd989,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-0fb4c439-4acc-4b40-b876-b8cc4242631b,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-da7cdd7c-ccfb-4d04-8f5c-7f0336e4dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-36e66069-e5be-44a0-9229-5f9a4fc3abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-5db82937-5f66-4d65-bcaa-9e37bca5b777,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-9c8a376f-560d-47f5-886b-a6cbe8d09129,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-a7b9edb8-3ba8-4309-b4f0-9286680d1ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102337234-172.17.0.6-1599313089755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-09ec7906-c99d-4be1-af03-97f0f70faf84,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-20b58c19-1d91-428b-8399-aafce292ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-2aae8f9c-2f88-487d-9c2e-2a6bcd9b30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-51f88788-6f55-4947-800c-c5027865bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-eb874244-fd3b-4029-8fbb-38087324dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-caad0992-57f4-4baa-af1a-7d765ed27d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-13454960-bf5e-4dc2-87f8-73a20fc77587,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-2238c31a-bf88-4bfe-9854-46697adfb6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102337234-172.17.0.6-1599313089755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-09ec7906-c99d-4be1-af03-97f0f70faf84,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-20b58c19-1d91-428b-8399-aafce292ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-2aae8f9c-2f88-487d-9c2e-2a6bcd9b30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-51f88788-6f55-4947-800c-c5027865bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-eb874244-fd3b-4029-8fbb-38087324dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-caad0992-57f4-4baa-af1a-7d765ed27d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-13454960-bf5e-4dc2-87f8-73a20fc77587,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-2238c31a-bf88-4bfe-9854-46697adfb6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063884592-172.17.0.6-1599313377772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37330,DS-4cc61a8d-2c4b-419a-9eb7-777a539d1736,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-887a4fc1-e073-4766-a5b3-7fc2b32d6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-38c7dd69-69aa-4b12-b247-9e2b86e1c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-1870eaf1-34da-4f0a-809d-a4c69fe580ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-6e79b0a2-5422-4cd7-98ab-0277d5b9a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-b3cf3c6a-7377-4b66-bf39-6239aa8893de,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-b322b752-a56b-436f-b3ab-904c31197c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-1124aa09-1e71-4fe2-badb-d902a0810bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063884592-172.17.0.6-1599313377772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37330,DS-4cc61a8d-2c4b-419a-9eb7-777a539d1736,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-887a4fc1-e073-4766-a5b3-7fc2b32d6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-38c7dd69-69aa-4b12-b247-9e2b86e1c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-1870eaf1-34da-4f0a-809d-a4c69fe580ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-6e79b0a2-5422-4cd7-98ab-0277d5b9a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-b3cf3c6a-7377-4b66-bf39-6239aa8893de,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-b322b752-a56b-436f-b3ab-904c31197c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-1124aa09-1e71-4fe2-badb-d902a0810bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597835372-172.17.0.6-1599313454720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-c104e05e-d5b3-43f0-9a90-f9cb7ba460d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1fc7d7d4-ce41-4470-a155-d151d5799dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-fe323830-789a-45f9-a3c1-546fb93e4101,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c2074a1f-7cd7-4e3f-994d-32cdcc09a736,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2efb6a78-d392-4ead-b3d7-a08cb3a78975,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-f68ca221-2e1a-41d5-950c-85313fd222d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-5091d373-a580-44b4-baa4-db6127671319,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-0f2b6368-3de9-42c0-ac47-1ef4bc1ffdb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597835372-172.17.0.6-1599313454720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-c104e05e-d5b3-43f0-9a90-f9cb7ba460d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1fc7d7d4-ce41-4470-a155-d151d5799dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-fe323830-789a-45f9-a3c1-546fb93e4101,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-c2074a1f-7cd7-4e3f-994d-32cdcc09a736,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-2efb6a78-d392-4ead-b3d7-a08cb3a78975,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-f68ca221-2e1a-41d5-950c-85313fd222d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-5091d373-a580-44b4-baa4-db6127671319,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-0f2b6368-3de9-42c0-ac47-1ef4bc1ffdb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385268540-172.17.0.6-1599315281899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-3905c3f4-5af7-407d-a183-5d24f076bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2ee68070-251d-4dce-b528-a69c8f36de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-628162b7-fbaa-4a10-ad6f-426d52eff61f,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-9dd3eb68-1498-4424-961c-24bcad2366b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-86ccd064-4953-4eab-b12f-a7afdf35eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-0045e845-377c-49d6-a79d-5995b0e171de,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-99930e1f-4337-4d28-908a-3db9f8dc4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-d179dc7a-d624-4728-a9e3-714fa039c4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385268540-172.17.0.6-1599315281899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-3905c3f4-5af7-407d-a183-5d24f076bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2ee68070-251d-4dce-b528-a69c8f36de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-628162b7-fbaa-4a10-ad6f-426d52eff61f,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-9dd3eb68-1498-4424-961c-24bcad2366b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-86ccd064-4953-4eab-b12f-a7afdf35eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-0045e845-377c-49d6-a79d-5995b0e171de,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-99930e1f-4337-4d28-908a-3db9f8dc4da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-d179dc7a-d624-4728-a9e3-714fa039c4e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059997101-172.17.0.6-1599315583546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-d7c842ce-0d55-45bc-80aa-5a24e6a71c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-0d957acc-aabc-48e5-93d3-56dbd610a4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a7229be7-e367-40cb-b35d-479d2aaa5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-92725864-59af-4a2f-8b82-5726bd11c397,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-175d2ddc-b882-4a59-aeab-e6d1d2627a56,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9870ec19-950e-4882-b218-bb00f5b20382,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-73eca0f1-78ae-46eb-a9a1-28fb9cf120c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-3a642d15-6742-4cf9-9b3d-13600dd38142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059997101-172.17.0.6-1599315583546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36813,DS-d7c842ce-0d55-45bc-80aa-5a24e6a71c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-0d957acc-aabc-48e5-93d3-56dbd610a4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a7229be7-e367-40cb-b35d-479d2aaa5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-92725864-59af-4a2f-8b82-5726bd11c397,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-175d2ddc-b882-4a59-aeab-e6d1d2627a56,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9870ec19-950e-4882-b218-bb00f5b20382,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-73eca0f1-78ae-46eb-a9a1-28fb9cf120c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-3a642d15-6742-4cf9-9b3d-13600dd38142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815209535-172.17.0.6-1599315815183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-2f84d939-8430-4dfd-a8c8-f74a507864a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-1ebaa0ce-4bcd-4158-a4ed-068cabcf4da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-92c9f5a2-5424-4e74-86ee-e28211782443,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-cb4a0e19-8c89-406d-aa0e-61d4f9eda88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-a27f43e1-1115-4002-add4-947d82c7156b,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-9e107c32-ddaf-4787-a60c-55ebadc97ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4dee2a00-7c0a-4df2-953c-351a26f93074,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8eff7f88-b695-44b1-bed9-457de07cb66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815209535-172.17.0.6-1599315815183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-2f84d939-8430-4dfd-a8c8-f74a507864a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-1ebaa0ce-4bcd-4158-a4ed-068cabcf4da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-92c9f5a2-5424-4e74-86ee-e28211782443,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-cb4a0e19-8c89-406d-aa0e-61d4f9eda88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-a27f43e1-1115-4002-add4-947d82c7156b,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-9e107c32-ddaf-4787-a60c-55ebadc97ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4dee2a00-7c0a-4df2-953c-351a26f93074,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8eff7f88-b695-44b1-bed9-457de07cb66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290091452-172.17.0.6-1599315934814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-b88d3958-accc-4ec0-9853-2646164046d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-384c9c07-f186-44a6-98cc-9421d7763ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-8eb71976-2c46-409a-a136-a1fdadf558c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80290562-0554-4076-ad66-54a55c308609,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-d2e6247f-f61a-4b4f-92cd-e867907c4761,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-6486c581-50a0-496a-ae5f-762d4d060db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ce8b71fc-953f-460c-ae06-c212e952e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-8d174674-2221-40b2-b19d-ec867ed81a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290091452-172.17.0.6-1599315934814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-b88d3958-accc-4ec0-9853-2646164046d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-384c9c07-f186-44a6-98cc-9421d7763ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-8eb71976-2c46-409a-a136-a1fdadf558c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80290562-0554-4076-ad66-54a55c308609,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-d2e6247f-f61a-4b4f-92cd-e867907c4761,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-6486c581-50a0-496a-ae5f-762d4d060db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ce8b71fc-953f-460c-ae06-c212e952e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-8d174674-2221-40b2-b19d-ec867ed81a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680001083-172.17.0.6-1599316334299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-dee6e689-4b28-48d6-aae8-d5cda6edd681,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-7aa6d927-11c5-45fd-9b4b-f3daa30b2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-956683a8-9fa6-4f56-8052-0c283e9a53cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-26d13c00-a169-4eaf-84f4-9e585b6f43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-ab7bf33d-1137-4c37-9c8a-61201d1e6493,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-2ed604a2-40fd-4a08-9343-a5224c3ec97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-4a3ffbe6-05be-4bc1-8eae-2fa25ceae3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-65207f19-7dab-4707-97a1-f9a9f89dc813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680001083-172.17.0.6-1599316334299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-dee6e689-4b28-48d6-aae8-d5cda6edd681,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-7aa6d927-11c5-45fd-9b4b-f3daa30b2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-956683a8-9fa6-4f56-8052-0c283e9a53cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-26d13c00-a169-4eaf-84f4-9e585b6f43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-ab7bf33d-1137-4c37-9c8a-61201d1e6493,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-2ed604a2-40fd-4a08-9343-a5224c3ec97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-4a3ffbe6-05be-4bc1-8eae-2fa25ceae3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-65207f19-7dab-4707-97a1-f9a9f89dc813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154664645-172.17.0.6-1599316453882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33045,DS-cf98eb0b-8a53-4b8b-a0e6-50e626d9337d,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-6fb22c04-0177-4160-a15c-327461d3fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-d8d2ba7a-e684-4503-98e6-f13bfa0e8286,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-cb66d630-8dad-4adb-a09f-21f0f7e3e737,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-f4971243-2d41-478e-831f-e4bc0079da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-319c11b3-a5e9-4db3-a35d-d0244a8af7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-e9af749a-fd34-4e39-a8a1-c7ecd6d78895,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-3da13c98-5335-4cd2-bc7e-991f628f49ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154664645-172.17.0.6-1599316453882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33045,DS-cf98eb0b-8a53-4b8b-a0e6-50e626d9337d,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-6fb22c04-0177-4160-a15c-327461d3fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-d8d2ba7a-e684-4503-98e6-f13bfa0e8286,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-cb66d630-8dad-4adb-a09f-21f0f7e3e737,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-f4971243-2d41-478e-831f-e4bc0079da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-319c11b3-a5e9-4db3-a35d-d0244a8af7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-e9af749a-fd34-4e39-a8a1-c7ecd6d78895,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-3da13c98-5335-4cd2-bc7e-991f628f49ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623618747-172.17.0.6-1599316781789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-803e8b79-b22e-4ac3-952e-d46aa86a6502,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-3e6a566f-9b8b-4bc8-b1b1-4e0df69b3402,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-17c138df-67ea-4e34-bf2e-7effe2e4530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-381d87d9-73d0-4339-8b21-d8a0371043ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-321a07bc-1bfd-48b0-bcfb-ac6a015d79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-497ed12c-ecbb-46de-942e-25307da6eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-3e91a6eb-b9b2-4937-a5a1-7d42e8feabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-396050d2-dcfd-4f46-954f-0bba52c3ec63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623618747-172.17.0.6-1599316781789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-803e8b79-b22e-4ac3-952e-d46aa86a6502,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-3e6a566f-9b8b-4bc8-b1b1-4e0df69b3402,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-17c138df-67ea-4e34-bf2e-7effe2e4530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-381d87d9-73d0-4339-8b21-d8a0371043ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-321a07bc-1bfd-48b0-bcfb-ac6a015d79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-497ed12c-ecbb-46de-942e-25307da6eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-3e91a6eb-b9b2-4937-a5a1-7d42e8feabe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-396050d2-dcfd-4f46-954f-0bba52c3ec63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5017
