reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539520121-172.17.0.7-1599354491459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-4f954ce4-9b0b-4398-83d3-a2ca7e93fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-d914a975-bf12-4e83-9744-0eb601a2fe48,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-b5f9b736-cc56-4657-b1b3-a69314e43a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-a30235e9-b3b5-4ad2-a905-80a8bd687066,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3055dabd-0cdb-4f0e-aef3-2595a81f93f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-afbc98f6-3ca3-4aaa-b797-59a47e96933b,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-480188f8-bcb4-4a59-924b-c3aa23177185,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1615ec9b-8416-440e-85b4-61dfccb6649b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539520121-172.17.0.7-1599354491459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-4f954ce4-9b0b-4398-83d3-a2ca7e93fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-d914a975-bf12-4e83-9744-0eb601a2fe48,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-b5f9b736-cc56-4657-b1b3-a69314e43a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-a30235e9-b3b5-4ad2-a905-80a8bd687066,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3055dabd-0cdb-4f0e-aef3-2595a81f93f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-afbc98f6-3ca3-4aaa-b797-59a47e96933b,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-480188f8-bcb4-4a59-924b-c3aa23177185,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1615ec9b-8416-440e-85b4-61dfccb6649b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773369533-172.17.0.7-1599354911662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-9e3e42c5-986b-4617-9b37-fff2292d1f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-b17000d5-b8f3-4b2b-b92f-0638984fbff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-a4c4ecff-13ab-498e-a8cd-b292004e382f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-442351ca-10d1-45cd-b3ad-c61c9ab54d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fc95b3d6-f80d-4f46-bc25-d9148e8d93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-7b7a1be0-d105-482f-82c8-33e9295f4869,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-77fcb18c-2577-4f7d-8b1a-e70abdb0798f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-85021659-dd44-4702-844e-6670e272380a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773369533-172.17.0.7-1599354911662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-9e3e42c5-986b-4617-9b37-fff2292d1f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-b17000d5-b8f3-4b2b-b92f-0638984fbff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-a4c4ecff-13ab-498e-a8cd-b292004e382f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-442351ca-10d1-45cd-b3ad-c61c9ab54d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fc95b3d6-f80d-4f46-bc25-d9148e8d93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-7b7a1be0-d105-482f-82c8-33e9295f4869,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-77fcb18c-2577-4f7d-8b1a-e70abdb0798f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-85021659-dd44-4702-844e-6670e272380a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865222675-172.17.0.7-1599354965891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-af372f18-e2c2-4d20-ad2c-3accfc35e24a,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-25972f17-6b6c-4fae-9a65-9fd21519be3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-e76cb4f9-acae-409c-aa2f-59b923bf4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-1882edde-71d8-4a09-b5c8-bb3392afd224,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c0401bc1-5a05-4d31-93c4-e898cbd5dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-c72794c7-d6d1-48b8-b3fe-b35e6925bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-62158f86-cbe2-4f4d-8ed8-34ff66fa0473,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-28021baa-7e61-47d8-82d5-485ff6fc794a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865222675-172.17.0.7-1599354965891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-af372f18-e2c2-4d20-ad2c-3accfc35e24a,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-25972f17-6b6c-4fae-9a65-9fd21519be3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-e76cb4f9-acae-409c-aa2f-59b923bf4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-1882edde-71d8-4a09-b5c8-bb3392afd224,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-c0401bc1-5a05-4d31-93c4-e898cbd5dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-c72794c7-d6d1-48b8-b3fe-b35e6925bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-62158f86-cbe2-4f4d-8ed8-34ff66fa0473,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-28021baa-7e61-47d8-82d5-485ff6fc794a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934135868-172.17.0.7-1599355074530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-a28792b2-f14d-4ac1-9f95-56b3fcc0d262,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-b63fd9c6-f76d-4bf7-aef7-ab051e8ef416,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-9b10a132-401b-4440-b060-e69d5ff305c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-35edd7cf-ea6a-4bdb-a034-fb3850850175,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a65beeb8-a150-4fcd-9b72-9e3578d46fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-4af66eb7-5ccd-4037-aee1-5db75ad34330,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-1b48d982-a49b-4877-b240-3fd31b073421,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9447c9f9-d8dd-4f50-8965-88b133ed2230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934135868-172.17.0.7-1599355074530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-a28792b2-f14d-4ac1-9f95-56b3fcc0d262,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-b63fd9c6-f76d-4bf7-aef7-ab051e8ef416,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-9b10a132-401b-4440-b060-e69d5ff305c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-35edd7cf-ea6a-4bdb-a034-fb3850850175,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a65beeb8-a150-4fcd-9b72-9e3578d46fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-4af66eb7-5ccd-4037-aee1-5db75ad34330,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-1b48d982-a49b-4877-b240-3fd31b073421,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-9447c9f9-d8dd-4f50-8965-88b133ed2230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670514928-172.17.0.7-1599355200048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-563095b5-cc53-4a45-938c-cda9503c9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-fc831c41-cda0-48f3-b3df-b0fa089c7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-79d374ba-7c27-4f58-9f44-b3b809d844be,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-3c11e4f0-21f2-4a21-be77-2f352e9b098f,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-b4a0f77c-de96-4f7b-aa84-ebe6ad68b946,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-11f87be5-c036-4e5e-97b1-aa5caf849529,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-8c27ac42-a5c5-4cce-a28e-03abf5ff4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-1922d4a3-adb0-407e-a2b4-36dc486fd969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670514928-172.17.0.7-1599355200048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-563095b5-cc53-4a45-938c-cda9503c9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-fc831c41-cda0-48f3-b3df-b0fa089c7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-79d374ba-7c27-4f58-9f44-b3b809d844be,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-3c11e4f0-21f2-4a21-be77-2f352e9b098f,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-b4a0f77c-de96-4f7b-aa84-ebe6ad68b946,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-11f87be5-c036-4e5e-97b1-aa5caf849529,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-8c27ac42-a5c5-4cce-a28e-03abf5ff4d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-1922d4a3-adb0-407e-a2b4-36dc486fd969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405556937-172.17.0.7-1599355373495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-3ef9e201-e056-43a1-b6f6-17a6ab314b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-a612754d-8672-4e0c-bd21-637a4ae20277,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-cf7ecf7e-88b2-4d77-b6c3-c41d0e2070c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-3681f3e6-687c-4fed-b8a1-4a54c32cf450,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e7616237-c7e4-4c89-a0a1-ae1f25929233,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-166e731d-4a66-4e85-8451-c8c90f8b6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-dd0aafeb-520f-4562-8eb7-da05ff05b1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-f513be28-805c-42bb-a8b0-89c5c618d8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405556937-172.17.0.7-1599355373495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-3ef9e201-e056-43a1-b6f6-17a6ab314b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-a612754d-8672-4e0c-bd21-637a4ae20277,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-cf7ecf7e-88b2-4d77-b6c3-c41d0e2070c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-3681f3e6-687c-4fed-b8a1-4a54c32cf450,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e7616237-c7e4-4c89-a0a1-ae1f25929233,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-166e731d-4a66-4e85-8451-c8c90f8b6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-dd0aafeb-520f-4562-8eb7-da05ff05b1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-f513be28-805c-42bb-a8b0-89c5c618d8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116059979-172.17.0.7-1599355695222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-ddbe5842-2435-4032-bd25-e4cf2d7ca7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fbc4e3a1-c6a0-4c80-b2eb-6eea2631ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-9563c45b-8a64-423a-85cf-178621b85ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-24e758b7-cc0e-4c04-ac07-c16625c2d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-6823f540-07c3-4360-ae44-e678b1d2abc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-bdae5d19-6acd-4f6e-b862-d2bc40ec7d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-ba0bf901-eacb-4d14-af9e-6211c13ae59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-0e9a3ab4-fe2e-4cdd-8a7e-204ec21a82e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116059979-172.17.0.7-1599355695222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-ddbe5842-2435-4032-bd25-e4cf2d7ca7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fbc4e3a1-c6a0-4c80-b2eb-6eea2631ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-9563c45b-8a64-423a-85cf-178621b85ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-24e758b7-cc0e-4c04-ac07-c16625c2d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-6823f540-07c3-4360-ae44-e678b1d2abc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-bdae5d19-6acd-4f6e-b862-d2bc40ec7d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-ba0bf901-eacb-4d14-af9e-6211c13ae59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-0e9a3ab4-fe2e-4cdd-8a7e-204ec21a82e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812135252-172.17.0.7-1599356035540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-12994212-7f2e-45dc-a64c-869a0b71632e,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7769fd57-ea1e-4aa2-aef2-6494a3152c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5cfadf1f-cc58-4e5b-9320-18b71248e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-5f464ed0-bb5c-4118-a9aa-70269db6dde9,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-c6066d9a-4523-4ae0-8f55-5017a11cd351,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b42b185e-ab2e-45be-b725-92e89cd8332d,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-98949f7f-eef5-4a68-84f9-74f83610984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-8fb300cc-9a57-4870-a6a0-693e90e93b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812135252-172.17.0.7-1599356035540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-12994212-7f2e-45dc-a64c-869a0b71632e,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7769fd57-ea1e-4aa2-aef2-6494a3152c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5cfadf1f-cc58-4e5b-9320-18b71248e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-5f464ed0-bb5c-4118-a9aa-70269db6dde9,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-c6066d9a-4523-4ae0-8f55-5017a11cd351,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b42b185e-ab2e-45be-b725-92e89cd8332d,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-98949f7f-eef5-4a68-84f9-74f83610984e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-8fb300cc-9a57-4870-a6a0-693e90e93b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211132685-172.17.0.7-1599356488244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-e64dffe6-685d-4194-8bad-2d5c42a8f058,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-1294c9a6-8bf6-43a5-b055-2bd38871f182,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-7474965e-52bc-40b5-82fb-a509cbff15bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-d7345bcc-260d-44fd-9ac3-780d63eba4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-b102ab6f-f660-40f6-95c7-e0c6f8a6141e,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-af9db8c0-17c7-472b-b5ad-428bd6a348cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-7742fc25-19e4-4c9e-bc55-2e3829d292b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-0da6796d-09e0-4b59-87fd-ee5053307094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211132685-172.17.0.7-1599356488244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-e64dffe6-685d-4194-8bad-2d5c42a8f058,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-1294c9a6-8bf6-43a5-b055-2bd38871f182,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-7474965e-52bc-40b5-82fb-a509cbff15bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-d7345bcc-260d-44fd-9ac3-780d63eba4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-b102ab6f-f660-40f6-95c7-e0c6f8a6141e,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-af9db8c0-17c7-472b-b5ad-428bd6a348cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-7742fc25-19e4-4c9e-bc55-2e3829d292b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-0da6796d-09e0-4b59-87fd-ee5053307094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754692691-172.17.0.7-1599356563375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-9f5f9f13-4d31-4124-8c89-9ebedce37ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-5d867b22-c6e8-4c5a-8bf4-27780316746c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ab540862-f96c-4fdf-beef-89b924488ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-62ca543f-9154-4b6e-a5c9-78cc54c16b13,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-b2637676-e235-409a-94be-b1be3e498f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-c5fce992-6488-4452-b4df-5a7d52d9faed,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-36cd3800-b6f6-4b40-85b1-1b66d6d5611d,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c9c8bfda-60c7-495c-82c4-01a843ad93a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754692691-172.17.0.7-1599356563375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-9f5f9f13-4d31-4124-8c89-9ebedce37ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-5d867b22-c6e8-4c5a-8bf4-27780316746c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ab540862-f96c-4fdf-beef-89b924488ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-62ca543f-9154-4b6e-a5c9-78cc54c16b13,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-b2637676-e235-409a-94be-b1be3e498f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-c5fce992-6488-4452-b4df-5a7d52d9faed,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-36cd3800-b6f6-4b40-85b1-1b66d6d5611d,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c9c8bfda-60c7-495c-82c4-01a843ad93a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470236285-172.17.0.7-1599356893417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-3bc95877-c29e-41ea-bd47-884566f6626a,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d036e220-93bf-40a2-b67c-2e527b535b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-eb2a6793-c00b-41f2-95cd-c22a71a820bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-50131b00-a519-4432-8439-4f8d9de6a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b5054355-bf8f-404c-b58d-788c78c7ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-b6c996d9-a15b-4794-80f3-0197b04c311c,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-83e77ff3-e246-473b-a27b-da039d7a0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-fe75fc0f-3809-4e41-a23a-6386a630495d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470236285-172.17.0.7-1599356893417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-3bc95877-c29e-41ea-bd47-884566f6626a,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d036e220-93bf-40a2-b67c-2e527b535b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-eb2a6793-c00b-41f2-95cd-c22a71a820bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-50131b00-a519-4432-8439-4f8d9de6a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-b5054355-bf8f-404c-b58d-788c78c7ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-b6c996d9-a15b-4794-80f3-0197b04c311c,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-83e77ff3-e246-473b-a27b-da039d7a0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-fe75fc0f-3809-4e41-a23a-6386a630495d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499730474-172.17.0.7-1599357151072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-4f33a8c2-bbe9-499b-bc70-b49203c839fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-7043d9d0-13ae-4d7e-910e-4e38aa660d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-e801677f-e642-438d-bc74-cc56f5801795,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-6cfedd56-b5ef-47e4-8085-955e49839174,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e83870b7-cc1c-46ec-bc5b-412b3b837907,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-d3cfeaf6-6471-4e76-b123-e03c5edb6481,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-23a91fe0-0e7f-4edb-bb1d-87386fb7b5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-297737ac-f70d-400b-88fc-d8ded22e8fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499730474-172.17.0.7-1599357151072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-4f33a8c2-bbe9-499b-bc70-b49203c839fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-7043d9d0-13ae-4d7e-910e-4e38aa660d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-e801677f-e642-438d-bc74-cc56f5801795,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-6cfedd56-b5ef-47e4-8085-955e49839174,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e83870b7-cc1c-46ec-bc5b-412b3b837907,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-d3cfeaf6-6471-4e76-b123-e03c5edb6481,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-23a91fe0-0e7f-4edb-bb1d-87386fb7b5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-297737ac-f70d-400b-88fc-d8ded22e8fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250760268-172.17.0.7-1599357226566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-1d9b69f1-6e61-405f-8b05-316025440487,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-7a820025-3cd8-4f82-b77d-c5eecf0b69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-d1b1fa55-1ac4-4798-aa79-591b05668d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-a7d95a17-bd8a-470e-b40f-e844a4bc4c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3448a43e-f1e7-4c7b-9afa-69693c690e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-5f73223f-b53c-4730-875d-ed0aca27f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-c4bbaf7d-5449-448b-938e-9b5ef27c9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-686de075-3b73-4a14-9b7e-84a1925d83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250760268-172.17.0.7-1599357226566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-1d9b69f1-6e61-405f-8b05-316025440487,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-7a820025-3cd8-4f82-b77d-c5eecf0b69bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-d1b1fa55-1ac4-4798-aa79-591b05668d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-a7d95a17-bd8a-470e-b40f-e844a4bc4c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-3448a43e-f1e7-4c7b-9afa-69693c690e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-5f73223f-b53c-4730-875d-ed0aca27f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-c4bbaf7d-5449-448b-938e-9b5ef27c9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-686de075-3b73-4a14-9b7e-84a1925d83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847169761-172.17.0.7-1599357293220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-86913992-49d1-4d5d-bd0f-0d32afd67237,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-8e1700c1-5d55-4a86-b556-aec5d4e8578b,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-c290a10c-865c-4e96-9c81-8900b2e9d108,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-18c5d9ef-16af-4c1d-9636-099870f0521b,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-bef17a41-051f-433f-ae43-6b5722b66f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-bee83123-38ae-49dd-b6f9-de02897dff67,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-e08e89a8-c784-4b5f-b177-8ea828497629,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f9010805-54ca-467e-93b0-75608c5e0242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847169761-172.17.0.7-1599357293220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-86913992-49d1-4d5d-bd0f-0d32afd67237,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-8e1700c1-5d55-4a86-b556-aec5d4e8578b,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-c290a10c-865c-4e96-9c81-8900b2e9d108,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-18c5d9ef-16af-4c1d-9636-099870f0521b,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-bef17a41-051f-433f-ae43-6b5722b66f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-bee83123-38ae-49dd-b6f9-de02897dff67,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-e08e89a8-c784-4b5f-b177-8ea828497629,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f9010805-54ca-467e-93b0-75608c5e0242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583788284-172.17.0.7-1599358101695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-4b349754-1276-4b36-bb73-611141c1cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-e3824960-83b1-4fc5-aebb-540b47d586f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-3fba6388-d250-4676-9a70-5e3cefba0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-a47dae2d-75aa-4481-b85c-3f48b5aeb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-4aef6d63-dace-444c-a80c-fae6e7eec9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-8835383c-01a0-4699-bd86-f9ac64b07b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-318e3d78-0922-4ba4-82e0-ac57eda0cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-18ccc753-065b-4498-814d-b858e4c814a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583788284-172.17.0.7-1599358101695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-4b349754-1276-4b36-bb73-611141c1cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-e3824960-83b1-4fc5-aebb-540b47d586f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-3fba6388-d250-4676-9a70-5e3cefba0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-a47dae2d-75aa-4481-b85c-3f48b5aeb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-4aef6d63-dace-444c-a80c-fae6e7eec9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-8835383c-01a0-4699-bd86-f9ac64b07b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-318e3d78-0922-4ba4-82e0-ac57eda0cf66,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-18ccc753-065b-4498-814d-b858e4c814a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791412162-172.17.0.7-1599358137713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-259a31bc-4c48-4dd8-b6a4-7b337edc202f,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-89a87905-998e-4b70-b7b3-a6a99a6ee088,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-6881cfdd-d918-409b-98da-1a8cd716051d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e5ea90f1-ead1-455e-8439-c31598d6f00b,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-ecb92e36-4c96-42da-ada5-59a323ccb3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-ab71afda-8f56-4cd9-a117-a3f20bce7e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-a25b168b-2597-4ca6-8802-8c2e4942e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-4ac2f8ae-bb90-4543-9dd2-9a809a6f945c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791412162-172.17.0.7-1599358137713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-259a31bc-4c48-4dd8-b6a4-7b337edc202f,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-89a87905-998e-4b70-b7b3-a6a99a6ee088,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-6881cfdd-d918-409b-98da-1a8cd716051d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-e5ea90f1-ead1-455e-8439-c31598d6f00b,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-ecb92e36-4c96-42da-ada5-59a323ccb3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-ab71afda-8f56-4cd9-a117-a3f20bce7e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-a25b168b-2597-4ca6-8802-8c2e4942e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-4ac2f8ae-bb90-4543-9dd2-9a809a6f945c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592133695-172.17.0.7-1599358230962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-aecde446-dc68-4d8c-a276-12e1c7840b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-0808eaf9-eedd-4e42-a7e0-ff1377261eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-03c57b72-74ad-4332-b94d-baac1d62144b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-7ed87211-b128-4306-b290-1398654ba1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-122342ae-b44c-4713-9cd3-70440e5904bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-78623dec-bf2c-4fd2-8baa-c04d64f992f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-0ea29c02-fa27-4fde-9d94-cb6e297cb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-724495b0-b8b7-4f83-a14d-2d8d8e4d0e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592133695-172.17.0.7-1599358230962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-aecde446-dc68-4d8c-a276-12e1c7840b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-0808eaf9-eedd-4e42-a7e0-ff1377261eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-03c57b72-74ad-4332-b94d-baac1d62144b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-7ed87211-b128-4306-b290-1398654ba1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-122342ae-b44c-4713-9cd3-70440e5904bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-78623dec-bf2c-4fd2-8baa-c04d64f992f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-0ea29c02-fa27-4fde-9d94-cb6e297cb5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-724495b0-b8b7-4f83-a14d-2d8d8e4d0e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201860850-172.17.0.7-1599358565882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-8898768e-4432-48e5-81ea-4f0d6910af66,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-f927c79a-e3c4-4b9e-a44d-d1c765141079,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9da3c65c-857e-484b-aa2a-15b3921cbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-e88227e9-2b26-4796-b2a5-93f0b2d71665,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-26e52321-01af-4150-aa24-5e6a1dbe6283,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-01d45875-cb50-4e70-b16e-d10aac0959d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-1f560373-4c44-4a4e-a50f-dadb183ea617,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-de898b22-89c5-438f-91fd-5def6baef0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201860850-172.17.0.7-1599358565882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-8898768e-4432-48e5-81ea-4f0d6910af66,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-f927c79a-e3c4-4b9e-a44d-d1c765141079,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9da3c65c-857e-484b-aa2a-15b3921cbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-e88227e9-2b26-4796-b2a5-93f0b2d71665,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-26e52321-01af-4150-aa24-5e6a1dbe6283,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-01d45875-cb50-4e70-b16e-d10aac0959d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-1f560373-4c44-4a4e-a50f-dadb183ea617,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-de898b22-89c5-438f-91fd-5def6baef0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388022090-172.17.0.7-1599358937265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-ad90ab0d-e78f-4708-bc5a-afb5e5fd5185,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b573009e-6c7e-4450-90c9-4f4f645173f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-5c7dd657-e31b-44c5-95a3-9af4b5ba6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-897e0f72-4999-4561-9c36-5f3f099957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-056bab0d-d404-4bd7-8328-2171497a925c,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-99974304-6a8b-4058-9673-22309e9fbe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-c5330a66-40ae-454a-8c3d-a25e7977f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-e5612645-09bb-438a-bc9a-2454545dfbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388022090-172.17.0.7-1599358937265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-ad90ab0d-e78f-4708-bc5a-afb5e5fd5185,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b573009e-6c7e-4450-90c9-4f4f645173f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-5c7dd657-e31b-44c5-95a3-9af4b5ba6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-897e0f72-4999-4561-9c36-5f3f099957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-056bab0d-d404-4bd7-8328-2171497a925c,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-99974304-6a8b-4058-9673-22309e9fbe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-c5330a66-40ae-454a-8c3d-a25e7977f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-e5612645-09bb-438a-bc9a-2454545dfbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762203906-172.17.0.7-1599359253690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-dc135a01-6bba-4e6a-884e-da88764dd846,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-34c103f0-86ce-44ef-9a83-cd15672d9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-a9d0321c-bc88-4cd6-a118-967dd30e1587,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-749e977d-c997-492d-a164-cbbb315b5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-1416a15e-175f-4f8b-a885-42e71400bc88,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e21bb5d9-83c4-4e6e-9c22-4bd9afa5d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-62c7ce91-9328-441c-b63f-43e665deed93,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-7874f118-3eef-4899-947f-af8ca0e09534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762203906-172.17.0.7-1599359253690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-dc135a01-6bba-4e6a-884e-da88764dd846,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-34c103f0-86ce-44ef-9a83-cd15672d9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-a9d0321c-bc88-4cd6-a118-967dd30e1587,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-749e977d-c997-492d-a164-cbbb315b5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-1416a15e-175f-4f8b-a885-42e71400bc88,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e21bb5d9-83c4-4e6e-9c22-4bd9afa5d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-62c7ce91-9328-441c-b63f-43e665deed93,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-7874f118-3eef-4899-947f-af8ca0e09534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 4943
