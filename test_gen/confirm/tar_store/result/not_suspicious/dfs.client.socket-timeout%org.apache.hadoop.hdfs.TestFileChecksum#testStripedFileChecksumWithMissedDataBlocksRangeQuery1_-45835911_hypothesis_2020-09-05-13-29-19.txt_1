reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198163590-172.17.0.2-1599312968217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-9ecf2c29-b53e-40b2-bae7-16df4d8e77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-534a469d-5ed1-4748-9108-dd338da8ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-cba5295a-985c-4332-8320-04984dea0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-2a003396-0a4b-42c8-b891-7dae88232422,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-09ed4200-4839-465c-8f46-59c3ef08e847,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-0c124fb1-56e8-4fd4-97f7-de3016793367,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-de9a1535-1aea-4f35-a0a7-5da6959135b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-064f2b69-b4eb-4c21-acd0-b0e86489f6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198163590-172.17.0.2-1599312968217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-9ecf2c29-b53e-40b2-bae7-16df4d8e77b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-534a469d-5ed1-4748-9108-dd338da8ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-cba5295a-985c-4332-8320-04984dea0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-2a003396-0a4b-42c8-b891-7dae88232422,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-09ed4200-4839-465c-8f46-59c3ef08e847,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-0c124fb1-56e8-4fd4-97f7-de3016793367,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-de9a1535-1aea-4f35-a0a7-5da6959135b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-064f2b69-b4eb-4c21-acd0-b0e86489f6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845260170-172.17.0.2-1599313097530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-8d98a19b-7ca5-4e10-8d5c-5e7ae0e47712,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-9555089a-f92d-4a5e-a5c2-cb7db2ee64aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-07686540-5356-48de-9ff6-c504b958ef60,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-ba25d622-648e-4c15-b81b-6dd88d703c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-e2bdb13a-47f8-4a6c-be22-0556630c8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-6df0463f-b235-4772-ab9b-e611e01d0cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-957f141d-7a8c-41a7-be4f-a3fbcf3c2251,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-384880c0-16b6-414e-9d22-0afb664bfc82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845260170-172.17.0.2-1599313097530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-8d98a19b-7ca5-4e10-8d5c-5e7ae0e47712,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-9555089a-f92d-4a5e-a5c2-cb7db2ee64aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-07686540-5356-48de-9ff6-c504b958ef60,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-ba25d622-648e-4c15-b81b-6dd88d703c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-e2bdb13a-47f8-4a6c-be22-0556630c8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-6df0463f-b235-4772-ab9b-e611e01d0cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-957f141d-7a8c-41a7-be4f-a3fbcf3c2251,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-384880c0-16b6-414e-9d22-0afb664bfc82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268575730-172.17.0.2-1599313235309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42766,DS-80abc3b2-d684-4ba0-b3a3-80cc08f9a560,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-ba49c75d-35a6-4a95-b77c-c3d02b48af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-96b2e5be-fc52-4113-b9ef-c5a029c9dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-1ee4000f-44da-4a6f-9c6a-677e3c943a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-2bd5b784-dd0f-446e-93dc-e98d4b55b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-6245b0d1-eec7-4a07-a7b5-3cc4bed1a180,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-07bfae89-e242-4ba5-a43f-1e35431c9962,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-c333e06b-5cd8-4fe8-82ba-96f5bacdbde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268575730-172.17.0.2-1599313235309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42766,DS-80abc3b2-d684-4ba0-b3a3-80cc08f9a560,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-ba49c75d-35a6-4a95-b77c-c3d02b48af5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-96b2e5be-fc52-4113-b9ef-c5a029c9dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-1ee4000f-44da-4a6f-9c6a-677e3c943a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-2bd5b784-dd0f-446e-93dc-e98d4b55b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-6245b0d1-eec7-4a07-a7b5-3cc4bed1a180,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-07bfae89-e242-4ba5-a43f-1e35431c9962,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-c333e06b-5cd8-4fe8-82ba-96f5bacdbde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734838628-172.17.0.2-1599313346293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-a239e7be-84bb-4ef2-83bf-4725d6ff5cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-9bc7edcb-79da-4843-869c-92cd78a234a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e6e7543e-d72f-4587-a46a-cef788aa3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-433fae5a-90b8-442e-a3e6-6de0d1e05b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-a9e6cb7e-fd01-4103-ac8d-46c661b29cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-6765677f-04d6-4c4b-924b-88d91b02b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a9b6145e-8feb-4e62-ab22-f4647086e521,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-f4fd4ee6-abd8-41f4-9adf-6f62aa050b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734838628-172.17.0.2-1599313346293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-a239e7be-84bb-4ef2-83bf-4725d6ff5cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-9bc7edcb-79da-4843-869c-92cd78a234a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e6e7543e-d72f-4587-a46a-cef788aa3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-433fae5a-90b8-442e-a3e6-6de0d1e05b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-a9e6cb7e-fd01-4103-ac8d-46c661b29cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-6765677f-04d6-4c4b-924b-88d91b02b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a9b6145e-8feb-4e62-ab22-f4647086e521,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-f4fd4ee6-abd8-41f4-9adf-6f62aa050b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58876697-172.17.0.2-1599313410714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-7f75d074-077c-4d54-bfad-8d3b9b3dceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3b1624d1-05d2-4c85-86ad-84da621e9968,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2a0c2664-052c-47b4-bf27-468b484609cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-7caefc34-7462-4a66-9094-de49bce5aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b3ad34e5-d75d-471a-a9f0-21726c17ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-de60afeb-83b8-4a45-869b-a6606d0c8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-336945c0-bbd2-4033-838c-62002ae2bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-18c7da20-17d6-44be-83e7-ae5b0b2edaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58876697-172.17.0.2-1599313410714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-7f75d074-077c-4d54-bfad-8d3b9b3dceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3b1624d1-05d2-4c85-86ad-84da621e9968,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2a0c2664-052c-47b4-bf27-468b484609cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-7caefc34-7462-4a66-9094-de49bce5aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b3ad34e5-d75d-471a-a9f0-21726c17ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-de60afeb-83b8-4a45-869b-a6606d0c8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-336945c0-bbd2-4033-838c-62002ae2bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-18c7da20-17d6-44be-83e7-ae5b0b2edaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828496402-172.17.0.2-1599313616880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-d16d088f-39ab-4a1b-8d82-60c5c5bf3f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-59fb5446-7feb-4265-9049-f63df7b2981d,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-0dae675b-1ba4-4950-bf1d-d45dae0f536a,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-01d904d8-b866-48f0-b010-9b752985543e,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-70e1ad92-8edf-4b0f-ab13-4be41e3e8725,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-06af20a3-c044-4c7b-97e6-e86a119c6c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-257edd64-b15a-4a9f-bec1-c45c8b8c935d,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-e17d0c8f-523a-40d1-8e35-ff88a87b2e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828496402-172.17.0.2-1599313616880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-d16d088f-39ab-4a1b-8d82-60c5c5bf3f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-59fb5446-7feb-4265-9049-f63df7b2981d,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-0dae675b-1ba4-4950-bf1d-d45dae0f536a,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-01d904d8-b866-48f0-b010-9b752985543e,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-70e1ad92-8edf-4b0f-ab13-4be41e3e8725,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-06af20a3-c044-4c7b-97e6-e86a119c6c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-257edd64-b15a-4a9f-bec1-c45c8b8c935d,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-e17d0c8f-523a-40d1-8e35-ff88a87b2e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217143169-172.17.0.2-1599314215538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33030,DS-9aab5144-89c2-4cd2-b3de-ee0ed5a8c681,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-42b091ab-f0bc-4b4c-9e8e-0d320d92bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1f3413ff-0e50-40b7-920e-9a9bad8cb132,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-98b97f0d-6a8e-497c-a332-21bf5d2bd68b,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-1112c4e6-ec26-4714-9cc4-a3bd6f2bfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2d4aaf68-571b-43f8-8b60-04a0ceb589a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-36e67bc4-ada2-497a-9661-e00d43f17c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-a0ea2fad-acc9-4b35-bec4-b6e4bc00f89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217143169-172.17.0.2-1599314215538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33030,DS-9aab5144-89c2-4cd2-b3de-ee0ed5a8c681,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-42b091ab-f0bc-4b4c-9e8e-0d320d92bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1f3413ff-0e50-40b7-920e-9a9bad8cb132,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-98b97f0d-6a8e-497c-a332-21bf5d2bd68b,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-1112c4e6-ec26-4714-9cc4-a3bd6f2bfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2d4aaf68-571b-43f8-8b60-04a0ceb589a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-36e67bc4-ada2-497a-9661-e00d43f17c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-a0ea2fad-acc9-4b35-bec4-b6e4bc00f89c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088681110-172.17.0.2-1599314246040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38898,DS-a995d2ff-36ff-433d-943a-d77026db6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-e11b5df7-0c1c-44c5-ab9e-3c29e88ee16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-c344c4e2-e9e6-4763-9fe5-aaa81cd5ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-47f76e7e-c2ae-44d7-bf68-78302fd3c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-af11e74b-a869-4c6d-9a0d-8d17d3274eba,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-bf54571c-7e21-4337-9e43-ac48c0f2b625,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-72dedfb0-7456-4d2b-aacd-c6fc02fb1675,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-d42aa0f1-6868-4357-a760-30dff8b00b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088681110-172.17.0.2-1599314246040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38898,DS-a995d2ff-36ff-433d-943a-d77026db6c24,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-e11b5df7-0c1c-44c5-ab9e-3c29e88ee16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-c344c4e2-e9e6-4763-9fe5-aaa81cd5ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-47f76e7e-c2ae-44d7-bf68-78302fd3c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-af11e74b-a869-4c6d-9a0d-8d17d3274eba,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-bf54571c-7e21-4337-9e43-ac48c0f2b625,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-72dedfb0-7456-4d2b-aacd-c6fc02fb1675,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-d42aa0f1-6868-4357-a760-30dff8b00b08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151386037-172.17.0.2-1599314627293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-75d7b6a7-35be-4ab8-9965-8486e9c1e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-26f86402-f9f9-4f49-b305-3a8d23a898df,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-1b48b15a-0e2e-4bf7-883c-0e280bcdac38,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-fd7b40c4-3d32-4541-813f-386ba746ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-dab74666-546e-4c1a-bcb6-a9b313e7ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-28b0e3ae-7c50-41a9-9c04-95d8fab1fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-9665ea9b-f15a-4179-aea1-78b27fc7bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-58abca1a-b221-436e-b639-86f3bc45050c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151386037-172.17.0.2-1599314627293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-75d7b6a7-35be-4ab8-9965-8486e9c1e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-26f86402-f9f9-4f49-b305-3a8d23a898df,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-1b48b15a-0e2e-4bf7-883c-0e280bcdac38,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-fd7b40c4-3d32-4541-813f-386ba746ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-dab74666-546e-4c1a-bcb6-a9b313e7ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-28b0e3ae-7c50-41a9-9c04-95d8fab1fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-9665ea9b-f15a-4179-aea1-78b27fc7bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-58abca1a-b221-436e-b639-86f3bc45050c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719371310-172.17.0.2-1599315272770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-b257a244-c105-4679-a5b8-330039b5e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-85538bd0-cc87-4f6a-8a5b-083f68fed1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-69005a14-f6dd-4a71-a958-184531c2e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-676b60d9-0bd9-4cc5-b7cd-13242c846c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e5d20160-26b1-4d91-b6bb-a72b5abbe9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-5deaa600-0104-4404-9ae7-11d614af470d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-1eda37c6-feba-4d39-bb78-80bd44e0730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-01892181-cbd6-4b6f-99ec-862d712a2d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719371310-172.17.0.2-1599315272770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-b257a244-c105-4679-a5b8-330039b5e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-85538bd0-cc87-4f6a-8a5b-083f68fed1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-69005a14-f6dd-4a71-a958-184531c2e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-676b60d9-0bd9-4cc5-b7cd-13242c846c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e5d20160-26b1-4d91-b6bb-a72b5abbe9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-5deaa600-0104-4404-9ae7-11d614af470d,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-1eda37c6-feba-4d39-bb78-80bd44e0730a,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-01892181-cbd6-4b6f-99ec-862d712a2d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742642158-172.17.0.2-1599315450733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36576,DS-fa9c8c98-d355-45b8-9394-38033c5e111a,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-65c3914f-591e-40ac-9fcd-9f51591d73f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-6f2af96f-a9db-41d8-96a7-3b64ab230f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-515d3cd8-11f0-4254-93c2-e2e43f737f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d45a0714-d89e-4d07-a78e-e6d6d62db5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-fd550974-906f-4aeb-a079-6aa4f177b371,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-176caa7b-4e68-411b-a24e-be1795e984c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ce3ee0b5-d597-43e3-a412-a666481ebc79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742642158-172.17.0.2-1599315450733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36576,DS-fa9c8c98-d355-45b8-9394-38033c5e111a,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-65c3914f-591e-40ac-9fcd-9f51591d73f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-6f2af96f-a9db-41d8-96a7-3b64ab230f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-515d3cd8-11f0-4254-93c2-e2e43f737f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d45a0714-d89e-4d07-a78e-e6d6d62db5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-fd550974-906f-4aeb-a079-6aa4f177b371,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-176caa7b-4e68-411b-a24e-be1795e984c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ce3ee0b5-d597-43e3-a412-a666481ebc79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817535271-172.17.0.2-1599316381232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-f7fad0d7-d1ab-45af-9457-d6cd6a2862be,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-39e82cbd-6d1c-4928-bce4-80fe2c7a0994,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-da6e64a8-1ab4-4ecf-a5c1-2c4ef9dc0d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-ce9ac6d3-2f90-429b-b623-74697c0a6081,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-5db70f8a-e09b-4198-9851-60ff0cb0aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-584b1b22-3e65-4836-a1b3-99ca85c26388,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-0d010d4a-d61c-4ccf-b7c2-0aa6bae2fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-cd09f7b0-d4e6-49ca-b66c-dc07bafa9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817535271-172.17.0.2-1599316381232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-f7fad0d7-d1ab-45af-9457-d6cd6a2862be,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-39e82cbd-6d1c-4928-bce4-80fe2c7a0994,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-da6e64a8-1ab4-4ecf-a5c1-2c4ef9dc0d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-ce9ac6d3-2f90-429b-b623-74697c0a6081,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-5db70f8a-e09b-4198-9851-60ff0cb0aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-584b1b22-3e65-4836-a1b3-99ca85c26388,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-0d010d4a-d61c-4ccf-b7c2-0aa6bae2fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-cd09f7b0-d4e6-49ca-b66c-dc07bafa9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554122892-172.17.0.2-1599316753422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-ba3eaf1d-798d-4786-9ca7-e9be462db342,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e3f7f957-6c3c-4cc5-a85b-9a8a5f21dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-c366aa19-8565-4138-9d4a-0866e77a94d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-213d91b7-c809-442d-bb1d-e5015482c876,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-cdb43755-bfa9-4d1e-9d81-960f9adbf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-279391a7-9972-455d-a81f-0bb7fda06990,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-bbde200b-7a73-4325-b0e8-65857e5414c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-8bf62e22-31b8-4203-ab7c-bdb64260a2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554122892-172.17.0.2-1599316753422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-ba3eaf1d-798d-4786-9ca7-e9be462db342,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e3f7f957-6c3c-4cc5-a85b-9a8a5f21dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-c366aa19-8565-4138-9d4a-0866e77a94d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-213d91b7-c809-442d-bb1d-e5015482c876,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-cdb43755-bfa9-4d1e-9d81-960f9adbf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-279391a7-9972-455d-a81f-0bb7fda06990,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-bbde200b-7a73-4325-b0e8-65857e5414c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-8bf62e22-31b8-4203-ab7c-bdb64260a2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366809082-172.17.0.2-1599316781404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-03f0232b-77aa-4c5d-8be6-f5e7f4ae5ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-d109b93c-5a27-4769-8ba5-32a83467691e,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-c2299a81-fbc7-4448-9bd8-fbe263479dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-3fd60fd9-3f1b-46e9-8708-691cb757d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-a1006bf5-1cf4-4ca1-9cc9-84299c07e064,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f54fff3f-d674-4f6c-b51a-f4871e6a3dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-cdf17d6b-99c3-4237-a33b-35ac52deaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-9e7295e9-f5c4-4a9f-bc11-a09b74a7e61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366809082-172.17.0.2-1599316781404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46053,DS-03f0232b-77aa-4c5d-8be6-f5e7f4ae5ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-d109b93c-5a27-4769-8ba5-32a83467691e,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-c2299a81-fbc7-4448-9bd8-fbe263479dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-3fd60fd9-3f1b-46e9-8708-691cb757d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-a1006bf5-1cf4-4ca1-9cc9-84299c07e064,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-f54fff3f-d674-4f6c-b51a-f4871e6a3dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-cdf17d6b-99c3-4237-a33b-35ac52deaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-9e7295e9-f5c4-4a9f-bc11-a09b74a7e61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578828520-172.17.0.2-1599317081433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-80c681c9-4206-4957-9f64-9113c2bd1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-0b660121-f798-4c24-9c70-1ca070c449ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-d031ad51-cd81-4eb3-81e1-746902e9d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-21cc1b73-bd3d-40c4-9153-90e64d252645,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-0a4633ec-9db7-4918-a77c-8e9fae8c3ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-f993dc4a-d241-4c99-a20e-436573fc6db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b8e645bc-8de8-4d03-a32c-e8e2d5e66556,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-4be03a2d-bb05-4622-8686-26f7997856ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578828520-172.17.0.2-1599317081433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-80c681c9-4206-4957-9f64-9113c2bd1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-0b660121-f798-4c24-9c70-1ca070c449ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-d031ad51-cd81-4eb3-81e1-746902e9d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-21cc1b73-bd3d-40c4-9153-90e64d252645,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-0a4633ec-9db7-4918-a77c-8e9fae8c3ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-f993dc4a-d241-4c99-a20e-436573fc6db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b8e645bc-8de8-4d03-a32c-e8e2d5e66556,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-4be03a2d-bb05-4622-8686-26f7997856ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4539
