reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728645534-172.17.0.15-1599326019118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-1f869884-a211-4fad-92e3-5973d08b8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-a7288676-71d8-4ad1-ab5d-1944486f10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2f5e0dc5-c5fc-4ad2-8980-93d277dc56ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e7a580b0-38b1-43e8-88bc-202a764ec729,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-b24c4531-6644-4939-a6ab-91faf0a73e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-5ed1701b-7ae5-4a4f-8dad-858dc211034e,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-382bfafd-9992-4307-a2eb-de950e503cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-ecd5a262-4d44-479e-a8bb-f45edb096227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728645534-172.17.0.15-1599326019118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-1f869884-a211-4fad-92e3-5973d08b8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-a7288676-71d8-4ad1-ab5d-1944486f10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-2f5e0dc5-c5fc-4ad2-8980-93d277dc56ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e7a580b0-38b1-43e8-88bc-202a764ec729,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-b24c4531-6644-4939-a6ab-91faf0a73e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-5ed1701b-7ae5-4a4f-8dad-858dc211034e,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-382bfafd-9992-4307-a2eb-de950e503cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-ecd5a262-4d44-479e-a8bb-f45edb096227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962942694-172.17.0.15-1599326524686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-2151254c-15d2-4200-8327-8df8f852369f,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-6c6fc155-fe60-4877-99f1-70279da01198,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-dbdbfdff-e636-4241-b27e-e9ab5eb13580,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-df6474da-518a-462c-92a1-c2083431815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4e2040d0-87ac-4f39-a071-5c3393655350,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-ff214db9-9031-4599-a349-7a77e57c73a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-5e2005f4-244b-4e89-af4e-af2c0429dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-964d4b7d-e5cd-43cb-bb60-f043f719667f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962942694-172.17.0.15-1599326524686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-2151254c-15d2-4200-8327-8df8f852369f,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-6c6fc155-fe60-4877-99f1-70279da01198,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-dbdbfdff-e636-4241-b27e-e9ab5eb13580,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-df6474da-518a-462c-92a1-c2083431815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-4e2040d0-87ac-4f39-a071-5c3393655350,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-ff214db9-9031-4599-a349-7a77e57c73a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-5e2005f4-244b-4e89-af4e-af2c0429dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-964d4b7d-e5cd-43cb-bb60-f043f719667f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126347169-172.17.0.15-1599326959484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-350e2955-a137-423d-b1bd-87e9479433d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-883bf341-45f9-4371-92a7-353c31b4dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-70642c6e-ec37-4bf4-93e0-c379cc33eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d8606385-c56b-4070-b5b3-cefe4b4a104b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-dc60ac0e-711c-455f-b93e-26b3e35f1472,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-9d64b50a-b59a-4f70-9641-c03410d82341,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-17669f4c-ade3-4fc6-bd3b-ce5c11ead2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-795eac70-83d7-4809-bfc1-9770c442974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126347169-172.17.0.15-1599326959484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-350e2955-a137-423d-b1bd-87e9479433d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-883bf341-45f9-4371-92a7-353c31b4dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-70642c6e-ec37-4bf4-93e0-c379cc33eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d8606385-c56b-4070-b5b3-cefe4b4a104b,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-dc60ac0e-711c-455f-b93e-26b3e35f1472,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-9d64b50a-b59a-4f70-9641-c03410d82341,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-17669f4c-ade3-4fc6-bd3b-ce5c11ead2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-795eac70-83d7-4809-bfc1-9770c442974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740811578-172.17.0.15-1599327369557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-5cb8dcbf-168f-4742-b461-f8ecfa1a08d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-37e5e952-7f4c-4b6b-82a7-cb49cc327c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-bd296b0d-c839-4e4e-a138-f00dbdc24787,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8c9e9e65-e8cf-4d54-a226-c7a8c872ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-a19c7a66-f70a-4358-80a9-4583aa049ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-ce9b75b3-81f5-4b5a-b720-0ac22422e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-7cca75eb-aba1-4e23-b7dd-f299db9a6bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-ff49a719-8683-4e6b-b9d4-c2f8259feb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740811578-172.17.0.15-1599327369557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-5cb8dcbf-168f-4742-b461-f8ecfa1a08d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-37e5e952-7f4c-4b6b-82a7-cb49cc327c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-bd296b0d-c839-4e4e-a138-f00dbdc24787,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8c9e9e65-e8cf-4d54-a226-c7a8c872ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-a19c7a66-f70a-4358-80a9-4583aa049ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-ce9b75b3-81f5-4b5a-b720-0ac22422e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-7cca75eb-aba1-4e23-b7dd-f299db9a6bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-ff49a719-8683-4e6b-b9d4-c2f8259feb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090058585-172.17.0.15-1599327753406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-4cb3e187-29e5-409e-82db-010c0ba38fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5df54364-c480-4a48-bca6-73300d9838dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-17d14f30-2161-4b59-a816-bfde00d82782,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-f415e11b-0842-471a-ae33-d4e38779ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-75cc14c7-fa20-451f-ab49-047375ab9d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-5051c652-c026-4725-841e-f1ae0257cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-7051d0e2-3479-4fc4-85fe-15544a40eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-819e56b4-8eeb-444e-ac22-a6b4d2e11c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090058585-172.17.0.15-1599327753406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-4cb3e187-29e5-409e-82db-010c0ba38fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5df54364-c480-4a48-bca6-73300d9838dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-17d14f30-2161-4b59-a816-bfde00d82782,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-f415e11b-0842-471a-ae33-d4e38779ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-75cc14c7-fa20-451f-ab49-047375ab9d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-5051c652-c026-4725-841e-f1ae0257cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-7051d0e2-3479-4fc4-85fe-15544a40eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-819e56b4-8eeb-444e-ac22-a6b4d2e11c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917458351-172.17.0.15-1599328278244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46529,DS-6fdf4ed9-b668-4eb5-b19d-b4b75b033b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-1fc432f4-656f-4b8f-b354-ec4d23b71671,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-1e85f190-4d4e-4058-9d6b-5f627000693d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2acd43bf-3ebb-43a5-a07b-8097e2338e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-0b630fb7-fb40-429a-b714-12636a91daca,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1a7d13a9-39bc-4571-9714-c031ec5c2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-beb833f5-04af-4a01-befc-0809b77d94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-38433a24-64a9-4cdc-a5e5-1d8461afe883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917458351-172.17.0.15-1599328278244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46529,DS-6fdf4ed9-b668-4eb5-b19d-b4b75b033b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-1fc432f4-656f-4b8f-b354-ec4d23b71671,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-1e85f190-4d4e-4058-9d6b-5f627000693d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2acd43bf-3ebb-43a5-a07b-8097e2338e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-0b630fb7-fb40-429a-b714-12636a91daca,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1a7d13a9-39bc-4571-9714-c031ec5c2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-beb833f5-04af-4a01-befc-0809b77d94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-38433a24-64a9-4cdc-a5e5-1d8461afe883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153479993-172.17.0.15-1599328388406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46793,DS-fd89d2e9-516a-405a-8490-c5b4ccdf7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ebf7ce6f-021a-44ec-8e51-9d87a25cd68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-b489992c-d658-4d1c-9331-038dd943e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-01e95282-d96e-43ba-a164-797eb54ac715,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-869a48d1-1934-44a9-974b-0c9fece1b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c468a7f0-261a-48d2-9d9c-0a66ba21b089,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-2bc8b7e8-d47f-4bc5-a8f7-4b7f9923ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-823cf38a-4688-49f0-a913-547ae95d2093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153479993-172.17.0.15-1599328388406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46793,DS-fd89d2e9-516a-405a-8490-c5b4ccdf7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ebf7ce6f-021a-44ec-8e51-9d87a25cd68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-b489992c-d658-4d1c-9331-038dd943e98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-01e95282-d96e-43ba-a164-797eb54ac715,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-869a48d1-1934-44a9-974b-0c9fece1b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c468a7f0-261a-48d2-9d9c-0a66ba21b089,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-2bc8b7e8-d47f-4bc5-a8f7-4b7f9923ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-823cf38a-4688-49f0-a913-547ae95d2093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598861422-172.17.0.15-1599328552028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-a4e1e476-5593-4dc3-b630-b4fd38f0174f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-81bcc4ab-6463-47e1-a75f-03798e810769,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-14d46339-5d39-43e1-8167-6b1222433313,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-1dfc412b-9dd6-43f2-aadb-85e6d93785a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-2113714b-4592-4b5f-a4cb-e15b9dd0ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-8b195110-c0de-4c77-81ed-1de884da5bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-df1ade73-66c3-4464-9d63-64f22d82b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-113d2bac-dd18-4002-ab91-a95e5c8796f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598861422-172.17.0.15-1599328552028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-a4e1e476-5593-4dc3-b630-b4fd38f0174f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-81bcc4ab-6463-47e1-a75f-03798e810769,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-14d46339-5d39-43e1-8167-6b1222433313,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-1dfc412b-9dd6-43f2-aadb-85e6d93785a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-2113714b-4592-4b5f-a4cb-e15b9dd0ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-8b195110-c0de-4c77-81ed-1de884da5bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-df1ade73-66c3-4464-9d63-64f22d82b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-113d2bac-dd18-4002-ab91-a95e5c8796f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880263306-172.17.0.15-1599328728529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-2c2bb2f8-9387-4d67-bb1e-04d49418916f,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-cf5f921c-e133-47ca-9034-2a62b10f0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-9730f6bc-a873-4fd5-88b4-2037693a40db,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-cceed14c-bf58-4a08-ab8f-45a9d72f5882,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-e197c0d7-9b8d-4c9c-9293-f8b747a80e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-3bdb40e7-6254-41aa-a80f-98e405f403db,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-94b867a7-c3f8-4f61-bdf2-0d875db1a485,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-1ac3d3fe-4b88-4a64-9883-a79534c32e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880263306-172.17.0.15-1599328728529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-2c2bb2f8-9387-4d67-bb1e-04d49418916f,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-cf5f921c-e133-47ca-9034-2a62b10f0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-9730f6bc-a873-4fd5-88b4-2037693a40db,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-cceed14c-bf58-4a08-ab8f-45a9d72f5882,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-e197c0d7-9b8d-4c9c-9293-f8b747a80e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-3bdb40e7-6254-41aa-a80f-98e405f403db,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-94b867a7-c3f8-4f61-bdf2-0d875db1a485,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-1ac3d3fe-4b88-4a64-9883-a79534c32e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223710476-172.17.0.15-1599329145287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-8d965784-fe94-43cc-a75f-c6ed51d8be35,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-625725fc-d293-46e5-bd94-f7736094d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-a108fa7a-47cd-4dd8-8606-4a9f8a97d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-5a441a5d-d890-4ff8-bf83-7ec703ef9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-33f896ed-1546-4cc5-810e-a657a7604428,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-530657f7-8e2c-435c-bf5d-c67ee3366bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-991848c2-1154-41d3-b4e9-78dd1abf4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-779e8cdb-e555-4ad8-8fdb-93b2ceefaa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223710476-172.17.0.15-1599329145287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-8d965784-fe94-43cc-a75f-c6ed51d8be35,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-625725fc-d293-46e5-bd94-f7736094d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-a108fa7a-47cd-4dd8-8606-4a9f8a97d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-5a441a5d-d890-4ff8-bf83-7ec703ef9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-33f896ed-1546-4cc5-810e-a657a7604428,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-530657f7-8e2c-435c-bf5d-c67ee3366bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-991848c2-1154-41d3-b4e9-78dd1abf4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-779e8cdb-e555-4ad8-8fdb-93b2ceefaa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87876683-172.17.0.15-1599329503450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-3c672682-bc54-4131-bb08-57a25b454d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-bf2294b4-823a-413b-837d-3cc8312a826d,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-713b215b-35ed-491f-bbe7-3aaaeba41fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-d4b3458b-f95a-413c-bc38-8c2adaa0b41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-19be9a83-86b4-417d-b91c-88a9c4db4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-e2f14881-f314-4ede-b081-c9b17421954c,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-609d78b6-6d2f-432c-8f98-32fae35fc328,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f03ff374-735d-4271-b310-ba61c992a35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87876683-172.17.0.15-1599329503450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-3c672682-bc54-4131-bb08-57a25b454d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-bf2294b4-823a-413b-837d-3cc8312a826d,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-713b215b-35ed-491f-bbe7-3aaaeba41fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-d4b3458b-f95a-413c-bc38-8c2adaa0b41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-19be9a83-86b4-417d-b91c-88a9c4db4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-e2f14881-f314-4ede-b081-c9b17421954c,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-609d78b6-6d2f-432c-8f98-32fae35fc328,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f03ff374-735d-4271-b310-ba61c992a35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67948218-172.17.0.15-1599330699476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-58a3dc4c-147b-4da2-a839-0f617734afde,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-18e24eb2-7258-4533-bc61-3f2b152fa4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-e116cba3-bbc2-4370-9b61-7b7c67c153f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-b1b7989b-c6ce-4600-b690-a201de33c934,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-3e22dbf1-9f21-44e3-986c-ea0b155437e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-21609528-9388-4728-8038-e64695c373fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-9cde1919-91c9-4694-997e-380257bbe831,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-56dda3ce-0120-4342-ae84-51a4c5b4e241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67948218-172.17.0.15-1599330699476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-58a3dc4c-147b-4da2-a839-0f617734afde,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-18e24eb2-7258-4533-bc61-3f2b152fa4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-e116cba3-bbc2-4370-9b61-7b7c67c153f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-b1b7989b-c6ce-4600-b690-a201de33c934,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-3e22dbf1-9f21-44e3-986c-ea0b155437e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-21609528-9388-4728-8038-e64695c373fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-9cde1919-91c9-4694-997e-380257bbe831,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-56dda3ce-0120-4342-ae84-51a4c5b4e241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544295472-172.17.0.15-1599330926125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-3758dbc5-5287-4a25-8dde-2864590ebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-30cb9238-0477-408b-afe7-fd46c2dc1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-48c17d60-0d88-4324-b2a7-43ef6f77f315,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-448b5b67-69ff-4363-a291-3da7cdacf5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-87c33ff4-73e3-4da4-ab08-fea75556b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-fcd0a771-b7ab-424e-b281-2c036f52572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-ed750c99-3e00-4988-8e79-9ed20051d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c56d26ae-44df-406e-953a-9d39dc1696dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544295472-172.17.0.15-1599330926125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-3758dbc5-5287-4a25-8dde-2864590ebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-30cb9238-0477-408b-afe7-fd46c2dc1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-48c17d60-0d88-4324-b2a7-43ef6f77f315,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-448b5b67-69ff-4363-a291-3da7cdacf5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-87c33ff4-73e3-4da4-ab08-fea75556b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-fcd0a771-b7ab-424e-b281-2c036f52572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-ed750c99-3e00-4988-8e79-9ed20051d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c56d26ae-44df-406e-953a-9d39dc1696dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55750188-172.17.0.15-1599331146160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-e178fb8e-4fe2-40a5-ba68-f8eade353070,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-490a7525-2e53-43f0-96d0-1df4d18d2140,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-17c3eda9-8b46-42d6-939d-75286f7bbbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ccca5a49-4130-4456-ba6d-b422dab9cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-33261a02-abd4-4b9f-b572-2d0872f70bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e8508b34-d02e-4767-8270-9e643bcfc65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6bee610d-365f-4dd1-ac2f-82b22efc0960,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-20f3a05d-6483-4b03-a902-413882354ad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55750188-172.17.0.15-1599331146160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-e178fb8e-4fe2-40a5-ba68-f8eade353070,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-490a7525-2e53-43f0-96d0-1df4d18d2140,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-17c3eda9-8b46-42d6-939d-75286f7bbbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ccca5a49-4130-4456-ba6d-b422dab9cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-33261a02-abd4-4b9f-b572-2d0872f70bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e8508b34-d02e-4767-8270-9e643bcfc65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6bee610d-365f-4dd1-ac2f-82b22efc0960,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-20f3a05d-6483-4b03-a902-413882354ad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209805005-172.17.0.15-1599331213251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-7af4e92a-f86f-4eef-b5be-bb53df14e741,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-a134a227-df80-4976-9215-a8261d798d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-06e829d8-b0f3-4f62-b6dd-f29b8c43a156,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-3a41061f-02df-4fdd-94aa-7d2eea37c5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-21a1e86a-2234-432a-8613-e91eb9f280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-2cebbc94-3576-44f8-9f2b-2ca030976629,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8e579d29-e989-496d-8edf-1db968d4f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1005fdcf-b27d-499e-8e4c-fb44ac5c705a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209805005-172.17.0.15-1599331213251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43042,DS-7af4e92a-f86f-4eef-b5be-bb53df14e741,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-a134a227-df80-4976-9215-a8261d798d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-06e829d8-b0f3-4f62-b6dd-f29b8c43a156,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-3a41061f-02df-4fdd-94aa-7d2eea37c5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-21a1e86a-2234-432a-8613-e91eb9f280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-2cebbc94-3576-44f8-9f2b-2ca030976629,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8e579d29-e989-496d-8edf-1db968d4f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1005fdcf-b27d-499e-8e4c-fb44ac5c705a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5380
