reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38479558-172.17.0.19-1599382310927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-9612eca2-c49a-4008-9708-81bbbed88083,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-10f176c3-66b4-4c51-acc3-a5ac235404fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-0a2c463e-cf27-4507-8f99-26d1c085fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-7c6fe683-1e1c-49d8-9b59-94fb7729a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-5eb88e2d-7671-4e8e-9b28-ffbf3b531a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-efe4e933-3ad2-4e2e-944f-8c4c3b38aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-c023136f-d173-477e-b245-505b43fc4e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-07cf4ddf-76c2-49d0-a1ac-ea9492a6d354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38479558-172.17.0.19-1599382310927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-9612eca2-c49a-4008-9708-81bbbed88083,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-10f176c3-66b4-4c51-acc3-a5ac235404fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-0a2c463e-cf27-4507-8f99-26d1c085fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-7c6fe683-1e1c-49d8-9b59-94fb7729a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-5eb88e2d-7671-4e8e-9b28-ffbf3b531a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-efe4e933-3ad2-4e2e-944f-8c4c3b38aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-c023136f-d173-477e-b245-505b43fc4e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-07cf4ddf-76c2-49d0-a1ac-ea9492a6d354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188459117-172.17.0.19-1599382357811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-5f5ae64a-c499-4251-92b4-18697499e971,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-108cf603-750c-4dee-a240-ea00cc88dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-93bf1e21-8fe1-4697-ab5a-00cd4e0a2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-33cb45ca-d71f-4717-b829-ff709fa47545,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-d58abdf0-e46c-4528-ac30-5629d8cd285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-cf5a1122-48fc-40ac-89c3-9386804fd617,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-7001098e-f40b-40e8-8bf3-5c44757de22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5975c4da-2d12-41e0-820e-19ffb109368e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188459117-172.17.0.19-1599382357811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-5f5ae64a-c499-4251-92b4-18697499e971,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-108cf603-750c-4dee-a240-ea00cc88dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-93bf1e21-8fe1-4697-ab5a-00cd4e0a2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-33cb45ca-d71f-4717-b829-ff709fa47545,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-d58abdf0-e46c-4528-ac30-5629d8cd285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-cf5a1122-48fc-40ac-89c3-9386804fd617,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-7001098e-f40b-40e8-8bf3-5c44757de22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-5975c4da-2d12-41e0-820e-19ffb109368e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710177280-172.17.0.19-1599382417500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42444,DS-668bcc36-23f4-4570-85e1-1dd7a86cbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-dd329cf3-c734-4aa2-b195-e3c090de41cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-3dba687c-51e5-48b4-b1b5-4176ab5450f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-edb1b7cc-3a53-4b71-8bf2-4ebc566aecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-f4a45351-30a0-4c6e-867d-1dc2a2d9abf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-c8ee8170-9b9d-4d85-a40b-1bf4f347b381,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-84333fdf-9be4-4f07-86c2-72221d4b4666,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-70fa1b27-0635-4e70-a878-8fe2d71eca3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710177280-172.17.0.19-1599382417500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42444,DS-668bcc36-23f4-4570-85e1-1dd7a86cbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-dd329cf3-c734-4aa2-b195-e3c090de41cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-3dba687c-51e5-48b4-b1b5-4176ab5450f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-edb1b7cc-3a53-4b71-8bf2-4ebc566aecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-f4a45351-30a0-4c6e-867d-1dc2a2d9abf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-c8ee8170-9b9d-4d85-a40b-1bf4f347b381,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-84333fdf-9be4-4f07-86c2-72221d4b4666,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-70fa1b27-0635-4e70-a878-8fe2d71eca3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160033447-172.17.0.19-1599382494033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46213,DS-69ddca35-fc29-4e06-a023-489655eeeb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8faaf67b-ec65-418f-aed3-453bb5b61267,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-19ef9194-d80d-47b1-ae72-0168c522d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1ddf2968-88c9-44c9-9f9b-a66686e41183,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9417a4ff-cfba-4ebd-b995-8409c58ec40e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-172293f5-b789-4505-97f5-0302749c8628,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-895c22bb-6f99-42c4-a959-00129117b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-14d1cc07-e131-4277-b3fe-875642a85700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160033447-172.17.0.19-1599382494033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46213,DS-69ddca35-fc29-4e06-a023-489655eeeb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8faaf67b-ec65-418f-aed3-453bb5b61267,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-19ef9194-d80d-47b1-ae72-0168c522d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1ddf2968-88c9-44c9-9f9b-a66686e41183,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9417a4ff-cfba-4ebd-b995-8409c58ec40e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-172293f5-b789-4505-97f5-0302749c8628,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-895c22bb-6f99-42c4-a959-00129117b55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-14d1cc07-e131-4277-b3fe-875642a85700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856889864-172.17.0.19-1599382796712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39135,DS-61edb4ea-050c-40d0-9061-1245b96cb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-b5f0481a-94bf-4073-b4d8-a9e2197e4675,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-93a308a9-2e62-406d-8d21-438628c1d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-155f4e11-c828-4d65-ad1a-74775a0d00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-a0803c15-610c-4a25-9bff-3b92a763c720,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-98cbe7fa-5438-4f65-8518-6c5db5d7a519,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-8789cc82-2331-4d18-bd57-75e46e2515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f4aada2c-a589-4026-9e90-9846a34fea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856889864-172.17.0.19-1599382796712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39135,DS-61edb4ea-050c-40d0-9061-1245b96cb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-b5f0481a-94bf-4073-b4d8-a9e2197e4675,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-93a308a9-2e62-406d-8d21-438628c1d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-155f4e11-c828-4d65-ad1a-74775a0d00c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-a0803c15-610c-4a25-9bff-3b92a763c720,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-98cbe7fa-5438-4f65-8518-6c5db5d7a519,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-8789cc82-2331-4d18-bd57-75e46e2515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f4aada2c-a589-4026-9e90-9846a34fea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259388215-172.17.0.19-1599382931640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36714,DS-8c44642b-4b4a-4c17-a3ed-8ec527c2c56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-27968446-5010-4cd3-b61c-aace965ebde0,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-728c1e17-665b-4bc4-ba9f-2e22bfe1de63,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-68228b20-7523-472e-af78-f9e7bf526334,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-6afccea5-7b11-471b-9dd1-67ffba416aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f6b4f88d-2c27-4998-8c86-dec742d9115d,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-ca5b0f83-675b-4fec-b8ef-17d4d25e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ecc291d6-750b-43f6-8e1a-834d2a96b42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259388215-172.17.0.19-1599382931640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36714,DS-8c44642b-4b4a-4c17-a3ed-8ec527c2c56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-27968446-5010-4cd3-b61c-aace965ebde0,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-728c1e17-665b-4bc4-ba9f-2e22bfe1de63,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-68228b20-7523-472e-af78-f9e7bf526334,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-6afccea5-7b11-471b-9dd1-67ffba416aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f6b4f88d-2c27-4998-8c86-dec742d9115d,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-ca5b0f83-675b-4fec-b8ef-17d4d25e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ecc291d6-750b-43f6-8e1a-834d2a96b42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256506387-172.17.0.19-1599382966336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-be2d2417-2d05-46d4-8fb8-a41d301c4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-e48714a0-6ebc-4b8a-ad3f-9e4b0dc040ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-535fb712-ce1d-457d-a392-34a55e6604de,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-8d4e89a1-6fa7-44d5-8713-ee165d3e4ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-f39e2501-df74-41bd-8a9b-ec0f2b184a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-46916145-4016-4b01-afe5-66beca997bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-7874edc6-c8ae-4f95-87e4-1d24dc68615e,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-631d9c36-1a01-4680-ad8e-4bc2f6622bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256506387-172.17.0.19-1599382966336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-be2d2417-2d05-46d4-8fb8-a41d301c4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-e48714a0-6ebc-4b8a-ad3f-9e4b0dc040ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-535fb712-ce1d-457d-a392-34a55e6604de,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-8d4e89a1-6fa7-44d5-8713-ee165d3e4ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-f39e2501-df74-41bd-8a9b-ec0f2b184a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-46916145-4016-4b01-afe5-66beca997bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-7874edc6-c8ae-4f95-87e4-1d24dc68615e,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-631d9c36-1a01-4680-ad8e-4bc2f6622bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113872971-172.17.0.19-1599383206666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-8bf34eff-0409-489f-ab3a-8d34ef67b764,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-b1947d33-b094-4ca6-90f4-1b794f6885d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-42c185b5-6422-45fd-aade-71898c6f25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-3c62d0bc-469a-414f-b942-ae60994339dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-15ef61c5-2679-46ca-a81b-a6cdc9270a84,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-82885ceb-8faa-419a-82e4-b00a3079d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-af052f92-ace4-4bd7-81fd-861b6cebfef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-1bc2fd1a-626f-4fc6-884e-471561cf3e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113872971-172.17.0.19-1599383206666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-8bf34eff-0409-489f-ab3a-8d34ef67b764,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-b1947d33-b094-4ca6-90f4-1b794f6885d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-42c185b5-6422-45fd-aade-71898c6f25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-3c62d0bc-469a-414f-b942-ae60994339dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-15ef61c5-2679-46ca-a81b-a6cdc9270a84,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-82885ceb-8faa-419a-82e4-b00a3079d5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-af052f92-ace4-4bd7-81fd-861b6cebfef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-1bc2fd1a-626f-4fc6-884e-471561cf3e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525948450-172.17.0.19-1599383292314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-8b7a72f6-0a46-4eb9-ac57-e029c5d39d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-2da3411d-6c13-4492-b72c-83b796139e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-e11f85f1-17ae-4949-a4e3-f1896f26bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8b48a7a2-b870-48d1-b2e4-a2405d6fec32,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-8c0cbe4b-fd97-4044-96d0-e70b5b4f241e,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f96fbfd0-ace1-4491-bc61-2221ffba43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-eaca2349-a55a-477c-9e14-9e9c9391d519,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-884f6eaf-4eda-473b-9367-682a0cd0a810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525948450-172.17.0.19-1599383292314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-8b7a72f6-0a46-4eb9-ac57-e029c5d39d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-2da3411d-6c13-4492-b72c-83b796139e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-e11f85f1-17ae-4949-a4e3-f1896f26bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8b48a7a2-b870-48d1-b2e4-a2405d6fec32,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-8c0cbe4b-fd97-4044-96d0-e70b5b4f241e,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f96fbfd0-ace1-4491-bc61-2221ffba43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-eaca2349-a55a-477c-9e14-9e9c9391d519,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-884f6eaf-4eda-473b-9367-682a0cd0a810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62469591-172.17.0.19-1599383856924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-0c7d6ef5-d557-4d22-a698-59765231e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2040c963-c317-47b2-9985-7960fb75848b,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8b5ecc4e-239e-4eb5-82c6-371fff0057d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2a1e4f4f-8459-4b96-b744-9aa6e9148823,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-6d4c7ff4-eaff-4fcf-8c0c-c553dbfabc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-a9390f6c-6f88-4e8e-aae1-6e3828f9844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-78a31b58-4c2d-4e99-9362-828e68a627d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-d12ad9df-24e1-45d2-809c-7d39eb55ac5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62469591-172.17.0.19-1599383856924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-0c7d6ef5-d557-4d22-a698-59765231e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2040c963-c317-47b2-9985-7960fb75848b,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8b5ecc4e-239e-4eb5-82c6-371fff0057d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2a1e4f4f-8459-4b96-b744-9aa6e9148823,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-6d4c7ff4-eaff-4fcf-8c0c-c553dbfabc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-a9390f6c-6f88-4e8e-aae1-6e3828f9844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-78a31b58-4c2d-4e99-9362-828e68a627d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-d12ad9df-24e1-45d2-809c-7d39eb55ac5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897849276-172.17.0.19-1599383965170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-2cdc2a04-c8cb-4960-8c5d-0073b41b8afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-e7b2ac5f-1df4-4331-baa2-7794302f15b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-0b54ac1b-052b-4e48-bef4-96705c6de94b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-886ad66a-b903-4f71-b07c-8957a5f8ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-b983a02b-61db-4e15-be63-56b5f86f2174,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-e97e306d-e37f-4fe0-a7ef-590e4278d748,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-910ba636-e1ea-4a89-a987-3ed6ef10c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-e1aaa917-c733-4537-9083-cd904b4f6791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897849276-172.17.0.19-1599383965170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-2cdc2a04-c8cb-4960-8c5d-0073b41b8afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-e7b2ac5f-1df4-4331-baa2-7794302f15b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-0b54ac1b-052b-4e48-bef4-96705c6de94b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-886ad66a-b903-4f71-b07c-8957a5f8ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-b983a02b-61db-4e15-be63-56b5f86f2174,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-e97e306d-e37f-4fe0-a7ef-590e4278d748,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-910ba636-e1ea-4a89-a987-3ed6ef10c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-e1aaa917-c733-4537-9083-cd904b4f6791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629108694-172.17.0.19-1599383984259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-9af11eb8-090b-4942-a977-ce30c7e9455d,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-25268dd0-daf4-4de7-8345-fc7ba46c06db,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-e33351ec-aae4-48ca-8eeb-8a4ec390becf,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-02e7c776-9884-4f05-827d-798ffcf17c26,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-866954d7-82be-4a55-a6b5-b06b686674ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-b42cc4a6-3650-439f-89f8-9a97f23191cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c7079eb7-9580-48de-b40f-d0274e47e953,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2629263d-d4d3-4a7a-8d9b-910a0f2b14c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629108694-172.17.0.19-1599383984259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-9af11eb8-090b-4942-a977-ce30c7e9455d,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-25268dd0-daf4-4de7-8345-fc7ba46c06db,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-e33351ec-aae4-48ca-8eeb-8a4ec390becf,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-02e7c776-9884-4f05-827d-798ffcf17c26,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-866954d7-82be-4a55-a6b5-b06b686674ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-b42cc4a6-3650-439f-89f8-9a97f23191cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c7079eb7-9580-48de-b40f-d0274e47e953,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-2629263d-d4d3-4a7a-8d9b-910a0f2b14c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205943052-172.17.0.19-1599384071516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-30f12f50-f08c-4666-bc6f-1335b4a4b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-9c7f799d-7c10-4aa3-a3b5-f6442fa48540,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-a4708360-cc14-47fc-8559-7fcb56608596,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-28478df6-b328-48a4-aa57-8e4ede1f2096,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-b23420c1-99de-44f4-aa04-2bedbda5b217,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-03a78182-ead4-4592-90cf-3691f06d617d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-bf7c3b57-79f0-41fc-b573-cffc048c04be,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-61e2fb2f-8c7e-4f0a-a3d3-4562540dd8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205943052-172.17.0.19-1599384071516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-30f12f50-f08c-4666-bc6f-1335b4a4b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-9c7f799d-7c10-4aa3-a3b5-f6442fa48540,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-a4708360-cc14-47fc-8559-7fcb56608596,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-28478df6-b328-48a4-aa57-8e4ede1f2096,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-b23420c1-99de-44f4-aa04-2bedbda5b217,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-03a78182-ead4-4592-90cf-3691f06d617d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-bf7c3b57-79f0-41fc-b573-cffc048c04be,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-61e2fb2f-8c7e-4f0a-a3d3-4562540dd8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374000813-172.17.0.19-1599384108076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-91b6ddc8-68a0-434b-8074-7fc32162f912,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-ecf3eaa9-c65f-46b8-ab48-3960a0251a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-e32a4ab3-ed13-42f9-87fc-8be85b6865a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-b114bd90-be8d-42f4-9de0-43eada227b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-f4c1d0f2-fc2b-49a9-923b-20b3115eeacd,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-11d7723f-8fc5-4e3e-b767-5963249f50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-3965e5c6-28d6-478e-8a3d-ffc56a242d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-01bc5d60-1856-4fdd-b067-17098e0da046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374000813-172.17.0.19-1599384108076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-91b6ddc8-68a0-434b-8074-7fc32162f912,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-ecf3eaa9-c65f-46b8-ab48-3960a0251a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-e32a4ab3-ed13-42f9-87fc-8be85b6865a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-b114bd90-be8d-42f4-9de0-43eada227b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-f4c1d0f2-fc2b-49a9-923b-20b3115eeacd,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-11d7723f-8fc5-4e3e-b767-5963249f50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-3965e5c6-28d6-478e-8a3d-ffc56a242d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-01bc5d60-1856-4fdd-b067-17098e0da046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169570099-172.17.0.19-1599384274780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-79807cf9-1468-4859-b3f7-1bf763c1e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-8f7ea8b6-010e-4139-850d-8892075c9894,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-cc503859-55bc-438a-8a32-5448f0d867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-2d349ae4-ce74-4872-bc24-b27f8dae20bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-0e17e98c-c539-4e67-a1b7-1cf2b9258dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-edebfda4-ce35-4f6f-8e13-6925fa6697ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-16fa9a11-1d9b-40c6-910c-d4db59f02cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-f8ef3f8e-ae68-47ca-98f9-6bb4d7cc25b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169570099-172.17.0.19-1599384274780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-79807cf9-1468-4859-b3f7-1bf763c1e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-8f7ea8b6-010e-4139-850d-8892075c9894,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-cc503859-55bc-438a-8a32-5448f0d867fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-2d349ae4-ce74-4872-bc24-b27f8dae20bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-0e17e98c-c539-4e67-a1b7-1cf2b9258dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-edebfda4-ce35-4f6f-8e13-6925fa6697ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-16fa9a11-1d9b-40c6-910c-d4db59f02cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-f8ef3f8e-ae68-47ca-98f9-6bb4d7cc25b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415664003-172.17.0.19-1599384292567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40897,DS-a13226ac-7822-4560-9d87-c8de43f45cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-d461da4a-9d0c-4ed4-80b6-1b60bbddba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-765b34f0-3f69-4ff0-9625-4562053dcf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-5dc16084-709c-42c4-83cb-e773ca2cb028,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-fc6f3bb4-e61d-458a-a3ef-afd9d89f4c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-a2dcc3a0-f56d-4a6e-8563-39db21996c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-99974182-902c-4c06-b5cb-7a605951dc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-734ae682-f3e0-4cc5-8956-0ee98b9c7adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415664003-172.17.0.19-1599384292567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40897,DS-a13226ac-7822-4560-9d87-c8de43f45cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-d461da4a-9d0c-4ed4-80b6-1b60bbddba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-765b34f0-3f69-4ff0-9625-4562053dcf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-5dc16084-709c-42c4-83cb-e773ca2cb028,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-fc6f3bb4-e61d-458a-a3ef-afd9d89f4c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-a2dcc3a0-f56d-4a6e-8563-39db21996c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-99974182-902c-4c06-b5cb-7a605951dc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-734ae682-f3e0-4cc5-8956-0ee98b9c7adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961193239-172.17.0.19-1599384435521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-673e29f8-3933-4e41-bc29-c6ab1cf99c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-57aff603-621f-4817-a9ef-595cd73a01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5ded5dc8-9f7a-43d2-a199-c37d91894031,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-97baff53-862a-40d1-a3b8-024fcbc58f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ede0122e-92cc-44ab-8289-1c9c16229398,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-1b784161-bf63-40d6-ba7e-364d1662d4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-7dfb2c05-bfbd-4626-b4d9-86454d45a3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-3db4b4f7-e09b-47b6-983f-a78fb1ca0c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961193239-172.17.0.19-1599384435521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-673e29f8-3933-4e41-bc29-c6ab1cf99c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-57aff603-621f-4817-a9ef-595cd73a01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-5ded5dc8-9f7a-43d2-a199-c37d91894031,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-97baff53-862a-40d1-a3b8-024fcbc58f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ede0122e-92cc-44ab-8289-1c9c16229398,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-1b784161-bf63-40d6-ba7e-364d1662d4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-7dfb2c05-bfbd-4626-b4d9-86454d45a3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-3db4b4f7-e09b-47b6-983f-a78fb1ca0c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917554003-172.17.0.19-1599384503163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-565081d0-4b24-44c9-9d5b-5947784d0193,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0bb72a6a-68da-4692-a8f8-2ac6ede7089c,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-6ded529c-5ef3-48de-bca0-3e10c0d5ac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4e66a0c2-574c-4476-88a6-ea3a26390782,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-936ad1d0-d1a8-4985-841b-468e03fbdd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-7a465c61-723c-4ae1-bf91-98e387464dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-d44dfdaa-67cd-4d9c-87b7-5448d2cfc7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-b758f805-59c4-4216-bd60-07577cc4c70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917554003-172.17.0.19-1599384503163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-565081d0-4b24-44c9-9d5b-5947784d0193,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0bb72a6a-68da-4692-a8f8-2ac6ede7089c,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-6ded529c-5ef3-48de-bca0-3e10c0d5ac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4e66a0c2-574c-4476-88a6-ea3a26390782,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-936ad1d0-d1a8-4985-841b-468e03fbdd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-7a465c61-723c-4ae1-bf91-98e387464dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-d44dfdaa-67cd-4d9c-87b7-5448d2cfc7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-b758f805-59c4-4216-bd60-07577cc4c70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384822215-172.17.0.19-1599384588360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-e9cf87c2-0e03-469b-b92c-aab3a7c70deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-f5abbd26-8ea6-441a-b56d-e6203ce8b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-0ca4044f-495c-4b21-ab52-5fe8f1d10f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-9f1fdb7e-6aa0-496e-b5cd-15a10fc95814,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-91e399cf-0645-46b7-b56e-0a1db1e505b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-f0fe0e99-f7fd-43c5-8983-0faadc84ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-7010a0f2-89f5-4079-91e2-00fc241e02af,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f64b39fb-e710-4628-97c8-d53ff8fb5dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384822215-172.17.0.19-1599384588360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-e9cf87c2-0e03-469b-b92c-aab3a7c70deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-f5abbd26-8ea6-441a-b56d-e6203ce8b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-0ca4044f-495c-4b21-ab52-5fe8f1d10f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-9f1fdb7e-6aa0-496e-b5cd-15a10fc95814,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-91e399cf-0645-46b7-b56e-0a1db1e505b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-f0fe0e99-f7fd-43c5-8983-0faadc84ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-7010a0f2-89f5-4079-91e2-00fc241e02af,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f64b39fb-e710-4628-97c8-d53ff8fb5dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657839731-172.17.0.19-1599384740016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-5430f414-e090-4598-a65c-d53d66232493,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-e6132a5d-d58f-41e6-af73-af773987daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-780adc8d-c56d-4b7d-880c-95904f31f032,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0db5fac6-ebc0-4374-9cfa-e39863f07fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1cf945aa-57e4-4057-b68d-13ca43565e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-367cbf62-b976-4142-bd07-799866682b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-09ad9372-081b-47f9-b134-a687e2c886de,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-28efb82b-32a7-49b1-a43a-4378aa92bd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657839731-172.17.0.19-1599384740016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-5430f414-e090-4598-a65c-d53d66232493,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-e6132a5d-d58f-41e6-af73-af773987daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-780adc8d-c56d-4b7d-880c-95904f31f032,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0db5fac6-ebc0-4374-9cfa-e39863f07fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-1cf945aa-57e4-4057-b68d-13ca43565e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-367cbf62-b976-4142-bd07-799866682b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-09ad9372-081b-47f9-b134-a687e2c886de,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-28efb82b-32a7-49b1-a43a-4378aa92bd14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040441819-172.17.0.19-1599384756740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-7bb155bb-0000-4441-879c-810edf831693,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-eda6961f-91d1-44cb-bde0-00cd22ff8754,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-e21da0b6-9e11-4867-826d-43e1843d2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-420802f1-505f-41b0-bf0d-6b25a61c35e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-e5252603-9dad-46f7-9e11-d9121c4b0274,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-c0a197c2-f6c8-4956-9a72-4160591083bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-bbffbad9-e4cf-4641-8504-019b28773f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0fc325ce-0fcb-4634-8a94-a041465a3dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040441819-172.17.0.19-1599384756740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-7bb155bb-0000-4441-879c-810edf831693,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-eda6961f-91d1-44cb-bde0-00cd22ff8754,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-e21da0b6-9e11-4867-826d-43e1843d2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-420802f1-505f-41b0-bf0d-6b25a61c35e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-e5252603-9dad-46f7-9e11-d9121c4b0274,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-c0a197c2-f6c8-4956-9a72-4160591083bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-bbffbad9-e4cf-4641-8504-019b28773f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0fc325ce-0fcb-4634-8a94-a041465a3dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 2839
