reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310783097-172.17.0.10-1599385513285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-7cd5bfe3-b655-4a9e-bbf2-795f1c088d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5b47f828-3534-4d9d-856f-9a96d62df6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-241ca358-86b7-4030-8925-aac5d0121887,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-5e6ce5fd-5248-46b7-9e80-2aa8ffdb3228,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-e154c7a6-92cf-40ff-baf7-f99c5bd20d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-3c319698-daaa-40c2-ac1b-17bde4d9648f,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-f82d04f9-4553-4361-81d3-e4dda6655ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-dabde8a5-e640-4650-8d6b-0be4049b765c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310783097-172.17.0.10-1599385513285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-7cd5bfe3-b655-4a9e-bbf2-795f1c088d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5b47f828-3534-4d9d-856f-9a96d62df6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-241ca358-86b7-4030-8925-aac5d0121887,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-5e6ce5fd-5248-46b7-9e80-2aa8ffdb3228,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-e154c7a6-92cf-40ff-baf7-f99c5bd20d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-3c319698-daaa-40c2-ac1b-17bde4d9648f,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-f82d04f9-4553-4361-81d3-e4dda6655ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-dabde8a5-e640-4650-8d6b-0be4049b765c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900227108-172.17.0.10-1599385552994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-5e1fd06b-02cb-44ec-9ed4-1b1101a74872,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-91a03870-d6a2-4b9b-9f0c-9586f62b3501,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-f95840cd-7751-4759-885a-f3c6d1f4b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-4f471023-1a95-4960-b59a-de67696c40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-daa34214-7300-485f-992b-e4161af5af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-58353449-e727-4de9-a704-bb5691841ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-8a401950-dec1-48ef-a5ae-1016d3239570,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-70711d7f-1683-4c76-acf3-773f799ee9e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900227108-172.17.0.10-1599385552994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-5e1fd06b-02cb-44ec-9ed4-1b1101a74872,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-91a03870-d6a2-4b9b-9f0c-9586f62b3501,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-f95840cd-7751-4759-885a-f3c6d1f4b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-4f471023-1a95-4960-b59a-de67696c40ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-daa34214-7300-485f-992b-e4161af5af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-58353449-e727-4de9-a704-bb5691841ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-8a401950-dec1-48ef-a5ae-1016d3239570,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-70711d7f-1683-4c76-acf3-773f799ee9e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044227099-172.17.0.10-1599385638265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-74f6f212-ae75-4c27-8b56-1b34959f1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-b3aa9129-22a9-4852-b7cf-dea32a72fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-bbd52877-6f2e-410b-a001-187edf44790d,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1d0a74b5-3f7f-46be-aeb1-17c23bde0020,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-4077e287-5aea-41c1-85b6-6ad5ea77e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-1bc190c5-021e-4b9e-87e7-aadeabdaa6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-97764974-1c06-426a-9403-3d0ab4a4e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-bc4fb664-c5ca-4e61-b41b-6679e1af17f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044227099-172.17.0.10-1599385638265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-74f6f212-ae75-4c27-8b56-1b34959f1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-b3aa9129-22a9-4852-b7cf-dea32a72fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-bbd52877-6f2e-410b-a001-187edf44790d,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1d0a74b5-3f7f-46be-aeb1-17c23bde0020,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-4077e287-5aea-41c1-85b6-6ad5ea77e67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-1bc190c5-021e-4b9e-87e7-aadeabdaa6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-97764974-1c06-426a-9403-3d0ab4a4e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-bc4fb664-c5ca-4e61-b41b-6679e1af17f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170444447-172.17.0.10-1599385720445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32823,DS-87fce1a4-db9b-43b5-b63a-5dcc4d6ce6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-a4a479e5-5914-4213-a50e-37ed456c442e,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-93dde1ea-5661-411e-83a4-9123a5fb338f,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fa6114be-116e-41fe-9c1a-55328b605713,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-ee940e90-63c3-4761-9ffa-5bae36606a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-09acc07e-467a-40c7-84ba-aaea8dcec024,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-6e84d097-ab29-4330-b328-550d94fc016a,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-c90debc6-a4fd-4d9c-b2a2-0dd4b28803a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170444447-172.17.0.10-1599385720445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32823,DS-87fce1a4-db9b-43b5-b63a-5dcc4d6ce6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-a4a479e5-5914-4213-a50e-37ed456c442e,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-93dde1ea-5661-411e-83a4-9123a5fb338f,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fa6114be-116e-41fe-9c1a-55328b605713,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-ee940e90-63c3-4761-9ffa-5bae36606a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-09acc07e-467a-40c7-84ba-aaea8dcec024,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-6e84d097-ab29-4330-b328-550d94fc016a,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-c90debc6-a4fd-4d9c-b2a2-0dd4b28803a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516609503-172.17.0.10-1599385781815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-c01a5bd8-165b-4498-80b4-6b7836406a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-6dc62cac-f27c-442b-b195-0b7e025c1069,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d74efbc8-3b89-49ed-8bff-ba8550885ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-b8bd10a3-a635-4a59-b326-8ce92fb4a386,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-f70f741b-08f9-4e03-b169-64107d654134,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-cfbc175f-11cd-42b6-a842-cc3dd6b2bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-4e5e1321-5b8c-433d-a4c3-0bab05f97b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-9b7a0d56-0b1e-4c88-b072-2775cb4d81b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516609503-172.17.0.10-1599385781815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-c01a5bd8-165b-4498-80b4-6b7836406a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-6dc62cac-f27c-442b-b195-0b7e025c1069,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d74efbc8-3b89-49ed-8bff-ba8550885ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-b8bd10a3-a635-4a59-b326-8ce92fb4a386,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-f70f741b-08f9-4e03-b169-64107d654134,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-cfbc175f-11cd-42b6-a842-cc3dd6b2bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-4e5e1321-5b8c-433d-a4c3-0bab05f97b09,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-9b7a0d56-0b1e-4c88-b072-2775cb4d81b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912387720-172.17.0.10-1599385983858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-4f7dd81c-81e3-4cab-b305-a3c79284dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-fdd81501-2ca5-4f92-bace-8aec1f03ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-18eafff2-1b1e-458c-ac1f-fb770eeb3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-8978ea5b-e326-40eb-a810-4b807a18dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-8a7837bc-6628-43ef-9287-902f5cb82ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-82b85756-7668-48ed-80ee-9ec4df0042d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-9467e613-ad1d-472f-9111-6214725b4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5b4da6e5-a48b-4c14-8492-c2425b08abde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912387720-172.17.0.10-1599385983858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-4f7dd81c-81e3-4cab-b305-a3c79284dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-fdd81501-2ca5-4f92-bace-8aec1f03ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-18eafff2-1b1e-458c-ac1f-fb770eeb3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-8978ea5b-e326-40eb-a810-4b807a18dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-8a7837bc-6628-43ef-9287-902f5cb82ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-82b85756-7668-48ed-80ee-9ec4df0042d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-9467e613-ad1d-472f-9111-6214725b4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5b4da6e5-a48b-4c14-8492-c2425b08abde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237549715-172.17.0.10-1599386013368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-d6c41b05-c4a0-4a3f-bc91-22f366524e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f43f3e4d-4943-42ad-93ac-f7873226df74,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-b3503e58-ac83-4d37-932c-f15fde91d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-81373a3c-c28c-434e-a84d-35cdc681b587,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-8e6bdb12-28b8-49ca-b5d2-5da9b0a18d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-16a44e6c-a632-4e8a-8057-e2b6d2572a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-50956d19-6210-4f07-b41f-d072636dacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-5c79a4c0-5328-4cfe-ba40-ef1b32216b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237549715-172.17.0.10-1599386013368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-d6c41b05-c4a0-4a3f-bc91-22f366524e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-f43f3e4d-4943-42ad-93ac-f7873226df74,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-b3503e58-ac83-4d37-932c-f15fde91d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-81373a3c-c28c-434e-a84d-35cdc681b587,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-8e6bdb12-28b8-49ca-b5d2-5da9b0a18d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-16a44e6c-a632-4e8a-8057-e2b6d2572a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-50956d19-6210-4f07-b41f-d072636dacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-5c79a4c0-5328-4cfe-ba40-ef1b32216b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998656402-172.17.0.10-1599386054691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-10feb077-8c41-4dc2-8324-e460fa6fc118,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-677ea647-b5d5-4a93-b53e-c06f3aa81029,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-8ebbdbaa-e8f8-4259-a301-e0d7dc7d3ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-9f80c18c-0a64-497a-80e4-92347a012705,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-868a327d-86ee-47cb-98ce-471a48e5b324,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-6e787f82-c856-467b-a065-91f726be69f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-3c2d72d1-4547-4bb0-a936-090deee82350,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-3eb1af73-48f1-4d29-b7b0-b28a766fe2d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998656402-172.17.0.10-1599386054691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-10feb077-8c41-4dc2-8324-e460fa6fc118,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-677ea647-b5d5-4a93-b53e-c06f3aa81029,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-8ebbdbaa-e8f8-4259-a301-e0d7dc7d3ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-9f80c18c-0a64-497a-80e4-92347a012705,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-868a327d-86ee-47cb-98ce-471a48e5b324,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-6e787f82-c856-467b-a065-91f726be69f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-3c2d72d1-4547-4bb0-a936-090deee82350,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-3eb1af73-48f1-4d29-b7b0-b28a766fe2d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505369566-172.17.0.10-1599386179846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-5c285578-feb8-40fd-ae93-abe0609f151e,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-ea7f2216-4e82-4d39-9f8a-fd32ea203391,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e0cb8ee8-a96e-40c3-ad5a-40d8e8f8d98d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-541893ec-7dc2-4677-bcd9-83dacfcab12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-b0ada19b-f438-4249-a32e-0004170ef239,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-515150d4-f669-469c-ad21-d835d9037e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-28198e65-64ae-46e8-a277-3e3e49b3caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-722d1000-5fcb-4f2a-b8df-1552a8dc3f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505369566-172.17.0.10-1599386179846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-5c285578-feb8-40fd-ae93-abe0609f151e,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-ea7f2216-4e82-4d39-9f8a-fd32ea203391,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e0cb8ee8-a96e-40c3-ad5a-40d8e8f8d98d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-541893ec-7dc2-4677-bcd9-83dacfcab12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-b0ada19b-f438-4249-a32e-0004170ef239,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-515150d4-f669-469c-ad21-d835d9037e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-28198e65-64ae-46e8-a277-3e3e49b3caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-722d1000-5fcb-4f2a-b8df-1552a8dc3f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084028132-172.17.0.10-1599386363287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-a7dea2b0-1ad9-4f27-9863-b63f7058a323,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-837a27d9-f3b9-40be-9743-942b58a047fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-a5b098b1-8972-4b97-a0ef-0d8e0c8395c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-60080cab-7365-4270-862a-1e7a94ee53b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-5f63fe94-8e9f-4234-9341-2eb61872e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4f594557-9685-4572-958d-ac96ef47b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-eabf2117-da28-4718-a350-d3e6a2de0c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-591b3bae-1a35-488d-8725-ea019dddb716,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084028132-172.17.0.10-1599386363287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-a7dea2b0-1ad9-4f27-9863-b63f7058a323,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-837a27d9-f3b9-40be-9743-942b58a047fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-a5b098b1-8972-4b97-a0ef-0d8e0c8395c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-60080cab-7365-4270-862a-1e7a94ee53b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-5f63fe94-8e9f-4234-9341-2eb61872e01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-4f594557-9685-4572-958d-ac96ef47b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-eabf2117-da28-4718-a350-d3e6a2de0c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-591b3bae-1a35-488d-8725-ea019dddb716,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685172509-172.17.0.10-1599386482592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-df0676e9-7e4e-47b6-aadb-9d5bff6ce625,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-43b31f22-f246-4a46-9441-2683adf9ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-97a61235-fb25-4ded-acce-4c15e4ea76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-99833db3-04ae-40fd-b70f-1994ae5c939d,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-1da88a66-8ce4-4bb3-b052-980b636245b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-75af642f-3a46-479e-924a-1d840119db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-71d1b279-48fd-42f2-9065-dbc2346689c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-9e6971c8-1e44-46fd-9cd7-2ced9c090143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685172509-172.17.0.10-1599386482592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-df0676e9-7e4e-47b6-aadb-9d5bff6ce625,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-43b31f22-f246-4a46-9441-2683adf9ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-97a61235-fb25-4ded-acce-4c15e4ea76a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-99833db3-04ae-40fd-b70f-1994ae5c939d,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-1da88a66-8ce4-4bb3-b052-980b636245b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-75af642f-3a46-479e-924a-1d840119db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-71d1b279-48fd-42f2-9065-dbc2346689c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-9e6971c8-1e44-46fd-9cd7-2ced9c090143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241984055-172.17.0.10-1599386748576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-37ad31ce-f5ca-4bb7-a377-dc2a8e48d345,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-12ed352d-c6f6-4211-922f-096298c7f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-e0987a28-f9e2-4ea8-88d7-c85a867d066b,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-155afd6b-285e-42e3-b2e9-8c38b8fe7351,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-40a5646b-9196-4b8c-b81e-7f64b5b53ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-4c40a4c4-790b-4c3f-b243-cf07ed9a0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-71fb0c69-6666-4518-b10f-d810134ad433,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-d428b265-7687-47b7-8b58-fce9f82c5a56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241984055-172.17.0.10-1599386748576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-37ad31ce-f5ca-4bb7-a377-dc2a8e48d345,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-12ed352d-c6f6-4211-922f-096298c7f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-e0987a28-f9e2-4ea8-88d7-c85a867d066b,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-155afd6b-285e-42e3-b2e9-8c38b8fe7351,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-40a5646b-9196-4b8c-b81e-7f64b5b53ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-4c40a4c4-790b-4c3f-b243-cf07ed9a0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-71fb0c69-6666-4518-b10f-d810134ad433,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-d428b265-7687-47b7-8b58-fce9f82c5a56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905942515-172.17.0.10-1599386778585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43447,DS-dc24e845-51ad-4793-97c9-cf6bc213afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ecf4d6b0-d0e3-4478-b202-6cf35f00f348,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-01473024-1824-49f8-8118-4f48220de372,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-24bbcb95-2a57-4aef-9277-9b6610e7abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-f9986463-0207-40f9-b582-ba02bf15c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-120fdc85-ba0c-48a1-a964-b1700bcf1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-795a434b-a8ed-4889-9563-1b9def95cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b6792944-bb95-42d3-abae-644aa4728606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905942515-172.17.0.10-1599386778585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43447,DS-dc24e845-51ad-4793-97c9-cf6bc213afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ecf4d6b0-d0e3-4478-b202-6cf35f00f348,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-01473024-1824-49f8-8118-4f48220de372,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-24bbcb95-2a57-4aef-9277-9b6610e7abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-f9986463-0207-40f9-b582-ba02bf15c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-120fdc85-ba0c-48a1-a964-b1700bcf1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-795a434b-a8ed-4889-9563-1b9def95cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b6792944-bb95-42d3-abae-644aa4728606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731075553-172.17.0.10-1599387469662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-332338a5-5140-4195-a58a-32ac076f064b,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-04402e14-e9e9-4e92-af19-a2ba56121cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-f355b8c8-cc2d-439a-8eb5-bcd0d446479e,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-53c79337-ac77-4a82-9c5d-b5da98be9989,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-4b89a418-4b13-44d0-bb03-ecf33de3eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-cc0e00ee-fd71-438c-9aff-6cdb516e9c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-f2c9f8d1-5a3c-4edc-9895-21bc90ba55a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-cca21f57-bac6-4503-9aca-b7d38837ad38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731075553-172.17.0.10-1599387469662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-332338a5-5140-4195-a58a-32ac076f064b,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-04402e14-e9e9-4e92-af19-a2ba56121cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-f355b8c8-cc2d-439a-8eb5-bcd0d446479e,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-53c79337-ac77-4a82-9c5d-b5da98be9989,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-4b89a418-4b13-44d0-bb03-ecf33de3eab8,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-cc0e00ee-fd71-438c-9aff-6cdb516e9c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-f2c9f8d1-5a3c-4edc-9895-21bc90ba55a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-cca21f57-bac6-4503-9aca-b7d38837ad38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178527491-172.17.0.10-1599387671959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-ceab4f1b-6207-4e9a-92c4-6b9df9be1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-43488baf-3d7f-437b-bac8-3994c04b24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-188ab331-9191-44c7-a77c-053c00bb3a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-b51af415-d156-485b-94b6-87c28b01ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-1dc968ff-4473-4630-84fd-0a0d1f92bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-88506b98-06bb-4568-a3d2-5cb06e83b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-7b890479-a70d-44e1-ba0f-b4ee545b5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-4f159e64-ec58-46a8-9093-d5ecf58a8e8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178527491-172.17.0.10-1599387671959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-ceab4f1b-6207-4e9a-92c4-6b9df9be1e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-43488baf-3d7f-437b-bac8-3994c04b24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-188ab331-9191-44c7-a77c-053c00bb3a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-b51af415-d156-485b-94b6-87c28b01ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-1dc968ff-4473-4630-84fd-0a0d1f92bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-88506b98-06bb-4568-a3d2-5cb06e83b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-7b890479-a70d-44e1-ba0f-b4ee545b5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-4f159e64-ec58-46a8-9093-d5ecf58a8e8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163265206-172.17.0.10-1599387837786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42770,DS-d937d46f-5c71-4e9e-a349-30c6ed728d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a9d8d131-cc75-4696-859f-6be5a4d2f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d17d47d8-82de-4fb8-9f63-11a186df76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-9e263937-264e-4ec2-9488-ba5223ae41ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-b259ea0b-0eed-43ee-bc33-0cc5656323c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-5f0cd998-47f7-42f4-a9e0-0b7f06c30a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-2b366353-3431-46fa-9dad-1e3bc80b615d,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b9e7404c-ee13-43cb-a3db-df69a71ecd5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163265206-172.17.0.10-1599387837786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42770,DS-d937d46f-5c71-4e9e-a349-30c6ed728d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a9d8d131-cc75-4696-859f-6be5a4d2f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d17d47d8-82de-4fb8-9f63-11a186df76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-9e263937-264e-4ec2-9488-ba5223ae41ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-b259ea0b-0eed-43ee-bc33-0cc5656323c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-5f0cd998-47f7-42f4-a9e0-0b7f06c30a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-2b366353-3431-46fa-9dad-1e3bc80b615d,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b9e7404c-ee13-43cb-a3db-df69a71ecd5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385487669-172.17.0.10-1599387869878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-3b72623b-31b2-4ca5-99fd-c0670d14dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-77b45cc3-0bda-4c6d-9b75-74c37cc1c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-8673d136-f1da-461c-b400-c5a49a80b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-9727a13d-c1db-4577-a138-bf2ecce1317f,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-29c1c903-bcdd-42fa-93be-1a94591dc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-c0617eab-3efe-408c-8aab-48836a17cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-d1c1a1b1-4ec6-4e8e-aa6b-7d0fc39dfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-6c7050bb-a95b-4520-af3a-1ac75c97ff08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385487669-172.17.0.10-1599387869878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-3b72623b-31b2-4ca5-99fd-c0670d14dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-77b45cc3-0bda-4c6d-9b75-74c37cc1c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-8673d136-f1da-461c-b400-c5a49a80b2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-9727a13d-c1db-4577-a138-bf2ecce1317f,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-29c1c903-bcdd-42fa-93be-1a94591dc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-c0617eab-3efe-408c-8aab-48836a17cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-d1c1a1b1-4ec6-4e8e-aa6b-7d0fc39dfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-6c7050bb-a95b-4520-af3a-1ac75c97ff08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315308231-172.17.0.10-1599387899487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33542,DS-4d498bee-1057-4d86-b2ce-731ac9ae94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-49501ec4-c245-4753-8666-e1d908fb2ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-6760e665-3dbf-46cc-97d8-d4c0f181659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-def9469f-455e-4993-bc1e-09147f56afdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-d477c5cb-43a6-459e-8709-37fb11196608,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-50499834-7c22-4ed9-9eb2-a135e1dba94b,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-43047203-1aa3-429d-9038-9898130d282f,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0985a9e0-754e-4deb-8055-07249743ca6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315308231-172.17.0.10-1599387899487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33542,DS-4d498bee-1057-4d86-b2ce-731ac9ae94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-49501ec4-c245-4753-8666-e1d908fb2ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-6760e665-3dbf-46cc-97d8-d4c0f181659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-def9469f-455e-4993-bc1e-09147f56afdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-d477c5cb-43a6-459e-8709-37fb11196608,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-50499834-7c22-4ed9-9eb2-a135e1dba94b,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-43047203-1aa3-429d-9038-9898130d282f,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0985a9e0-754e-4deb-8055-07249743ca6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864110116-172.17.0.10-1599388060214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-90705123-5169-48fa-abaa-2d0bdd1ee831,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-ceeeda3a-8f00-4abb-8d91-dd8b5d6d2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-46e04a49-06db-4142-a4df-da26c182498a,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-39a22683-f4cf-4338-83a3-cfcb2690d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-db083d6d-93f1-4b64-842c-2d396044e134,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-e98a200a-5f35-45d0-8d78-385991715e61,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-70352def-30ef-4558-9a8e-ccdfae0086b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-ea0d602e-1777-49e7-9cdd-51803c7df34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864110116-172.17.0.10-1599388060214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-90705123-5169-48fa-abaa-2d0bdd1ee831,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-ceeeda3a-8f00-4abb-8d91-dd8b5d6d2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-46e04a49-06db-4142-a4df-da26c182498a,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-39a22683-f4cf-4338-83a3-cfcb2690d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-db083d6d-93f1-4b64-842c-2d396044e134,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-e98a200a-5f35-45d0-8d78-385991715e61,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-70352def-30ef-4558-9a8e-ccdfae0086b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-ea0d602e-1777-49e7-9cdd-51803c7df34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220274935-172.17.0.10-1599388303738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-9fc5289d-1069-4f62-a0c1-a972e2c1109e,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5dd23a40-1a48-47e5-a7ae-cab9a8625746,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-e6ccac56-f513-46dd-8516-4d69c333b436,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-cbae0bd3-4a60-4959-a0a0-b3feb0ad5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-5fe561e7-1121-4b2f-91ec-0c802a9addf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3dbe9d18-72a5-4aba-9d88-14e55b0bea44,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-2b54b6d0-ba12-4be4-a188-6dbff1448a72,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-60ef1e7a-b3ef-42cc-b0c5-d11e54455f62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220274935-172.17.0.10-1599388303738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-9fc5289d-1069-4f62-a0c1-a972e2c1109e,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5dd23a40-1a48-47e5-a7ae-cab9a8625746,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-e6ccac56-f513-46dd-8516-4d69c333b436,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-cbae0bd3-4a60-4959-a0a0-b3feb0ad5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-5fe561e7-1121-4b2f-91ec-0c802a9addf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3dbe9d18-72a5-4aba-9d88-14e55b0bea44,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-2b54b6d0-ba12-4be4-a188-6dbff1448a72,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-60ef1e7a-b3ef-42cc-b0c5-d11e54455f62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631011622-172.17.0.10-1599388402959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-26d33e9d-7618-4ec9-ab29-e3480c492780,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-758845e5-bc86-4d65-8a50-991e856274e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-274f0269-651c-40a5-94f5-0b496c6df187,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-73a383cf-9767-48c0-a90e-63c4eca8cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-0e6dd2fc-2964-4c12-8eee-b25162aa1872,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-c28c8c4d-967a-410c-98e1-9940151898da,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-5928ac57-1a0e-4024-aa8a-45e1899f6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-7188b089-b101-4484-970c-651c5c15d28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631011622-172.17.0.10-1599388402959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-26d33e9d-7618-4ec9-ab29-e3480c492780,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-758845e5-bc86-4d65-8a50-991e856274e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-274f0269-651c-40a5-94f5-0b496c6df187,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-73a383cf-9767-48c0-a90e-63c4eca8cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-0e6dd2fc-2964-4c12-8eee-b25162aa1872,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-c28c8c4d-967a-410c-98e1-9940151898da,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-5928ac57-1a0e-4024-aa8a-45e1899f6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-7188b089-b101-4484-970c-651c5c15d28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779817692-172.17.0.10-1599388508725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-8279a0d9-577f-4b1b-b4b0-7e9c6dd39bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-56dff412-eefe-4779-a8d1-d6c0ae02bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-06b70dac-013f-41c9-bc48-024b814a688b,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-932cb20a-ebb1-4bda-ba06-e32634d9a71e,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-3147b132-dd97-4fa4-b5e4-7691dbafb464,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-3c4f919d-b61e-4b29-ab10-bdebb7226962,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-0f0d0e02-af48-408f-b291-2884342d927b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-c6302171-b257-4c24-8721-00c1bbe52de0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779817692-172.17.0.10-1599388508725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-8279a0d9-577f-4b1b-b4b0-7e9c6dd39bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-56dff412-eefe-4779-a8d1-d6c0ae02bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-06b70dac-013f-41c9-bc48-024b814a688b,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-932cb20a-ebb1-4bda-ba06-e32634d9a71e,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-3147b132-dd97-4fa4-b5e4-7691dbafb464,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-3c4f919d-b61e-4b29-ab10-bdebb7226962,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-0f0d0e02-af48-408f-b291-2884342d927b,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-c6302171-b257-4c24-8721-00c1bbe52de0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442209287-172.17.0.10-1599388574506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5291c8c0-1600-4d23-b19c-9888e8ac60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-caba0488-61a5-40bc-8bfe-369dbcd37887,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-290fcf73-683d-4b12-b4d9-a5bd62aa59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7c5a463c-2c1d-4e3a-8355-0e7c02fc0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-2ae8c50d-34b8-4ff0-a2e6-2941cd048c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-44493d45-cd8c-4b1e-a7d3-9ea4a4c5f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-90f2adaa-7a02-4f53-9828-f0ba591a4823,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-6194fe08-6bf9-4418-bf4e-ee48bef41875,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442209287-172.17.0.10-1599388574506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5291c8c0-1600-4d23-b19c-9888e8ac60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-caba0488-61a5-40bc-8bfe-369dbcd37887,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-290fcf73-683d-4b12-b4d9-a5bd62aa59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7c5a463c-2c1d-4e3a-8355-0e7c02fc0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-2ae8c50d-34b8-4ff0-a2e6-2941cd048c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-44493d45-cd8c-4b1e-a7d3-9ea4a4c5f70a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-90f2adaa-7a02-4f53-9828-f0ba591a4823,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-6194fe08-6bf9-4418-bf4e-ee48bef41875,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160481722-172.17.0.10-1599388612114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-0f64ad6e-c68d-48d1-b946-d50543b497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-60059b82-6d54-4359-a8af-90c9aa6e30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-5c1500cc-ce86-4ba8-89b1-44750c62c76f,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-adeb855e-7f25-4921-8eb4-57567985fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-636a2a8a-f024-4885-a6c6-2395b9c6841d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-7e632001-29ba-41cf-8181-792ca39052b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-9a4700d8-cfe3-49bb-ba61-d166ce096f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c36fd188-fb1e-4f0e-a441-ac25054155df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160481722-172.17.0.10-1599388612114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-0f64ad6e-c68d-48d1-b946-d50543b497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-60059b82-6d54-4359-a8af-90c9aa6e30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-5c1500cc-ce86-4ba8-89b1-44750c62c76f,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-adeb855e-7f25-4921-8eb4-57567985fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-636a2a8a-f024-4885-a6c6-2395b9c6841d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-7e632001-29ba-41cf-8181-792ca39052b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-9a4700d8-cfe3-49bb-ba61-d166ce096f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-c36fd188-fb1e-4f0e-a441-ac25054155df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37611992-172.17.0.10-1599388678418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-1bcf35c4-74e2-4022-bab2-063e8219b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-fbfaa720-86ac-4bdb-8c11-6efc2c191a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-a81c4a4b-981d-48aa-adbf-d20a12d46681,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-60d0cc7e-57cd-48dc-8ae9-eb7dc133249b,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-0bc5cb75-f71c-4acf-8b5b-f09e9854763b,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-ccfc52b1-8639-4701-8e15-70269c0229d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-41823380-db64-4eee-8c65-2cd203d4e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-010482ed-3619-412d-8b82-93c86c09b9f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37611992-172.17.0.10-1599388678418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-1bcf35c4-74e2-4022-bab2-063e8219b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-fbfaa720-86ac-4bdb-8c11-6efc2c191a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-a81c4a4b-981d-48aa-adbf-d20a12d46681,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-60d0cc7e-57cd-48dc-8ae9-eb7dc133249b,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-0bc5cb75-f71c-4acf-8b5b-f09e9854763b,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-ccfc52b1-8639-4701-8e15-70269c0229d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-41823380-db64-4eee-8c65-2cd203d4e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-010482ed-3619-412d-8b82-93c86c09b9f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351578774-172.17.0.10-1599388715183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36357,DS-43a0c553-550b-48f6-b759-b495c31c6178,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-31579b43-2b10-4053-b931-a93f965477b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-272d057b-d285-4ef5-a857-0d6cf07cca33,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-61ee7f6b-6a41-48c0-8b64-f2a02b66d342,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f7758138-8dda-4f95-b35b-a6f939770c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-deac12bf-a7d2-4600-bbf5-d24ddab518d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-9bb18a61-dbf9-4eb5-a9d0-ddc5102f7562,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-b9a962a4-4074-45a2-a74e-190cbf4aac05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351578774-172.17.0.10-1599388715183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36357,DS-43a0c553-550b-48f6-b759-b495c31c6178,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-31579b43-2b10-4053-b931-a93f965477b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-272d057b-d285-4ef5-a857-0d6cf07cca33,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-61ee7f6b-6a41-48c0-8b64-f2a02b66d342,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-f7758138-8dda-4f95-b35b-a6f939770c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-deac12bf-a7d2-4600-bbf5-d24ddab518d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-9bb18a61-dbf9-4eb5-a9d0-ddc5102f7562,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-b9a962a4-4074-45a2-a74e-190cbf4aac05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445447605-172.17.0.10-1599388845798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-b74a266b-e486-4e50-b867-b19207a28d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-7e75349a-a189-4c95-84a4-5464ea99ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-23f8b73a-aa91-4970-9566-d7819fc18186,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-908d14e9-a800-4c1f-a38c-f85410bc3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-70655d6a-34e1-44d5-9602-6483c8626202,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-3a8c5c36-2edd-4a1d-93c8-159bbcbc2871,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-38e971be-5a0a-4abe-b1d0-e62e09ad4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-f7323c71-96e5-47fa-9c1a-2bc9631483fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445447605-172.17.0.10-1599388845798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-b74a266b-e486-4e50-b867-b19207a28d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-7e75349a-a189-4c95-84a4-5464ea99ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-23f8b73a-aa91-4970-9566-d7819fc18186,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-908d14e9-a800-4c1f-a38c-f85410bc3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-70655d6a-34e1-44d5-9602-6483c8626202,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-3a8c5c36-2edd-4a1d-93c8-159bbcbc2871,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-38e971be-5a0a-4abe-b1d0-e62e09ad4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-f7323c71-96e5-47fa-9c1a-2bc9631483fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001119496-172.17.0.10-1599389024518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-01732d37-9a94-4540-8173-4e5ba63015ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-8c70cb04-00d3-4b78-8c05-51a7192a1342,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-a917a70e-8ba3-43c1-acdb-9ad1d9aca349,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-eb4ad3fb-195b-4091-a452-3bf0a9d8598b,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-c0a98884-a78c-4766-bd12-9f476897e803,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-843ca867-e3f8-4b69-ad63-33f136f5c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-a2f942a7-cb55-454b-8ac4-1e59f2acb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bd7f775a-f46b-4920-96d0-8a221379ee65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001119496-172.17.0.10-1599389024518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-01732d37-9a94-4540-8173-4e5ba63015ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-8c70cb04-00d3-4b78-8c05-51a7192a1342,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-a917a70e-8ba3-43c1-acdb-9ad1d9aca349,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-eb4ad3fb-195b-4091-a452-3bf0a9d8598b,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-c0a98884-a78c-4766-bd12-9f476897e803,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-843ca867-e3f8-4b69-ad63-33f136f5c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-a2f942a7-cb55-454b-8ac4-1e59f2acb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bd7f775a-f46b-4920-96d0-8a221379ee65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588121870-172.17.0.10-1599389065861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-887415d9-5d59-42e6-aa85-0c344eed1528,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-8c711912-1cb2-4534-b7c4-c78bdb41310a,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-1e5ddeb6-7383-4181-9fa6-9d444c16ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-fdd9b26d-d57e-4c2e-8314-44605327cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-0d436b3e-b951-4d50-8506-75f317f73634,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-bed42c05-3bb9-4ee8-976b-1bdafaa28a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-b631f282-9d65-469c-a1b6-e813b8256b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-108694e0-94d8-4169-9c6c-649978fa5239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588121870-172.17.0.10-1599389065861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-887415d9-5d59-42e6-aa85-0c344eed1528,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-8c711912-1cb2-4534-b7c4-c78bdb41310a,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-1e5ddeb6-7383-4181-9fa6-9d444c16ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-fdd9b26d-d57e-4c2e-8314-44605327cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-0d436b3e-b951-4d50-8506-75f317f73634,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-bed42c05-3bb9-4ee8-976b-1bdafaa28a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-b631f282-9d65-469c-a1b6-e813b8256b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-108694e0-94d8-4169-9c6c-649978fa5239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380406496-172.17.0.10-1599389355732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-366ee987-f7b1-416c-80cd-6a46d90592d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-02518c41-8f63-4841-981d-35f5d9aa2c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-b5592b39-5783-49f3-9866-22e8737bf4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-64a5ac75-534e-4bc1-8009-b7498eb66381,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-13b3bbe5-68bb-4dd9-835d-08a0fa018035,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c3f80f8c-1613-40d3-83fb-13e95f960a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-8b6847cd-e1e3-44ff-84b2-f55e96c6c0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-32a8040a-5668-42bb-87de-2de2594cff8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380406496-172.17.0.10-1599389355732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-366ee987-f7b1-416c-80cd-6a46d90592d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-02518c41-8f63-4841-981d-35f5d9aa2c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-b5592b39-5783-49f3-9866-22e8737bf4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-64a5ac75-534e-4bc1-8009-b7498eb66381,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-13b3bbe5-68bb-4dd9-835d-08a0fa018035,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c3f80f8c-1613-40d3-83fb-13e95f960a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-8b6847cd-e1e3-44ff-84b2-f55e96c6c0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-32a8040a-5668-42bb-87de-2de2594cff8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481658721-172.17.0.10-1599389464096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-39af799e-3289-4a22-91f4-88a7ab457cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-4db6d864-af7f-4d4b-8146-808a8bc31104,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-6df00166-8cb0-4013-8085-76c49aca99e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-eafecb7e-3c67-4746-881f-c72d2b2e63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-d12221a7-67a1-45b7-9476-9f21c13a3746,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-84cea752-2c2a-4b0b-936d-3e6f5780dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-25c57c11-b7a0-4772-ab10-e970a8f1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-7753978a-6842-4d13-a530-c6f8e99023d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481658721-172.17.0.10-1599389464096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-39af799e-3289-4a22-91f4-88a7ab457cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-4db6d864-af7f-4d4b-8146-808a8bc31104,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-6df00166-8cb0-4013-8085-76c49aca99e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-eafecb7e-3c67-4746-881f-c72d2b2e63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-d12221a7-67a1-45b7-9476-9f21c13a3746,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-84cea752-2c2a-4b0b-936d-3e6f5780dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-25c57c11-b7a0-4772-ab10-e970a8f1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-7753978a-6842-4d13-a530-c6f8e99023d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034861480-172.17.0.10-1599389891629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-7bea91d2-1b34-4349-8e0e-73c51f27dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-c2b5fb38-3a63-4b85-a852-5de642123cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-16e634a7-d722-4cfa-bccc-ca6145f87732,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-7d3b9b6a-18d8-4e69-9de9-80f589c47ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-f52d981a-c889-4769-baf4-0a95df63daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-5159ed46-27a8-4846-8429-e0834f7fee44,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-cf2e2d50-1add-465a-8288-37c88039cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-48897e63-e094-469e-b74e-f0c2a4d6c84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034861480-172.17.0.10-1599389891629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-7bea91d2-1b34-4349-8e0e-73c51f27dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-c2b5fb38-3a63-4b85-a852-5de642123cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-16e634a7-d722-4cfa-bccc-ca6145f87732,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-7d3b9b6a-18d8-4e69-9de9-80f589c47ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-f52d981a-c889-4769-baf4-0a95df63daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-5159ed46-27a8-4846-8429-e0834f7fee44,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-cf2e2d50-1add-465a-8288-37c88039cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-48897e63-e094-469e-b74e-f0c2a4d6c84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230485603-172.17.0.10-1599390088519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-8893aaf8-27c5-4116-be2e-dfb870003ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-b975dfab-a9e1-4c69-968c-271740b1caa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-04b7b0fe-146c-4a84-b299-cac6d0fa9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-5ec5ccf5-5fd6-4e82-9f0d-6a408548f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b16ce1f9-faf8-4ef5-a0d9-f12313d7bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-4c7eef02-5ba5-4ebd-ade4-bef2ac87c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-2f4cb4fd-4412-427f-8024-85e50b2b35ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-70858ec4-98b6-44d0-823d-a114ce203295,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230485603-172.17.0.10-1599390088519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-8893aaf8-27c5-4116-be2e-dfb870003ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-b975dfab-a9e1-4c69-968c-271740b1caa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-04b7b0fe-146c-4a84-b299-cac6d0fa9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-5ec5ccf5-5fd6-4e82-9f0d-6a408548f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b16ce1f9-faf8-4ef5-a0d9-f12313d7bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-4c7eef02-5ba5-4ebd-ade4-bef2ac87c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-2f4cb4fd-4412-427f-8024-85e50b2b35ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-70858ec4-98b6-44d0-823d-a114ce203295,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5243
