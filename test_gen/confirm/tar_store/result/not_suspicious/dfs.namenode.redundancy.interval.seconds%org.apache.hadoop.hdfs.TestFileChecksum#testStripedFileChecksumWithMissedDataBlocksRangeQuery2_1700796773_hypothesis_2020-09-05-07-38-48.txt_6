reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838334233-172.17.0.11-1599291579120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-9b80e2e8-f2c4-44a9-a824-0a65cca70977,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-f5f4a0a4-6c6e-4bc4-9600-146c4e02814f,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-512dfd6f-cc59-4895-bf77-4f93c0e6f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-14d9b237-3a36-4941-b141-86e35d69013c,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-63b29697-c600-4315-8c04-6b541541b685,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bfda9c2d-2103-4c47-837d-20cfdd6b15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-fa822ff1-784e-4ab8-9c9a-68e58ee413c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-68107663-3c98-4394-acf6-f83060b74b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838334233-172.17.0.11-1599291579120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-9b80e2e8-f2c4-44a9-a824-0a65cca70977,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-f5f4a0a4-6c6e-4bc4-9600-146c4e02814f,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-512dfd6f-cc59-4895-bf77-4f93c0e6f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-14d9b237-3a36-4941-b141-86e35d69013c,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-63b29697-c600-4315-8c04-6b541541b685,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bfda9c2d-2103-4c47-837d-20cfdd6b15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-fa822ff1-784e-4ab8-9c9a-68e58ee413c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-68107663-3c98-4394-acf6-f83060b74b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968648832-172.17.0.11-1599291796757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38473,DS-ac269c24-a0ce-4a18-8040-c9906e7f05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-272b7a6d-6bea-4166-8a58-7e62f7b50fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-1491e1fc-660b-4979-8cfa-32b7c91484fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-ee011ae6-f30a-4b82-a671-39c91aad9452,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5085bd16-3b9c-4ef2-a469-7d02decb16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-5bc97852-6449-482e-ad2e-8c85a81ccc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-77b5543b-84ab-4fad-9d63-f71eefe5fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-dfc845df-0d47-4d0a-aaea-7440a0d4ccec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968648832-172.17.0.11-1599291796757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38473,DS-ac269c24-a0ce-4a18-8040-c9906e7f05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-272b7a6d-6bea-4166-8a58-7e62f7b50fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-1491e1fc-660b-4979-8cfa-32b7c91484fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-ee011ae6-f30a-4b82-a671-39c91aad9452,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5085bd16-3b9c-4ef2-a469-7d02decb16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-5bc97852-6449-482e-ad2e-8c85a81ccc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-77b5543b-84ab-4fad-9d63-f71eefe5fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-dfc845df-0d47-4d0a-aaea-7440a0d4ccec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985217114-172.17.0.11-1599291966492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-1b203622-f59a-4930-b990-962ad5ed7639,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bf3c9d64-e7ba-4a48-b673-1f297f227dac,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-e4df3bc3-9e05-4250-adec-1c14b7b8470b,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-f402667c-4b18-4586-9531-41514c77c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-174bc0ea-3f39-4125-9895-f7cf1ec56679,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-9ae57f09-74d3-4c27-b8c6-1f8524672c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a5ea9945-3db0-44f1-a908-e71be6e07810,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-3bcddb67-7b62-4f48-b664-06aee413b87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985217114-172.17.0.11-1599291966492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-1b203622-f59a-4930-b990-962ad5ed7639,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bf3c9d64-e7ba-4a48-b673-1f297f227dac,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-e4df3bc3-9e05-4250-adec-1c14b7b8470b,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-f402667c-4b18-4586-9531-41514c77c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-174bc0ea-3f39-4125-9895-f7cf1ec56679,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-9ae57f09-74d3-4c27-b8c6-1f8524672c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a5ea9945-3db0-44f1-a908-e71be6e07810,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-3bcddb67-7b62-4f48-b664-06aee413b87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902326417-172.17.0.11-1599292228448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-a8d37b69-4bcd-437b-b165-23d053a2d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-2ea05317-e6bf-438a-87f1-c439159da5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7f29ae94-1249-438b-aee6-c8acba5f2473,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-ebb4d778-e0e3-45f5-8a42-f868b66e7498,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-37a244f4-b462-48ff-93b0-69b8b5200700,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-59aab8fd-29f1-442e-afef-af49ad72cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-428b9870-5a46-431e-a3df-76bdababca17,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-b397f98b-9e31-416f-94db-3f52b3e56c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902326417-172.17.0.11-1599292228448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-a8d37b69-4bcd-437b-b165-23d053a2d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-2ea05317-e6bf-438a-87f1-c439159da5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7f29ae94-1249-438b-aee6-c8acba5f2473,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-ebb4d778-e0e3-45f5-8a42-f868b66e7498,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-37a244f4-b462-48ff-93b0-69b8b5200700,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-59aab8fd-29f1-442e-afef-af49ad72cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-428b9870-5a46-431e-a3df-76bdababca17,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-b397f98b-9e31-416f-94db-3f52b3e56c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240547302-172.17.0.11-1599293001249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-b194666d-8ff4-407d-9988-b19139caff94,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-d069dfcf-0e73-400d-8ade-8a8f5bc33515,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-be2d340b-b90d-467e-85ab-f0250ce42c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-b665efbc-7d4d-4d22-8c07-84accb4c9e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-9438f391-79e8-419c-b4c0-2968afda0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e6beaa23-50b4-4870-836f-e04755cbb064,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-fbc9cd8e-4e94-49ad-8911-4c7523de6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-aa7428b9-9f4f-42dd-8c0f-1324dd2d225a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240547302-172.17.0.11-1599293001249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-b194666d-8ff4-407d-9988-b19139caff94,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-d069dfcf-0e73-400d-8ade-8a8f5bc33515,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-be2d340b-b90d-467e-85ab-f0250ce42c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-b665efbc-7d4d-4d22-8c07-84accb4c9e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-9438f391-79e8-419c-b4c0-2968afda0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e6beaa23-50b4-4870-836f-e04755cbb064,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-fbc9cd8e-4e94-49ad-8911-4c7523de6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-aa7428b9-9f4f-42dd-8c0f-1324dd2d225a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317430440-172.17.0.11-1599293322568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-ecb6c7db-2e38-4969-87df-89e99ef53c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-9c595d6a-706c-43e9-93ee-fc21ab2fed55,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-39569d21-5d29-4d40-9418-2d4575d9e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-0715448f-5f1c-43e2-ba55-f8dd5742b43f,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-7e93b056-2bc1-4a2c-9f8a-a1339fba2258,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-98a8bcd8-6df7-4f83-a50d-864ef8e3e714,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-0d36ba67-f07e-40d7-8f3d-0e901f9677f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-0a76c9a3-0205-4c46-b836-c60e80114603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317430440-172.17.0.11-1599293322568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-ecb6c7db-2e38-4969-87df-89e99ef53c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-9c595d6a-706c-43e9-93ee-fc21ab2fed55,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-39569d21-5d29-4d40-9418-2d4575d9e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-0715448f-5f1c-43e2-ba55-f8dd5742b43f,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-7e93b056-2bc1-4a2c-9f8a-a1339fba2258,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-98a8bcd8-6df7-4f83-a50d-864ef8e3e714,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-0d36ba67-f07e-40d7-8f3d-0e901f9677f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-0a76c9a3-0205-4c46-b836-c60e80114603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381065316-172.17.0.11-1599293854040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-c670ded2-7ad5-4214-bd85-842d5529342c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-d3a18552-83f0-44bb-8e92-c87fd9a7813a,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-7b1d6ffe-8232-4645-8017-e4f51b179920,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-e18fea0f-9a85-483a-b759-72b3645b5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-4ba6f278-b993-4095-9408-d9d111bf0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-fe693776-7b9b-4643-bce3-f9375f6993f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-73010ba7-9d7d-467d-9466-429857ffe2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-d16a9559-f965-4830-bff5-a70d815a1b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381065316-172.17.0.11-1599293854040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-c670ded2-7ad5-4214-bd85-842d5529342c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-d3a18552-83f0-44bb-8e92-c87fd9a7813a,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-7b1d6ffe-8232-4645-8017-e4f51b179920,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-e18fea0f-9a85-483a-b759-72b3645b5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-4ba6f278-b993-4095-9408-d9d111bf0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-fe693776-7b9b-4643-bce3-f9375f6993f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-73010ba7-9d7d-467d-9466-429857ffe2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-d16a9559-f965-4830-bff5-a70d815a1b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902639443-172.17.0.11-1599294092208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-5b8ccee3-ce10-4f1d-adcf-bc2890591eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-38738277-d59b-4368-ba87-c49b378bb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-3112c186-a8b3-49b2-a698-25ddd1e61b16,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-526800e2-5d55-4255-b2d4-69465da0963d,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-c70930e0-f50c-482f-937f-4425722ca797,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1da96686-3344-42c7-aaec-88cbaa969e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-7f6a9938-05fd-4917-8915-cde2c654d773,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-a6d88cfa-bc80-4f94-8816-9543ccef8caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902639443-172.17.0.11-1599294092208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-5b8ccee3-ce10-4f1d-adcf-bc2890591eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-38738277-d59b-4368-ba87-c49b378bb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-3112c186-a8b3-49b2-a698-25ddd1e61b16,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-526800e2-5d55-4255-b2d4-69465da0963d,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-c70930e0-f50c-482f-937f-4425722ca797,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-1da96686-3344-42c7-aaec-88cbaa969e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-7f6a9938-05fd-4917-8915-cde2c654d773,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-a6d88cfa-bc80-4f94-8816-9543ccef8caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557950357-172.17.0.11-1599294167659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-ce030064-7312-429a-a404-158716e6c587,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-48f2cb20-6e2e-417e-b6ef-63520fc0666b,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-1af1058c-beca-4851-bf96-d296b9832db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-059564bd-b4bd-4ef8-b201-1781080bd944,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-cfe869b8-92b3-48c1-a9f3-89da781ea15c,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-0d7e6439-dc6b-4aba-8a7e-c8692e68f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-752f5020-981c-4027-94ca-882af9c91b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-bb08ead9-86b4-4bbc-98b3-941bc3f1b8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557950357-172.17.0.11-1599294167659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-ce030064-7312-429a-a404-158716e6c587,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-48f2cb20-6e2e-417e-b6ef-63520fc0666b,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-1af1058c-beca-4851-bf96-d296b9832db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-059564bd-b4bd-4ef8-b201-1781080bd944,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-cfe869b8-92b3-48c1-a9f3-89da781ea15c,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-0d7e6439-dc6b-4aba-8a7e-c8692e68f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-752f5020-981c-4027-94ca-882af9c91b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-bb08ead9-86b4-4bbc-98b3-941bc3f1b8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096348954-172.17.0.11-1599294747351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-4282e336-62ca-4613-b16f-9c142c29499a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-9da04cb3-e393-42f0-8536-af6c915f5682,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-a40e9766-0c13-409f-b62b-b25c86ce3a58,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-57e4ea5d-b9e4-4d20-a38c-dc1cf1fe00f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-e917a6cc-cd7e-4435-a050-076047c81f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-96b5fac2-11f1-4073-94fc-ffe68c13adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-57e0fe16-e369-42ce-ba05-02940f8e9412,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8c7f7ee5-c3ef-4e99-bb9a-96b9ed55a5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096348954-172.17.0.11-1599294747351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-4282e336-62ca-4613-b16f-9c142c29499a,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-9da04cb3-e393-42f0-8536-af6c915f5682,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-a40e9766-0c13-409f-b62b-b25c86ce3a58,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-57e4ea5d-b9e4-4d20-a38c-dc1cf1fe00f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-e917a6cc-cd7e-4435-a050-076047c81f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-96b5fac2-11f1-4073-94fc-ffe68c13adf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-57e0fe16-e369-42ce-ba05-02940f8e9412,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8c7f7ee5-c3ef-4e99-bb9a-96b9ed55a5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762239707-172.17.0.11-1599296285812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-cab2f8fc-5fe0-4d4f-88ee-b3135d2a5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-dddd5340-c373-463e-84eb-77b4226da26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-135c45b0-47f2-459d-8cdf-e180cd87f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-308b2db1-d6e4-4ae4-986c-bad2ad4c812e,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-13c33b5f-fdfb-4997-939c-70f7133090a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e126179b-3459-423a-9b19-46cab06bd25b,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-8a29a84b-80f3-43f9-9ae9-da4dde329d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-50ef041b-f7a1-433f-807c-3c0feda6cd47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762239707-172.17.0.11-1599296285812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-cab2f8fc-5fe0-4d4f-88ee-b3135d2a5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-dddd5340-c373-463e-84eb-77b4226da26f,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-135c45b0-47f2-459d-8cdf-e180cd87f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-308b2db1-d6e4-4ae4-986c-bad2ad4c812e,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-13c33b5f-fdfb-4997-939c-70f7133090a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-e126179b-3459-423a-9b19-46cab06bd25b,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-8a29a84b-80f3-43f9-9ae9-da4dde329d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-50ef041b-f7a1-433f-807c-3c0feda6cd47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 10s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999432044-172.17.0.11-1599297155276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-2fb83449-aec5-4bd2-9184-fca2823d1356,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-0bb7e8ca-30e2-4997-9aba-ef9204ab7a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8891536f-f89a-45ac-a1f7-bf008a268794,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d3f69959-88ae-4d80-b503-06e43a240891,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-90d319b2-9545-4174-923f-5065691b6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9c80d114-fcbc-487f-8b83-30d0a87f4cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-49d82fbf-11e7-451c-93ef-ddb81dae6c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-15ebea3f-a92a-4786-911e-628b2a1cd8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999432044-172.17.0.11-1599297155276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-2fb83449-aec5-4bd2-9184-fca2823d1356,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-0bb7e8ca-30e2-4997-9aba-ef9204ab7a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8891536f-f89a-45ac-a1f7-bf008a268794,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d3f69959-88ae-4d80-b503-06e43a240891,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-90d319b2-9545-4174-923f-5065691b6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9c80d114-fcbc-487f-8b83-30d0a87f4cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-49d82fbf-11e7-451c-93ef-ddb81dae6c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-15ebea3f-a92a-4786-911e-628b2a1cd8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5810
