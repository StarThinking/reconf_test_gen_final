reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220259969-172.17.0.21-1599318647939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-90bf1b6b-5065-41c3-abe9-e26de7e9b154,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-79195f4b-d842-4435-bfc4-96d056645e68,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-1afdaffe-8df1-4f52-9404-6151017f7059,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-b8d70307-c090-4bfd-9271-087caaddce37,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-3d9701f6-454a-43b4-9a3e-57e15b063f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-eb08a12d-854b-4d18-b25b-5fbf3d9bff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-a0f44ba8-c7fe-45a8-a769-18c0cab41591,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-38aef0a4-d407-405e-ac33-66d8432eda95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220259969-172.17.0.21-1599318647939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-90bf1b6b-5065-41c3-abe9-e26de7e9b154,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-79195f4b-d842-4435-bfc4-96d056645e68,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-1afdaffe-8df1-4f52-9404-6151017f7059,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-b8d70307-c090-4bfd-9271-087caaddce37,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-3d9701f6-454a-43b4-9a3e-57e15b063f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-eb08a12d-854b-4d18-b25b-5fbf3d9bff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-a0f44ba8-c7fe-45a8-a769-18c0cab41591,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-38aef0a4-d407-405e-ac33-66d8432eda95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199709120-172.17.0.21-1599318689398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-8e64ed07-6aa6-4165-8846-0406967252cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-0fcac0fe-dcc0-423a-9516-cd2c5c476c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-11f8c92c-ba64-497a-92eb-88caf8a5d839,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-80963208-bd7c-4e26-a252-21055db0a3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-08cb5125-d836-425b-938b-f2fea88339f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-29d7601a-5fa8-4f96-8582-2b233fe4bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-51ded723-844a-4281-bcc4-c961b2c7e91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-4f7e1bd5-eb13-46e2-bc20-e3ff5c0f7bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199709120-172.17.0.21-1599318689398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-8e64ed07-6aa6-4165-8846-0406967252cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-0fcac0fe-dcc0-423a-9516-cd2c5c476c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-11f8c92c-ba64-497a-92eb-88caf8a5d839,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-80963208-bd7c-4e26-a252-21055db0a3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-08cb5125-d836-425b-938b-f2fea88339f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-29d7601a-5fa8-4f96-8582-2b233fe4bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-51ded723-844a-4281-bcc4-c961b2c7e91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-4f7e1bd5-eb13-46e2-bc20-e3ff5c0f7bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237442025-172.17.0.21-1599318763903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-00113a4b-d23a-4d48-9f2c-f3f673371a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ebc17bf1-ea9a-4f57-8501-23df1e38a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-a86376b1-7bc1-4196-bbac-890058628fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7f873cb0-40ba-457a-b983-1b9eb37e24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-b701e0ec-c8ed-46f2-aba2-a6459d200739,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-25a8d20e-8503-452e-a26d-51624b308868,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-099dc6bc-691d-4134-9ca1-610aca92d4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-eeefe7e5-b23b-4d1e-8808-f4cbab813aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237442025-172.17.0.21-1599318763903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-00113a4b-d23a-4d48-9f2c-f3f673371a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ebc17bf1-ea9a-4f57-8501-23df1e38a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-a86376b1-7bc1-4196-bbac-890058628fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-7f873cb0-40ba-457a-b983-1b9eb37e24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-b701e0ec-c8ed-46f2-aba2-a6459d200739,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-25a8d20e-8503-452e-a26d-51624b308868,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-099dc6bc-691d-4134-9ca1-610aca92d4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-eeefe7e5-b23b-4d1e-8808-f4cbab813aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518634494-172.17.0.21-1599319627097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-c112aee9-374d-4d21-9619-ce8a02d2085b,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-3edf9330-f1ce-4735-8074-63832e768500,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-2214cb04-ec4a-4893-a4a4-386ca3715538,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0f0c1c20-471e-4b31-80fe-e195ba1212ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1a0d90a9-16a6-4ddc-a4b0-30b66fd39fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-c9340865-2ac5-4fa3-89ee-2d2a84af9156,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-addf3634-2f03-4d1c-b6c7-4022a40e3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-1e8ca4f4-e81f-4c80-8ea4-a6fcacf86a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518634494-172.17.0.21-1599319627097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-c112aee9-374d-4d21-9619-ce8a02d2085b,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-3edf9330-f1ce-4735-8074-63832e768500,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-2214cb04-ec4a-4893-a4a4-386ca3715538,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0f0c1c20-471e-4b31-80fe-e195ba1212ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1a0d90a9-16a6-4ddc-a4b0-30b66fd39fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-c9340865-2ac5-4fa3-89ee-2d2a84af9156,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-addf3634-2f03-4d1c-b6c7-4022a40e3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-1e8ca4f4-e81f-4c80-8ea4-a6fcacf86a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323136795-172.17.0.21-1599319895719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-9cb31d1a-077a-4c20-9a61-36510b7d9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-e932d73b-8d62-489f-8636-fa9b057d7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-0c000ac4-2c83-4c19-ba61-ac89bf5bc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-cc3227e8-fa89-434f-afdf-389f4c5633d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9e23ce44-9434-4985-a0cc-744b225f30d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-77a41124-ac3b-46bf-a573-fa434e36ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a7b54e14-647f-498e-82e9-ef0e89366006,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-e1a59cfb-b079-483b-8311-309c4dd33663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323136795-172.17.0.21-1599319895719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-9cb31d1a-077a-4c20-9a61-36510b7d9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-e932d73b-8d62-489f-8636-fa9b057d7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-0c000ac4-2c83-4c19-ba61-ac89bf5bc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-cc3227e8-fa89-434f-afdf-389f4c5633d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9e23ce44-9434-4985-a0cc-744b225f30d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-77a41124-ac3b-46bf-a573-fa434e36ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a7b54e14-647f-498e-82e9-ef0e89366006,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-e1a59cfb-b079-483b-8311-309c4dd33663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064195059-172.17.0.21-1599320388321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-f24beb40-8470-4f66-8364-ba5b4d388060,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-abc83ccc-e908-46fe-84f3-ca8231b23604,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-aaba660b-cf5c-4658-b2c2-b4f0ac613d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-c454ed3a-119a-4aae-8c1d-8bc5301f7cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-5fbf365f-fb96-476f-922c-c361c20208cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-3d328274-8fdf-434c-9d8d-0effdc201a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-25e4e295-1786-46fc-8871-2452bef67f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d0f0ba8b-a34e-474b-9897-4c55dcfa7382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064195059-172.17.0.21-1599320388321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-f24beb40-8470-4f66-8364-ba5b4d388060,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-abc83ccc-e908-46fe-84f3-ca8231b23604,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-aaba660b-cf5c-4658-b2c2-b4f0ac613d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-c454ed3a-119a-4aae-8c1d-8bc5301f7cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-5fbf365f-fb96-476f-922c-c361c20208cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-3d328274-8fdf-434c-9d8d-0effdc201a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-25e4e295-1786-46fc-8871-2452bef67f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d0f0ba8b-a34e-474b-9897-4c55dcfa7382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121615771-172.17.0.21-1599320812997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-0430bdc9-060f-466f-bf65-32ec5c141468,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-2281ad2f-7646-4a12-bb76-a313d75ecdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-38e850fc-db23-498b-b40c-30feb483a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-cd34357c-644c-45d2-9981-276a113316c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-5b9de04f-c7b5-42db-884a-8a7563e04382,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8bbe25de-0c7a-47b8-8735-5f47f8d9e757,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-4d8e1ffe-4657-4997-9440-d560478384ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-f37b610e-fe3d-4793-8f1c-09eb816f3e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121615771-172.17.0.21-1599320812997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-0430bdc9-060f-466f-bf65-32ec5c141468,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-2281ad2f-7646-4a12-bb76-a313d75ecdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-38e850fc-db23-498b-b40c-30feb483a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-cd34357c-644c-45d2-9981-276a113316c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-5b9de04f-c7b5-42db-884a-8a7563e04382,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-8bbe25de-0c7a-47b8-8735-5f47f8d9e757,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-4d8e1ffe-4657-4997-9440-d560478384ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-f37b610e-fe3d-4793-8f1c-09eb816f3e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487796299-172.17.0.21-1599320847957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-fc4a2653-e6bf-4080-a0a7-a6a413f86202,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-72213da8-2c8c-460b-80f2-e3220920b939,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-13c1679b-be6f-471c-9327-6f281bbc481d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-4b25907b-3ecf-4fd4-8721-0484aff3ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-6e8a1d24-fa46-4e80-9588-c7b516a5fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-c84ccb4d-b198-4193-a14e-eec3da140a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-674380fa-b3c2-4c61-8985-193b31352d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-bac0c046-7e7d-40e6-a29e-fda7f3da7e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487796299-172.17.0.21-1599320847957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-fc4a2653-e6bf-4080-a0a7-a6a413f86202,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-72213da8-2c8c-460b-80f2-e3220920b939,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-13c1679b-be6f-471c-9327-6f281bbc481d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-4b25907b-3ecf-4fd4-8721-0484aff3ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-6e8a1d24-fa46-4e80-9588-c7b516a5fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-c84ccb4d-b198-4193-a14e-eec3da140a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-674380fa-b3c2-4c61-8985-193b31352d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-bac0c046-7e7d-40e6-a29e-fda7f3da7e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646836420-172.17.0.21-1599320963284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-8ff0f53a-7c87-4746-aea0-d06bea1c4306,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-4f3fbb04-1e8b-47aa-8aaf-ae9113b5769f,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-778963c5-332d-450a-8114-80c31726c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-1f056867-7ef8-4543-bbe5-fbfc4b392606,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-e7a72d2e-4005-4917-9b08-1fd8dbc89124,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-6ae7f8df-76db-4134-a233-685095bdd4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b140a932-5193-4751-90a9-9191b4a09c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-b89ef86b-0e26-4e6b-9d69-5c421633b647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646836420-172.17.0.21-1599320963284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-8ff0f53a-7c87-4746-aea0-d06bea1c4306,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-4f3fbb04-1e8b-47aa-8aaf-ae9113b5769f,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-778963c5-332d-450a-8114-80c31726c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-1f056867-7ef8-4543-bbe5-fbfc4b392606,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-e7a72d2e-4005-4917-9b08-1fd8dbc89124,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-6ae7f8df-76db-4134-a233-685095bdd4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b140a932-5193-4751-90a9-9191b4a09c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-b89ef86b-0e26-4e6b-9d69-5c421633b647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007136921-172.17.0.21-1599321271444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-18baffe1-5d69-43d5-8a54-b8aa12c07aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-7b530eb6-344b-46e1-96b2-5be39015c997,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-4b8ed5c4-bf20-400d-b048-7820250bf3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-c6d5fa50-710b-4827-ab37-3d70d4af5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-4aa3cc9c-1230-48b8-aae4-b7270a0a3ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-c5eb480b-2d7e-433d-b680-602c216331cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a9088bac-754c-4ee9-b151-78f1f3502d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-3be884fb-7bbf-40cd-a4f9-c98248a2680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007136921-172.17.0.21-1599321271444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-18baffe1-5d69-43d5-8a54-b8aa12c07aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-7b530eb6-344b-46e1-96b2-5be39015c997,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-4b8ed5c4-bf20-400d-b048-7820250bf3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-c6d5fa50-710b-4827-ab37-3d70d4af5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-4aa3cc9c-1230-48b8-aae4-b7270a0a3ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-c5eb480b-2d7e-433d-b680-602c216331cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a9088bac-754c-4ee9-b151-78f1f3502d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-3be884fb-7bbf-40cd-a4f9-c98248a2680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004525979-172.17.0.21-1599321533892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-b75c4342-8910-4514-a712-459957f2a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-46ec28a5-67d8-42b5-96f1-037581392700,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-26c37086-e5b1-4f44-9ef2-68e7cf2260e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-3ff650a0-1637-484f-9514-63710fb7f848,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ac4ec62b-8235-4070-82c9-3144434b5613,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4b15a06d-c757-4ac1-b435-83a63907f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-2e9cbbb2-2a90-4ceb-85a7-ad5f17544636,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-e1eb5e9b-9f18-4b0c-a937-fee81fc83408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004525979-172.17.0.21-1599321533892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-b75c4342-8910-4514-a712-459957f2a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-46ec28a5-67d8-42b5-96f1-037581392700,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-26c37086-e5b1-4f44-9ef2-68e7cf2260e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-3ff650a0-1637-484f-9514-63710fb7f848,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ac4ec62b-8235-4070-82c9-3144434b5613,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4b15a06d-c757-4ac1-b435-83a63907f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-2e9cbbb2-2a90-4ceb-85a7-ad5f17544636,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-e1eb5e9b-9f18-4b0c-a937-fee81fc83408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015777291-172.17.0.21-1599322693463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-4b0f87c6-5bf5-4d7e-a565-3dcfcfc5d763,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-f0931d70-f762-4417-82aa-f3d3c188d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-13edb7f7-b8ce-43a3-8bfd-0e21e53cb8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-5baecbf3-b9ff-48e4-b39c-bfb436e1cf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f906cdf0-f1ea-4579-b327-11965adf4899,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-1b970ee0-9ec8-4129-8819-dbaba3c80370,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-19724d44-cdc6-4259-904c-17543060c710,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-41194e25-3b9f-47eb-937e-0c89d75d8307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015777291-172.17.0.21-1599322693463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-4b0f87c6-5bf5-4d7e-a565-3dcfcfc5d763,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-f0931d70-f762-4417-82aa-f3d3c188d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-13edb7f7-b8ce-43a3-8bfd-0e21e53cb8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-5baecbf3-b9ff-48e4-b39c-bfb436e1cf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f906cdf0-f1ea-4579-b327-11965adf4899,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-1b970ee0-9ec8-4129-8819-dbaba3c80370,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-19724d44-cdc6-4259-904c-17543060c710,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-41194e25-3b9f-47eb-937e-0c89d75d8307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272857105-172.17.0.21-1599322860687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-2cc07f22-2514-4a17-8ec8-60f2cec467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-54da34c2-b532-4f8d-9a1e-7e0d7ee6ffde,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-b44da52a-711b-4eb9-a5ca-81853e9febc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c67bf47e-16a3-4d1a-ab13-6d5701a2a36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f16c3184-23f3-4789-89e7-63ac7cd1503a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-7a7814cd-c031-4083-974a-eb20007410c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-e764924a-1c7b-49aa-ac4b-bd6a60820553,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-5fcc929c-87e5-4c5c-8d2a-4d93537b7aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272857105-172.17.0.21-1599322860687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-2cc07f22-2514-4a17-8ec8-60f2cec467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-54da34c2-b532-4f8d-9a1e-7e0d7ee6ffde,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-b44da52a-711b-4eb9-a5ca-81853e9febc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-c67bf47e-16a3-4d1a-ab13-6d5701a2a36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-f16c3184-23f3-4789-89e7-63ac7cd1503a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-7a7814cd-c031-4083-974a-eb20007410c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-e764924a-1c7b-49aa-ac4b-bd6a60820553,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-5fcc929c-87e5-4c5c-8d2a-4d93537b7aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282091474-172.17.0.21-1599322898670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-57d4bdf7-940c-4beb-8c7d-b3fb630374bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-56d0bee1-8ee0-4c83-b6c5-356313666cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-cfa0edc7-2281-404c-84fa-de443ebadbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-025fd4f8-61d6-4759-8acc-a85c8f5d6775,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-a991b8c9-7be8-43c1-b784-64e38230a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-1c1eba0f-0d9a-4b7e-b942-731c11863b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-602a432d-7e81-4b09-8bfb-37eb0c8b7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-7b2c67fe-ff04-4fc1-a284-7145b1dac452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282091474-172.17.0.21-1599322898670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-57d4bdf7-940c-4beb-8c7d-b3fb630374bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-56d0bee1-8ee0-4c83-b6c5-356313666cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-cfa0edc7-2281-404c-84fa-de443ebadbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-025fd4f8-61d6-4759-8acc-a85c8f5d6775,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-a991b8c9-7be8-43c1-b784-64e38230a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-1c1eba0f-0d9a-4b7e-b942-731c11863b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-602a432d-7e81-4b09-8bfb-37eb0c8b7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-7b2c67fe-ff04-4fc1-a284-7145b1dac452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876011564-172.17.0.21-1599323091121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-6ec5637e-7ba9-4d33-a2b5-2c3e23503948,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-a6138293-fba6-470f-93b2-d747a7bfb566,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-923d7b9a-a8a3-4f12-a43e-66a980d6d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-8fbab566-c03d-47dd-bab5-b8a1413f99da,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c70c1af3-9dc1-4fa1-868f-0d3fa1251aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-28dd9fb6-3de2-40bc-a057-59fd09a3de6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-039b97ec-97aa-456b-9c58-8a2e536d59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-abb81aff-89bf-4f20-ae39-4d20b30af2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876011564-172.17.0.21-1599323091121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-6ec5637e-7ba9-4d33-a2b5-2c3e23503948,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-a6138293-fba6-470f-93b2-d747a7bfb566,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-923d7b9a-a8a3-4f12-a43e-66a980d6d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-8fbab566-c03d-47dd-bab5-b8a1413f99da,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c70c1af3-9dc1-4fa1-868f-0d3fa1251aad,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-28dd9fb6-3de2-40bc-a057-59fd09a3de6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-039b97ec-97aa-456b-9c58-8a2e536d59f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-abb81aff-89bf-4f20-ae39-4d20b30af2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715072366-172.17.0.21-1599323380444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-8288ee07-87b0-4005-9da2-13e1e81f4463,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-487acd19-1dfb-47a7-a7d7-228f5bdf83ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-22353fb5-aa9e-4393-8007-32c4f4dcd24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-4a7af21e-b3cd-4438-a662-ec043c428afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-865d8025-ae81-4496-8f84-de545ef981be,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-83d268c4-deca-4226-bf0f-5a4ba6b13935,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-bdd55339-4dcb-45ee-8cbc-3338ec18edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-53f3f681-452a-448f-9f52-c87f9012da2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715072366-172.17.0.21-1599323380444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-8288ee07-87b0-4005-9da2-13e1e81f4463,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-487acd19-1dfb-47a7-a7d7-228f5bdf83ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-22353fb5-aa9e-4393-8007-32c4f4dcd24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-4a7af21e-b3cd-4438-a662-ec043c428afb,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-865d8025-ae81-4496-8f84-de545ef981be,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-83d268c4-deca-4226-bf0f-5a4ba6b13935,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-bdd55339-4dcb-45ee-8cbc-3338ec18edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-53f3f681-452a-448f-9f52-c87f9012da2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062703421-172.17.0.21-1599323567795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-1d244fe5-0d39-48f6-88f4-7758378cdbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-4db34f7d-c9f7-428a-a84c-44926f8ee84e,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-ca8f7a85-6f87-49be-ba6b-00e0c0c9bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-00d71884-ffc0-4ec8-879d-a138d3894223,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-524fe9f4-9237-4090-96a1-995a10e0b975,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e0747d3d-5a88-4998-a5ac-195bb3b930bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-12beef82-4ea7-42ec-b40a-923b8583d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-c8fedec1-92f4-4746-9659-5ebd2e085d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062703421-172.17.0.21-1599323567795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-1d244fe5-0d39-48f6-88f4-7758378cdbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-4db34f7d-c9f7-428a-a84c-44926f8ee84e,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-ca8f7a85-6f87-49be-ba6b-00e0c0c9bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-00d71884-ffc0-4ec8-879d-a138d3894223,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-524fe9f4-9237-4090-96a1-995a10e0b975,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e0747d3d-5a88-4998-a5ac-195bb3b930bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-12beef82-4ea7-42ec-b40a-923b8583d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-c8fedec1-92f4-4746-9659-5ebd2e085d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115339884-172.17.0.21-1599323598049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43899,DS-6c4494eb-032e-4c1d-ac1e-03611dc2d890,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-e8040c0b-9b3d-40b7-9a78-32c46fc6ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-df4c72f7-22ee-4b69-92bb-c17f8153bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-5b08f2ad-e6bb-4ed7-a640-f75ef3cc32df,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c85cb6ff-75f7-4498-a750-252f1357498b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-a5e3e406-ecd0-4a96-bf25-aafceef5735b,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-0d8bcd2b-0634-4a8e-865a-763d2b655362,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-0722a4a4-3a51-4874-9223-6d960845a1f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115339884-172.17.0.21-1599323598049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43899,DS-6c4494eb-032e-4c1d-ac1e-03611dc2d890,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-e8040c0b-9b3d-40b7-9a78-32c46fc6ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-df4c72f7-22ee-4b69-92bb-c17f8153bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-5b08f2ad-e6bb-4ed7-a640-f75ef3cc32df,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c85cb6ff-75f7-4498-a750-252f1357498b,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-a5e3e406-ecd0-4a96-bf25-aafceef5735b,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-0d8bcd2b-0634-4a8e-865a-763d2b655362,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-0722a4a4-3a51-4874-9223-6d960845a1f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5538
