reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374025858-172.17.0.6-1599306906582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-fb561454-8f9c-41c7-9ee4-67c1f64d7844,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-78531bc1-ed7c-42ff-aad4-445cb5807a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-425919d1-309c-4eb9-ac63-727985dcaf11,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-0f137148-6f36-4957-92bf-edccb4e2c976,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-409cc0bd-f3a4-4c99-b0ca-d41097a26bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-4b1431df-e3bc-4ad7-978c-bb0aec2a10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-cdac536e-1a36-4c14-a151-f4f6d96d31b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-98ffbb6a-f43c-4fa4-ab0f-cfda028801e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374025858-172.17.0.6-1599306906582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-fb561454-8f9c-41c7-9ee4-67c1f64d7844,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-78531bc1-ed7c-42ff-aad4-445cb5807a94,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-425919d1-309c-4eb9-ac63-727985dcaf11,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-0f137148-6f36-4957-92bf-edccb4e2c976,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-409cc0bd-f3a4-4c99-b0ca-d41097a26bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-4b1431df-e3bc-4ad7-978c-bb0aec2a10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-cdac536e-1a36-4c14-a151-f4f6d96d31b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-98ffbb6a-f43c-4fa4-ab0f-cfda028801e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400536333-172.17.0.6-1599307752630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-778114a6-d8ad-4d5d-959f-5538b9c31c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-bc2ac822-0917-4906-b40e-3a6c03333398,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-2f45b40b-9d7f-4385-86f8-9f28cbff6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8551d0ad-4a5a-428b-b0ac-92ce7d6b28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-550669dd-b134-4ffe-847d-fc327da8449b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-78f2991c-fe09-4c08-8602-906abb1cef4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-37d966f6-19c9-4d73-b1cb-866313af01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-fbbe7ff9-7ea8-4971-9428-04f0f6171628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400536333-172.17.0.6-1599307752630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-778114a6-d8ad-4d5d-959f-5538b9c31c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-bc2ac822-0917-4906-b40e-3a6c03333398,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-2f45b40b-9d7f-4385-86f8-9f28cbff6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8551d0ad-4a5a-428b-b0ac-92ce7d6b28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-550669dd-b134-4ffe-847d-fc327da8449b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-78f2991c-fe09-4c08-8602-906abb1cef4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-37d966f6-19c9-4d73-b1cb-866313af01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-fbbe7ff9-7ea8-4971-9428-04f0f6171628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538609218-172.17.0.6-1599307913132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-a1ca2832-4ade-4905-99e3-d09f7e569483,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e061a132-bd71-48e0-92ad-48a4612c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-c979c080-c07d-4d21-9ebb-ba87ee805fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-95f66bbc-96b1-4b74-82a5-0447bc388c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-be6b65b9-8d0d-4711-be93-aa6a76b1b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-28c90f46-084c-417b-ad93-0162bb2002a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-7d8aa27a-7ca9-4f76-bc28-a5046a90ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-72cb60f7-7b8c-4648-b449-47755dddb436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538609218-172.17.0.6-1599307913132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-a1ca2832-4ade-4905-99e3-d09f7e569483,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e061a132-bd71-48e0-92ad-48a4612c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-c979c080-c07d-4d21-9ebb-ba87ee805fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-95f66bbc-96b1-4b74-82a5-0447bc388c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-be6b65b9-8d0d-4711-be93-aa6a76b1b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-28c90f46-084c-417b-ad93-0162bb2002a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-7d8aa27a-7ca9-4f76-bc28-a5046a90ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-72cb60f7-7b8c-4648-b449-47755dddb436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265115953-172.17.0.6-1599308252126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-fe52fcd5-5145-40a1-92ba-b7edb021d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0677e3db-0fab-40db-be37-2289b0ffc441,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-b2bdb24c-4fb4-40d3-abb5-b2ebaa7566e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-6f127be8-9692-4f2d-8cb9-33f9b33b0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-855eed11-6e9a-4a34-abea-a6d2846b4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-c38f04e5-861c-44f5-adad-8e8eeee44234,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-705de677-1ae8-4832-90ac-f78ee180a373,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-05702b41-357d-4811-b8d3-5a76427c1d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265115953-172.17.0.6-1599308252126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-fe52fcd5-5145-40a1-92ba-b7edb021d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-0677e3db-0fab-40db-be37-2289b0ffc441,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-b2bdb24c-4fb4-40d3-abb5-b2ebaa7566e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-6f127be8-9692-4f2d-8cb9-33f9b33b0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-855eed11-6e9a-4a34-abea-a6d2846b4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-c38f04e5-861c-44f5-adad-8e8eeee44234,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-705de677-1ae8-4832-90ac-f78ee180a373,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-05702b41-357d-4811-b8d3-5a76427c1d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950328580-172.17.0.6-1599308513546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-ea04cfa7-7090-4572-ad30-57650abe1062,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-df7daac3-77ac-42ee-b9ab-95e0e0ca371f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c8775e8d-a9a0-40bd-b471-73b900fd596b,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-839943ad-6969-47ab-8ef7-99d8a89e68b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-059b8c75-59ac-4879-aaa1-6d103180f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-b74d661e-7e07-44d5-8d3a-3a64c8acf1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-588cf9c0-53db-460d-8987-c1d86d58d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-eb4a4b99-130b-4880-870a-fe422667901c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950328580-172.17.0.6-1599308513546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-ea04cfa7-7090-4572-ad30-57650abe1062,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-df7daac3-77ac-42ee-b9ab-95e0e0ca371f,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c8775e8d-a9a0-40bd-b471-73b900fd596b,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-839943ad-6969-47ab-8ef7-99d8a89e68b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-059b8c75-59ac-4879-aaa1-6d103180f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-b74d661e-7e07-44d5-8d3a-3a64c8acf1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-588cf9c0-53db-460d-8987-c1d86d58d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-eb4a4b99-130b-4880-870a-fe422667901c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165735876-172.17.0.6-1599308548330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-c42f59e1-3f19-4ff3-9cac-2f00637e0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1d22f97c-6434-4c54-ace4-9c865fc492bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-8f3d216e-3f54-44d1-be8d-f6c7298b19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-da207e66-59ac-4132-9b31-7d03f254f6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e2425a67-f2dc-4764-9e9a-2bb5759527e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-7a4d9c93-15e6-45e9-888e-fe56a0bce8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6f26d26f-cade-43e1-b9aa-e4dd24ca489c,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-31d12d59-e02e-430d-9ea4-4dadad0804ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165735876-172.17.0.6-1599308548330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-c42f59e1-3f19-4ff3-9cac-2f00637e0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1d22f97c-6434-4c54-ace4-9c865fc492bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-8f3d216e-3f54-44d1-be8d-f6c7298b19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-da207e66-59ac-4132-9b31-7d03f254f6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e2425a67-f2dc-4764-9e9a-2bb5759527e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-7a4d9c93-15e6-45e9-888e-fe56a0bce8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6f26d26f-cade-43e1-b9aa-e4dd24ca489c,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-31d12d59-e02e-430d-9ea4-4dadad0804ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553995237-172.17.0.6-1599308773443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37209,DS-d0ace123-98bd-4ed5-983a-447338d7d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-00e5a6fa-1646-4659-aae5-b0eab3982df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-f6e53ca5-3b18-4261-85b4-f0784089db74,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-0626b986-4ce2-4f96-8530-e5036c7ba456,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-984330b4-6c6c-4359-906c-5bae5f19ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-a36d6596-63dc-422f-8d54-5bfba7c07eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-68d5ccd9-8117-4099-98e0-2d8c96f00a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-5801cf42-46e4-4a24-8fc6-7e62d2fc4e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553995237-172.17.0.6-1599308773443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37209,DS-d0ace123-98bd-4ed5-983a-447338d7d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-00e5a6fa-1646-4659-aae5-b0eab3982df8,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-f6e53ca5-3b18-4261-85b4-f0784089db74,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-0626b986-4ce2-4f96-8530-e5036c7ba456,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-984330b4-6c6c-4359-906c-5bae5f19ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-a36d6596-63dc-422f-8d54-5bfba7c07eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-68d5ccd9-8117-4099-98e0-2d8c96f00a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-5801cf42-46e4-4a24-8fc6-7e62d2fc4e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467852217-172.17.0.6-1599308974878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-3af945e6-4c4f-447d-8e20-623b1781167f,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-1d50ae37-07b9-4c27-91c8-1671738b9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-9e8e67fa-e798-4eb7-9d96-75307df32f11,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-52788be0-5d16-4a1a-b58b-376833a0dccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-4d8b2c96-89e1-4271-93b8-b3e55c31926d,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-455b0cab-b3f3-4d36-bdf9-079a993246ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-86fe69a0-7494-495e-80b6-6856cb9baddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-e8769be8-2304-4d4b-839a-70af8a3066ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467852217-172.17.0.6-1599308974878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-3af945e6-4c4f-447d-8e20-623b1781167f,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-1d50ae37-07b9-4c27-91c8-1671738b9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-9e8e67fa-e798-4eb7-9d96-75307df32f11,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-52788be0-5d16-4a1a-b58b-376833a0dccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-4d8b2c96-89e1-4271-93b8-b3e55c31926d,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-455b0cab-b3f3-4d36-bdf9-079a993246ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-86fe69a0-7494-495e-80b6-6856cb9baddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-e8769be8-2304-4d4b-839a-70af8a3066ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249239994-172.17.0.6-1599309014829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-27957528-7cc3-42ca-a4cd-d4d360223dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-1e9bfe8e-a549-4507-a260-9560913897d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-876e1d36-8832-4dd9-8e8a-64201690ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-dd2dd8ca-e221-42cb-87f2-1aefa0156528,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-3b3a0c1c-b1e6-4800-87ea-d91e2215eac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-35c383b9-e98b-4224-aa2a-fd5eab09fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-80ffe240-7bc5-402d-aace-b95c6ca60ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-b6d8d94a-691d-4590-9ae0-a1660f9ba5ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249239994-172.17.0.6-1599309014829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-27957528-7cc3-42ca-a4cd-d4d360223dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-1e9bfe8e-a549-4507-a260-9560913897d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-876e1d36-8832-4dd9-8e8a-64201690ce71,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-dd2dd8ca-e221-42cb-87f2-1aefa0156528,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-3b3a0c1c-b1e6-4800-87ea-d91e2215eac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-35c383b9-e98b-4224-aa2a-fd5eab09fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-80ffe240-7bc5-402d-aace-b95c6ca60ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-b6d8d94a-691d-4590-9ae0-a1660f9ba5ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011455204-172.17.0.6-1599309479789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-dc85f2ef-9b4b-4b9b-9608-7f31e1e9e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-7b643582-581c-41ea-b30f-5a414a583538,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-df2d4d14-0d30-49f1-a2ff-261a3b7530df,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-72ba51ac-201d-470f-aaea-af886225db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-7136623f-6eac-4587-a317-960f278c908d,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-be00170e-d629-46f4-bd9b-9bcc8ffbe30f,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-eb2234e4-4ed4-4826-895b-f58570d4d427,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-5de4eef6-c81f-40c1-a860-a66ebdab09aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011455204-172.17.0.6-1599309479789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-dc85f2ef-9b4b-4b9b-9608-7f31e1e9e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-7b643582-581c-41ea-b30f-5a414a583538,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-df2d4d14-0d30-49f1-a2ff-261a3b7530df,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-72ba51ac-201d-470f-aaea-af886225db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-7136623f-6eac-4587-a317-960f278c908d,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-be00170e-d629-46f4-bd9b-9bcc8ffbe30f,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-eb2234e4-4ed4-4826-895b-f58570d4d427,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-5de4eef6-c81f-40c1-a860-a66ebdab09aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895789376-172.17.0.6-1599309559926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-1f997a07-81df-43dd-a854-70472f046b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-ee08e2f3-ce29-4c09-b9cd-58c523429930,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-3ac20ba6-b1cf-4f19-bb8c-538901bc639b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-0d44cced-a9ce-47ce-aed1-e7ff33c6ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-a395ec6b-79eb-4362-be64-9964f65e3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-449093c9-5a45-4857-90d4-773d9e130378,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-bc0d2971-c67c-4d02-af59-f411567fa95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-eee5eb05-ec9c-49ac-a59c-cca975554c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895789376-172.17.0.6-1599309559926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-1f997a07-81df-43dd-a854-70472f046b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-ee08e2f3-ce29-4c09-b9cd-58c523429930,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-3ac20ba6-b1cf-4f19-bb8c-538901bc639b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-0d44cced-a9ce-47ce-aed1-e7ff33c6ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-a395ec6b-79eb-4362-be64-9964f65e3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-449093c9-5a45-4857-90d4-773d9e130378,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-bc0d2971-c67c-4d02-af59-f411567fa95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-eee5eb05-ec9c-49ac-a59c-cca975554c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290229175-172.17.0.6-1599309973559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39133,DS-9fa6f4cf-9531-49df-955e-bc3463bdbe20,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-94c7c7cb-654b-4636-999d-585587176109,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-f49036a1-8346-42c8-ac7d-6e7a1af654dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-784110ef-a8a0-4480-a7ed-d793fb7ca833,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-5e46fc42-7b8b-4e9c-baab-4b702ed2c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-7762b76e-dd6e-4cb9-be70-b8a49ea10bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-4f99a545-c90f-4b64-9fb7-f5a9fde762db,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-cf2c1c81-24b0-4cb0-8bf0-12adee503976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290229175-172.17.0.6-1599309973559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39133,DS-9fa6f4cf-9531-49df-955e-bc3463bdbe20,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-94c7c7cb-654b-4636-999d-585587176109,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-f49036a1-8346-42c8-ac7d-6e7a1af654dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-784110ef-a8a0-4480-a7ed-d793fb7ca833,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-5e46fc42-7b8b-4e9c-baab-4b702ed2c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-7762b76e-dd6e-4cb9-be70-b8a49ea10bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-4f99a545-c90f-4b64-9fb7-f5a9fde762db,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-cf2c1c81-24b0-4cb0-8bf0-12adee503976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052193626-172.17.0.6-1599310157690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41518,DS-f4410f04-6f30-4857-b3dd-216fea70df86,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e39c07ad-dc71-420c-8701-62c65e158821,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-ca9a1de8-5c25-4b16-bfae-7dcd3616ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-25baea79-5b90-4278-988b-7f477815a566,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-8af3dd3c-9839-43d9-8e64-77f789fffabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-cf35e160-f533-4e19-8198-7a4d90ac79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-41f631f8-b960-479f-8542-850d42967f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-2057897a-5fdc-4f1a-a4eb-86fbf6091b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052193626-172.17.0.6-1599310157690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41518,DS-f4410f04-6f30-4857-b3dd-216fea70df86,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e39c07ad-dc71-420c-8701-62c65e158821,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-ca9a1de8-5c25-4b16-bfae-7dcd3616ad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-25baea79-5b90-4278-988b-7f477815a566,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-8af3dd3c-9839-43d9-8e64-77f789fffabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-cf35e160-f533-4e19-8198-7a4d90ac79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-41f631f8-b960-479f-8542-850d42967f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-2057897a-5fdc-4f1a-a4eb-86fbf6091b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948914817-172.17.0.6-1599310294022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-e335819f-8bde-4122-80b3-5aae73bc170c,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-37a20bfc-730a-4db3-bfe0-1bbe2246dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-6197a234-5579-4d88-947d-9093262b555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b7489716-dfd1-405e-bd82-fe958691f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-2dd455da-44ca-46a9-8e50-6a49cbd7b078,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-2a60cdf6-d0d9-4697-b705-34990a7308e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-40a87158-2c20-4a69-9ef0-f3396d1382c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-c956d58e-134f-4d7a-a2dc-e417a6e61f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948914817-172.17.0.6-1599310294022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-e335819f-8bde-4122-80b3-5aae73bc170c,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-37a20bfc-730a-4db3-bfe0-1bbe2246dd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-6197a234-5579-4d88-947d-9093262b555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b7489716-dfd1-405e-bd82-fe958691f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-2dd455da-44ca-46a9-8e50-6a49cbd7b078,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-2a60cdf6-d0d9-4697-b705-34990a7308e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-40a87158-2c20-4a69-9ef0-f3396d1382c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-c956d58e-134f-4d7a-a2dc-e417a6e61f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938663137-172.17.0.6-1599310670780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-17c3ec1d-7e3a-4d90-9513-ee84aa5ed74f,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-ed6085fc-b115-43d5-a042-c2a2867ba452,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-4ab8b887-1a3f-4fc7-a72a-f5a72747b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-0344ea93-d7d6-4466-8df6-4ab258810285,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-3b71ff2e-8a91-43c4-94d6-d9245d1c7bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-7e052595-0a1d-4b47-9e4b-b5e66ce7e830,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-112a946f-c28f-4fbb-8534-53bf01027d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-bb8dedd9-dd9f-4f7b-9565-72f178e9c489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938663137-172.17.0.6-1599310670780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-17c3ec1d-7e3a-4d90-9513-ee84aa5ed74f,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-ed6085fc-b115-43d5-a042-c2a2867ba452,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-4ab8b887-1a3f-4fc7-a72a-f5a72747b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-0344ea93-d7d6-4466-8df6-4ab258810285,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-3b71ff2e-8a91-43c4-94d6-d9245d1c7bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-7e052595-0a1d-4b47-9e4b-b5e66ce7e830,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-112a946f-c28f-4fbb-8534-53bf01027d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-bb8dedd9-dd9f-4f7b-9565-72f178e9c489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804594489-172.17.0.6-1599310883934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-bf275e30-0b83-4ffb-88fb-fd47ecf9a885,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-bdb30b3d-f64d-4673-a2d4-5559010ef209,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f2b16091-24fa-4f47-8ff6-8fa69120875f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-e10c0f3f-678c-4bb2-bd03-65709c7bb11c,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-d42cea62-f12f-47d2-99af-142a34e87833,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-a52db8cb-2cc4-431a-ac22-1b5a3918485a,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-9bb8c0ad-8430-4f92-ad44-cc98db29e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-f4b1979e-6d1f-43ac-bc92-1f936df72c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804594489-172.17.0.6-1599310883934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-bf275e30-0b83-4ffb-88fb-fd47ecf9a885,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-bdb30b3d-f64d-4673-a2d4-5559010ef209,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f2b16091-24fa-4f47-8ff6-8fa69120875f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-e10c0f3f-678c-4bb2-bd03-65709c7bb11c,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-d42cea62-f12f-47d2-99af-142a34e87833,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-a52db8cb-2cc4-431a-ac22-1b5a3918485a,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-9bb8c0ad-8430-4f92-ad44-cc98db29e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-f4b1979e-6d1f-43ac-bc92-1f936df72c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295167252-172.17.0.6-1599311347455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-9a1ff3f3-edd6-4ae3-8a6d-0a75a08f3d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-cf370d85-5a0a-4237-b6f2-7b71e30f2a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-09bd8e57-e434-4bc6-af7f-969af54df2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-e6af5367-b9ce-4532-ae3f-9ba41c4b2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-995b45cf-7e63-4a89-bf1d-b230f8279203,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-e38d8678-30bd-4782-8dc2-a2671451c575,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-818d464f-7c5b-4d6d-af74-006f6f127c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-785cd00e-901a-4be5-83c1-9787b1e3cddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295167252-172.17.0.6-1599311347455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-9a1ff3f3-edd6-4ae3-8a6d-0a75a08f3d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-cf370d85-5a0a-4237-b6f2-7b71e30f2a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-09bd8e57-e434-4bc6-af7f-969af54df2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-e6af5367-b9ce-4532-ae3f-9ba41c4b2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-995b45cf-7e63-4a89-bf1d-b230f8279203,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-e38d8678-30bd-4782-8dc2-a2671451c575,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-818d464f-7c5b-4d6d-af74-006f6f127c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-785cd00e-901a-4be5-83c1-9787b1e3cddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074903906-172.17.0.6-1599311382317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-fc60b708-3404-46cf-8de6-ad42815719aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-4a2be719-5227-41f3-b4bb-73d18fb9650d,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-b3724a5b-6687-48e6-aa1d-3bc35609757f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-f809f6a1-b2d6-4218-9683-24e355d12062,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-27c674ad-95b8-41a0-9dc5-21ff37d837db,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-d56981b6-a1bf-49c6-b0d3-b9101901219a,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-da216aee-e799-45c5-ba4d-ffcf9343972d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d4245ecf-07ac-4b33-90ee-6db0e73ab34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074903906-172.17.0.6-1599311382317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-fc60b708-3404-46cf-8de6-ad42815719aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-4a2be719-5227-41f3-b4bb-73d18fb9650d,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-b3724a5b-6687-48e6-aa1d-3bc35609757f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-f809f6a1-b2d6-4218-9683-24e355d12062,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-27c674ad-95b8-41a0-9dc5-21ff37d837db,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-d56981b6-a1bf-49c6-b0d3-b9101901219a,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-da216aee-e799-45c5-ba4d-ffcf9343972d,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d4245ecf-07ac-4b33-90ee-6db0e73ab34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028331600-172.17.0.6-1599311880708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-7099b6a4-58c0-45c4-b1d2-9d83e778dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9bc631a5-73b3-4bf1-ae37-da1d91593a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-2550e2c2-c984-4a8d-9a74-7cfeaa00f31c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-4fc4b3aa-8fad-4236-8a42-602c11f443e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-e01e29df-87e7-488a-af77-d580dbc004f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-ca3c8563-be1d-411f-b36f-6cd534fe8fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-69897b48-9d51-4162-87d1-95216d692ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-2ffb1546-0a51-4990-88a2-7973abd3abe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028331600-172.17.0.6-1599311880708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-7099b6a4-58c0-45c4-b1d2-9d83e778dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9bc631a5-73b3-4bf1-ae37-da1d91593a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-2550e2c2-c984-4a8d-9a74-7cfeaa00f31c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-4fc4b3aa-8fad-4236-8a42-602c11f443e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-e01e29df-87e7-488a-af77-d580dbc004f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-ca3c8563-be1d-411f-b36f-6cd534fe8fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-69897b48-9d51-4162-87d1-95216d692ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-2ffb1546-0a51-4990-88a2-7973abd3abe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469699922-172.17.0.6-1599312216684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-e180b9e4-2634-4b64-a736-d7579b058114,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e2a3c3cc-28ab-480d-87b0-d6d4308dd391,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-3294b3dd-eb18-466d-bdbc-58b34914d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-118a4992-2c47-42bf-bf3b-12619d8d3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-cdca067b-404b-4911-bb5e-f85faeffa321,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-4c202e63-d270-4ffc-a0d0-0b07da9d6206,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-0892458b-3588-4bcd-88ea-3a1894c178e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-f236ad88-4806-48d8-abdb-d0c74d48725d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469699922-172.17.0.6-1599312216684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-e180b9e4-2634-4b64-a736-d7579b058114,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e2a3c3cc-28ab-480d-87b0-d6d4308dd391,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-3294b3dd-eb18-466d-bdbc-58b34914d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-118a4992-2c47-42bf-bf3b-12619d8d3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-cdca067b-404b-4911-bb5e-f85faeffa321,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-4c202e63-d270-4ffc-a0d0-0b07da9d6206,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-0892458b-3588-4bcd-88ea-3a1894c178e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-f236ad88-4806-48d8-abdb-d0c74d48725d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5932
