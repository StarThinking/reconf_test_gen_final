reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140485096-172.17.0.14-1599348010985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-9132ff7f-de2a-4c37-bcfc-851e7ff1fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e9210edc-7d2e-416d-867c-ebe56144d35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-9e997a68-3420-4c59-92f6-83f65b3407c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-96f4b61e-331a-4a36-a351-fe61c53c11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-88572885-a75a-40b8-8a31-3dba400bf409,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f699b258-da95-4b9a-936e-93edd8159023,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-a9438e90-60d8-446b-964a-5baef5b307d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-840d2394-cd91-4d63-a78a-6bc7f9d75512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140485096-172.17.0.14-1599348010985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-9132ff7f-de2a-4c37-bcfc-851e7ff1fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e9210edc-7d2e-416d-867c-ebe56144d35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-9e997a68-3420-4c59-92f6-83f65b3407c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-96f4b61e-331a-4a36-a351-fe61c53c11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-88572885-a75a-40b8-8a31-3dba400bf409,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f699b258-da95-4b9a-936e-93edd8159023,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-a9438e90-60d8-446b-964a-5baef5b307d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-840d2394-cd91-4d63-a78a-6bc7f9d75512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347109190-172.17.0.14-1599348671635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39250,DS-a18498bb-a4d1-4214-b312-8a0220f3fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-4dec6cd8-1e26-4373-871c-2c6e4c5bba09,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b43aa3b0-396a-419c-88fd-61e9c1fdb0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-d68ca78e-5929-4790-b0f7-547393e28b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-90575e41-f6c4-4540-8911-9d8894347b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-b80b944e-10eb-45d7-84ce-d97dfbaef51a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-92f1e547-1876-4800-96bd-a213bfcd15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-04247554-642d-4392-a474-e52ba4ab6ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347109190-172.17.0.14-1599348671635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39250,DS-a18498bb-a4d1-4214-b312-8a0220f3fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-4dec6cd8-1e26-4373-871c-2c6e4c5bba09,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b43aa3b0-396a-419c-88fd-61e9c1fdb0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-d68ca78e-5929-4790-b0f7-547393e28b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-90575e41-f6c4-4540-8911-9d8894347b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-b80b944e-10eb-45d7-84ce-d97dfbaef51a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-92f1e547-1876-4800-96bd-a213bfcd15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-04247554-642d-4392-a474-e52ba4ab6ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132163458-172.17.0.14-1599349337775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-df5557eb-c3ba-43e9-a51b-6c50db9054fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-bb0c787d-db98-4a82-bcd2-420c774b048a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-51c762e2-d1a0-476a-a112-c3be56b9d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-247ec6d4-65a2-4252-9272-ed0d6745d06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-f3f466ce-28a5-4adb-bef6-fc474ccd3907,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-32f85982-e5b2-4aee-97c3-14ff4cfef7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-ae3be0ac-a0d8-4b87-b7bc-1facad6137ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-8e991a7d-5c39-4cdc-b443-386814c60b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132163458-172.17.0.14-1599349337775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-df5557eb-c3ba-43e9-a51b-6c50db9054fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-bb0c787d-db98-4a82-bcd2-420c774b048a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-51c762e2-d1a0-476a-a112-c3be56b9d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-247ec6d4-65a2-4252-9272-ed0d6745d06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-f3f466ce-28a5-4adb-bef6-fc474ccd3907,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-32f85982-e5b2-4aee-97c3-14ff4cfef7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-ae3be0ac-a0d8-4b87-b7bc-1facad6137ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-8e991a7d-5c39-4cdc-b443-386814c60b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005362047-172.17.0.14-1599349808068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-ecf35bfc-6499-49db-b3bb-c198b76f3dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-9d5c5309-1323-4d7d-a8bf-c375f370487e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-84f43b2f-02e2-4c0d-86c0-a7eee967abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-d3caa7ea-7013-4b71-87b9-607406e4b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-e6c52258-3bdc-4aff-bc3e-860b5d9ea89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-262fd719-d247-4b95-bab6-1aad532ea662,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-ec266269-23be-4e3c-bbe4-f50735cd9948,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-deb7779a-f0b9-4009-a42e-420d5f96ea86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005362047-172.17.0.14-1599349808068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-ecf35bfc-6499-49db-b3bb-c198b76f3dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-9d5c5309-1323-4d7d-a8bf-c375f370487e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-84f43b2f-02e2-4c0d-86c0-a7eee967abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-d3caa7ea-7013-4b71-87b9-607406e4b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-e6c52258-3bdc-4aff-bc3e-860b5d9ea89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-262fd719-d247-4b95-bab6-1aad532ea662,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-ec266269-23be-4e3c-bbe4-f50735cd9948,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-deb7779a-f0b9-4009-a42e-420d5f96ea86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312301757-172.17.0.14-1599350112486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44746,DS-5ff663f6-78f1-443f-a88d-d367e412357b,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-0689058a-5894-4a87-8679-d6d095db0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-90913a49-b499-457b-b948-f4ed86bb85d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c2aaa395-8262-4e80-bf19-640463f6ed74,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-20f12ec8-df7e-474e-8135-f546f2f7fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-3c0457e5-167f-4529-bdae-b60bf70cc757,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-79f88a43-93e8-49aa-bbf0-4d833b1fac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fd0e6438-e573-4a3f-b801-b77822f81a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312301757-172.17.0.14-1599350112486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44746,DS-5ff663f6-78f1-443f-a88d-d367e412357b,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-0689058a-5894-4a87-8679-d6d095db0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-90913a49-b499-457b-b948-f4ed86bb85d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-c2aaa395-8262-4e80-bf19-640463f6ed74,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-20f12ec8-df7e-474e-8135-f546f2f7fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-3c0457e5-167f-4529-bdae-b60bf70cc757,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-79f88a43-93e8-49aa-bbf0-4d833b1fac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-fd0e6438-e573-4a3f-b801-b77822f81a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583220056-172.17.0.14-1599350669103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-e225a1ec-3cc6-43bb-9219-f144f4f97180,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-1e784b68-4202-4d05-b7e2-c8e02ce23ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e8e0982f-a8f0-4381-806f-ea25ba3cecae,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-73a0bbf0-9872-4f61-9617-f10679c56d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-748be01e-b1c9-4648-9218-bef883e65c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-d1ef0d0d-d81b-46ca-be90-86e070fab1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e965ce8b-6b90-4688-98bf-2b2de41582e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-09852c21-2b2c-40fb-81fd-503e6e234409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583220056-172.17.0.14-1599350669103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-e225a1ec-3cc6-43bb-9219-f144f4f97180,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-1e784b68-4202-4d05-b7e2-c8e02ce23ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e8e0982f-a8f0-4381-806f-ea25ba3cecae,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-73a0bbf0-9872-4f61-9617-f10679c56d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-748be01e-b1c9-4648-9218-bef883e65c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-d1ef0d0d-d81b-46ca-be90-86e070fab1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-e965ce8b-6b90-4688-98bf-2b2de41582e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-09852c21-2b2c-40fb-81fd-503e6e234409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936863382-172.17.0.14-1599350702187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-cbff17d8-2437-49f2-bf7b-25dc7bc04dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-0996c8f9-99ec-4c81-8e4e-24cd08ccf15e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7c5c025d-640e-414d-b17d-8eef805c1172,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-70bf373f-19ec-4843-9468-fc7cdd59e216,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-40aa4c22-4587-4105-b6a4-ddfde389f460,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-630d4922-0fdc-4e2f-a8ac-8d0e8940d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-d6c866c2-3676-4bb3-9ca8-8543793f2316,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-91655d4e-4758-4973-aec3-1986ad1a19df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936863382-172.17.0.14-1599350702187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-cbff17d8-2437-49f2-bf7b-25dc7bc04dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-0996c8f9-99ec-4c81-8e4e-24cd08ccf15e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7c5c025d-640e-414d-b17d-8eef805c1172,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-70bf373f-19ec-4843-9468-fc7cdd59e216,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-40aa4c22-4587-4105-b6a4-ddfde389f460,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-630d4922-0fdc-4e2f-a8ac-8d0e8940d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-d6c866c2-3676-4bb3-9ca8-8543793f2316,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-91655d4e-4758-4973-aec3-1986ad1a19df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574636266-172.17.0.14-1599350760521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-d9fe2772-aee2-43f4-b5a1-2cb353ed17f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c89699ea-7780-4984-9344-78ba042ce811,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-f499202d-654c-44ff-814c-7ce10db621a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-4740bbad-bf4e-4f07-880b-ac8d0a1f3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d669415a-f6f1-4bb8-a2e1-a27b04c39c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-4c09af34-1cfa-47be-bdcd-f44f43a186f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-6ed52716-1bef-4f10-8c12-01d5408fa643,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-eb61c916-52ca-41c5-8ead-4be52d9efda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574636266-172.17.0.14-1599350760521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-d9fe2772-aee2-43f4-b5a1-2cb353ed17f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c89699ea-7780-4984-9344-78ba042ce811,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-f499202d-654c-44ff-814c-7ce10db621a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-4740bbad-bf4e-4f07-880b-ac8d0a1f3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d669415a-f6f1-4bb8-a2e1-a27b04c39c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-4c09af34-1cfa-47be-bdcd-f44f43a186f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-6ed52716-1bef-4f10-8c12-01d5408fa643,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-eb61c916-52ca-41c5-8ead-4be52d9efda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403537838-172.17.0.14-1599351301705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-43676f06-74be-40e9-922c-a34174edea59,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-f880dc25-4272-46ce-8e9e-b6ecd00510fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-2e4f2260-fcac-4350-bede-f96a46e3a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-7dece7d9-024c-4b7b-9127-22f29c7a16af,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-5fcbbf8b-efa8-421f-bc0c-f62c7f5726a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-fcb968ef-3842-44cd-b721-5bb58618043b,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-d9309a07-dbd7-4293-b409-f5dc65aa3de7,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-e64253dd-8cd0-4237-b5ee-47f12cb2bc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403537838-172.17.0.14-1599351301705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36490,DS-43676f06-74be-40e9-922c-a34174edea59,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-f880dc25-4272-46ce-8e9e-b6ecd00510fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-2e4f2260-fcac-4350-bede-f96a46e3a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-7dece7d9-024c-4b7b-9127-22f29c7a16af,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-5fcbbf8b-efa8-421f-bc0c-f62c7f5726a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-fcb968ef-3842-44cd-b721-5bb58618043b,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-d9309a07-dbd7-4293-b409-f5dc65aa3de7,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-e64253dd-8cd0-4237-b5ee-47f12cb2bc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349999704-172.17.0.14-1599351554327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-6e29820c-32d0-47c5-b3a9-197bde72027d,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-acc1d96b-5833-4bc6-8c41-a25d4a189f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-05a27491-32a2-454c-b588-48473ef43908,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-c0830c15-b17e-4fb6-863f-eba04d9f8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-7ed32b72-0c92-411a-83d4-dd507c977668,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-1c188871-0d80-483d-9d44-6a60fdcfa6de,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-0446f54d-01cd-46bb-b0d6-cd1d1fcceff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-0a536869-08ef-4ecf-b474-7ec2b5ad062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349999704-172.17.0.14-1599351554327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-6e29820c-32d0-47c5-b3a9-197bde72027d,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-acc1d96b-5833-4bc6-8c41-a25d4a189f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-05a27491-32a2-454c-b588-48473ef43908,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-c0830c15-b17e-4fb6-863f-eba04d9f8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-7ed32b72-0c92-411a-83d4-dd507c977668,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-1c188871-0d80-483d-9d44-6a60fdcfa6de,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-0446f54d-01cd-46bb-b0d6-cd1d1fcceff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-0a536869-08ef-4ecf-b474-7ec2b5ad062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602459975-172.17.0.14-1599351589150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-1a1529df-23a9-4389-85d5-20f81beb54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-b0afd4af-a569-46c4-8d58-7bcbda85db42,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5e2540b6-a96c-4521-aa6f-121b24bfc114,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-45612231-a726-4a57-b574-9a36ab6d3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-663ac86e-0819-46d7-8a29-471fa016f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-31b53614-efcd-43e3-a613-561678126b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5014a15f-4f96-4d13-a478-376cac97cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-0bb56fe9-5e3a-4be8-9d0f-ffa85c070ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602459975-172.17.0.14-1599351589150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-1a1529df-23a9-4389-85d5-20f81beb54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-b0afd4af-a569-46c4-8d58-7bcbda85db42,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5e2540b6-a96c-4521-aa6f-121b24bfc114,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-45612231-a726-4a57-b574-9a36ab6d3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-663ac86e-0819-46d7-8a29-471fa016f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-31b53614-efcd-43e3-a613-561678126b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5014a15f-4f96-4d13-a478-376cac97cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-0bb56fe9-5e3a-4be8-9d0f-ffa85c070ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362580363-172.17.0.14-1599351849053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33181,DS-93637f46-cd1a-4388-81bc-3d9a221b91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-9b7db0a5-b921-4e51-a913-696368338e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-1d788287-389b-474f-83d4-e25ad9aae542,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-8ba86bda-fce4-42a6-b87d-4e9c3981ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-4f3ff008-3355-4fad-9f75-1342fea37245,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-8854b283-1f9a-4451-acfd-98bf85dc5988,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-4b8df2cb-d877-4c43-bc04-68df54a4d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-2fec6d35-7808-49c1-806f-2e3859beecf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362580363-172.17.0.14-1599351849053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33181,DS-93637f46-cd1a-4388-81bc-3d9a221b91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-9b7db0a5-b921-4e51-a913-696368338e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-1d788287-389b-474f-83d4-e25ad9aae542,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-8ba86bda-fce4-42a6-b87d-4e9c3981ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-4f3ff008-3355-4fad-9f75-1342fea37245,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-8854b283-1f9a-4451-acfd-98bf85dc5988,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-4b8df2cb-d877-4c43-bc04-68df54a4d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-2fec6d35-7808-49c1-806f-2e3859beecf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457702304-172.17.0.14-1599351936618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-7b7b9035-40f9-4dc3-b6ec-26ae496ba098,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-48400061-3703-4010-b15b-7329405cb518,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-17d39822-8996-45b5-b824-c6e96c5a9486,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-38d5e389-d661-4556-89c6-7cded3e263db,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-815ef9f7-f246-4344-b7a3-910d9c1602bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-13c9ad31-a877-4cb3-98bc-001134c92549,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b430bc87-cfa4-4858-aeb7-9a2f37c41842,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-9a69be60-9600-4b5f-8ff4-17a348109922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457702304-172.17.0.14-1599351936618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-7b7b9035-40f9-4dc3-b6ec-26ae496ba098,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-48400061-3703-4010-b15b-7329405cb518,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-17d39822-8996-45b5-b824-c6e96c5a9486,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-38d5e389-d661-4556-89c6-7cded3e263db,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-815ef9f7-f246-4344-b7a3-910d9c1602bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-13c9ad31-a877-4cb3-98bc-001134c92549,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b430bc87-cfa4-4858-aeb7-9a2f37c41842,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-9a69be60-9600-4b5f-8ff4-17a348109922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386528502-172.17.0.14-1599352092988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-391483b3-2f29-4904-83f5-b73f8788193a,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-9cf45d24-9ce6-4244-b8c6-5fae3622c927,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-34a6110b-6727-48f5-8be7-ba822d1a6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-d6f7420a-4646-4712-a891-094cd65f7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-43277617-fda8-4e55-ab84-c875dee0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-e997fce2-b954-4444-93bd-4b9b9f2be6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-d672ad6e-db90-4e5c-bfaa-f7edd73624d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-4e1c39ed-9278-4d5e-a8a6-c5b52d232ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386528502-172.17.0.14-1599352092988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-391483b3-2f29-4904-83f5-b73f8788193a,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-9cf45d24-9ce6-4244-b8c6-5fae3622c927,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-34a6110b-6727-48f5-8be7-ba822d1a6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-d6f7420a-4646-4712-a891-094cd65f7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-43277617-fda8-4e55-ab84-c875dee0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-e997fce2-b954-4444-93bd-4b9b9f2be6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-d672ad6e-db90-4e5c-bfaa-f7edd73624d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-4e1c39ed-9278-4d5e-a8a6-c5b52d232ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089277342-172.17.0.14-1599352638354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-101add3a-5602-46df-a9d8-5a7ce9f7e212,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-22776607-eedd-40bf-9469-792b004f476b,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-90991ba0-30a9-40d3-9ca1-29faef04d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-dce1ce4b-7f08-448b-abef-c3b42045029d,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-d0fe2d37-cb68-4e82-954e-cfb7ff91efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-bae14051-b267-46ba-a947-4d23239f4854,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-eb3f33ee-dd1e-4545-8eca-a95712256876,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-21319dad-822e-4643-985f-58f80eef3c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089277342-172.17.0.14-1599352638354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-101add3a-5602-46df-a9d8-5a7ce9f7e212,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-22776607-eedd-40bf-9469-792b004f476b,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-90991ba0-30a9-40d3-9ca1-29faef04d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-dce1ce4b-7f08-448b-abef-c3b42045029d,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-d0fe2d37-cb68-4e82-954e-cfb7ff91efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-bae14051-b267-46ba-a947-4d23239f4854,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-eb3f33ee-dd1e-4545-8eca-a95712256876,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-21319dad-822e-4643-985f-58f80eef3c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617178374-172.17.0.14-1599352667398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-fd825cea-7c40-4b77-a1ca-09de6ef801b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-49de7825-0cb7-47a3-9994-a94a04a7fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-2bbf036a-a37a-48a8-be1f-9b2e21cf1579,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-ac60f679-c754-4c90-9863-e2c4ae72c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-3f410a41-9685-444c-94be-23b2c186fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-38791316-ce64-4060-9d0b-bdb0df7bbc43,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-d2f2892f-0032-4abf-a773-981f8274f685,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-45e88efa-6c4b-4e2b-b1e2-bb6a515295f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617178374-172.17.0.14-1599352667398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-fd825cea-7c40-4b77-a1ca-09de6ef801b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-49de7825-0cb7-47a3-9994-a94a04a7fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-2bbf036a-a37a-48a8-be1f-9b2e21cf1579,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-ac60f679-c754-4c90-9863-e2c4ae72c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-3f410a41-9685-444c-94be-23b2c186fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-38791316-ce64-4060-9d0b-bdb0df7bbc43,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-d2f2892f-0032-4abf-a773-981f8274f685,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-45e88efa-6c4b-4e2b-b1e2-bb6a515295f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4967
