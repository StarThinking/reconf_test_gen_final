reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443165432-172.17.0.12-1599369469173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43335,DS-2ad1bfea-863e-467c-b145-74c439cb1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-71ed50db-06ec-4216-86ed-04a6b8a2252b,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-a0e57b26-8f7b-487b-926a-4e36276f90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0911c565-6409-4e0b-a814-11798bd5cbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-aa2e5671-944f-41c8-bbe4-8f3da9bea37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d6842ed0-c538-4da9-a838-b5830f3c0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ad9f66b1-88ff-4863-ae7c-36cb5ad0021e,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-2e0c6e57-f66e-4129-89b4-c6d7cb3a80bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443165432-172.17.0.12-1599369469173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43335,DS-2ad1bfea-863e-467c-b145-74c439cb1bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-71ed50db-06ec-4216-86ed-04a6b8a2252b,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-a0e57b26-8f7b-487b-926a-4e36276f90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0911c565-6409-4e0b-a814-11798bd5cbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-aa2e5671-944f-41c8-bbe4-8f3da9bea37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d6842ed0-c538-4da9-a838-b5830f3c0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ad9f66b1-88ff-4863-ae7c-36cb5ad0021e,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-2e0c6e57-f66e-4129-89b4-c6d7cb3a80bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243937433-172.17.0.12-1599369565270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-b125fd33-796c-4acd-ab01-09b47a6f8f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-029d7ca4-2ae5-40df-b544-1d750297e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-505cafbf-1a41-4ae4-af0b-0834b872db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-1630739f-c627-4b08-8143-bef732eaabcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-16d119d4-bdbe-4ceb-ba31-0b0d17bd13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-bc104ed1-6d4f-48f4-9273-bbade17e8c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-91ae0a8f-cc78-42b6-bda4-7c6eaf01d1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-cf687d77-97af-4426-8af9-dd8e5cccd7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243937433-172.17.0.12-1599369565270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-b125fd33-796c-4acd-ab01-09b47a6f8f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-029d7ca4-2ae5-40df-b544-1d750297e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-505cafbf-1a41-4ae4-af0b-0834b872db8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-1630739f-c627-4b08-8143-bef732eaabcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-16d119d4-bdbe-4ceb-ba31-0b0d17bd13c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-bc104ed1-6d4f-48f4-9273-bbade17e8c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-91ae0a8f-cc78-42b6-bda4-7c6eaf01d1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-cf687d77-97af-4426-8af9-dd8e5cccd7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498198400-172.17.0.12-1599369929633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-c4ec61c6-1e6d-4357-832d-4b67f0c84406,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-a22c8e47-597c-495d-b26b-4f95ffbdc700,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-6c76907b-36a9-43ba-b819-618995f6359e,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-a4f69b27-324d-478d-aa6e-ab6ca2182b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-da0689a0-ae4d-4480-bf07-a841398c96ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-200506c6-34f2-4ae8-b9da-a5c05ebd2642,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-24aac889-53fe-4323-aaaa-b5e68e8ff524,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-f3390926-f8cc-461d-935b-090890a2eef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498198400-172.17.0.12-1599369929633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-c4ec61c6-1e6d-4357-832d-4b67f0c84406,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-a22c8e47-597c-495d-b26b-4f95ffbdc700,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-6c76907b-36a9-43ba-b819-618995f6359e,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-a4f69b27-324d-478d-aa6e-ab6ca2182b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-da0689a0-ae4d-4480-bf07-a841398c96ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-200506c6-34f2-4ae8-b9da-a5c05ebd2642,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-24aac889-53fe-4323-aaaa-b5e68e8ff524,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-f3390926-f8cc-461d-935b-090890a2eef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958770659-172.17.0.12-1599370097262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-ab4602d0-1f3a-406c-ba07-ade6c49c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-cdda6d3d-3bba-40a4-891f-e66b5e6555ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-bfdb0501-c6d7-489b-a498-3a9ed2616bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-f4281eb3-42ed-4cf7-a834-c0e9314b314c,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-91e5e449-f38b-440e-8010-90f24f382ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-89dcd450-76a0-4e9f-82fe-9bb0b2cd55db,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-c9cfd08c-4364-434e-8490-960fe42c1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-6797bbac-5335-4062-a5b1-73f88b52c433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958770659-172.17.0.12-1599370097262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-ab4602d0-1f3a-406c-ba07-ade6c49c08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-cdda6d3d-3bba-40a4-891f-e66b5e6555ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-bfdb0501-c6d7-489b-a498-3a9ed2616bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-f4281eb3-42ed-4cf7-a834-c0e9314b314c,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-91e5e449-f38b-440e-8010-90f24f382ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-89dcd450-76a0-4e9f-82fe-9bb0b2cd55db,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-c9cfd08c-4364-434e-8490-960fe42c1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-6797bbac-5335-4062-a5b1-73f88b52c433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953290965-172.17.0.12-1599370839236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-5b254f78-8b56-4ddd-9e55-363e8fd4ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-bd75be43-829d-4bcb-9427-bead75d8eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-4b3dac3a-4e95-4fe1-86ab-f1afa8638d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-82e46560-62e2-4de4-ac5e-6f8aca651709,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-f4f5d7a4-e9f9-4280-8f9c-879d6406b953,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-02e5172c-a42c-468d-90dc-f36cbfbdac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-9fbdc381-d7f7-4921-a0a9-6301d7d78f06,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-7ecf9635-4696-4106-94f1-242d639742ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953290965-172.17.0.12-1599370839236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-5b254f78-8b56-4ddd-9e55-363e8fd4ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-bd75be43-829d-4bcb-9427-bead75d8eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-4b3dac3a-4e95-4fe1-86ab-f1afa8638d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-82e46560-62e2-4de4-ac5e-6f8aca651709,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-f4f5d7a4-e9f9-4280-8f9c-879d6406b953,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-02e5172c-a42c-468d-90dc-f36cbfbdac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-9fbdc381-d7f7-4921-a0a9-6301d7d78f06,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-7ecf9635-4696-4106-94f1-242d639742ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640625840-172.17.0.12-1599371210178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-be17727b-deba-47ca-96b3-48470d9db943,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-c2f0f152-eddd-4348-8634-121bf9b137c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-3e578866-729e-4f03-a54c-bf31d1f3496c,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-53f682d1-a198-4aab-91ef-1c4107ba36da,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-65d00ac4-0dc8-457d-8d3f-e1c9cde81c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-7f22a630-0a23-4dec-90cc-c7fe9a9def87,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-e7760c43-d673-4874-a21c-2edb7a111678,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-f065e7fb-62b1-494f-b08a-5be5ebbbff26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640625840-172.17.0.12-1599371210178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-be17727b-deba-47ca-96b3-48470d9db943,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-c2f0f152-eddd-4348-8634-121bf9b137c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-3e578866-729e-4f03-a54c-bf31d1f3496c,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-53f682d1-a198-4aab-91ef-1c4107ba36da,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-65d00ac4-0dc8-457d-8d3f-e1c9cde81c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-7f22a630-0a23-4dec-90cc-c7fe9a9def87,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-e7760c43-d673-4874-a21c-2edb7a111678,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-f065e7fb-62b1-494f-b08a-5be5ebbbff26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809473140-172.17.0.12-1599372093334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36924,DS-dd63ace8-c11d-48c4-a383-e12668f7803e,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-76336d4e-7e99-46f7-984a-88e5942e2203,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-c42e6d65-aad9-4819-96e2-ba9898845412,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-67f6e39d-1019-4fc9-8ba6-f4aad308a79e,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-52cd4828-7e44-4cc7-aeab-e7a3c5016523,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-0319317c-da82-4dcb-99b2-401cada93125,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-ba1acefc-1bfe-41a2-ae72-5ff3cc6c70b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-aa2c9d66-56d6-4d6a-a814-258ab720928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809473140-172.17.0.12-1599372093334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36924,DS-dd63ace8-c11d-48c4-a383-e12668f7803e,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-76336d4e-7e99-46f7-984a-88e5942e2203,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-c42e6d65-aad9-4819-96e2-ba9898845412,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-67f6e39d-1019-4fc9-8ba6-f4aad308a79e,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-52cd4828-7e44-4cc7-aeab-e7a3c5016523,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-0319317c-da82-4dcb-99b2-401cada93125,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-ba1acefc-1bfe-41a2-ae72-5ff3cc6c70b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-aa2c9d66-56d6-4d6a-a814-258ab720928f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170109120-172.17.0.12-1599373277023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-28cc2d0b-f55b-4524-af6b-662066f46552,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-6ced2b90-a2f8-4e5f-9ffc-118997335740,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-6cc71b64-5899-43b4-9b48-0f197f987e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-bf86a52e-2922-4ee9-8910-fe2ef0d6db08,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-0c01963b-6ad3-4fc8-a68c-a7a2fff872cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-793ec7a8-a505-41e7-836c-601b1b7ff393,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-67c3bd63-16fd-4874-83c0-c3310db94d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-b23b9862-f14a-4110-b7db-214328ddd5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170109120-172.17.0.12-1599373277023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-28cc2d0b-f55b-4524-af6b-662066f46552,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-6ced2b90-a2f8-4e5f-9ffc-118997335740,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-6cc71b64-5899-43b4-9b48-0f197f987e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-bf86a52e-2922-4ee9-8910-fe2ef0d6db08,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-0c01963b-6ad3-4fc8-a68c-a7a2fff872cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-793ec7a8-a505-41e7-836c-601b1b7ff393,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-67c3bd63-16fd-4874-83c0-c3310db94d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-b23b9862-f14a-4110-b7db-214328ddd5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638501472-172.17.0.12-1599373386749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-b6e3550c-4a55-43ee-a2f2-b73afbee62fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-e95aa81b-ce32-4c29-ba68-2c8a93cc1201,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-0b1b389f-9902-4db3-b221-4bb8f16174d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c60adb9d-5f38-4e05-9620-30a8d49cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-63d9d0ad-18f8-4bc8-8fdd-02242f1d865a,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-e3e8a26e-b9f0-4aff-b2c3-b8b48e0ff387,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-07338330-2f32-4347-89f9-5acb688ba1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-61c5d42b-54c2-4ef3-8b43-24b34c5bdbea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638501472-172.17.0.12-1599373386749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-b6e3550c-4a55-43ee-a2f2-b73afbee62fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-e95aa81b-ce32-4c29-ba68-2c8a93cc1201,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-0b1b389f-9902-4db3-b221-4bb8f16174d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c60adb9d-5f38-4e05-9620-30a8d49cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-63d9d0ad-18f8-4bc8-8fdd-02242f1d865a,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-e3e8a26e-b9f0-4aff-b2c3-b8b48e0ff387,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-07338330-2f32-4347-89f9-5acb688ba1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-61c5d42b-54c2-4ef3-8b43-24b34c5bdbea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754523612-172.17.0.12-1599373681671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-da86d660-0f3c-43b2-b833-ce28ef69ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-9842c056-c4e4-4f5b-b209-d782b53be66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-916ec789-9b5c-4083-bbac-183175d72995,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-65634ede-2d2d-462f-b1d8-7d9b0206862f,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-f0983a73-ec2a-4977-9fd2-c4f63f59e4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-b106631e-513e-4b1e-9c43-49d7b88e7020,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-8f112d0b-2217-46eb-8449-3a21c1c53d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-f49ac3bc-1540-4532-8a27-82a57084d6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754523612-172.17.0.12-1599373681671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-da86d660-0f3c-43b2-b833-ce28ef69ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-9842c056-c4e4-4f5b-b209-d782b53be66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-916ec789-9b5c-4083-bbac-183175d72995,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-65634ede-2d2d-462f-b1d8-7d9b0206862f,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-f0983a73-ec2a-4977-9fd2-c4f63f59e4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-b106631e-513e-4b1e-9c43-49d7b88e7020,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-8f112d0b-2217-46eb-8449-3a21c1c53d68,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-f49ac3bc-1540-4532-8a27-82a57084d6ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639991927-172.17.0.12-1599374355271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-87dfa6d1-87b0-4984-af47-c2d8b04f521f,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-2f2d0f62-d2f7-4ae9-88b0-4528304411d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-7f26459e-cc84-43fb-ac71-9db83cdc7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-ad52a9bb-76b3-4534-a5c2-eb886f607f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-d673ddca-68d0-46cf-9296-bb611aa2657a,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-c716e047-f9aa-47e6-9a32-d434abaa2541,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-579042a2-2705-4091-8762-26a9a2db25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-f7dba22e-8272-49fd-aa78-55d0188864cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639991927-172.17.0.12-1599374355271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-87dfa6d1-87b0-4984-af47-c2d8b04f521f,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-2f2d0f62-d2f7-4ae9-88b0-4528304411d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-7f26459e-cc84-43fb-ac71-9db83cdc7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-ad52a9bb-76b3-4534-a5c2-eb886f607f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-d673ddca-68d0-46cf-9296-bb611aa2657a,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-c716e047-f9aa-47e6-9a32-d434abaa2541,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-579042a2-2705-4091-8762-26a9a2db25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-f7dba22e-8272-49fd-aa78-55d0188864cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151538712-172.17.0.12-1599374468190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-5a9f8766-0a0c-426a-b47f-2ca264514e29,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-b3a29dbb-c4a7-4b3e-8ba1-742a3d7d8968,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-95cc862d-daa8-4a18-aaea-a49e7a83ae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-7e19a9e4-c270-4e5f-812d-771da6c5c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9c8111ad-0430-437f-822f-58b8b5317ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-fb203ae0-6267-4757-bafc-c60ed4a7d542,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-7bf3a258-81ec-4b6c-9946-4d729e93e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-ce10a371-6394-47ab-a015-ddfc40b4ea2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151538712-172.17.0.12-1599374468190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-5a9f8766-0a0c-426a-b47f-2ca264514e29,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-b3a29dbb-c4a7-4b3e-8ba1-742a3d7d8968,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-95cc862d-daa8-4a18-aaea-a49e7a83ae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-7e19a9e4-c270-4e5f-812d-771da6c5c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9c8111ad-0430-437f-822f-58b8b5317ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-fb203ae0-6267-4757-bafc-c60ed4a7d542,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-7bf3a258-81ec-4b6c-9946-4d729e93e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-ce10a371-6394-47ab-a015-ddfc40b4ea2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136687172-172.17.0.12-1599374507216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-1176474c-17e7-4a24-95c3-a0e6b463f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-67905b91-93a9-4c3e-b77d-055adab97efe,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-254d6600-c70d-419e-b747-978cc963d284,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-8c920bbb-2236-4ff2-9cfc-f9392c2f29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-116ba7e3-7c47-4062-856c-3e9bef3304d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-90937b51-d075-420e-869c-ce5dc662899c,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-dc95e9ac-b392-4156-b42f-81a14927a297,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-65da9318-2eb2-43ce-ba64-6c1cb084f25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136687172-172.17.0.12-1599374507216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-1176474c-17e7-4a24-95c3-a0e6b463f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-67905b91-93a9-4c3e-b77d-055adab97efe,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-254d6600-c70d-419e-b747-978cc963d284,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-8c920bbb-2236-4ff2-9cfc-f9392c2f29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-116ba7e3-7c47-4062-856c-3e9bef3304d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-90937b51-d075-420e-869c-ce5dc662899c,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-dc95e9ac-b392-4156-b42f-81a14927a297,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-65da9318-2eb2-43ce-ba64-6c1cb084f25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906233481-172.17.0.12-1599374615620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-266caeac-4e57-477b-bb96-c75b7c6b7dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-a1314cec-5a8c-4dec-a81a-163012a1cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-fc42997d-a877-472c-804f-004976868dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-65060317-c97f-4628-96a7-e56afc352e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2ddcbceb-d19c-4861-89ac-79754401ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-12b35660-230b-489d-8b8e-e11bc3552cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-0e67ee1f-7b6c-4633-b2b4-f8fb54666309,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-8734e21f-87fc-4d92-9eee-56eb45905e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906233481-172.17.0.12-1599374615620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-266caeac-4e57-477b-bb96-c75b7c6b7dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-a1314cec-5a8c-4dec-a81a-163012a1cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-fc42997d-a877-472c-804f-004976868dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-65060317-c97f-4628-96a7-e56afc352e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2ddcbceb-d19c-4861-89ac-79754401ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-12b35660-230b-489d-8b8e-e11bc3552cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-0e67ee1f-7b6c-4633-b2b4-f8fb54666309,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-8734e21f-87fc-4d92-9eee-56eb45905e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034956764-172.17.0.12-1599374901954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33112,DS-5235edd4-3577-46cf-8a63-13a5f978df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-4e882280-c14c-450a-9f5c-88ef54b795a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-070ea53a-2da8-4844-930f-a56d5cde87ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-71053a07-586e-45ae-9134-cead0d8113d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-555c952f-591b-4cc0-a10d-824e6ec23ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-30621fdb-41d4-4230-bcd2-bfd5dbc32622,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-05d3f0d7-9b03-4e0f-b857-19081a01f87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-6aa38f8b-4dc5-4db0-aac6-5a9a8fb7b018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034956764-172.17.0.12-1599374901954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33112,DS-5235edd4-3577-46cf-8a63-13a5f978df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-4e882280-c14c-450a-9f5c-88ef54b795a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-070ea53a-2da8-4844-930f-a56d5cde87ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-71053a07-586e-45ae-9134-cead0d8113d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-555c952f-591b-4cc0-a10d-824e6ec23ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-30621fdb-41d4-4230-bcd2-bfd5dbc32622,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-05d3f0d7-9b03-4e0f-b857-19081a01f87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-6aa38f8b-4dc5-4db0-aac6-5a9a8fb7b018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739975467-172.17.0.12-1599375106914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-51dc931f-4a64-4ebe-85b4-bc8796d7d54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-a33927d6-bbdd-4084-93ca-05d4be6dbbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-4203258a-900d-4305-855d-33e0858acd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-290fc9a4-1b2e-4f7d-98b2-6d4764a0332f,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3ad20e46-e60a-435c-83d8-437edbd63917,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f4df042c-a386-4c12-a559-a3c9b1c1f847,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-ffb79880-8545-4b17-9b89-659711f5814b,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-27426052-adec-4fe3-a83a-b8e187b4ce70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739975467-172.17.0.12-1599375106914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-51dc931f-4a64-4ebe-85b4-bc8796d7d54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-a33927d6-bbdd-4084-93ca-05d4be6dbbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-4203258a-900d-4305-855d-33e0858acd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-290fc9a4-1b2e-4f7d-98b2-6d4764a0332f,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-3ad20e46-e60a-435c-83d8-437edbd63917,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f4df042c-a386-4c12-a559-a3c9b1c1f847,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-ffb79880-8545-4b17-9b89-659711f5814b,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-27426052-adec-4fe3-a83a-b8e187b4ce70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107331529-172.17.0.12-1599375518723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-4a1511a4-34bb-4ac4-9762-a4eedf85d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-3da4652f-190e-43b4-9cb8-5a7b4af5397a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-36da9896-0965-4472-b2be-39efa3048d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f7e57e54-95d7-489e-b902-5dc3c2c6168d,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-322f9779-9829-429b-9b7d-6a90abcc533f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-67fe38b8-ef4f-4850-ba63-9236beda68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-df431bc1-1cf6-40c5-b5f7-79b3fa01a914,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-bd0aa402-5542-4f91-bfc5-29a6eed07cb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107331529-172.17.0.12-1599375518723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-4a1511a4-34bb-4ac4-9762-a4eedf85d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-3da4652f-190e-43b4-9cb8-5a7b4af5397a,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-36da9896-0965-4472-b2be-39efa3048d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-f7e57e54-95d7-489e-b902-5dc3c2c6168d,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-322f9779-9829-429b-9b7d-6a90abcc533f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-67fe38b8-ef4f-4850-ba63-9236beda68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-df431bc1-1cf6-40c5-b5f7-79b3fa01a914,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-bd0aa402-5542-4f91-bfc5-29a6eed07cb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6793
