reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922948392-172.17.0.3-1599329180831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-fa5d9cb5-f778-42ae-b8d3-6bc44a383b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-173b3378-350f-4921-92f0-1986a38d883a,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-78cffac7-ed5d-4bdf-8263-919f48cdbe76,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-a58f6bc2-30f4-4c94-bad6-eee895eb58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-05ffd35e-2ec9-4142-b986-bb5a8572e739,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-3dff2de7-89ff-4ec9-a4ca-cb64f656e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-e7c0ef08-adb5-4c40-9e0a-f26f14765443,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2682552d-36ac-4665-bd14-4d4e53b75789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922948392-172.17.0.3-1599329180831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-fa5d9cb5-f778-42ae-b8d3-6bc44a383b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-173b3378-350f-4921-92f0-1986a38d883a,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-78cffac7-ed5d-4bdf-8263-919f48cdbe76,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-a58f6bc2-30f4-4c94-bad6-eee895eb58e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-05ffd35e-2ec9-4142-b986-bb5a8572e739,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-3dff2de7-89ff-4ec9-a4ca-cb64f656e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-e7c0ef08-adb5-4c40-9e0a-f26f14765443,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2682552d-36ac-4665-bd14-4d4e53b75789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252715282-172.17.0.3-1599329212477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-0cc0dace-7659-4b39-a141-6eefa18a987c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-15b3117a-eba4-40f8-81d9-82f9e52150d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-e482cd90-b287-4bb5-9b0c-aeb05357ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-9916c2b5-3edc-4c34-8c7d-10c33d2f9226,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-8e632bdf-b99a-4808-b86c-30b96f8f9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ade0e790-06a0-410d-a3b5-8e3f76dbacab,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-35679e9f-2f80-40ed-8ef9-fada61f42226,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-02871ce4-8f56-419c-b466-05ae67709634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252715282-172.17.0.3-1599329212477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-0cc0dace-7659-4b39-a141-6eefa18a987c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-15b3117a-eba4-40f8-81d9-82f9e52150d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-e482cd90-b287-4bb5-9b0c-aeb05357ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-9916c2b5-3edc-4c34-8c7d-10c33d2f9226,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-8e632bdf-b99a-4808-b86c-30b96f8f9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ade0e790-06a0-410d-a3b5-8e3f76dbacab,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-35679e9f-2f80-40ed-8ef9-fada61f42226,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-02871ce4-8f56-419c-b466-05ae67709634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693735146-172.17.0.3-1599329703881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-ebeab6e4-4e99-4214-b40d-3a7a008e5c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-9c23b78f-2733-4c2f-9bd3-9902d1cd858b,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-33870ce1-a9d7-4ebc-922e-02400e78dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-d6ee5837-4124-4d91-8093-1e59b4d21ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-4b5521e8-db33-4680-9dbd-e93ff95f3167,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-64ff7ad2-dd25-442e-ac2e-01284f56b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-25275262-d800-41b2-9079-5fbef34008c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-86adc19d-809e-4889-86dd-d00af5aae266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693735146-172.17.0.3-1599329703881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-ebeab6e4-4e99-4214-b40d-3a7a008e5c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-9c23b78f-2733-4c2f-9bd3-9902d1cd858b,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-33870ce1-a9d7-4ebc-922e-02400e78dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-d6ee5837-4124-4d91-8093-1e59b4d21ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-4b5521e8-db33-4680-9dbd-e93ff95f3167,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-64ff7ad2-dd25-442e-ac2e-01284f56b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-25275262-d800-41b2-9079-5fbef34008c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-86adc19d-809e-4889-86dd-d00af5aae266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294636708-172.17.0.3-1599330133151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-7005b05a-9b9e-42b3-8468-32a941ea3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-765d4d8d-5a2d-4965-94d2-5da94bb4dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-41866231-666a-4a8a-8f0a-c3481fdc3c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-663f3401-6c72-4c23-a57f-17eb7083e607,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-73c64953-1f20-4d84-b894-a694f26761b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-5de8d105-105b-4371-9ba1-780e57b600c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-21315b96-8c7c-4899-a2ae-cb40383aa8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2d7b6bec-e3b7-4e0f-9dd7-a424c55fc023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294636708-172.17.0.3-1599330133151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-7005b05a-9b9e-42b3-8468-32a941ea3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-765d4d8d-5a2d-4965-94d2-5da94bb4dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-41866231-666a-4a8a-8f0a-c3481fdc3c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-663f3401-6c72-4c23-a57f-17eb7083e607,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-73c64953-1f20-4d84-b894-a694f26761b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-5de8d105-105b-4371-9ba1-780e57b600c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-21315b96-8c7c-4899-a2ae-cb40383aa8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-2d7b6bec-e3b7-4e0f-9dd7-a424c55fc023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390168835-172.17.0.3-1599331511457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44842,DS-78c178fe-9a7a-4e84-8d6c-c8f6917dcaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-37b07243-397b-4263-99fa-5c76f816d102,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5245a510-c3bf-4c9d-931f-5cad8c3380c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-974e4c32-3a53-4f9f-a485-58a97d8281a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-24c0dc3d-105f-4f03-a3d0-f52dac48cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-9a4d9987-4fa2-4c7f-95df-b80b0e56ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-a2baf8b7-c764-497a-b71b-d90bee50f132,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7fcf6928-ed88-4c86-a368-6fbaaeda04bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390168835-172.17.0.3-1599331511457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44842,DS-78c178fe-9a7a-4e84-8d6c-c8f6917dcaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-37b07243-397b-4263-99fa-5c76f816d102,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5245a510-c3bf-4c9d-931f-5cad8c3380c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-974e4c32-3a53-4f9f-a485-58a97d8281a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-24c0dc3d-105f-4f03-a3d0-f52dac48cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-9a4d9987-4fa2-4c7f-95df-b80b0e56ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-a2baf8b7-c764-497a-b71b-d90bee50f132,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7fcf6928-ed88-4c86-a368-6fbaaeda04bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292525006-172.17.0.3-1599331752832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-c25e3a33-8c60-4b51-839f-e362fa55b444,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-affb3286-d75a-4fa9-a6fa-aa0a828eafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-2991184e-e211-4a6e-9b76-7bf8ca59d878,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3426f8f6-64fe-4813-9791-6a965f4c1270,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-2d2bc9a0-25d6-405c-9b6a-620ecc5296fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-8d295242-9c81-4966-9640-776dbcec9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-14836537-a176-4d91-adaa-a4da3e92d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-0a57e7a9-4355-474d-8945-7aac1dc3aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292525006-172.17.0.3-1599331752832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-c25e3a33-8c60-4b51-839f-e362fa55b444,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-affb3286-d75a-4fa9-a6fa-aa0a828eafc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-2991184e-e211-4a6e-9b76-7bf8ca59d878,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3426f8f6-64fe-4813-9791-6a965f4c1270,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-2d2bc9a0-25d6-405c-9b6a-620ecc5296fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-8d295242-9c81-4966-9640-776dbcec9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-14836537-a176-4d91-adaa-a4da3e92d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-0a57e7a9-4355-474d-8945-7aac1dc3aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386777178-172.17.0.3-1599331841323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-c3e5a3cc-b281-4d40-9a29-073771e40616,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-6bdf9522-cd5a-433a-9ab8-74a5004f7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4814f94f-28e8-45b1-a925-9fba0a999bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-1ada64ab-0634-42fa-b673-904c3612379b,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5653809c-dabb-45d5-80f8-5f667c9ceeee,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-6ed46d88-9e46-47af-9eb8-376996c19fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-c47e5de6-e923-47f6-b394-7d94b16930cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-d46f0730-32af-440e-8793-4ceac9f5d1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386777178-172.17.0.3-1599331841323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-c3e5a3cc-b281-4d40-9a29-073771e40616,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-6bdf9522-cd5a-433a-9ab8-74a5004f7dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4814f94f-28e8-45b1-a925-9fba0a999bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-1ada64ab-0634-42fa-b673-904c3612379b,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5653809c-dabb-45d5-80f8-5f667c9ceeee,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-6ed46d88-9e46-47af-9eb8-376996c19fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-c47e5de6-e923-47f6-b394-7d94b16930cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-d46f0730-32af-440e-8793-4ceac9f5d1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789883696-172.17.0.3-1599332008054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-ca7b443a-6054-440c-b60c-8e8c328ea264,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-37b27c2c-6fce-4fcc-a6af-af0b0a7a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-ff8e1ece-4d1b-4f8e-a083-dfe7898448ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-f10b3101-9ad7-479e-902e-1bd0a164b047,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-4aa958e7-f2df-46ff-ba41-a9452d8063a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-0bd1e91d-f2c5-4c12-8fbf-82b0b3d05180,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-d7dfc07e-6455-42ee-8e7b-70a8db171037,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-b8fb2134-6a89-4d24-a96c-241e16422a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789883696-172.17.0.3-1599332008054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-ca7b443a-6054-440c-b60c-8e8c328ea264,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-37b27c2c-6fce-4fcc-a6af-af0b0a7a3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-ff8e1ece-4d1b-4f8e-a083-dfe7898448ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-f10b3101-9ad7-479e-902e-1bd0a164b047,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-4aa958e7-f2df-46ff-ba41-a9452d8063a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-0bd1e91d-f2c5-4c12-8fbf-82b0b3d05180,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-d7dfc07e-6455-42ee-8e7b-70a8db171037,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-b8fb2134-6a89-4d24-a96c-241e16422a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241765368-172.17.0.3-1599332098107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-f0ae1929-11b6-438b-ab3c-ada2d93b26f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-6a9a4388-b7a6-4c92-a59e-80415fb5fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-df5dc20b-7f6c-415f-8674-168ae766acd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-10692579-b663-4c51-9d3e-4ab58c916c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-3ecfe5a5-f381-4b1e-9fe3-a37d560c3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-3e12d58e-1fb8-4cc1-9051-3a66b25adf41,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-83468dbb-4c83-4a8f-a1f6-4cd4407e8346,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-12fd2821-6f22-4785-b328-8e3a674d161c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241765368-172.17.0.3-1599332098107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37311,DS-f0ae1929-11b6-438b-ab3c-ada2d93b26f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-6a9a4388-b7a6-4c92-a59e-80415fb5fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-df5dc20b-7f6c-415f-8674-168ae766acd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-10692579-b663-4c51-9d3e-4ab58c916c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-3ecfe5a5-f381-4b1e-9fe3-a37d560c3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-3e12d58e-1fb8-4cc1-9051-3a66b25adf41,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-83468dbb-4c83-4a8f-a1f6-4cd4407e8346,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-12fd2821-6f22-4785-b328-8e3a674d161c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429788583-172.17.0.3-1599332532190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-26200840-098c-4e6e-8365-8eab7d9c50e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-27ea45e8-7e19-40f4-8219-9d51c58507ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-055a27e6-e024-4184-b945-c57bd7c557e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-5bf2e1b5-efa5-4d9f-a51b-a1e151e381b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-01e8e229-a05d-48ad-9f42-fba48e8d3398,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-000ba428-c56d-45f3-819a-c44c56b12fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-7eba6bb1-2358-49d6-a8c5-7023dbf2c836,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-02689749-c549-41ab-a00c-4267e0cd98b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429788583-172.17.0.3-1599332532190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-26200840-098c-4e6e-8365-8eab7d9c50e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-27ea45e8-7e19-40f4-8219-9d51c58507ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-055a27e6-e024-4184-b945-c57bd7c557e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-5bf2e1b5-efa5-4d9f-a51b-a1e151e381b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-01e8e229-a05d-48ad-9f42-fba48e8d3398,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-000ba428-c56d-45f3-819a-c44c56b12fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-7eba6bb1-2358-49d6-a8c5-7023dbf2c836,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-02689749-c549-41ab-a00c-4267e0cd98b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315744123-172.17.0.3-1599332562711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-0c8385ca-c12c-437c-953c-739b1d2e9b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-5c463dab-b7b6-49ac-bad0-2c2ecde8cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-8d730dd5-ac68-4138-8feb-94eac6718fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-2cbe8385-2951-4c46-941e-5ae4f9b169f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-c868c181-841f-4f8c-a512-69674fc900ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d7b04b59-86ee-4e6d-bc9e-ea22f639d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-0d8b4f3d-02b5-49b4-9fac-09e1f62198b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-652d1041-7e2b-498f-a34e-eee17911ec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315744123-172.17.0.3-1599332562711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-0c8385ca-c12c-437c-953c-739b1d2e9b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-5c463dab-b7b6-49ac-bad0-2c2ecde8cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-8d730dd5-ac68-4138-8feb-94eac6718fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-2cbe8385-2951-4c46-941e-5ae4f9b169f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-c868c181-841f-4f8c-a512-69674fc900ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d7b04b59-86ee-4e6d-bc9e-ea22f639d45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-0d8b4f3d-02b5-49b4-9fac-09e1f62198b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-652d1041-7e2b-498f-a34e-eee17911ec02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 100m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882911179-172.17.0.3-1599333262027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-ba6f9ffe-2879-44e6-bb31-c662db50bdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-a0b9cb7e-3796-4f26-bb5c-a1146eefda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b5de6981-2ae2-40ab-a18d-3e2253f63dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-42c9386c-6384-4fd6-9ef3-21d3b0a5eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-fa80b887-bfe1-4b26-930b-a647d820de76,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-12190197-c074-415b-bb31-ccdc2901954c,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-7fbe7aa7-a8b7-42e8-a887-861a72842fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-a5e21025-2c74-4f9a-b173-5b56de85edcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882911179-172.17.0.3-1599333262027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-ba6f9ffe-2879-44e6-bb31-c662db50bdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-a0b9cb7e-3796-4f26-bb5c-a1146eefda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b5de6981-2ae2-40ab-a18d-3e2253f63dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-42c9386c-6384-4fd6-9ef3-21d3b0a5eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-fa80b887-bfe1-4b26-930b-a647d820de76,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-12190197-c074-415b-bb31-ccdc2901954c,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-7fbe7aa7-a8b7-42e8-a887-861a72842fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-a5e21025-2c74-4f9a-b173-5b56de85edcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4471
