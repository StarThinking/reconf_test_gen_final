reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929448470-172.17.0.4-1599352191993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-70d908cf-b70e-4741-8b01-e52ab9e5f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-49aefba8-cce0-43ba-b087-3a543fd36a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-3f7959ae-136f-42d2-8d5c-a59ab60c357b,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-28e7a42e-1c42-4288-913c-b9edfb2ac1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-7ffbae4e-79f5-4970-ba85-f31ec9bf0271,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-646e2cd8-1dee-4a73-8696-3bc6756ba8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-d46b2ccb-e6f6-4b08-88ee-c86b10ab8fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-cb0569da-0dea-41bd-b8d6-426c52ee9fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929448470-172.17.0.4-1599352191993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-70d908cf-b70e-4741-8b01-e52ab9e5f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-49aefba8-cce0-43ba-b087-3a543fd36a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-3f7959ae-136f-42d2-8d5c-a59ab60c357b,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-28e7a42e-1c42-4288-913c-b9edfb2ac1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-7ffbae4e-79f5-4970-ba85-f31ec9bf0271,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-646e2cd8-1dee-4a73-8696-3bc6756ba8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-d46b2ccb-e6f6-4b08-88ee-c86b10ab8fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-cb0569da-0dea-41bd-b8d6-426c52ee9fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485642022-172.17.0.4-1599352590731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-07e9be91-6dc8-432c-b5b1-38ffad646482,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-d734e821-44bd-4922-8313-de61cb007b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-07a22c5f-b903-48df-851e-0695caee8827,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-adbc80c5-e529-4de0-b027-ef6f1928d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-f513a484-e701-4bac-9dca-39d812d34686,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-b9f4b9f8-c924-40ef-b66a-8ae172e6100c,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-153ab385-ece1-440c-8367-a087a2260ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-552999d8-97ab-4c04-8b8b-ce41533e8acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485642022-172.17.0.4-1599352590731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-07e9be91-6dc8-432c-b5b1-38ffad646482,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-d734e821-44bd-4922-8313-de61cb007b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-07a22c5f-b903-48df-851e-0695caee8827,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-adbc80c5-e529-4de0-b027-ef6f1928d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-f513a484-e701-4bac-9dca-39d812d34686,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-b9f4b9f8-c924-40ef-b66a-8ae172e6100c,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-153ab385-ece1-440c-8367-a087a2260ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-552999d8-97ab-4c04-8b8b-ce41533e8acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152450267-172.17.0.4-1599352787918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-9dbaddfb-4746-47a4-b524-6e91553aa777,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-d9fb45fe-11da-49a1-881d-82dc27f6ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-4fe36639-bd13-4e71-a6a8-a79fe20b4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-31124dce-8bb2-4e50-8a1f-43f6f7aea4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-71705c39-cbce-434e-a218-ff5a7885d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-07cf51bc-9321-434d-8822-bdb820f1edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-55286e8e-4843-4123-b902-4874330d73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a4dab182-57b0-4337-92e3-51ebd1377322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152450267-172.17.0.4-1599352787918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-9dbaddfb-4746-47a4-b524-6e91553aa777,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-d9fb45fe-11da-49a1-881d-82dc27f6ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-4fe36639-bd13-4e71-a6a8-a79fe20b4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-31124dce-8bb2-4e50-8a1f-43f6f7aea4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-71705c39-cbce-434e-a218-ff5a7885d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-07cf51bc-9321-434d-8822-bdb820f1edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-55286e8e-4843-4123-b902-4874330d73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-a4dab182-57b0-4337-92e3-51ebd1377322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214989542-172.17.0.4-1599353306440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-df867ecc-9b2e-4016-ae5a-042cc1c2eb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e9097248-f73e-4e72-84ef-9f2bc2b507ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6a1af9ed-8ecc-46c7-96df-7f934a5da35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-0b1593d5-0e05-4bc2-a96f-2e6049a10430,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-3ae5b809-60f1-4eac-90e8-d4476cef875b,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-03d06e68-d245-47f0-9cb6-8dd5ee0082ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-72be15d7-d946-4e39-8301-c3a56176e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d6033fba-e68e-4727-b0a5-395ddceda39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214989542-172.17.0.4-1599353306440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-df867ecc-9b2e-4016-ae5a-042cc1c2eb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e9097248-f73e-4e72-84ef-9f2bc2b507ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6a1af9ed-8ecc-46c7-96df-7f934a5da35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-0b1593d5-0e05-4bc2-a96f-2e6049a10430,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-3ae5b809-60f1-4eac-90e8-d4476cef875b,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-03d06e68-d245-47f0-9cb6-8dd5ee0082ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-72be15d7-d946-4e39-8301-c3a56176e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d6033fba-e68e-4727-b0a5-395ddceda39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269319157-172.17.0.4-1599353820520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-f29a9a94-311a-4a2f-906e-099ebefaba42,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-e4b086ac-f472-429b-87ed-1a27a665d847,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-b442d8bc-c4ed-479c-83bc-4335915e15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-aa46fdcd-ada1-4b2a-be60-1952c763670e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-27f61011-0f2e-42fe-bf67-b8f93208741f,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-6f75f5f9-bf6c-40b9-833a-d3b29b6857ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-70c7c32a-bca1-4498-abfe-7c150719961d,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-dcd957a5-5e4a-4b44-9578-fca2e450e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269319157-172.17.0.4-1599353820520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-f29a9a94-311a-4a2f-906e-099ebefaba42,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-e4b086ac-f472-429b-87ed-1a27a665d847,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-b442d8bc-c4ed-479c-83bc-4335915e15fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-aa46fdcd-ada1-4b2a-be60-1952c763670e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-27f61011-0f2e-42fe-bf67-b8f93208741f,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-6f75f5f9-bf6c-40b9-833a-d3b29b6857ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-70c7c32a-bca1-4498-abfe-7c150719961d,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-dcd957a5-5e4a-4b44-9578-fca2e450e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717688686-172.17.0.4-1599354059574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-dfecc90b-f080-422d-b61f-2f1173678fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-968c1713-0591-4f5c-b1ed-bb63534ba7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a0fe2216-1271-44de-a842-ec22059ec60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-c75c9062-0cc1-4e50-a7b5-ef763ecb06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-4ec97dfe-8af2-49c3-b31e-61427e7829aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-f682076c-2321-46c2-92d9-ed2cd7581276,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-b8845e7e-a386-4e23-a5db-729cb3951d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-654d887a-b571-4488-bd06-febcb579e481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717688686-172.17.0.4-1599354059574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-dfecc90b-f080-422d-b61f-2f1173678fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-968c1713-0591-4f5c-b1ed-bb63534ba7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a0fe2216-1271-44de-a842-ec22059ec60e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-c75c9062-0cc1-4e50-a7b5-ef763ecb06a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-4ec97dfe-8af2-49c3-b31e-61427e7829aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-f682076c-2321-46c2-92d9-ed2cd7581276,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-b8845e7e-a386-4e23-a5db-729cb3951d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-654d887a-b571-4488-bd06-febcb579e481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587002749-172.17.0.4-1599354773988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-cda283b3-7f85-444b-9bfb-c087b5e2af79,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-68e12f19-36fa-485d-898e-8a8b8a6d920c,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-0dd8881a-02f7-44c3-bd0d-f109b0752219,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-87883670-4ca2-40c0-9691-fbdaf8aa6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ade0e8df-32ff-48b8-8c3b-d867d294bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-50a94c54-11f5-4c3f-a024-3af29fe03a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-b52d6401-1b4b-4138-b611-f1fb9e824b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-c2f96a07-2569-4410-9d79-12304ae79514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587002749-172.17.0.4-1599354773988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-cda283b3-7f85-444b-9bfb-c087b5e2af79,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-68e12f19-36fa-485d-898e-8a8b8a6d920c,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-0dd8881a-02f7-44c3-bd0d-f109b0752219,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-87883670-4ca2-40c0-9691-fbdaf8aa6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ade0e8df-32ff-48b8-8c3b-d867d294bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-50a94c54-11f5-4c3f-a024-3af29fe03a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-b52d6401-1b4b-4138-b611-f1fb9e824b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-c2f96a07-2569-4410-9d79-12304ae79514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40364467-172.17.0.4-1599355301775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-2cfdcbb4-a124-4ca5-b90a-6f798c3d1346,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-2a9a9aed-e9fd-453c-9ef8-ca5503b1bde9,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-4894f7a8-4aeb-4bd0-a1e5-965ad610faee,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-8b76aa6a-8156-4adc-9609-e6d50ecfff72,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-d6a08b52-030b-4e6c-92ba-4e6c93267489,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-0e6eb8f8-30ca-456e-b2d9-1cb1d6b26fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-651da356-0502-49e7-a775-07fe924db85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7a01751c-9e5c-45e6-ad51-b55001c2854e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40364467-172.17.0.4-1599355301775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-2cfdcbb4-a124-4ca5-b90a-6f798c3d1346,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-2a9a9aed-e9fd-453c-9ef8-ca5503b1bde9,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-4894f7a8-4aeb-4bd0-a1e5-965ad610faee,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-8b76aa6a-8156-4adc-9609-e6d50ecfff72,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-d6a08b52-030b-4e6c-92ba-4e6c93267489,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-0e6eb8f8-30ca-456e-b2d9-1cb1d6b26fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-651da356-0502-49e7-a775-07fe924db85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7a01751c-9e5c-45e6-ad51-b55001c2854e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735444493-172.17.0.4-1599355637218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-aa1ba42c-3fd9-4d69-b170-045023ebea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-002cde3b-e968-4adf-851d-a40424ab6da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-04faa390-953c-440d-97f2-98143ccc534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-4cd3bc96-2c9a-4c60-8a2c-d97bfe85abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a11cafdc-0b93-4872-9d4f-7fc4b84dd68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-a414a08b-bf2d-42ed-b62d-cc9185f90522,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-33c37b32-bb2d-4375-bd13-9741a4152d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-3040caa2-c5da-4f1e-876f-816bfbe30c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735444493-172.17.0.4-1599355637218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-aa1ba42c-3fd9-4d69-b170-045023ebea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-002cde3b-e968-4adf-851d-a40424ab6da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-04faa390-953c-440d-97f2-98143ccc534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-4cd3bc96-2c9a-4c60-8a2c-d97bfe85abfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a11cafdc-0b93-4872-9d4f-7fc4b84dd68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-a414a08b-bf2d-42ed-b62d-cc9185f90522,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-33c37b32-bb2d-4375-bd13-9741a4152d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-3040caa2-c5da-4f1e-876f-816bfbe30c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039945557-172.17.0.4-1599355836273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-572bc473-d0cf-43d6-8077-36f4d1d4c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-4c1be532-05f3-4c96-aa58-77c5cd1eb788,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0b6c2335-3b0b-4750-9beb-c92325dcb139,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-06b84476-7c00-417a-b8c9-b8d5742fc8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f7c3a61b-0e71-4032-9c1a-6da86ebec63e,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-5e131eb0-63e0-444f-a604-2ec43bf15f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-0c6b5347-50fe-49cb-aaf4-e7b0ddbe821f,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-e64e829b-0c92-4554-8adb-1662d135862f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039945557-172.17.0.4-1599355836273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-572bc473-d0cf-43d6-8077-36f4d1d4c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-4c1be532-05f3-4c96-aa58-77c5cd1eb788,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0b6c2335-3b0b-4750-9beb-c92325dcb139,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-06b84476-7c00-417a-b8c9-b8d5742fc8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f7c3a61b-0e71-4032-9c1a-6da86ebec63e,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-5e131eb0-63e0-444f-a604-2ec43bf15f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-0c6b5347-50fe-49cb-aaf4-e7b0ddbe821f,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-e64e829b-0c92-4554-8adb-1662d135862f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721342555-172.17.0.4-1599355954381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-6b7bef26-a44c-4c4a-892b-26f3f06b8e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-f08aac8d-0e8e-47bb-977e-c14a123947d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-c3110e12-a982-46d2-9e08-662c21f5de06,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-294ad760-187f-4a4b-b400-4f3d07229a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-1a69d767-ed12-4e87-96cb-cd639041462b,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-c4079fac-3647-4906-a7b3-720f4ca017f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-7242abf4-28a8-462d-af94-dfcd0af10c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-9e8341ac-77a6-4099-9cea-459e4d64141d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721342555-172.17.0.4-1599355954381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-6b7bef26-a44c-4c4a-892b-26f3f06b8e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-f08aac8d-0e8e-47bb-977e-c14a123947d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-c3110e12-a982-46d2-9e08-662c21f5de06,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-294ad760-187f-4a4b-b400-4f3d07229a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-1a69d767-ed12-4e87-96cb-cd639041462b,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-c4079fac-3647-4906-a7b3-720f4ca017f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-7242abf4-28a8-462d-af94-dfcd0af10c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-9e8341ac-77a6-4099-9cea-459e4d64141d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231654899-172.17.0.4-1599356174410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-c6346a7f-7aa4-4776-9052-a1bb9357437d,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-e882c29e-9a7d-44dd-bada-5c9dee911632,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-5b2c449f-c122-44ae-9a74-f4773ec636f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-2781cf89-628b-4588-ada5-cb506cb957b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-4f8f9705-fcff-491f-ae89-053c2f7e17bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-88f795ec-2bea-43a1-8d99-31c1579b912d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-d9c1ee7b-c562-47b6-a3d4-b268ff497aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-99e3ecda-f999-41b1-8829-2f94cff73200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231654899-172.17.0.4-1599356174410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-c6346a7f-7aa4-4776-9052-a1bb9357437d,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-e882c29e-9a7d-44dd-bada-5c9dee911632,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-5b2c449f-c122-44ae-9a74-f4773ec636f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-2781cf89-628b-4588-ada5-cb506cb957b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-4f8f9705-fcff-491f-ae89-053c2f7e17bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-88f795ec-2bea-43a1-8d99-31c1579b912d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-d9c1ee7b-c562-47b6-a3d4-b268ff497aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-99e3ecda-f999-41b1-8829-2f94cff73200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060750522-172.17.0.4-1599356397075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6d441a38-b160-4ced-8965-cef15d5958b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-f91420ee-2e3b-4736-b913-ece80054e004,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-0d74b0ac-384b-4977-945f-0bcf9a3a3ada,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-9a329eab-dd3b-461a-a25a-0517df54f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-e9b102b8-adc3-4035-9070-0d577d17ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-76187df5-09e4-4b1e-b1d4-dbfcab84685b,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-600bdb16-eb26-466b-855d-8f73652e4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-bc77de4f-fc21-40be-8983-0a047af57d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060750522-172.17.0.4-1599356397075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6d441a38-b160-4ced-8965-cef15d5958b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-f91420ee-2e3b-4736-b913-ece80054e004,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-0d74b0ac-384b-4977-945f-0bcf9a3a3ada,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-9a329eab-dd3b-461a-a25a-0517df54f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-e9b102b8-adc3-4035-9070-0d577d17ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-76187df5-09e4-4b1e-b1d4-dbfcab84685b,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-600bdb16-eb26-466b-855d-8f73652e4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-bc77de4f-fc21-40be-8983-0a047af57d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512558736-172.17.0.4-1599356483021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-4f606213-defc-4a06-90f6-d7a1c4e6b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-af4f9fc2-b0f7-40b1-8bc1-23e28332454b,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-c40dfbe8-3000-4d7e-a132-29ceb811a486,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8b57b1a6-eb4c-4a7c-84b6-3c5c72e9a524,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-f0dffb96-551f-4b98-b727-847369684e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-21498f5e-0582-45b4-9088-63427a286225,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-bec3397f-a609-4f74-abd9-845a67b9bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-36928815-b281-44b4-a8cd-2357edd544f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512558736-172.17.0.4-1599356483021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34017,DS-4f606213-defc-4a06-90f6-d7a1c4e6b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-af4f9fc2-b0f7-40b1-8bc1-23e28332454b,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-c40dfbe8-3000-4d7e-a132-29ceb811a486,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8b57b1a6-eb4c-4a7c-84b6-3c5c72e9a524,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-f0dffb96-551f-4b98-b727-847369684e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-21498f5e-0582-45b4-9088-63427a286225,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-bec3397f-a609-4f74-abd9-845a67b9bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-36928815-b281-44b4-a8cd-2357edd544f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5872
