reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241273439-172.17.0.7-1599340769007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-729f29b1-d1ef-480a-af29-cd4f21a2c069,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-0314aa8e-5d16-4054-b77a-b45ac1ecbaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b9c33d52-a36d-4d83-a9f2-ace9a64565f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-ffdb8b51-ca75-4b43-aa6c-0ff3bd66af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-1fa5b5df-cc9b-46aa-a2dc-b55527934728,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-abd872ba-d66d-4986-bafe-b2c01f64b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eaf082a4-4da0-4fb4-a862-772b9b891a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-a1adad13-bfb1-4bd6-bce7-05d5c0b499db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241273439-172.17.0.7-1599340769007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-729f29b1-d1ef-480a-af29-cd4f21a2c069,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-0314aa8e-5d16-4054-b77a-b45ac1ecbaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b9c33d52-a36d-4d83-a9f2-ace9a64565f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-ffdb8b51-ca75-4b43-aa6c-0ff3bd66af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-1fa5b5df-cc9b-46aa-a2dc-b55527934728,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-abd872ba-d66d-4986-bafe-b2c01f64b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eaf082a4-4da0-4fb4-a862-772b9b891a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-a1adad13-bfb1-4bd6-bce7-05d5c0b499db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372947671-172.17.0.7-1599340862231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-3ab7dd27-672b-4056-a4bb-7957bc4a1964,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-31d6f4c6-3dfe-45a9-8d28-59a0c4b52c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-a8d9c4d9-6496-450e-bdff-5626a4d47eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-1ec98787-93f1-42ee-91d1-39512d6fdef9,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f4e19599-476e-46db-b78d-eef2046d8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-89336510-8f27-4410-b8c6-303475ff6bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-9e1cdd1f-2ba6-405d-9534-ebf8261ddebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c4ca2946-9c54-4a07-b1cb-5b19e34501db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372947671-172.17.0.7-1599340862231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-3ab7dd27-672b-4056-a4bb-7957bc4a1964,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-31d6f4c6-3dfe-45a9-8d28-59a0c4b52c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-a8d9c4d9-6496-450e-bdff-5626a4d47eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-1ec98787-93f1-42ee-91d1-39512d6fdef9,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f4e19599-476e-46db-b78d-eef2046d8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-89336510-8f27-4410-b8c6-303475ff6bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-9e1cdd1f-2ba6-405d-9534-ebf8261ddebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c4ca2946-9c54-4a07-b1cb-5b19e34501db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193294114-172.17.0.7-1599340900915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40146,DS-1ec51754-34ee-4cf7-9cd4-ea9a968e0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-e1514115-9b78-4de8-a63e-934168b66e08,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-c8093b10-9cf9-4725-9894-dc827c66ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-90789ae5-0984-4856-afbf-405e0209dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-02195ab4-62be-4990-a6b3-7a3b28367bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9518041e-a6e0-4fc4-84ba-a83edfdc0368,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-afc4891e-c944-4919-adda-63cd1d28953c,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dbec7b1-8a3d-46ee-b752-1147716798d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193294114-172.17.0.7-1599340900915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40146,DS-1ec51754-34ee-4cf7-9cd4-ea9a968e0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-e1514115-9b78-4de8-a63e-934168b66e08,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-c8093b10-9cf9-4725-9894-dc827c66ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-90789ae5-0984-4856-afbf-405e0209dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-02195ab4-62be-4990-a6b3-7a3b28367bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9518041e-a6e0-4fc4-84ba-a83edfdc0368,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-afc4891e-c944-4919-adda-63cd1d28953c,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dbec7b1-8a3d-46ee-b752-1147716798d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673319682-172.17.0.7-1599340977032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-a9bc6626-456a-468d-9c3f-7f70bc1e9416,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-29ce7975-bab3-46ab-adb1-ded597aa4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ccd08a6c-f61a-423a-9d6d-c747d1efe967,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f9159ebd-e3e5-4405-9762-90ec546fb4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-93c86857-ca6d-404b-810b-002f16b6203f,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-4c7da127-2ade-49ee-a51b-0c7665d2e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-14d45f16-ca00-4d7c-aa89-95bfd2b44fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-7f98a8f2-e986-47f2-b551-e9fa1f40cc3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673319682-172.17.0.7-1599340977032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-a9bc6626-456a-468d-9c3f-7f70bc1e9416,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-29ce7975-bab3-46ab-adb1-ded597aa4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ccd08a6c-f61a-423a-9d6d-c747d1efe967,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-f9159ebd-e3e5-4405-9762-90ec546fb4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-93c86857-ca6d-404b-810b-002f16b6203f,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-4c7da127-2ade-49ee-a51b-0c7665d2e10a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-14d45f16-ca00-4d7c-aa89-95bfd2b44fae,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-7f98a8f2-e986-47f2-b551-e9fa1f40cc3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533064673-172.17.0.7-1599341186166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ef5d607-a2fd-4083-8028-5f42da1ee470,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-983146e6-4358-49f2-87ed-55b853162a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-91de952c-e261-4c90-8c22-a7d789ef44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-666c24f2-286f-4d9b-88d5-8c33d74f76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-45f64d0e-4428-4b02-86d2-696bb5decfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-563bd990-0ceb-4eb2-b12e-f6c0d69080d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-968b494a-735b-4970-8096-2e5f981ab1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-9fa13b8f-4910-47c4-9960-1017be80ad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533064673-172.17.0.7-1599341186166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ef5d607-a2fd-4083-8028-5f42da1ee470,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-983146e6-4358-49f2-87ed-55b853162a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-91de952c-e261-4c90-8c22-a7d789ef44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-666c24f2-286f-4d9b-88d5-8c33d74f76cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-45f64d0e-4428-4b02-86d2-696bb5decfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-563bd990-0ceb-4eb2-b12e-f6c0d69080d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-968b494a-735b-4970-8096-2e5f981ab1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-9fa13b8f-4910-47c4-9960-1017be80ad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091270241-172.17.0.7-1599341313633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-5cf26a5f-b296-4376-8678-b919bacbb682,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-1efa389b-0bb2-45b8-9623-61624a38852d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-17f236f5-793f-467f-a617-648a4c02eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b2c65506-ff77-4586-8a6c-ec6ca107233b,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-8257eebb-9159-44e1-9ed8-de0b286d4322,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-02174f48-077e-4230-8449-59eb99f630e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-8f568bdc-b83a-4ad6-aaaa-a4cf6efc5f79,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-685266b6-0b53-4097-ae41-c47fff72f256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091270241-172.17.0.7-1599341313633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-5cf26a5f-b296-4376-8678-b919bacbb682,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-1efa389b-0bb2-45b8-9623-61624a38852d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-17f236f5-793f-467f-a617-648a4c02eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-b2c65506-ff77-4586-8a6c-ec6ca107233b,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-8257eebb-9159-44e1-9ed8-de0b286d4322,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-02174f48-077e-4230-8449-59eb99f630e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-8f568bdc-b83a-4ad6-aaaa-a4cf6efc5f79,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-685266b6-0b53-4097-ae41-c47fff72f256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053182036-172.17.0.7-1599341679216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-467743f4-3c2a-4812-bbd5-a344bdb7f509,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9275188f-f598-40eb-947f-1652a5baf37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-915a0657-2a6a-4d3e-9549-1a5484bceb48,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-c21641f1-f06e-46f1-a494-d898c8e23de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-f4cfd5a9-df32-41fa-b5a5-bc0d5171812b,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3ce8b5a9-263e-4707-afb2-228de5de0188,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7632017a-f3d0-48f1-a35b-f45cec5a6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-6bd19aac-9126-4d17-b1ff-502f058e85b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053182036-172.17.0.7-1599341679216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35674,DS-467743f4-3c2a-4812-bbd5-a344bdb7f509,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9275188f-f598-40eb-947f-1652a5baf37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-915a0657-2a6a-4d3e-9549-1a5484bceb48,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-c21641f1-f06e-46f1-a494-d898c8e23de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-f4cfd5a9-df32-41fa-b5a5-bc0d5171812b,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-3ce8b5a9-263e-4707-afb2-228de5de0188,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7632017a-f3d0-48f1-a35b-f45cec5a6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-6bd19aac-9126-4d17-b1ff-502f058e85b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252376981-172.17.0.7-1599342018937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-8082ad62-3987-454b-8b1a-8e85d78f0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-1669ed40-f39e-473e-8f01-b64551223b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-21779e1e-b0e6-41c8-8ec9-599eac7d1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-1e2d05cc-fc94-4d64-85bd-1e71956b3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-481e3418-c934-467a-8854-cba85330f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-086f2619-9133-4d45-8068-433f0e31c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-649c99f6-0101-4191-924a-fc8d24e06397,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-edce47f1-1ebd-445b-9577-1d2144fb7e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252376981-172.17.0.7-1599342018937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36286,DS-8082ad62-3987-454b-8b1a-8e85d78f0f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-1669ed40-f39e-473e-8f01-b64551223b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-21779e1e-b0e6-41c8-8ec9-599eac7d1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-1e2d05cc-fc94-4d64-85bd-1e71956b3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-481e3418-c934-467a-8854-cba85330f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-086f2619-9133-4d45-8068-433f0e31c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-649c99f6-0101-4191-924a-fc8d24e06397,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-edce47f1-1ebd-445b-9577-1d2144fb7e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689110803-172.17.0.7-1599342463451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-683a8824-04fb-47b1-b782-2ed3d17df355,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-ec4a543c-240f-4628-aba4-4c7ddb7efdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-0fee8654-66b7-4b2b-a755-021f20cee370,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-dac87e58-98b3-4ed0-9ad4-9c9361de9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-5fc0ff71-4f2d-4a34-aea3-addefa08a207,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-807bcf68-880e-4c59-a037-dd8334ff72f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b2e1790-0c90-4f7b-afdb-a1416388a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-85b3d8e6-2fd5-4224-bf30-d5176eef8757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689110803-172.17.0.7-1599342463451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-683a8824-04fb-47b1-b782-2ed3d17df355,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-ec4a543c-240f-4628-aba4-4c7ddb7efdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-0fee8654-66b7-4b2b-a755-021f20cee370,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-dac87e58-98b3-4ed0-9ad4-9c9361de9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-5fc0ff71-4f2d-4a34-aea3-addefa08a207,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-807bcf68-880e-4c59-a037-dd8334ff72f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b2e1790-0c90-4f7b-afdb-a1416388a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-85b3d8e6-2fd5-4224-bf30-d5176eef8757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594001931-172.17.0.7-1599342735639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-81ed300e-163a-4d4a-a91e-3bf04f005b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1701495c-af36-491c-a0ba-c9e3d30d7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-b242c295-0276-479d-810a-5ac4dabb6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-463589c9-64f3-457a-8e20-7cebcfb31678,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-d7b3bf40-bb7e-4045-8a14-9a41030330bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d49e415d-a8ac-4156-bc54-de7027a246d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-0eb56d93-74e6-4b1b-9d4c-13bec8da58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-77d002c9-e24f-4d3f-99be-e423af7a8d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594001931-172.17.0.7-1599342735639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-81ed300e-163a-4d4a-a91e-3bf04f005b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-1701495c-af36-491c-a0ba-c9e3d30d7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-b242c295-0276-479d-810a-5ac4dabb6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-463589c9-64f3-457a-8e20-7cebcfb31678,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-d7b3bf40-bb7e-4045-8a14-9a41030330bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d49e415d-a8ac-4156-bc54-de7027a246d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-0eb56d93-74e6-4b1b-9d4c-13bec8da58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-77d002c9-e24f-4d3f-99be-e423af7a8d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145497337-172.17.0.7-1599343139279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-8dedd55c-6092-41b9-9cdf-86d3591971cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-71e96e35-c5b2-4226-a88a-915d4deb650c,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-fd8ef135-fbfe-4bda-bb2b-190b2e89cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-8a444a81-18ea-4bab-b853-a613d85c9728,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-ddbfb152-720c-43d0-879f-f03d5e0285c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-72b274fb-6902-42ae-acf9-ee19f0ad66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-ab79ee6a-769f-4fd8-a1e9-92e7032910cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-51793b30-cf3c-42e5-a74a-aea1d441a93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145497337-172.17.0.7-1599343139279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-8dedd55c-6092-41b9-9cdf-86d3591971cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-71e96e35-c5b2-4226-a88a-915d4deb650c,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-fd8ef135-fbfe-4bda-bb2b-190b2e89cd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-8a444a81-18ea-4bab-b853-a613d85c9728,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-ddbfb152-720c-43d0-879f-f03d5e0285c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-72b274fb-6902-42ae-acf9-ee19f0ad66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-ab79ee6a-769f-4fd8-a1e9-92e7032910cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-51793b30-cf3c-42e5-a74a-aea1d441a93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518660292-172.17.0.7-1599343642104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-0ce4d359-916d-45d6-8b97-6eaa3e804f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-68f544af-a773-4300-b8f0-468217002d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-5ae212f5-3fb9-44c2-a8c2-9ebd31c1f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-0abe1e70-cf2e-41f5-8aa9-61ba2f8c1cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-631d4a68-6465-4814-95a6-229ee84067b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-30c06c35-086c-45db-b74a-e5f8c31cc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-9a78da6d-762b-4c60-9f04-1d1efef95412,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-86f216da-948c-4575-ad6e-2be090d2ddf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518660292-172.17.0.7-1599343642104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-0ce4d359-916d-45d6-8b97-6eaa3e804f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-68f544af-a773-4300-b8f0-468217002d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-5ae212f5-3fb9-44c2-a8c2-9ebd31c1f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-0abe1e70-cf2e-41f5-8aa9-61ba2f8c1cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-631d4a68-6465-4814-95a6-229ee84067b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-30c06c35-086c-45db-b74a-e5f8c31cc1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-9a78da6d-762b-4c60-9f04-1d1efef95412,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-86f216da-948c-4575-ad6e-2be090d2ddf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664993126-172.17.0.7-1599344034440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43459,DS-4d1d7c52-6210-4927-8c55-6ec3a0cbf57d,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-103a9748-82ec-4abb-92c8-5ece0d23e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-c6f1e76a-cd6e-4dc9-a269-efe3e7377600,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-9ea3f2bd-2599-443a-ba66-7fd486492a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-57bf092a-8030-4894-b3c1-0e5363e920f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-6776d4be-c61e-40dc-a582-ab6167f76f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-5bf1bfdb-deb9-40c2-8e95-0e5bd3934ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-a5f3e8c1-1897-4c90-a805-ee9e4ca27fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664993126-172.17.0.7-1599344034440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43459,DS-4d1d7c52-6210-4927-8c55-6ec3a0cbf57d,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-103a9748-82ec-4abb-92c8-5ece0d23e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-c6f1e76a-cd6e-4dc9-a269-efe3e7377600,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-9ea3f2bd-2599-443a-ba66-7fd486492a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-57bf092a-8030-4894-b3c1-0e5363e920f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-6776d4be-c61e-40dc-a582-ab6167f76f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-5bf1bfdb-deb9-40c2-8e95-0e5bd3934ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-a5f3e8c1-1897-4c90-a805-ee9e4ca27fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698574873-172.17.0.7-1599344514337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-f3432d09-5246-4db9-8126-643d24bba705,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-b81581ca-e762-403d-a520-ab65c7455caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-b2114c1f-e123-47c7-b715-ffcc7fde5130,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-bfbf4b95-9f19-4f40-8a63-fb78979480f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-7497f23e-0c32-41df-bb5f-c4c2f351760d,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-bbc2d6e8-670f-41bf-9cbd-4a9db9dd6f53,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-419945a9-a0aa-45a4-8301-eb1fa9e47b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2f179880-6567-4b17-8c14-f935145783be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698574873-172.17.0.7-1599344514337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-f3432d09-5246-4db9-8126-643d24bba705,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-b81581ca-e762-403d-a520-ab65c7455caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-b2114c1f-e123-47c7-b715-ffcc7fde5130,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-bfbf4b95-9f19-4f40-8a63-fb78979480f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-7497f23e-0c32-41df-bb5f-c4c2f351760d,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-bbc2d6e8-670f-41bf-9cbd-4a9db9dd6f53,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-419945a9-a0aa-45a4-8301-eb1fa9e47b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2f179880-6567-4b17-8c14-f935145783be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208784077-172.17.0.7-1599344555148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3ca4c40e-72c0-42c0-81e4-40fb1b15c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-6cb483d7-afc4-4978-8ca5-7846229cae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-58b3a6ce-7a90-452f-939e-51d23351af68,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-500c5431-43f6-4457-adab-eb5ae895034d,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-c4110d72-db34-4bdb-8f59-dd8f4df91f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-6dad5e21-292e-430f-9177-f70fea6ce0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-2f21a528-1b79-44ff-8ed1-22b1af72b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-4e39c33d-5b39-4f07-b7fd-e273d37860cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208784077-172.17.0.7-1599344555148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-3ca4c40e-72c0-42c0-81e4-40fb1b15c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-6cb483d7-afc4-4978-8ca5-7846229cae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-58b3a6ce-7a90-452f-939e-51d23351af68,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-500c5431-43f6-4457-adab-eb5ae895034d,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-c4110d72-db34-4bdb-8f59-dd8f4df91f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-6dad5e21-292e-430f-9177-f70fea6ce0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-2f21a528-1b79-44ff-8ed1-22b1af72b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-4e39c33d-5b39-4f07-b7fd-e273d37860cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880149098-172.17.0.7-1599344761336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-20003e25-ca4b-4ecc-bdd3-907777c3a562,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-c89aa1e0-f0c9-4d59-9136-4c6d21cbd4be,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-641a22a3-9710-457c-96b8-f40f9e678253,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-33f7bddb-dd4b-4d6a-94fa-f1017abd5024,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-89995759-e657-4b9d-a92f-dca23f570f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-9172be3b-ca57-4705-ad79-d72a09b5b111,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-db32aaa5-33ea-4e40-9efb-1a8529c03238,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-cdd940d6-a8d6-49e0-9130-5f732493e788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880149098-172.17.0.7-1599344761336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-20003e25-ca4b-4ecc-bdd3-907777c3a562,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-c89aa1e0-f0c9-4d59-9136-4c6d21cbd4be,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-641a22a3-9710-457c-96b8-f40f9e678253,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-33f7bddb-dd4b-4d6a-94fa-f1017abd5024,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-89995759-e657-4b9d-a92f-dca23f570f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-9172be3b-ca57-4705-ad79-d72a09b5b111,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-db32aaa5-33ea-4e40-9efb-1a8529c03238,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-cdd940d6-a8d6-49e0-9130-5f732493e788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954771839-172.17.0.7-1599345510202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36743,DS-e006e43c-b692-4d5b-9906-327e6148be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-df964964-37ff-4ab2-915b-1ac81dd7ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-176665bb-c545-4069-a473-a5e2fa254586,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-98adee6d-c324-45a1-a5c1-90157a01e660,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-fdffc16c-f416-4cac-a4ad-fd166945370d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-270f780f-4ebb-4260-955d-d2c09f625db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-49ebf6c4-7937-4c84-8ba1-61af56a10806,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-4adfc1b4-1605-4544-a4c1-8e81d796ad04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954771839-172.17.0.7-1599345510202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36743,DS-e006e43c-b692-4d5b-9906-327e6148be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-df964964-37ff-4ab2-915b-1ac81dd7ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-176665bb-c545-4069-a473-a5e2fa254586,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-98adee6d-c324-45a1-a5c1-90157a01e660,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-fdffc16c-f416-4cac-a4ad-fd166945370d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-270f780f-4ebb-4260-955d-d2c09f625db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-49ebf6c4-7937-4c84-8ba1-61af56a10806,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-4adfc1b4-1605-4544-a4c1-8e81d796ad04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413502770-172.17.0.7-1599345630034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-b006485b-7411-475e-b90e-f0232fa92af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-43d60b48-c631-499d-bc60-3bee58e392e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-df367b55-c9e4-42cb-b22d-c68b400227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-4c73c760-a055-4499-b291-3ee9f17ab4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-5fd45c09-9c85-427e-9abf-82b8ebd793d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b74bbf65-85ea-449e-98d6-98614f8d7af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-805e55dc-27a3-4141-b796-9912ad75342b,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-01bce05d-1148-4be3-9a82-45731c65019f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413502770-172.17.0.7-1599345630034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-b006485b-7411-475e-b90e-f0232fa92af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-43d60b48-c631-499d-bc60-3bee58e392e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-df367b55-c9e4-42cb-b22d-c68b400227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-4c73c760-a055-4499-b291-3ee9f17ab4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-5fd45c09-9c85-427e-9abf-82b8ebd793d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b74bbf65-85ea-449e-98d6-98614f8d7af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-805e55dc-27a3-4141-b796-9912ad75342b,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-01bce05d-1148-4be3-9a82-45731c65019f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5361
