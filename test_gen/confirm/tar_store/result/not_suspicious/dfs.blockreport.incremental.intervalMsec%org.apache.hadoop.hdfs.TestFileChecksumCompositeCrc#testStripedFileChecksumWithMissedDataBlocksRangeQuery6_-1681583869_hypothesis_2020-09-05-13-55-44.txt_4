reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596383106-172.17.0.6-1599314285611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37966,DS-f4fe2a34-be3d-421d-990e-c2d3a6a5b0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-516703bf-b278-4eb7-8207-32bc3adb5833,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-fc47ab8e-4764-4a95-a45e-0d90dbcd1d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e1bdd41d-fcda-4ce6-b2b4-44e2d5aa615c,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-75bb422b-b8c2-4aad-9fce-4cd23fde789d,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-8a32e910-b08c-44d0-b7d3-e953210f3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-f767275e-e37d-4cb0-832e-6984be8b9bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-ed9ae401-e4d9-465a-b13b-23c1ef37ce29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596383106-172.17.0.6-1599314285611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37966,DS-f4fe2a34-be3d-421d-990e-c2d3a6a5b0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-516703bf-b278-4eb7-8207-32bc3adb5833,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-fc47ab8e-4764-4a95-a45e-0d90dbcd1d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e1bdd41d-fcda-4ce6-b2b4-44e2d5aa615c,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-75bb422b-b8c2-4aad-9fce-4cd23fde789d,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-8a32e910-b08c-44d0-b7d3-e953210f3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-f767275e-e37d-4cb0-832e-6984be8b9bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-ed9ae401-e4d9-465a-b13b-23c1ef37ce29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224045060-172.17.0.6-1599314515893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-bf46b7fd-a268-47cf-b0dc-4f54ae7b9527,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-869fcf6d-1549-4fa4-bf1d-27ff6e27fb66,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-1f4c0f56-bec6-4366-a9a6-3379c758ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-34442c7f-6d87-4d3d-87a5-dc7b54f9d495,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-89b9362c-fa76-487e-bfc8-4e2ea45b91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-009b5fbe-2b99-4c9a-871b-3cb45a0fa1de,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a7049b71-cd35-42f5-a851-6be666f2c533,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-951edb97-23a6-494a-ba7e-fb43a79cf0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224045060-172.17.0.6-1599314515893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-bf46b7fd-a268-47cf-b0dc-4f54ae7b9527,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-869fcf6d-1549-4fa4-bf1d-27ff6e27fb66,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-1f4c0f56-bec6-4366-a9a6-3379c758ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-34442c7f-6d87-4d3d-87a5-dc7b54f9d495,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-89b9362c-fa76-487e-bfc8-4e2ea45b91f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-009b5fbe-2b99-4c9a-871b-3cb45a0fa1de,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a7049b71-cd35-42f5-a851-6be666f2c533,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-951edb97-23a6-494a-ba7e-fb43a79cf0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511920950-172.17.0.6-1599314555902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-dbebf5c7-3651-4cd8-bdd8-5db1e2994c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-80b86c61-054d-4868-948e-dfa4d17e4fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ca975f2a-8aae-4632-94f8-5352947ced66,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-006d81a8-2c3b-4da6-af75-c545581aafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-a97e2f8c-8d9b-4a0c-ac1e-d73fbbdcceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-7b93e2b4-4730-4ffa-9ac3-b73bef82b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-fa268a10-f7a3-4f70-a27c-e02fdaaf2195,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c17ab3d3-6671-4e9e-9ff9-985044301f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511920950-172.17.0.6-1599314555902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-dbebf5c7-3651-4cd8-bdd8-5db1e2994c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-80b86c61-054d-4868-948e-dfa4d17e4fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-ca975f2a-8aae-4632-94f8-5352947ced66,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-006d81a8-2c3b-4da6-af75-c545581aafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-a97e2f8c-8d9b-4a0c-ac1e-d73fbbdcceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-7b93e2b4-4730-4ffa-9ac3-b73bef82b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-fa268a10-f7a3-4f70-a27c-e02fdaaf2195,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c17ab3d3-6671-4e9e-9ff9-985044301f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281987953-172.17.0.6-1599314647226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-2672c189-f1f5-44c7-a8cb-d051bd1970e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-aa3304f4-05ed-4d9f-9d64-5cd2ea56fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-df1f9624-dc22-4682-9689-b22c1e86e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-b005edd8-32d4-4173-942c-17c1792ee940,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-2e18c631-b4e7-4f20-a92a-624a64d0d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-ef14856f-5da9-45ce-9008-fae34f822927,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-50ba5365-637e-4cf7-9bf6-c73748daf6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-13fdcac9-a53c-4e7e-9453-a80bb36a6c4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281987953-172.17.0.6-1599314647226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-2672c189-f1f5-44c7-a8cb-d051bd1970e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-aa3304f4-05ed-4d9f-9d64-5cd2ea56fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-df1f9624-dc22-4682-9689-b22c1e86e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-b005edd8-32d4-4173-942c-17c1792ee940,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-2e18c631-b4e7-4f20-a92a-624a64d0d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-ef14856f-5da9-45ce-9008-fae34f822927,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-50ba5365-637e-4cf7-9bf6-c73748daf6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-13fdcac9-a53c-4e7e-9453-a80bb36a6c4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062091670-172.17.0.6-1599314876358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-3ede1eeb-eee5-4bb4-84a4-8ed7d28f5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-1d9d7493-c124-470a-b6d4-5cb1307ace00,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-e461642c-5aa1-447d-b953-406ef5b99e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-76146a13-c96d-4075-8438-141744974c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-96c1c1eb-6faf-435a-bb89-aed64a37aba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-1fd83dab-1e6d-46e4-84d7-247d040505b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-7a501004-b4aa-4cc4-9d63-5817fb9c86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-99204ab7-4871-4c42-860d-1ac7852c705e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062091670-172.17.0.6-1599314876358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-3ede1eeb-eee5-4bb4-84a4-8ed7d28f5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-1d9d7493-c124-470a-b6d4-5cb1307ace00,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-e461642c-5aa1-447d-b953-406ef5b99e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-76146a13-c96d-4075-8438-141744974c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-96c1c1eb-6faf-435a-bb89-aed64a37aba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-1fd83dab-1e6d-46e4-84d7-247d040505b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-7a501004-b4aa-4cc4-9d63-5817fb9c86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-99204ab7-4871-4c42-860d-1ac7852c705e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567310424-172.17.0.6-1599315240157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-de6faa8c-1c5a-44df-945c-4f8cdd669cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-2b646d76-3888-431c-927d-7b6c0682687e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-02e0a699-2a8e-4f24-ab72-281610ceb7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-c9b2cd45-01d7-440a-8fb1-30cfa7e1cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-98517a0c-6579-4953-a8a8-03cbb895deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-e1b15608-f5ec-4fc4-8565-05c0e39587af,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-692da38d-3a51-415b-bcda-750ee8b62330,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-68a6e9e3-f46d-4569-8b79-1dd485810582,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567310424-172.17.0.6-1599315240157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-de6faa8c-1c5a-44df-945c-4f8cdd669cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-2b646d76-3888-431c-927d-7b6c0682687e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-02e0a699-2a8e-4f24-ab72-281610ceb7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-c9b2cd45-01d7-440a-8fb1-30cfa7e1cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-98517a0c-6579-4953-a8a8-03cbb895deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-e1b15608-f5ec-4fc4-8565-05c0e39587af,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-692da38d-3a51-415b-bcda-750ee8b62330,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-68a6e9e3-f46d-4569-8b79-1dd485810582,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529365488-172.17.0.6-1599315281200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-acc4aa86-fe11-4bcc-acd5-0b208cb62c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-5db18a40-5d6d-45d9-a771-a55791fc274e,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-85c268b8-4657-49eb-b5d2-7886922dafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-02be1fe3-03af-4fb6-9540-c019a2ff61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8121ddaa-a39a-42f9-b75d-3210486bf7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-287d9c9f-4a92-4ece-89cc-cd9ecff83393,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-05168e3a-24e1-4357-b440-824ce3e47f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-22238ce0-5d65-41b2-88ef-698deb059369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529365488-172.17.0.6-1599315281200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-acc4aa86-fe11-4bcc-acd5-0b208cb62c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-5db18a40-5d6d-45d9-a771-a55791fc274e,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-85c268b8-4657-49eb-b5d2-7886922dafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-02be1fe3-03af-4fb6-9540-c019a2ff61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8121ddaa-a39a-42f9-b75d-3210486bf7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-287d9c9f-4a92-4ece-89cc-cd9ecff83393,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-05168e3a-24e1-4357-b440-824ce3e47f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-22238ce0-5d65-41b2-88ef-698deb059369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631583605-172.17.0.6-1599315465782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-f791b351-227e-4f50-a15c-5c606d900546,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-7e7a01d2-a85b-4b87-bf36-e1ce66dea925,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-0eac9970-2c35-49c4-8e18-4e31c09fa521,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-cc2213c3-8f4d-47aa-b7f0-104e71a661ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-8cf173dd-c3d7-47e0-b9c4-843e31e7d705,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-e26d43cb-0983-4a94-a9d6-5fc1d1a8d175,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-341ee2f4-285a-4161-95c9-e038e86b4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e390cfd-c689-46b5-9523-b58b17a8f5d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631583605-172.17.0.6-1599315465782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-f791b351-227e-4f50-a15c-5c606d900546,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-7e7a01d2-a85b-4b87-bf36-e1ce66dea925,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-0eac9970-2c35-49c4-8e18-4e31c09fa521,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-cc2213c3-8f4d-47aa-b7f0-104e71a661ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-8cf173dd-c3d7-47e0-b9c4-843e31e7d705,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-e26d43cb-0983-4a94-a9d6-5fc1d1a8d175,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-341ee2f4-285a-4161-95c9-e038e86b4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e390cfd-c689-46b5-9523-b58b17a8f5d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245601729-172.17.0.6-1599315900038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45758,DS-a122729d-60b4-4830-b5b9-14878c9fc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-375acae9-553c-4355-aef4-78e9c893366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5fccae41-d3e3-4625-bc3b-b8339e9837bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-1d9802e4-b23d-4c6f-a5a4-5bf3db06ea54,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-600b0275-e581-453f-b876-59c050fdd70d,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-abca6b3c-c116-4122-9528-9f3d35cb1642,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-ec476461-3fe4-4adf-89ca-22b54def17aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-87f12755-f2d9-4640-8574-78c56b5514e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245601729-172.17.0.6-1599315900038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45758,DS-a122729d-60b4-4830-b5b9-14878c9fc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-375acae9-553c-4355-aef4-78e9c893366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5fccae41-d3e3-4625-bc3b-b8339e9837bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-1d9802e4-b23d-4c6f-a5a4-5bf3db06ea54,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-600b0275-e581-453f-b876-59c050fdd70d,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-abca6b3c-c116-4122-9528-9f3d35cb1642,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-ec476461-3fe4-4adf-89ca-22b54def17aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-87f12755-f2d9-4640-8574-78c56b5514e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740726848-172.17.0.6-1599316078815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-9d580db7-22cc-44c9-b578-45ac03b48a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-f413c325-9f7e-4098-bfcb-a635782e0dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-b8720603-bdbb-43fe-8334-c7b0b9c95d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-acb21377-4882-40b0-909f-312c06f1c927,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e452976e-6bfe-437e-8139-26d80df41a76,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-c7aa60b0-ecb3-4a2d-95a0-22b6970696ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-924614d9-03b5-4522-8f5c-fa17fe16d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-aae51edb-b177-4548-a994-cdf0eea5f3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740726848-172.17.0.6-1599316078815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-9d580db7-22cc-44c9-b578-45ac03b48a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-f413c325-9f7e-4098-bfcb-a635782e0dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-b8720603-bdbb-43fe-8334-c7b0b9c95d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-acb21377-4882-40b0-909f-312c06f1c927,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e452976e-6bfe-437e-8139-26d80df41a76,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-c7aa60b0-ecb3-4a2d-95a0-22b6970696ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-924614d9-03b5-4522-8f5c-fa17fe16d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-aae51edb-b177-4548-a994-cdf0eea5f3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154527009-172.17.0.6-1599316132207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-1de10b25-2b33-4ab1-ba51-4b49184f5550,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d51d841d-aa4b-4ed0-9746-9ef2fb9e630d,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-64a9a508-a039-45d8-b6a7-2625bf409f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-d12a3131-3676-4cba-8ddd-52b3fbcb3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-c3864dac-30ac-4fdd-953b-641a5752516b,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-55ee9546-9e2d-487e-93e1-662c793556ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-81b1e7de-1df3-49d9-b156-0ccf9a7beb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-0b290dc2-59bf-4902-a241-b792a5a530a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154527009-172.17.0.6-1599316132207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-1de10b25-2b33-4ab1-ba51-4b49184f5550,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d51d841d-aa4b-4ed0-9746-9ef2fb9e630d,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-64a9a508-a039-45d8-b6a7-2625bf409f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-d12a3131-3676-4cba-8ddd-52b3fbcb3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-c3864dac-30ac-4fdd-953b-641a5752516b,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-55ee9546-9e2d-487e-93e1-662c793556ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-81b1e7de-1df3-49d9-b156-0ccf9a7beb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-0b290dc2-59bf-4902-a241-b792a5a530a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935185355-172.17.0.6-1599316211270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39714,DS-f1ac4b18-cd9b-4aaa-a3c6-a34102db24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-e50cfdbc-f589-483c-ba3c-486337554e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0985e67b-180c-4406-9b3a-3277dc6875f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-7debef44-5ebe-472b-b96d-64943728a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-91d71fb8-7fc5-41d5-b4a8-b63cbc28e82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-f334d5a5-b3d7-4cee-a9e9-33182d2c1a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-4bf8908d-94fa-4ba3-9c30-05dae3b7380d,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-bdef2652-09af-46c8-a6cd-c01f01776729,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935185355-172.17.0.6-1599316211270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39714,DS-f1ac4b18-cd9b-4aaa-a3c6-a34102db24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-e50cfdbc-f589-483c-ba3c-486337554e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0985e67b-180c-4406-9b3a-3277dc6875f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-7debef44-5ebe-472b-b96d-64943728a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-91d71fb8-7fc5-41d5-b4a8-b63cbc28e82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-f334d5a5-b3d7-4cee-a9e9-33182d2c1a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-4bf8908d-94fa-4ba3-9c30-05dae3b7380d,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-bdef2652-09af-46c8-a6cd-c01f01776729,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932440328-172.17.0.6-1599316307178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-1a8062b3-2a20-4bfd-be52-4428e7bae1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-44b0cce2-4097-40d7-8ba3-0c158ddec78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-bee51e62-bd5f-4743-a655-11fa161a7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-8494de9a-3765-4f1b-ba47-c0b5c859d927,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-1cb4ccd4-e670-4839-91e7-4822e5769e52,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-276d4746-b07e-48f4-a9ce-4ebf9c365dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-2882d529-6a90-4230-a8d5-17694c2d4d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-02d83871-f35d-4d33-b03b-f9a0e93e2c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932440328-172.17.0.6-1599316307178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-1a8062b3-2a20-4bfd-be52-4428e7bae1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-44b0cce2-4097-40d7-8ba3-0c158ddec78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-bee51e62-bd5f-4743-a655-11fa161a7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-8494de9a-3765-4f1b-ba47-c0b5c859d927,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-1cb4ccd4-e670-4839-91e7-4822e5769e52,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-276d4746-b07e-48f4-a9ce-4ebf9c365dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-2882d529-6a90-4230-a8d5-17694c2d4d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-02d83871-f35d-4d33-b03b-f9a0e93e2c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99453639-172.17.0.6-1599316401825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-2b319668-dd51-490f-9d16-d36e1ad20fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-83c78991-355d-456d-af7d-8d973e5600e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-a51573c4-791f-4838-8b1d-2d9f419b97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-0b9e23e6-2297-4f32-9ba1-4564f8e0c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-47196b12-04a1-4a19-ad76-8aec47844002,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-5bc1522e-f978-4c8e-a922-614a23bc3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a8a5a906-47a7-4748-bf56-868b3691e316,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-be47cfa5-3309-4864-8f43-06b2592bde9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99453639-172.17.0.6-1599316401825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-2b319668-dd51-490f-9d16-d36e1ad20fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-83c78991-355d-456d-af7d-8d973e5600e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-a51573c4-791f-4838-8b1d-2d9f419b97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-0b9e23e6-2297-4f32-9ba1-4564f8e0c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-47196b12-04a1-4a19-ad76-8aec47844002,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-5bc1522e-f978-4c8e-a922-614a23bc3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a8a5a906-47a7-4748-bf56-868b3691e316,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-be47cfa5-3309-4864-8f43-06b2592bde9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181703908-172.17.0.6-1599316440316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-ab99ef6b-354a-4daa-be45-bb270764303c,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-07db901c-4f2a-45ad-9eed-731161904051,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-a09f7b3e-7d3c-4f57-82e5-564e9e3561c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-5f1d67d8-ae32-4b36-bfb5-1c22ef9d769f,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-26858e4c-9124-475d-a682-8f558be482b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-32eda06c-25e2-455b-9ce5-41d71dc8477a,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9098f8d1-91be-45b6-9fb7-5b0191367a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-1c526c54-0c9e-414e-92b0-700542964b9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181703908-172.17.0.6-1599316440316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-ab99ef6b-354a-4daa-be45-bb270764303c,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-07db901c-4f2a-45ad-9eed-731161904051,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-a09f7b3e-7d3c-4f57-82e5-564e9e3561c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-5f1d67d8-ae32-4b36-bfb5-1c22ef9d769f,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-26858e4c-9124-475d-a682-8f558be482b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-32eda06c-25e2-455b-9ce5-41d71dc8477a,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9098f8d1-91be-45b6-9fb7-5b0191367a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-1c526c54-0c9e-414e-92b0-700542964b9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009796522-172.17.0.6-1599317441144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-b0ea592d-e164-4659-be49-9130efb53773,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ec6098d3-1bdb-4683-bd6c-56c69d05310f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-537ab97a-605e-4d3c-bea9-fa51547c432c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-eeab6744-cb9d-4ba2-8fd5-9d974e617db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-117c17ec-5457-46eb-863f-0e3a00e3b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1ed24e7a-dece-4960-a6b1-990ab166089b,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a5af5fab-7471-4e64-8e21-5e3b8a60b435,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-c22aa513-8037-4f98-bcd0-1a25a29f625c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009796522-172.17.0.6-1599317441144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-b0ea592d-e164-4659-be49-9130efb53773,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ec6098d3-1bdb-4683-bd6c-56c69d05310f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-537ab97a-605e-4d3c-bea9-fa51547c432c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-eeab6744-cb9d-4ba2-8fd5-9d974e617db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-117c17ec-5457-46eb-863f-0e3a00e3b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1ed24e7a-dece-4960-a6b1-990ab166089b,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-a5af5fab-7471-4e64-8e21-5e3b8a60b435,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-c22aa513-8037-4f98-bcd0-1a25a29f625c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843229640-172.17.0.6-1599317521048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-960f240c-35dd-4a5c-99da-698b8534f346,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-586cb083-056e-48c9-b1bf-09b2c9082e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-88766fdc-f653-4d28-b9e9-93e674f1d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-47182c8c-b33b-4be8-8b46-03a8ddfbaea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f85e8ac3-9ade-4a50-b8e2-789952e4e8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-b2e0fcdb-0ccf-4de5-849c-a80b832f63a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-06482926-d166-4f96-9a5b-877728d06caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0b9e702e-1d44-4c07-8838-5fb86db48c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843229640-172.17.0.6-1599317521048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-960f240c-35dd-4a5c-99da-698b8534f346,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-586cb083-056e-48c9-b1bf-09b2c9082e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-88766fdc-f653-4d28-b9e9-93e674f1d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-47182c8c-b33b-4be8-8b46-03a8ddfbaea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f85e8ac3-9ade-4a50-b8e2-789952e4e8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-b2e0fcdb-0ccf-4de5-849c-a80b832f63a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-06482926-d166-4f96-9a5b-877728d06caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0b9e702e-1d44-4c07-8838-5fb86db48c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198321039-172.17.0.6-1599317615082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44657,DS-8ef8ae10-2252-4274-acd8-97ef7beec50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-b440f567-cc99-4ecd-9b10-82d09fc0639f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-530fbb8a-aa36-4ec3-9c0e-bddbe4985431,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-e0faa913-a606-44a6-b518-962e0fffbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-41335db2-78e0-4034-8272-61e55f40b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-228e61ec-8ddc-4a2f-9b52-3bbbb96165ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-ae5c2264-3e04-4ada-945d-ce965ca84092,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-1898e94b-ed52-4a9b-bfd8-cf641726b6c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198321039-172.17.0.6-1599317615082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44657,DS-8ef8ae10-2252-4274-acd8-97ef7beec50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-b440f567-cc99-4ecd-9b10-82d09fc0639f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-530fbb8a-aa36-4ec3-9c0e-bddbe4985431,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-e0faa913-a606-44a6-b518-962e0fffbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-41335db2-78e0-4034-8272-61e55f40b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-228e61ec-8ddc-4a2f-9b52-3bbbb96165ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-ae5c2264-3e04-4ada-945d-ce965ca84092,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-1898e94b-ed52-4a9b-bfd8-cf641726b6c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930862307-172.17.0.6-1599317943165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-7e136abc-48b0-46d9-be9a-4dc070ae629b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-09d0c4c3-47f9-4648-8aad-c7582622817f,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-d4ca743d-b684-4e9a-9220-1cd38c5c277c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-c2b9e32e-c205-4005-bab2-b19566009482,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-beba1564-e9bd-490c-a9ab-0b2797070eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7ec207e8-2a85-4bb1-bdd7-73bf5f8ca22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-28991734-3470-4558-825d-4f49c9b6d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f8c96053-5027-459d-8721-6ae3cf7d1f84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930862307-172.17.0.6-1599317943165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-7e136abc-48b0-46d9-be9a-4dc070ae629b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-09d0c4c3-47f9-4648-8aad-c7582622817f,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-d4ca743d-b684-4e9a-9220-1cd38c5c277c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-c2b9e32e-c205-4005-bab2-b19566009482,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-beba1564-e9bd-490c-a9ab-0b2797070eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-7ec207e8-2a85-4bb1-bdd7-73bf5f8ca22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-28991734-3470-4558-825d-4f49c9b6d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f8c96053-5027-459d-8721-6ae3cf7d1f84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587090795-172.17.0.6-1599318082373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-03fea4b5-1919-4f26-8252-3b054b85f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-3b5bceda-e174-45e0-8b01-7b4f1453d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-2c23184d-c845-4292-9ee4-138dad2a241b,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-3389b25d-7a12-426b-84a3-c6636219c993,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-81d767b1-e3dc-4256-b9dd-538ee2d1e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-dafee38c-6eac-4083-ada9-9253594fa017,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-44f4de80-78d0-4aaa-9738-97d03595f068,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-5995a63d-8b01-44ab-b0d4-27c98c78043b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587090795-172.17.0.6-1599318082373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-03fea4b5-1919-4f26-8252-3b054b85f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-3b5bceda-e174-45e0-8b01-7b4f1453d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-2c23184d-c845-4292-9ee4-138dad2a241b,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-3389b25d-7a12-426b-84a3-c6636219c993,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-81d767b1-e3dc-4256-b9dd-538ee2d1e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-dafee38c-6eac-4083-ada9-9253594fa017,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-44f4de80-78d0-4aaa-9738-97d03595f068,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-5995a63d-8b01-44ab-b0d4-27c98c78043b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908317754-172.17.0.6-1599318737554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-7fd76bcb-5678-42c5-9416-8e453126971b,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-aa287d80-14ef-4d59-9c7e-65fed9b0ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d637bfe0-78f2-40dd-a924-2bd59ede1925,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-6ded2099-9985-4fbf-8a8f-0039365600e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-2678a45a-b3a4-43a5-b3a7-c2f01eadc7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-93275e42-04dc-4278-94d5-180e625de202,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-68606ab9-52be-495e-a06b-03a022da2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-93cd6217-0b17-41a0-a206-e4677719fa7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908317754-172.17.0.6-1599318737554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-7fd76bcb-5678-42c5-9416-8e453126971b,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-aa287d80-14ef-4d59-9c7e-65fed9b0ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d637bfe0-78f2-40dd-a924-2bd59ede1925,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-6ded2099-9985-4fbf-8a8f-0039365600e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-2678a45a-b3a4-43a5-b3a7-c2f01eadc7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-93275e42-04dc-4278-94d5-180e625de202,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-68606ab9-52be-495e-a06b-03a022da2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-93cd6217-0b17-41a0-a206-e4677719fa7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637253215-172.17.0.6-1599318917364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-bec55ef8-dae2-41b6-a383-d94ca504cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-551008c2-4eb4-4d6a-848f-7a6a62c7220c,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-00a76c4e-0148-45cb-aba6-76af4c774289,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5691c7f2-32c5-477f-be1e-ae61532dca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8d4c44cc-89d5-40f3-84b1-707b039bc784,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-d995101f-fa32-4de9-8358-cc3df947e099,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9e5e30c9-26c9-4a55-898c-f1af155c5921,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-bbe9cd65-9f0b-4e68-b682-5d19f941805a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637253215-172.17.0.6-1599318917364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-bec55ef8-dae2-41b6-a383-d94ca504cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-551008c2-4eb4-4d6a-848f-7a6a62c7220c,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-00a76c4e-0148-45cb-aba6-76af4c774289,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5691c7f2-32c5-477f-be1e-ae61532dca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8d4c44cc-89d5-40f3-84b1-707b039bc784,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-d995101f-fa32-4de9-8358-cc3df947e099,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9e5e30c9-26c9-4a55-898c-f1af155c5921,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-bbe9cd65-9f0b-4e68-b682-5d19f941805a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550163901-172.17.0.6-1599318973331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-cfc0d194-3c15-4128-b82b-e81783d5b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-30babf4a-6383-4a5a-b39d-b9a9a2ad329c,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-5015905e-d16e-433b-8869-7d79ccaa8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-67bec499-4572-40b5-8e1d-6737d389f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-4b4db0a2-31a0-4fe7-be5b-8e10c45a2b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-1fdd8791-dd73-4c55-86d5-d0bdda62a146,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-208c6a1b-4281-416a-a825-c0da46a506af,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-d600a3ff-b656-422c-aabd-c820ae0cca7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550163901-172.17.0.6-1599318973331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-cfc0d194-3c15-4128-b82b-e81783d5b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-30babf4a-6383-4a5a-b39d-b9a9a2ad329c,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-5015905e-d16e-433b-8869-7d79ccaa8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-67bec499-4572-40b5-8e1d-6737d389f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-4b4db0a2-31a0-4fe7-be5b-8e10c45a2b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-1fdd8791-dd73-4c55-86d5-d0bdda62a146,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-208c6a1b-4281-416a-a825-c0da46a506af,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-d600a3ff-b656-422c-aabd-c820ae0cca7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364912027-172.17.0.6-1599319162588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-27e52078-3bf2-4b35-ac82-2d0def7aed07,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-2cc84b52-831d-4393-a75a-75d15e189672,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-eb6d808b-5e21-426f-a53f-fc9047579ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-b5810da6-2410-40f0-8a25-13a3a26d6705,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-9234644e-02f1-4c9d-b401-c8c178682cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-bd235ccf-93b5-41f6-8dd8-15b6816132b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-3a99f847-5326-427a-b1ec-df25eca793d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-34efd75c-6661-43e5-8184-a25f2a708f10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364912027-172.17.0.6-1599319162588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-27e52078-3bf2-4b35-ac82-2d0def7aed07,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-2cc84b52-831d-4393-a75a-75d15e189672,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-eb6d808b-5e21-426f-a53f-fc9047579ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-b5810da6-2410-40f0-8a25-13a3a26d6705,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-9234644e-02f1-4c9d-b401-c8c178682cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-bd235ccf-93b5-41f6-8dd8-15b6816132b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-3a99f847-5326-427a-b1ec-df25eca793d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-34efd75c-6661-43e5-8184-a25f2a708f10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955236456-172.17.0.6-1599319304196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-2fbe4f36-5744-4f2a-9320-2da492cb8c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-301da9d8-bf9c-4c94-9d67-65c8dca3ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-72fe2e8e-f755-4acf-a114-a1cb735defb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-49ef1d25-cc17-4205-9ff0-844fc13e131b,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-006e37d8-0137-4985-8c27-495c306a2571,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-c6fc7593-5793-4b5b-89a0-b4eb30100998,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-f15a5348-9b1a-4dfc-8ae2-22ffc1673fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-f8f4d7b9-0fd9-4f3e-aa18-7fa063eef41a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955236456-172.17.0.6-1599319304196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-2fbe4f36-5744-4f2a-9320-2da492cb8c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-301da9d8-bf9c-4c94-9d67-65c8dca3ef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-72fe2e8e-f755-4acf-a114-a1cb735defb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-49ef1d25-cc17-4205-9ff0-844fc13e131b,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-006e37d8-0137-4985-8c27-495c306a2571,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-c6fc7593-5793-4b5b-89a0-b4eb30100998,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-f15a5348-9b1a-4dfc-8ae2-22ffc1673fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-f8f4d7b9-0fd9-4f3e-aa18-7fa063eef41a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971904529-172.17.0.6-1599319441819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-c34d692f-31a0-4a0c-acfd-155107e135af,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-c6f5fcaf-83f4-4eb7-a549-e22cba5ec948,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-05c68f5a-e7ff-4eb8-b849-6a0133c585d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-6a3ed660-2a7d-4909-a401-fe39f14164a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-1109e8b8-98c7-4a5a-8d54-c78a8d3b440d,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-29405505-3e48-4e20-b494-ae7de210872c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a00d46f1-8bab-43a7-9f97-b0e83109fe37,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-419323a4-a865-4656-87e2-ea53eb75dbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971904529-172.17.0.6-1599319441819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-c34d692f-31a0-4a0c-acfd-155107e135af,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-c6f5fcaf-83f4-4eb7-a549-e22cba5ec948,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-05c68f5a-e7ff-4eb8-b849-6a0133c585d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-6a3ed660-2a7d-4909-a401-fe39f14164a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-1109e8b8-98c7-4a5a-8d54-c78a8d3b440d,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-29405505-3e48-4e20-b494-ae7de210872c,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a00d46f1-8bab-43a7-9f97-b0e83109fe37,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-419323a4-a865-4656-87e2-ea53eb75dbe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826971178-172.17.0.6-1599319574044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-1429f0eb-d5fc-4063-b1ef-284f33ffa792,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-6ec32f85-86ed-4d6e-ac6c-710bda77367b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-e78c936e-58fa-4cb1-84d9-30a1b579721f,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-7444dfb6-871d-4359-aef3-1d6e984fb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-ef2212ab-61af-4bc2-b4b1-173d4fbe29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-aaca4850-7748-421f-af87-c920b2812e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-4eb807f3-c370-474c-9a67-dca9a534260d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-85e386af-2a5d-48db-92f9-fd65dcfbdad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826971178-172.17.0.6-1599319574044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-1429f0eb-d5fc-4063-b1ef-284f33ffa792,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-6ec32f85-86ed-4d6e-ac6c-710bda77367b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-e78c936e-58fa-4cb1-84d9-30a1b579721f,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-7444dfb6-871d-4359-aef3-1d6e984fb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-ef2212ab-61af-4bc2-b4b1-173d4fbe29bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-aaca4850-7748-421f-af87-c920b2812e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-4eb807f3-c370-474c-9a67-dca9a534260d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-85e386af-2a5d-48db-92f9-fd65dcfbdad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108980426-172.17.0.6-1599319843863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-557f06ca-5a12-4410-a59b-e6e4444dcbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-b15018a6-673e-407d-878d-9879a7dac2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-33c9ea00-56d0-41dd-b1cd-371055f3c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-70563745-057b-4e7b-b2b9-4ab1c2129a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d55c2480-27c8-47e3-a51d-7139743c91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-69e7cb7e-e6cc-45df-84ec-ea983c1c3f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-84591b81-163d-49ca-bbaf-aa17a2e994b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-d3582683-eb2d-4fbf-a7ec-97db4611cfcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108980426-172.17.0.6-1599319843863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-557f06ca-5a12-4410-a59b-e6e4444dcbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-b15018a6-673e-407d-878d-9879a7dac2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-33c9ea00-56d0-41dd-b1cd-371055f3c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-70563745-057b-4e7b-b2b9-4ab1c2129a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-d55c2480-27c8-47e3-a51d-7139743c91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-69e7cb7e-e6cc-45df-84ec-ea983c1c3f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-84591b81-163d-49ca-bbaf-aa17a2e994b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-d3582683-eb2d-4fbf-a7ec-97db4611cfcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831176672-172.17.0.6-1599320188259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-6d5559ca-c327-4662-94ee-ed6f93b14980,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4d309152-ae7b-4ab4-ab43-d3d402dd63f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-4b38e2f9-7c0d-4835-ba6d-3e2cefbd7699,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-6e76e6b8-dc51-48c8-aa56-39c0e9b8bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-5af93676-4233-4488-8b8a-e77dc7007575,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-184ca5a1-c41d-4acc-94fa-a0c304101b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-f6072ddb-a3b9-427f-8a0b-c8f4b2a57ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-aea0cd5a-0d2d-4589-a6d6-2db5c11f9da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831176672-172.17.0.6-1599320188259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-6d5559ca-c327-4662-94ee-ed6f93b14980,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4d309152-ae7b-4ab4-ab43-d3d402dd63f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-4b38e2f9-7c0d-4835-ba6d-3e2cefbd7699,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-6e76e6b8-dc51-48c8-aa56-39c0e9b8bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-5af93676-4233-4488-8b8a-e77dc7007575,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-184ca5a1-c41d-4acc-94fa-a0c304101b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-f6072ddb-a3b9-427f-8a0b-c8f4b2a57ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-aea0cd5a-0d2d-4589-a6d6-2db5c11f9da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259528832-172.17.0.6-1599320306388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-0ade576b-7976-4a88-8220-fc188a3875f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-de1f2cb1-edb4-42e3-8b23-a579c61ff539,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-8f1f0c2f-1864-4f23-9235-6f174de216a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-30fa3b5e-0353-46aa-b43c-93ece221d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-a967f1bc-07c5-4dee-99b6-53997d814ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-6dfddfd0-7e57-484f-afeb-4f785b32a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-e776704b-a486-4709-b388-c45c919695db,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-90814740-e6a6-497b-90d1-d2a809be8d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259528832-172.17.0.6-1599320306388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-0ade576b-7976-4a88-8220-fc188a3875f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-de1f2cb1-edb4-42e3-8b23-a579c61ff539,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-8f1f0c2f-1864-4f23-9235-6f174de216a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-30fa3b5e-0353-46aa-b43c-93ece221d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-a967f1bc-07c5-4dee-99b6-53997d814ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-6dfddfd0-7e57-484f-afeb-4f785b32a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-e776704b-a486-4709-b388-c45c919695db,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-90814740-e6a6-497b-90d1-d2a809be8d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299534803-172.17.0.6-1599320343672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-f51f2b4f-5aa0-42e8-b757-37e4d166c509,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e70ea854-8ad3-4a75-8aec-a7c9133e3d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d544d593-b03e-4267-a208-863d46ab76b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-1f42675f-9e83-45ed-b0ae-5bd1a3883147,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-c8abd8de-d50b-4043-8b63-ea80629b9a52,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-1bc3ad40-65e5-440e-a453-2d8ae54e3c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-2a311788-40c1-4f57-aee9-881fb83a3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-67a14bec-f2f1-45c9-acb5-5f0d6637329f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299534803-172.17.0.6-1599320343672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-f51f2b4f-5aa0-42e8-b757-37e4d166c509,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e70ea854-8ad3-4a75-8aec-a7c9133e3d19,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d544d593-b03e-4267-a208-863d46ab76b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-1f42675f-9e83-45ed-b0ae-5bd1a3883147,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-c8abd8de-d50b-4043-8b63-ea80629b9a52,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-1bc3ad40-65e5-440e-a453-2d8ae54e3c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-2a311788-40c1-4f57-aee9-881fb83a3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-67a14bec-f2f1-45c9-acb5-5f0d6637329f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953015273-172.17.0.6-1599320500786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-c08532b1-78f1-46a9-8b57-f02b253d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-32af7c0a-3793-438d-ad84-2d09b108d079,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ea3b41cc-d802-4613-ac0b-152f3aa3285c,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ebb66260-0c7c-44fa-99f1-897b34708d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b06a7ce6-8d27-4ccb-b8ea-07d6329abc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-7da2ae61-2b47-4319-ae17-892d418a6201,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-b5a553b1-5090-4b52-9e1e-508d19da535a,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-f00990a9-74bc-4557-b20c-a7dbaa6a1f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953015273-172.17.0.6-1599320500786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-c08532b1-78f1-46a9-8b57-f02b253d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-32af7c0a-3793-438d-ad84-2d09b108d079,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ea3b41cc-d802-4613-ac0b-152f3aa3285c,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ebb66260-0c7c-44fa-99f1-897b34708d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b06a7ce6-8d27-4ccb-b8ea-07d6329abc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-7da2ae61-2b47-4319-ae17-892d418a6201,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-b5a553b1-5090-4b52-9e1e-508d19da535a,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-f00990a9-74bc-4557-b20c-a7dbaa6a1f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378086297-172.17.0.6-1599320548095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-dce5bb36-1b50-4372-bd9d-ba374d3cdd23,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-9bc8b165-4360-46e7-b908-df5ec70a2139,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-6ad32539-7d13-4f9c-8942-6d977be2197d,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-25f980bf-5402-4b5a-bba5-f82bf915a673,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-68605264-834d-417f-bb92-193217a92bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-ab6eabe6-d077-43cd-b8af-bdb88f1bb2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-b9642dd5-8fb6-428e-b9ee-c2b782181084,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-fa48dc4b-3534-478f-b3ba-d0ee6e8a1799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378086297-172.17.0.6-1599320548095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-dce5bb36-1b50-4372-bd9d-ba374d3cdd23,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-9bc8b165-4360-46e7-b908-df5ec70a2139,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-6ad32539-7d13-4f9c-8942-6d977be2197d,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-25f980bf-5402-4b5a-bba5-f82bf915a673,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-68605264-834d-417f-bb92-193217a92bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-ab6eabe6-d077-43cd-b8af-bdb88f1bb2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-b9642dd5-8fb6-428e-b9ee-c2b782181084,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-fa48dc4b-3534-478f-b3ba-d0ee6e8a1799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460805792-172.17.0.6-1599320587002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-e60fa09f-ea78-4216-88a5-d5124abea52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-039f2a2b-2e0d-445d-ae75-e14410c747a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-24352bfc-a9d8-4800-89b2-cc5a2658b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-74d9226c-397d-4a85-9cb5-6e9cdac83520,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-6e7900ba-703d-4ae8-a2d1-e07fc354fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-0e271263-1b71-4b19-a67a-1e4f78c1561d,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-128ab355-61e9-45a6-b64e-92b62282ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-4e5f8b83-8dfc-4b19-8e7b-7253cf7ebdc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460805792-172.17.0.6-1599320587002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-e60fa09f-ea78-4216-88a5-d5124abea52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-039f2a2b-2e0d-445d-ae75-e14410c747a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-24352bfc-a9d8-4800-89b2-cc5a2658b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-74d9226c-397d-4a85-9cb5-6e9cdac83520,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-6e7900ba-703d-4ae8-a2d1-e07fc354fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-0e271263-1b71-4b19-a67a-1e4f78c1561d,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-128ab355-61e9-45a6-b64e-92b62282ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-4e5f8b83-8dfc-4b19-8e7b-7253cf7ebdc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6680
