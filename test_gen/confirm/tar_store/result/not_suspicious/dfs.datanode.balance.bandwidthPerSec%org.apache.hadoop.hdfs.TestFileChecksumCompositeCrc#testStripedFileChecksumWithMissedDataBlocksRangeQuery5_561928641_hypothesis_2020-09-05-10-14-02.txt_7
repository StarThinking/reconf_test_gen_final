reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132133160-172.17.0.3-1599301043041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-0af0167f-9a02-4cd7-a324-cc320c6e5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-d4cbcbe1-05a8-48b5-8706-5a9e99c9b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-1177dc18-e720-4a37-9eb1-dc2147ac25bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-05df07d8-ece4-4863-bec9-9f33c01e5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-9fe59d8f-4e02-4461-afd3-2ab5b12d6dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-05a300a2-d3c4-44ee-a2f9-e856c738982d,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-1a8c44f1-65d0-43d7-a5f6-19a2659f0860,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d63b71e6-3914-4d7c-98ad-cd4dc8826b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132133160-172.17.0.3-1599301043041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-0af0167f-9a02-4cd7-a324-cc320c6e5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-d4cbcbe1-05a8-48b5-8706-5a9e99c9b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-1177dc18-e720-4a37-9eb1-dc2147ac25bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-05df07d8-ece4-4863-bec9-9f33c01e5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-9fe59d8f-4e02-4461-afd3-2ab5b12d6dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-05a300a2-d3c4-44ee-a2f9-e856c738982d,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-1a8c44f1-65d0-43d7-a5f6-19a2659f0860,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d63b71e6-3914-4d7c-98ad-cd4dc8826b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556836896-172.17.0.3-1599301114589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-1e9eaf33-b68f-436a-a1d3-d4e48d117aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-9a428b06-335a-46c0-b35d-5bc89c336ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-cd8c504b-bd91-47f3-851e-bf84db32b0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-93a004fa-ff09-4562-9740-9c9dbaff09c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-b8cb35c1-1c7b-4330-9efc-fe82a9f86b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-edcfeb7f-4f85-4bdd-97d6-3beee9606169,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-87595191-10e0-47a9-837d-8686e3605deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-217b30cc-f95d-4678-93f5-3f37d409da39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556836896-172.17.0.3-1599301114589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-1e9eaf33-b68f-436a-a1d3-d4e48d117aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-9a428b06-335a-46c0-b35d-5bc89c336ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-cd8c504b-bd91-47f3-851e-bf84db32b0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-93a004fa-ff09-4562-9740-9c9dbaff09c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-b8cb35c1-1c7b-4330-9efc-fe82a9f86b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-edcfeb7f-4f85-4bdd-97d6-3beee9606169,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-87595191-10e0-47a9-837d-8686e3605deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-217b30cc-f95d-4678-93f5-3f37d409da39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551687627-172.17.0.3-1599301321703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-81a1abe5-e39b-461a-a377-9f7b1cb8c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-42c3296e-7b2b-4bbd-8205-d50678399e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-747a318f-d494-4ebe-b389-28c5d271ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9d4bf223-378c-46be-bffa-d93bfded81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-b9df8b5f-881e-4ec5-b423-2334a9f67dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-63917db3-31ec-48e1-9779-a5504b358d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-c68c2b21-5244-45a6-bdfa-c9fd98261eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-b819e8db-0201-406a-b8d9-a1a9783f5b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551687627-172.17.0.3-1599301321703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-81a1abe5-e39b-461a-a377-9f7b1cb8c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-42c3296e-7b2b-4bbd-8205-d50678399e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-747a318f-d494-4ebe-b389-28c5d271ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9d4bf223-378c-46be-bffa-d93bfded81f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-b9df8b5f-881e-4ec5-b423-2334a9f67dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-63917db3-31ec-48e1-9779-a5504b358d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-c68c2b21-5244-45a6-bdfa-c9fd98261eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-b819e8db-0201-406a-b8d9-a1a9783f5b54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322886652-172.17.0.3-1599301542266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-77d4e1c6-c601-4621-a845-b5a4b3b014b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-21c947ff-6fd7-4c76-b968-1adc3995bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-165461be-1db5-4c54-adfc-483140901eae,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-069fd7fb-a87a-4c3d-8548-ea7983c9991f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-8195a915-8a77-4f3d-b9ea-0abad68ff05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-10ee17a8-5513-45ec-9e45-ba9a1856c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4845423a-aa13-4e7a-aa19-958bffb7b568,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-26ab539c-10ef-4ac4-bbf7-9aeb50969810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322886652-172.17.0.3-1599301542266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-77d4e1c6-c601-4621-a845-b5a4b3b014b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-21c947ff-6fd7-4c76-b968-1adc3995bc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-165461be-1db5-4c54-adfc-483140901eae,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-069fd7fb-a87a-4c3d-8548-ea7983c9991f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-8195a915-8a77-4f3d-b9ea-0abad68ff05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-10ee17a8-5513-45ec-9e45-ba9a1856c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4845423a-aa13-4e7a-aa19-958bffb7b568,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-26ab539c-10ef-4ac4-bbf7-9aeb50969810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089461987-172.17.0.3-1599301965329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-41bdc543-b1d0-4f1d-96d1-b5ee92a49af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-43557cd8-0cff-4ae4-971e-278a6afeb35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-aa6f572a-0b42-4d00-ac8b-2bf5e085a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-6507c20b-db22-4675-9472-ff1f108ae19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-5462fc7b-a0db-46aa-8429-05091c5dc988,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-6c26877b-bd41-4a77-bc3a-36d8a6c9a5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-2eca4237-ed2a-442b-89be-48002607dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-36613a19-b5c8-41f4-9d5a-04ae54a24cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089461987-172.17.0.3-1599301965329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-41bdc543-b1d0-4f1d-96d1-b5ee92a49af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-43557cd8-0cff-4ae4-971e-278a6afeb35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-aa6f572a-0b42-4d00-ac8b-2bf5e085a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-6507c20b-db22-4675-9472-ff1f108ae19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-5462fc7b-a0db-46aa-8429-05091c5dc988,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-6c26877b-bd41-4a77-bc3a-36d8a6c9a5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-2eca4237-ed2a-442b-89be-48002607dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-36613a19-b5c8-41f4-9d5a-04ae54a24cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068452997-172.17.0.3-1599302003082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39187,DS-2bd94813-40d2-4a34-bf0d-dfaa2d31eac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5236f725-e826-4955-a40a-65b52ab44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3fc28eb0-e5fd-4ec2-9959-8295c13c988f,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-36530669-62eb-47b4-9bed-b427275172d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-b299d200-6dd1-49c8-8e4d-b0def59e0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-8c01b0b7-fb9d-4814-936d-3c8229d300f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f6229bac-2a5d-4417-b338-9900b1964120,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-e9cb8584-6735-4f47-9eaf-b904088214fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068452997-172.17.0.3-1599302003082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39187,DS-2bd94813-40d2-4a34-bf0d-dfaa2d31eac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5236f725-e826-4955-a40a-65b52ab44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3fc28eb0-e5fd-4ec2-9959-8295c13c988f,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-36530669-62eb-47b4-9bed-b427275172d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-b299d200-6dd1-49c8-8e4d-b0def59e0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-8c01b0b7-fb9d-4814-936d-3c8229d300f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f6229bac-2a5d-4417-b338-9900b1964120,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-e9cb8584-6735-4f47-9eaf-b904088214fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557737321-172.17.0.3-1599302087495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-f997ab76-f457-49f5-8fcb-0a7970c226fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-aa47a2c3-cef4-4803-9432-149c6d9a59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b891ba63-0954-4299-8692-47a1ac8c7933,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-406138d6-1760-4f1d-a028-9e45aaaf8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-b26ae1ad-aeab-40ca-9563-625dc43ab10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-d1b86382-07d0-44db-acaf-1c958e39af16,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-986713e1-3390-475f-a0b0-320ac02f1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-3978a130-97e8-479c-855f-8dc969265a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557737321-172.17.0.3-1599302087495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-f997ab76-f457-49f5-8fcb-0a7970c226fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-aa47a2c3-cef4-4803-9432-149c6d9a59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b891ba63-0954-4299-8692-47a1ac8c7933,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-406138d6-1760-4f1d-a028-9e45aaaf8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-b26ae1ad-aeab-40ca-9563-625dc43ab10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-d1b86382-07d0-44db-acaf-1c958e39af16,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-986713e1-3390-475f-a0b0-320ac02f1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-3978a130-97e8-479c-855f-8dc969265a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959022619-172.17.0.3-1599302390696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-4409d5f7-edfc-405e-ace1-5716366b3876,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-f1bfa5ef-411b-4ecf-b348-11982270f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-041afc51-8344-4b57-a30e-2da9ba8249e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-3435066d-0feb-4238-85d0-429b615a807d,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-c832542e-d096-43d3-ada6-c70fa6ca6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-534d92e6-cd87-4bd9-b459-f9308c93e451,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-984aa12f-40b5-47f0-8915-8ab466f4255e,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-5b61dfd9-938e-477b-a4cf-fb7a9f7d3996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959022619-172.17.0.3-1599302390696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-4409d5f7-edfc-405e-ace1-5716366b3876,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-f1bfa5ef-411b-4ecf-b348-11982270f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-041afc51-8344-4b57-a30e-2da9ba8249e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-3435066d-0feb-4238-85d0-429b615a807d,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-c832542e-d096-43d3-ada6-c70fa6ca6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-534d92e6-cd87-4bd9-b459-f9308c93e451,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-984aa12f-40b5-47f0-8915-8ab466f4255e,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-5b61dfd9-938e-477b-a4cf-fb7a9f7d3996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935257110-172.17.0.3-1599303184782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-443f9c3d-8213-4f03-9295-f72e8e87ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-3487ac2f-2c95-4a2f-9e71-40f7232d7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1306dcef-0b70-4e20-95a1-6c4e9eae7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-9558d032-4a45-46f4-88a0-a5e12e29d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-afcdceb3-2ad4-47c3-bbba-cc049c11624d,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-08373eb7-8c47-4905-b2aa-3fb41e620b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-7f329ec0-d8dc-44f8-b866-f08bcbe08101,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-5865fb3e-2c62-4c67-89f6-5cba9d8da311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935257110-172.17.0.3-1599303184782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-443f9c3d-8213-4f03-9295-f72e8e87ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-3487ac2f-2c95-4a2f-9e71-40f7232d7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1306dcef-0b70-4e20-95a1-6c4e9eae7f68,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-9558d032-4a45-46f4-88a0-a5e12e29d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-afcdceb3-2ad4-47c3-bbba-cc049c11624d,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-08373eb7-8c47-4905-b2aa-3fb41e620b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-7f329ec0-d8dc-44f8-b866-f08bcbe08101,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-5865fb3e-2c62-4c67-89f6-5cba9d8da311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106787489-172.17.0.3-1599303451335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-e07a7397-1456-4721-bb7c-549fca61c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b4325db6-7e60-46b5-b668-30d2422bee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a2aeb833-398c-49a0-8db9-9078e8e2315c,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-500c2406-fbb5-4c96-b6df-82e830998610,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-642cbbcc-66c9-41d1-99ff-43346c349ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-d637eee8-0a2b-472c-8290-6b97402a077c,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b3999e22-27c4-464e-88a9-98078b90f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-325adeb4-773f-4c7d-983d-43af9119b75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106787489-172.17.0.3-1599303451335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-e07a7397-1456-4721-bb7c-549fca61c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b4325db6-7e60-46b5-b668-30d2422bee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a2aeb833-398c-49a0-8db9-9078e8e2315c,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-500c2406-fbb5-4c96-b6df-82e830998610,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-642cbbcc-66c9-41d1-99ff-43346c349ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-d637eee8-0a2b-472c-8290-6b97402a077c,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b3999e22-27c4-464e-88a9-98078b90f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-325adeb4-773f-4c7d-983d-43af9119b75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965403016-172.17.0.3-1599304067241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-00feee1f-c293-4062-88a8-c9e78c92a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-766aaf97-7f06-4683-bfbd-3ea789617e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5c57d7a5-4b1f-4d33-9b58-f4c5444c5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-9704cfcc-684d-4403-8026-2a5d04ebee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ab5361b5-9fcc-4d4c-b2e2-8df7ff3af75e,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-70a110e1-a5ee-44c6-8a34-13733a193aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d2b095a7-edf2-4b33-bc90-891a8ad7e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-002a384f-fb10-4772-9918-5fa07db6a763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965403016-172.17.0.3-1599304067241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-00feee1f-c293-4062-88a8-c9e78c92a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-766aaf97-7f06-4683-bfbd-3ea789617e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5c57d7a5-4b1f-4d33-9b58-f4c5444c5a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-9704cfcc-684d-4403-8026-2a5d04ebee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ab5361b5-9fcc-4d4c-b2e2-8df7ff3af75e,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-70a110e1-a5ee-44c6-8a34-13733a193aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d2b095a7-edf2-4b33-bc90-891a8ad7e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-002a384f-fb10-4772-9918-5fa07db6a763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232679992-172.17.0.3-1599304177959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-b59e1e18-8472-499d-a6f7-9b6e29ef482d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1bdcca1b-1b8a-4e38-838d-4a81d73bea65,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b116a44c-41b4-4114-90b0-041b069bf0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-3a3fa138-1b5a-42b3-ae52-08986e2f6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-5dcaf0af-0d6c-4a70-b22b-198fd8f62278,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-db5da94d-f325-448f-8d7f-a64038cd2812,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-9fc598e5-3e66-4449-99d9-3070e430c314,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2cbce404-d71a-4911-9482-287544b7ca96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232679992-172.17.0.3-1599304177959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-b59e1e18-8472-499d-a6f7-9b6e29ef482d,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1bdcca1b-1b8a-4e38-838d-4a81d73bea65,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b116a44c-41b4-4114-90b0-041b069bf0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-3a3fa138-1b5a-42b3-ae52-08986e2f6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-5dcaf0af-0d6c-4a70-b22b-198fd8f62278,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-db5da94d-f325-448f-8d7f-a64038cd2812,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-9fc598e5-3e66-4449-99d9-3070e430c314,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2cbce404-d71a-4911-9482-287544b7ca96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606917960-172.17.0.3-1599304337491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-83464d5a-54b4-46f3-8ff6-31a1de90da91,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-a86167e8-17ee-46d0-b990-4feb1e4fb957,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f0846dd8-81c9-423b-bbbd-ac61acee0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-24bc4343-66c8-4144-be65-37daa065d4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-cc408ac0-960e-4387-8edb-f303f78e97e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-7689f9c7-b1f2-46e3-a76a-8c6640965f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-fcd1c5fc-3e0a-4065-a4dc-bc127998820b,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-d877d02b-2928-4edf-829b-7a169a543a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606917960-172.17.0.3-1599304337491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-83464d5a-54b4-46f3-8ff6-31a1de90da91,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-a86167e8-17ee-46d0-b990-4feb1e4fb957,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f0846dd8-81c9-423b-bbbd-ac61acee0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-24bc4343-66c8-4144-be65-37daa065d4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-cc408ac0-960e-4387-8edb-f303f78e97e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-7689f9c7-b1f2-46e3-a76a-8c6640965f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-fcd1c5fc-3e0a-4065-a4dc-bc127998820b,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-d877d02b-2928-4edf-829b-7a169a543a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721160928-172.17.0.3-1599304372303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39088,DS-6a35325f-c9d7-448e-8e70-2a17b0df5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-d30d3680-4d13-4029-a4a4-8061c8a7d538,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5048899d-0695-4033-87ab-b897ac8a8923,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-9ed21990-6e9c-45c1-b420-1c32190114e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-b82da9f3-a7ad-418a-b05d-445377203609,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-9586c0dc-1cf5-43bb-bf95-68ac1d3ac1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-28f2a514-ecb3-4ff9-81b3-f02e2781d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-e4c44582-c32c-446c-b73c-852b872a4cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721160928-172.17.0.3-1599304372303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39088,DS-6a35325f-c9d7-448e-8e70-2a17b0df5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-d30d3680-4d13-4029-a4a4-8061c8a7d538,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5048899d-0695-4033-87ab-b897ac8a8923,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-9ed21990-6e9c-45c1-b420-1c32190114e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-b82da9f3-a7ad-418a-b05d-445377203609,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-9586c0dc-1cf5-43bb-bf95-68ac1d3ac1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-28f2a514-ecb3-4ff9-81b3-f02e2781d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-e4c44582-c32c-446c-b73c-852b872a4cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216442198-172.17.0.3-1599304785302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-bf99c4db-d72f-493b-8a60-99c2746d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-f071434a-93f2-4a12-a52c-937031b78482,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-a14b9b08-e27c-44dd-9376-bc27faae421d,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-7512fd0c-c692-459b-9954-53e6d49b601a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-c4c5ffcd-3a7e-4740-ba5a-8693ef370704,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-46b1201b-124f-4b69-8838-af32cb17ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-57379511-406a-4abe-aa39-00653eb09c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-2d653e7f-ed3b-41b0-b748-a92cf01d62b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216442198-172.17.0.3-1599304785302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-bf99c4db-d72f-493b-8a60-99c2746d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-f071434a-93f2-4a12-a52c-937031b78482,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-a14b9b08-e27c-44dd-9376-bc27faae421d,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-7512fd0c-c692-459b-9954-53e6d49b601a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-c4c5ffcd-3a7e-4740-ba5a-8693ef370704,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-46b1201b-124f-4b69-8838-af32cb17ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-57379511-406a-4abe-aa39-00653eb09c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-2d653e7f-ed3b-41b0-b748-a92cf01d62b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223507567-172.17.0.3-1599304889548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-094a69a0-356f-4e1f-99dd-05b1c319cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-82b1f6fe-65c0-4993-ac06-2edc3805e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-4b08c9f7-2745-4f65-bf12-50cd2f5c4641,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-4a55ac13-17e9-4977-8777-0e51db941ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-7364a1f6-0caf-421b-86c0-d40a63307d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-d40026a2-b8ce-455d-8072-6cebd434f9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-aa45041f-fe12-4531-b17b-a8da804907a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-b93d15bb-efd0-4bf1-a847-a36a0d4fb916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223507567-172.17.0.3-1599304889548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-094a69a0-356f-4e1f-99dd-05b1c319cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-82b1f6fe-65c0-4993-ac06-2edc3805e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-4b08c9f7-2745-4f65-bf12-50cd2f5c4641,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-4a55ac13-17e9-4977-8777-0e51db941ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-7364a1f6-0caf-421b-86c0-d40a63307d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-d40026a2-b8ce-455d-8072-6cebd434f9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-aa45041f-fe12-4531-b17b-a8da804907a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-b93d15bb-efd0-4bf1-a847-a36a0d4fb916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041835063-172.17.0.3-1599305425337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-2f125083-9835-49fc-af16-70f6366bbfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-e443c57c-39d1-498f-a35d-e6e5b3b52322,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-2a35dcec-b078-49a1-87a4-2c822d3c6691,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-f08cc22d-1055-42db-bf64-f7bbc57cce77,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-4ca3edb4-0fc3-4f26-9562-b69572d77231,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-3062d0ec-7dc6-46a2-8ffb-c12397869749,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-6f411388-0808-4b88-9361-ec3450888b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-f0c9ffb4-04a2-49c0-a40c-a6f9a15cc2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041835063-172.17.0.3-1599305425337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-2f125083-9835-49fc-af16-70f6366bbfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-e443c57c-39d1-498f-a35d-e6e5b3b52322,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-2a35dcec-b078-49a1-87a4-2c822d3c6691,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-f08cc22d-1055-42db-bf64-f7bbc57cce77,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-4ca3edb4-0fc3-4f26-9562-b69572d77231,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-3062d0ec-7dc6-46a2-8ffb-c12397869749,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-6f411388-0808-4b88-9361-ec3450888b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-f0c9ffb4-04a2-49c0-a40c-a6f9a15cc2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950460301-172.17.0.3-1599305770991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40870,DS-1eeda8f2-a395-412f-b971-e971afc8f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-aab60f36-803e-4b1f-afba-9162b5bad000,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-43c91ddd-6a8d-4023-9c3a-a254bbe7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-6c502a2d-98bb-427f-9b18-f5787409f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-fe542c70-bd47-4034-b7dd-e82e30cd8113,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-48e1fa85-b9a6-42b2-bc0a-9d53e61ca448,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-af9bdaf9-1b94-43c6-b4cb-9821215d6dde,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b2127f05-9c96-49dc-8c18-bf637f46ced3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950460301-172.17.0.3-1599305770991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40870,DS-1eeda8f2-a395-412f-b971-e971afc8f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-aab60f36-803e-4b1f-afba-9162b5bad000,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-43c91ddd-6a8d-4023-9c3a-a254bbe7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-6c502a2d-98bb-427f-9b18-f5787409f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-fe542c70-bd47-4034-b7dd-e82e30cd8113,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-48e1fa85-b9a6-42b2-bc0a-9d53e61ca448,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-af9bdaf9-1b94-43c6-b4cb-9821215d6dde,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b2127f05-9c96-49dc-8c18-bf637f46ced3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272955445-172.17.0.3-1599305936613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-3f9c8c3f-de8c-4767-a838-e8575e9c34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-1e64c9a8-42c1-42c4-976d-0e4bbe95b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-b9df0ffd-eab1-4a9c-8aff-6687a8ebf0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-b9c1d170-3cec-466a-9b4b-9ee486a8d320,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-f842db6f-08a5-426b-ba75-8d39a8943dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-908f897e-399d-448e-972d-cfc6788a5871,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9d180551-581a-4e8e-a3b0-63daf61fbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3ec21d88-b0f8-4259-b2c4-5449c77a6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272955445-172.17.0.3-1599305936613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-3f9c8c3f-de8c-4767-a838-e8575e9c34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-1e64c9a8-42c1-42c4-976d-0e4bbe95b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-b9df0ffd-eab1-4a9c-8aff-6687a8ebf0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-b9c1d170-3cec-466a-9b4b-9ee486a8d320,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-f842db6f-08a5-426b-ba75-8d39a8943dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-908f897e-399d-448e-972d-cfc6788a5871,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9d180551-581a-4e8e-a3b0-63daf61fbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-3ec21d88-b0f8-4259-b2c4-5449c77a6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056071958-172.17.0.3-1599305976817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45650,DS-408cb4a1-3ff1-4091-8a13-40df133657fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-eda196ad-0416-4cb2-aa9c-8674786fb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-8731d42a-2931-4e82-8ffb-febad81553d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-146ca9ea-1474-409f-b836-9691f73e386b,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-ae58d871-288a-4d0f-8ee6-345a4485db21,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-0278b3d4-7e84-4d9c-a35c-3170abf936e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-4b6b09c9-cab7-4c92-8071-85f910b83c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-e4d30d83-8171-4dba-9383-cb95b01eee2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056071958-172.17.0.3-1599305976817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45650,DS-408cb4a1-3ff1-4091-8a13-40df133657fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-eda196ad-0416-4cb2-aa9c-8674786fb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-8731d42a-2931-4e82-8ffb-febad81553d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-146ca9ea-1474-409f-b836-9691f73e386b,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-ae58d871-288a-4d0f-8ee6-345a4485db21,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-0278b3d4-7e84-4d9c-a35c-3170abf936e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-4b6b09c9-cab7-4c92-8071-85f910b83c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-e4d30d83-8171-4dba-9383-cb95b01eee2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5337
