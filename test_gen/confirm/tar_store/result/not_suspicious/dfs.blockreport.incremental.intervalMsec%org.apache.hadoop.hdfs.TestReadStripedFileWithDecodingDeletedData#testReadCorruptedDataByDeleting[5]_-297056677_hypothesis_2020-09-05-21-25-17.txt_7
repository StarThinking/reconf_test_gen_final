reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1938951090-172.17.0.2-1599341137088:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-779d6b6c-6089-47d8-8287-f5cf3eabd601,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-c753ad9c-5407-4734-9bb6-615ff7f61b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-0f9d90a3-a65e-44f8-a045-d2c0b7c5db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-1d701d7e-6352-44c0-98f2-fe55c0a22860,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-97b7349e-896a-4d57-9dcb-d9a33f7fb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d3e10115-35ee-4df6-bc32-a3b922db76e1,DISK]]; indices=[0, 2, 3, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1938951090-172.17.0.2-1599341137088:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-779d6b6c-6089-47d8-8287-f5cf3eabd601,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-c753ad9c-5407-4734-9bb6-615ff7f61b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-0f9d90a3-a65e-44f8-a045-d2c0b7c5db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-1d701d7e-6352-44c0-98f2-fe55c0a22860,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-97b7349e-896a-4d57-9dcb-d9a33f7fb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d3e10115-35ee-4df6-bc32-a3b922db76e1,DISK]]; indices=[0, 2, 3, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 5 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=5); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1938951090-172.17.0.2-1599341137088:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-779d6b6c-6089-47d8-8287-f5cf3eabd601,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-c753ad9c-5407-4734-9bb6-615ff7f61b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-0f9d90a3-a65e-44f8-a045-d2c0b7c5db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-1d701d7e-6352-44c0-98f2-fe55c0a22860,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-97b7349e-896a-4d57-9dcb-d9a33f7fb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d3e10115-35ee-4df6-bc32-a3b922db76e1,DISK]]; indices=[0, 2, 3, 4, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1938951090-172.17.0.2-1599341137088:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-779d6b6c-6089-47d8-8287-f5cf3eabd601,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-c753ad9c-5407-4734-9bb6-615ff7f61b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-0f9d90a3-a65e-44f8-a045-d2c0b7c5db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-1d701d7e-6352-44c0-98f2-fe55c0a22860,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-97b7349e-896a-4d57-9dcb-d9a33f7fb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d3e10115-35ee-4df6-bc32-a3b922db76e1,DISK]]; indices=[0, 2, 3, 4, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-465967938-172.17.0.2-1599341484861:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-0b82599e-9166-4bad-8a2d-b5d2e777c257,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-de521a75-4ce2-47d2-b8e0-6ce43b163105,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-c7b4f68b-7635-4005-9973-c8ae22980341,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-91e6f54c-0a91-405c-8724-338f0935ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-04526386-4119-45df-ad5b-ee9799a447a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-104bcd62-2bf1-4f04-a678-ee78eb98b8b0,DISK]]; indices=[0, 2, 3, 4, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-465967938-172.17.0.2-1599341484861:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-0b82599e-9166-4bad-8a2d-b5d2e777c257,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-de521a75-4ce2-47d2-b8e0-6ce43b163105,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-c7b4f68b-7635-4005-9973-c8ae22980341,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-91e6f54c-0a91-405c-8724-338f0935ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-04526386-4119-45df-ad5b-ee9799a447a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-104bcd62-2bf1-4f04-a678-ee78eb98b8b0,DISK]]; indices=[0, 2, 3, 4, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-465967938-172.17.0.2-1599341484861:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-0b82599e-9166-4bad-8a2d-b5d2e777c257,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-de521a75-4ce2-47d2-b8e0-6ce43b163105,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-c7b4f68b-7635-4005-9973-c8ae22980341,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-91e6f54c-0a91-405c-8724-338f0935ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-04526386-4119-45df-ad5b-ee9799a447a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-104bcd62-2bf1-4f04-a678-ee78eb98b8b0,DISK]]; indices=[0, 2, 3, 4, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-465967938-172.17.0.2-1599341484861:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-0b82599e-9166-4bad-8a2d-b5d2e777c257,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-de521a75-4ce2-47d2-b8e0-6ce43b163105,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-c7b4f68b-7635-4005-9973-c8ae22980341,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-91e6f54c-0a91-405c-8724-338f0935ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-04526386-4119-45df-ad5b-ee9799a447a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-104bcd62-2bf1-4f04-a678-ee78eb98b8b0,DISK]]; indices=[0, 2, 3, 4, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 6 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=6); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1637412319-172.17.0.2-1599341636094:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46091,DS-e4a5c409-3bc0-4f5c-9908-90064ae18265,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-0bfb7599-58bf-4a24-acf6-bada258c6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-b6d27055-2d25-4fc4-8f5e-9859c74310f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-be60acfc-6e2c-46dc-b3a9-34cd4a52cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-4a3380cf-4057-4906-a5b9-5ed77e1d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-6d0c005d-2675-43df-97ec-7597d03c4053,DISK]]; indices=[0, 1, 2, 3, 4, 5]}];  lastLocatedBlock=LocatedStripedBlock{BP-1637412319-172.17.0.2-1599341636094:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46091,DS-e4a5c409-3bc0-4f5c-9908-90064ae18265,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-0bfb7599-58bf-4a24-acf6-bada258c6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-b6d27055-2d25-4fc4-8f5e-9859c74310f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-be60acfc-6e2c-46dc-b3a9-34cd4a52cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-4a3380cf-4057-4906-a5b9-5ed77e1d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-6d0c005d-2675-43df-97ec-7597d03c4053,DISK]]; indices=[0, 1, 2, 3, 4, 5]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 6 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=6); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1637412319-172.17.0.2-1599341636094:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46091,DS-e4a5c409-3bc0-4f5c-9908-90064ae18265,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-0bfb7599-58bf-4a24-acf6-bada258c6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-b6d27055-2d25-4fc4-8f5e-9859c74310f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-be60acfc-6e2c-46dc-b3a9-34cd4a52cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-4a3380cf-4057-4906-a5b9-5ed77e1d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-6d0c005d-2675-43df-97ec-7597d03c4053,DISK]]; indices=[0, 1, 2, 3, 4, 5]}];  lastLocatedBlock=LocatedStripedBlock{BP-1637412319-172.17.0.2-1599341636094:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46091,DS-e4a5c409-3bc0-4f5c-9908-90064ae18265,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-0bfb7599-58bf-4a24-acf6-bada258c6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-b6d27055-2d25-4fc4-8f5e-9859c74310f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-be60acfc-6e2c-46dc-b3a9-34cd4a52cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-4a3380cf-4057-4906-a5b9-5ed77e1d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-6d0c005d-2675-43df-97ec-7597d03c4053,DISK]]; indices=[0, 1, 2, 3, 4, 5]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-2019959423-172.17.0.2-1599342536712:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-1aadd8ba-27f4-4e41-8b89-722406e456e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ecb27865-05d1-4385-9cc7-06dd32f1f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-43acaade-528c-46dc-a11b-52b0bd0d02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b7f4abae-1cbe-41d7-b23e-08b05b4a99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-30dd4327-5043-4b4e-a6b2-f15acf847eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c18d2450-c249-44b0-85d5-61726fd8e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8c17d6cb-e681-45fb-9e4b-e6b332079a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f4ffbf96-a678-463e-a63e-67eeb46c6675,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-2019959423-172.17.0.2-1599342536712:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-1aadd8ba-27f4-4e41-8b89-722406e456e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ecb27865-05d1-4385-9cc7-06dd32f1f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-43acaade-528c-46dc-a11b-52b0bd0d02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b7f4abae-1cbe-41d7-b23e-08b05b4a99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-30dd4327-5043-4b4e-a6b2-f15acf847eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c18d2450-c249-44b0-85d5-61726fd8e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8c17d6cb-e681-45fb-9e4b-e6b332079a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f4ffbf96-a678-463e-a63e-67eeb46c6675,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-2019959423-172.17.0.2-1599342536712:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-1aadd8ba-27f4-4e41-8b89-722406e456e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ecb27865-05d1-4385-9cc7-06dd32f1f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-43acaade-528c-46dc-a11b-52b0bd0d02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b7f4abae-1cbe-41d7-b23e-08b05b4a99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-30dd4327-5043-4b4e-a6b2-f15acf847eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c18d2450-c249-44b0-85d5-61726fd8e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8c17d6cb-e681-45fb-9e4b-e6b332079a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f4ffbf96-a678-463e-a63e-67eeb46c6675,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-2019959423-172.17.0.2-1599342536712:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-1aadd8ba-27f4-4e41-8b89-722406e456e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-ecb27865-05d1-4385-9cc7-06dd32f1f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-43acaade-528c-46dc-a11b-52b0bd0d02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-b7f4abae-1cbe-41d7-b23e-08b05b4a99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-30dd4327-5043-4b4e-a6b2-f15acf847eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c18d2450-c249-44b0-85d5-61726fd8e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8c17d6cb-e681-45fb-9e4b-e6b332079a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-f4ffbf96-a678-463e-a63e-67eeb46c6675,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-169159610-172.17.0.2-1599342863251:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-a6ffb02d-2939-4426-a796-07d759c4a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cb1b1dae-0348-44cd-88b5-6c422ec8fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-6a6c6d71-5c43-4945-9f68-b2a8017164d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-b8275fc8-1aa6-465f-a423-f590d70ad759,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6280ab82-9f54-4a3b-abbd-ce956dbf26ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-70c64d84-f513-468b-9409-b300de907757,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-5a368002-80c7-4d1e-a75a-e3f9ea5fbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-aeea4b9e-5137-4a2a-b26d-48dd75c7ef36,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-169159610-172.17.0.2-1599342863251:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-a6ffb02d-2939-4426-a796-07d759c4a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cb1b1dae-0348-44cd-88b5-6c422ec8fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-6a6c6d71-5c43-4945-9f68-b2a8017164d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-b8275fc8-1aa6-465f-a423-f590d70ad759,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6280ab82-9f54-4a3b-abbd-ce956dbf26ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-70c64d84-f513-468b-9409-b300de907757,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-5a368002-80c7-4d1e-a75a-e3f9ea5fbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-aeea4b9e-5137-4a2a-b26d-48dd75c7ef36,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-169159610-172.17.0.2-1599342863251:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-a6ffb02d-2939-4426-a796-07d759c4a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cb1b1dae-0348-44cd-88b5-6c422ec8fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-6a6c6d71-5c43-4945-9f68-b2a8017164d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-b8275fc8-1aa6-465f-a423-f590d70ad759,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6280ab82-9f54-4a3b-abbd-ce956dbf26ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-70c64d84-f513-468b-9409-b300de907757,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-5a368002-80c7-4d1e-a75a-e3f9ea5fbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-aeea4b9e-5137-4a2a-b26d-48dd75c7ef36,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-169159610-172.17.0.2-1599342863251:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-a6ffb02d-2939-4426-a796-07d759c4a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cb1b1dae-0348-44cd-88b5-6c422ec8fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-6a6c6d71-5c43-4945-9f68-b2a8017164d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-b8275fc8-1aa6-465f-a423-f590d70ad759,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6280ab82-9f54-4a3b-abbd-ce956dbf26ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-70c64d84-f513-468b-9409-b300de907757,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-5a368002-80c7-4d1e-a75a-e3f9ea5fbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-aeea4b9e-5137-4a2a-b26d-48dd75c7ef36,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1266117150-172.17.0.2-1599343595572:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-7d124c0e-0d8f-4707-83a2-fd9c6aeac011,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f282fd53-9943-4773-999c-fc1db07d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c6784be5-2be8-4a43-88a9-e1e341789a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-8905d25e-3595-49a8-bffe-c6c0267a5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1d8052d5-1669-4b58-8af4-79ce7bc36399,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c47f1c28-c6ae-460c-894f-f14cfc9b5705,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-958e5e35-f687-40c6-bde6-bf2d45a1352b,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-a203ea48-1f80-443c-b4af-a2af7bde233c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1266117150-172.17.0.2-1599343595572:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-7d124c0e-0d8f-4707-83a2-fd9c6aeac011,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f282fd53-9943-4773-999c-fc1db07d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c6784be5-2be8-4a43-88a9-e1e341789a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-8905d25e-3595-49a8-bffe-c6c0267a5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1d8052d5-1669-4b58-8af4-79ce7bc36399,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c47f1c28-c6ae-460c-894f-f14cfc9b5705,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-958e5e35-f687-40c6-bde6-bf2d45a1352b,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-a203ea48-1f80-443c-b4af-a2af7bde233c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1266117150-172.17.0.2-1599343595572:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-7d124c0e-0d8f-4707-83a2-fd9c6aeac011,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f282fd53-9943-4773-999c-fc1db07d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c6784be5-2be8-4a43-88a9-e1e341789a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-8905d25e-3595-49a8-bffe-c6c0267a5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1d8052d5-1669-4b58-8af4-79ce7bc36399,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c47f1c28-c6ae-460c-894f-f14cfc9b5705,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-958e5e35-f687-40c6-bde6-bf2d45a1352b,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-a203ea48-1f80-443c-b4af-a2af7bde233c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1266117150-172.17.0.2-1599343595572:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-7d124c0e-0d8f-4707-83a2-fd9c6aeac011,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-f282fd53-9943-4773-999c-fc1db07d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c6784be5-2be8-4a43-88a9-e1e341789a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-8905d25e-3595-49a8-bffe-c6c0267a5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1d8052d5-1669-4b58-8af4-79ce7bc36399,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-c47f1c28-c6ae-460c-894f-f14cfc9b5705,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-958e5e35-f687-40c6-bde6-bf2d45a1352b,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-a203ea48-1f80-443c-b4af-a2af7bde233c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1090199187-172.17.0.2-1599343692533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-2dc5698a-0a5e-4d1e-b85a-ef180cfd353e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cb5d94fa-5471-47ba-b875-595354c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-625d98ef-d109-46b5-8e99-3ba3411df912,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-bf761d0f-f8cb-4a83-96a0-42463d644e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2179bcc4-b562-4314-a1bc-c21d466250ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-6eb32f10-ded6-47d6-9c84-7b709a600260,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-2882a411-d94b-48ac-8586-dc0fe3164caf,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1090199187-172.17.0.2-1599343692533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-2dc5698a-0a5e-4d1e-b85a-ef180cfd353e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cb5d94fa-5471-47ba-b875-595354c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-625d98ef-d109-46b5-8e99-3ba3411df912,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-bf761d0f-f8cb-4a83-96a0-42463d644e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2179bcc4-b562-4314-a1bc-c21d466250ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-6eb32f10-ded6-47d6-9c84-7b709a600260,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-2882a411-d94b-48ac-8586-dc0fe3164caf,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1090199187-172.17.0.2-1599343692533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-2dc5698a-0a5e-4d1e-b85a-ef180cfd353e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cb5d94fa-5471-47ba-b875-595354c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-625d98ef-d109-46b5-8e99-3ba3411df912,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-bf761d0f-f8cb-4a83-96a0-42463d644e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2179bcc4-b562-4314-a1bc-c21d466250ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-6eb32f10-ded6-47d6-9c84-7b709a600260,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-2882a411-d94b-48ac-8586-dc0fe3164caf,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1090199187-172.17.0.2-1599343692533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-2dc5698a-0a5e-4d1e-b85a-ef180cfd353e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cb5d94fa-5471-47ba-b875-595354c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-625d98ef-d109-46b5-8e99-3ba3411df912,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-bf761d0f-f8cb-4a83-96a0-42463d644e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-2179bcc4-b562-4314-a1bc-c21d466250ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-6eb32f10-ded6-47d6-9c84-7b709a600260,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-2882a411-d94b-48ac-8586-dc0fe3164caf,DISK]]; indices=[0, 1, 2, 3, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-51807768-172.17.0.2-1599344240556:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-b774ffd9-78d7-40c8-ae41-15a6480deeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8726f580-576a-4762-a0ac-91e25e1e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-c7b411a8-b300-40ab-b9c4-f572badce0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0caea303-ce67-4e9d-ac3d-784eaef999da,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f8f833b2-49c1-49ca-a23e-34e2fb15636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-34f815f9-c366-46df-81a5-86df9b2f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-48cf5f46-b682-4bd4-82ce-44d645089bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-209d5c1f-4538-412d-b57c-12c3543ac409,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-51807768-172.17.0.2-1599344240556:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-b774ffd9-78d7-40c8-ae41-15a6480deeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8726f580-576a-4762-a0ac-91e25e1e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-c7b411a8-b300-40ab-b9c4-f572badce0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0caea303-ce67-4e9d-ac3d-784eaef999da,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f8f833b2-49c1-49ca-a23e-34e2fb15636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-34f815f9-c366-46df-81a5-86df9b2f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-48cf5f46-b682-4bd4-82ce-44d645089bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-209d5c1f-4538-412d-b57c-12c3543ac409,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-51807768-172.17.0.2-1599344240556:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-b774ffd9-78d7-40c8-ae41-15a6480deeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8726f580-576a-4762-a0ac-91e25e1e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-c7b411a8-b300-40ab-b9c4-f572badce0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0caea303-ce67-4e9d-ac3d-784eaef999da,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f8f833b2-49c1-49ca-a23e-34e2fb15636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-34f815f9-c366-46df-81a5-86df9b2f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-48cf5f46-b682-4bd4-82ce-44d645089bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-209d5c1f-4538-412d-b57c-12c3543ac409,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-51807768-172.17.0.2-1599344240556:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-b774ffd9-78d7-40c8-ae41-15a6480deeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8726f580-576a-4762-a0ac-91e25e1e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-c7b411a8-b300-40ab-b9c4-f572badce0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0caea303-ce67-4e9d-ac3d-784eaef999da,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f8f833b2-49c1-49ca-a23e-34e2fb15636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-34f815f9-c366-46df-81a5-86df9b2f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-48cf5f46-b682-4bd4-82ce-44d645089bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-209d5c1f-4538-412d-b57c-12c3543ac409,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-94900202-172.17.0.2-1599344408578:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-807d4306-2e3e-43cf-bdd0-d3ef8a4492a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bd71a37f-14f7-41ef-92a6-f1b6438d10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8c2dce9d-20f1-4a52-a4c4-24cf98f49494,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-8c64ef6b-b581-489f-b287-19d0db6db68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-7eb63b67-9f5f-427d-8f0e-e81c4336e398,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-18b76922-f825-4880-8955-e260cf519395,DISK]]; indices=[1, 2, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-94900202-172.17.0.2-1599344408578:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-807d4306-2e3e-43cf-bdd0-d3ef8a4492a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bd71a37f-14f7-41ef-92a6-f1b6438d10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8c2dce9d-20f1-4a52-a4c4-24cf98f49494,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-8c64ef6b-b581-489f-b287-19d0db6db68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-7eb63b67-9f5f-427d-8f0e-e81c4336e398,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-18b76922-f825-4880-8955-e260cf519395,DISK]]; indices=[1, 2, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-94900202-172.17.0.2-1599344408578:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-807d4306-2e3e-43cf-bdd0-d3ef8a4492a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bd71a37f-14f7-41ef-92a6-f1b6438d10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8c2dce9d-20f1-4a52-a4c4-24cf98f49494,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-8c64ef6b-b581-489f-b287-19d0db6db68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-7eb63b67-9f5f-427d-8f0e-e81c4336e398,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-18b76922-f825-4880-8955-e260cf519395,DISK]]; indices=[1, 2, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-94900202-172.17.0.2-1599344408578:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-807d4306-2e3e-43cf-bdd0-d3ef8a4492a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bd71a37f-14f7-41ef-92a6-f1b6438d10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8c2dce9d-20f1-4a52-a4c4-24cf98f49494,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-8c64ef6b-b581-489f-b287-19d0db6db68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-7eb63b67-9f5f-427d-8f0e-e81c4336e398,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-18b76922-f825-4880-8955-e260cf519395,DISK]]; indices=[1, 2, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-332971399-172.17.0.2-1599345202943:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-5cb5c1e4-620c-4faf-af88-1c38fdce7976,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-7f7eb155-72da-4f01-a2c4-f32dfebf38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-011187fe-1039-44b9-91af-8eec93b8adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-c8775a71-8eb9-4f0a-b221-2dff4079b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c288ae71-2a94-4b9a-a078-7623353915af,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-be00c70b-849c-4172-b2ec-b8a102a9e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-fb2cee63-cc42-46e8-b311-15b51fda65a5,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-332971399-172.17.0.2-1599345202943:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-5cb5c1e4-620c-4faf-af88-1c38fdce7976,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-7f7eb155-72da-4f01-a2c4-f32dfebf38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-011187fe-1039-44b9-91af-8eec93b8adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-c8775a71-8eb9-4f0a-b221-2dff4079b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c288ae71-2a94-4b9a-a078-7623353915af,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-be00c70b-849c-4172-b2ec-b8a102a9e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-fb2cee63-cc42-46e8-b311-15b51fda65a5,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-332971399-172.17.0.2-1599345202943:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-5cb5c1e4-620c-4faf-af88-1c38fdce7976,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-7f7eb155-72da-4f01-a2c4-f32dfebf38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-011187fe-1039-44b9-91af-8eec93b8adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-c8775a71-8eb9-4f0a-b221-2dff4079b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c288ae71-2a94-4b9a-a078-7623353915af,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-be00c70b-849c-4172-b2ec-b8a102a9e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-fb2cee63-cc42-46e8-b311-15b51fda65a5,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-332971399-172.17.0.2-1599345202943:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39669,DS-5cb5c1e4-620c-4faf-af88-1c38fdce7976,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-7f7eb155-72da-4f01-a2c4-f32dfebf38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-011187fe-1039-44b9-91af-8eec93b8adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-c8775a71-8eb9-4f0a-b221-2dff4079b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c288ae71-2a94-4b9a-a078-7623353915af,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-be00c70b-849c-4172-b2ec-b8a102a9e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-fb2cee63-cc42-46e8-b311-15b51fda65a5,DISK]]; indices=[0, 1, 3, 4, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-37743754-172.17.0.2-1599345824533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-721999ed-d7bc-4340-94ca-6ac58db25280,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b4301fd0-48f7-445d-9f2b-54d7ed7609f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-513a96b0-0a14-49f2-94c3-a158cf0aa43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2d9b47d3-fd7e-455a-a768-d97517ad30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-3a80c49b-6f6a-487b-8fec-8cfa5d4a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-30ad19d6-3c44-4f7a-b50d-2b85d5b66e3d,DISK]]; indices=[1, 2, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-37743754-172.17.0.2-1599345824533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-f5579e17-9523-4466-b196-02cb0d7ef0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-721999ed-d7bc-4340-94ca-6ac58db25280,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b4301fd0-48f7-445d-9f2b-54d7ed7609f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-513a96b0-0a14-49f2-94c3-a158cf0aa43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2d9b47d3-fd7e-455a-a768-d97517ad30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-3a80c49b-6f6a-487b-8fec-8cfa5d4a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-30ad19d6-3c44-4f7a-b50d-2b85d5b66e3d,DISK]]; indices=[0, 1, 2, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-37743754-172.17.0.2-1599345824533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-721999ed-d7bc-4340-94ca-6ac58db25280,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b4301fd0-48f7-445d-9f2b-54d7ed7609f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-513a96b0-0a14-49f2-94c3-a158cf0aa43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2d9b47d3-fd7e-455a-a768-d97517ad30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-3a80c49b-6f6a-487b-8fec-8cfa5d4a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-30ad19d6-3c44-4f7a-b50d-2b85d5b66e3d,DISK]]; indices=[1, 2, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-37743754-172.17.0.2-1599345824533:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-f5579e17-9523-4466-b196-02cb0d7ef0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-721999ed-d7bc-4340-94ca-6ac58db25280,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b4301fd0-48f7-445d-9f2b-54d7ed7609f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-513a96b0-0a14-49f2-94c3-a158cf0aa43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-2d9b47d3-fd7e-455a-a768-d97517ad30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-3a80c49b-6f6a-487b-8fec-8cfa5d4a6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-30ad19d6-3c44-4f7a-b50d-2b85d5b66e3d,DISK]]; indices=[0, 1, 2, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-131328320-172.17.0.2-1599345877078:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-ce3f782d-39c7-4566-9451-4f028a5b818e,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-3e360ac8-fc39-4b2c-93ef-022ae49d5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-801aaa94-3281-44be-bd93-7f8c765e62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-513095ed-53b1-4226-83e9-5365197a4f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-377345f4-14d6-4a39-9b80-21e7bd7f011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-9167f08f-df27-42df-894b-37fe5bf22263,DISK]]; indices=[1, 2, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-131328320-172.17.0.2-1599345877078:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-ce3f782d-39c7-4566-9451-4f028a5b818e,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-3e360ac8-fc39-4b2c-93ef-022ae49d5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-801aaa94-3281-44be-bd93-7f8c765e62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-513095ed-53b1-4226-83e9-5365197a4f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-377345f4-14d6-4a39-9b80-21e7bd7f011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-9167f08f-df27-42df-894b-37fe5bf22263,DISK]]; indices=[1, 2, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-131328320-172.17.0.2-1599345877078:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-ce3f782d-39c7-4566-9451-4f028a5b818e,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-3e360ac8-fc39-4b2c-93ef-022ae49d5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-801aaa94-3281-44be-bd93-7f8c765e62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-513095ed-53b1-4226-83e9-5365197a4f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-377345f4-14d6-4a39-9b80-21e7bd7f011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-9167f08f-df27-42df-894b-37fe5bf22263,DISK]]; indices=[1, 2, 3, 4, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-131328320-172.17.0.2-1599345877078:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-ce3f782d-39c7-4566-9451-4f028a5b818e,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-3e360ac8-fc39-4b2c-93ef-022ae49d5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-801aaa94-3281-44be-bd93-7f8c765e62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-513095ed-53b1-4226-83e9-5365197a4f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-377345f4-14d6-4a39-9b80-21e7bd7f011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-9167f08f-df27-42df-894b-37fe5bf22263,DISK]]; indices=[1, 2, 3, 4, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-209818186-172.17.0.2-1599346449181:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46588,DS-4c3bae25-970a-4387-8d0e-21f5367cc77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-723e2467-3658-45ec-ad7c-4da9f3d094a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-6f05a11f-178e-4fe7-be4b-1e663b1e4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-73ce2e40-30ef-4bce-8fa7-73d15ce08ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-527905ca-d2e4-484f-b908-53ac1dac7544,DISK]]; indices=[3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-209818186-172.17.0.2-1599346449181:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-dfc9ff5d-e61d-48fa-b8f8-7a7ed5fbab11,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-4c3bae25-970a-4387-8d0e-21f5367cc77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-723e2467-3658-45ec-ad7c-4da9f3d094a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-6f05a11f-178e-4fe7-be4b-1e663b1e4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-73ce2e40-30ef-4bce-8fa7-73d15ce08ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-527905ca-d2e4-484f-b908-53ac1dac7544,DISK]]; indices=[2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-209818186-172.17.0.2-1599346449181:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46588,DS-4c3bae25-970a-4387-8d0e-21f5367cc77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-723e2467-3658-45ec-ad7c-4da9f3d094a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-6f05a11f-178e-4fe7-be4b-1e663b1e4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-73ce2e40-30ef-4bce-8fa7-73d15ce08ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-527905ca-d2e4-484f-b908-53ac1dac7544,DISK]]; indices=[3, 4, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-209818186-172.17.0.2-1599346449181:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-dfc9ff5d-e61d-48fa-b8f8-7a7ed5fbab11,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-4c3bae25-970a-4387-8d0e-21f5367cc77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-723e2467-3658-45ec-ad7c-4da9f3d094a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-6f05a11f-178e-4fe7-be4b-1e663b1e4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-73ce2e40-30ef-4bce-8fa7-73d15ce08ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-527905ca-d2e4-484f-b908-53ac1dac7544,DISK]]; indices=[2, 3, 4, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1999817443-172.17.0.2-1599346481755:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6cd75c43-cb91-43f1-9226-9ebae72894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a4e65d7c-a8c1-4eed-971e-36ff39db1637,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d468bec7-cb51-4d14-9575-e57ee90cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-11a35f84-c1fc-4933-95c7-1b324497e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-9b280a06-de72-40a5-8d56-76a2976da2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1928fcf2-2acc-418b-a1fe-8f99c0b71c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-c11a4c09-bb7c-4a76-97fd-4ecbbc021906,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1999817443-172.17.0.2-1599346481755:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6cd75c43-cb91-43f1-9226-9ebae72894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a4e65d7c-a8c1-4eed-971e-36ff39db1637,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d468bec7-cb51-4d14-9575-e57ee90cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-11a35f84-c1fc-4933-95c7-1b324497e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-9b280a06-de72-40a5-8d56-76a2976da2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1928fcf2-2acc-418b-a1fe-8f99c0b71c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-c11a4c09-bb7c-4a76-97fd-4ecbbc021906,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1999817443-172.17.0.2-1599346481755:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6cd75c43-cb91-43f1-9226-9ebae72894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a4e65d7c-a8c1-4eed-971e-36ff39db1637,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d468bec7-cb51-4d14-9575-e57ee90cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-11a35f84-c1fc-4933-95c7-1b324497e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-9b280a06-de72-40a5-8d56-76a2976da2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1928fcf2-2acc-418b-a1fe-8f99c0b71c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-c11a4c09-bb7c-4a76-97fd-4ecbbc021906,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1999817443-172.17.0.2-1599346481755:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-6cd75c43-cb91-43f1-9226-9ebae72894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a4e65d7c-a8c1-4eed-971e-36ff39db1637,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-d468bec7-cb51-4d14-9575-e57ee90cf111,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-11a35f84-c1fc-4933-95c7-1b324497e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-9b280a06-de72-40a5-8d56-76a2976da2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1928fcf2-2acc-418b-a1fe-8f99c0b71c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-c11a4c09-bb7c-4a76-97fd-4ecbbc021906,DISK]]; indices=[0, 1, 2, 3, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1815661370-172.17.0.2-1599346822950:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b8d6d638-4ba6-48d8-b33f-4eb8622502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-8975c0da-4f4a-45f5-82f6-8cb4bc1cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-eca562d9-abd0-48e6-83f7-00fee9dea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6f873495-99cc-4357-b7ae-92e3a763b453,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-5a489f2d-9539-46ec-868b-39b4ec853ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-2c5b1701-442e-498f-905b-90db2ca2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-9eaf4ac6-df71-4d6f-b5cf-d52725636642,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f5903080-0cef-4405-bb97-908e47a013d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-a666d386-ac4f-4e1a-8650-b94ddd3fa849,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1815661370-172.17.0.2-1599346822950:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b8d6d638-4ba6-48d8-b33f-4eb8622502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-8975c0da-4f4a-45f5-82f6-8cb4bc1cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-eca562d9-abd0-48e6-83f7-00fee9dea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6f873495-99cc-4357-b7ae-92e3a763b453,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-5a489f2d-9539-46ec-868b-39b4ec853ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-2c5b1701-442e-498f-905b-90db2ca2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-9eaf4ac6-df71-4d6f-b5cf-d52725636642,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f5903080-0cef-4405-bb97-908e47a013d6,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1815661370-172.17.0.2-1599346822950:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b8d6d638-4ba6-48d8-b33f-4eb8622502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-8975c0da-4f4a-45f5-82f6-8cb4bc1cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-eca562d9-abd0-48e6-83f7-00fee9dea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6f873495-99cc-4357-b7ae-92e3a763b453,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-5a489f2d-9539-46ec-868b-39b4ec853ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-2c5b1701-442e-498f-905b-90db2ca2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-9eaf4ac6-df71-4d6f-b5cf-d52725636642,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f5903080-0cef-4405-bb97-908e47a013d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-a666d386-ac4f-4e1a-8650-b94ddd3fa849,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1815661370-172.17.0.2-1599346822950:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b8d6d638-4ba6-48d8-b33f-4eb8622502e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-8975c0da-4f4a-45f5-82f6-8cb4bc1cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-eca562d9-abd0-48e6-83f7-00fee9dea7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6f873495-99cc-4357-b7ae-92e3a763b453,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-5a489f2d-9539-46ec-868b-39b4ec853ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-2c5b1701-442e-498f-905b-90db2ca2e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-9eaf4ac6-df71-4d6f-b5cf-d52725636642,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-f5903080-0cef-4405-bb97-908e47a013d6,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-832442871-172.17.0.2-1599347876734:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-756dc9ef-aba5-4e7c-a239-15e1981b97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-69ed3105-c707-40e8-9cd9-914584154529,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-f8e6b1f0-777d-44fe-a1d8-3cbcbd3c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-9c29c0a4-04f6-4391-acaf-b83e138eefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-5a17e6f3-ffe5-4548-b2dd-32f62babafd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-e3468852-c863-4c15-80b5-11d492bd2ed6,DISK]]; indices=[1, 3, 4, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-832442871-172.17.0.2-1599347876734:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-756dc9ef-aba5-4e7c-a239-15e1981b97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-69ed3105-c707-40e8-9cd9-914584154529,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-f8e6b1f0-777d-44fe-a1d8-3cbcbd3c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-9c29c0a4-04f6-4391-acaf-b83e138eefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-5a17e6f3-ffe5-4548-b2dd-32f62babafd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-e3468852-c863-4c15-80b5-11d492bd2ed6,DISK]]; indices=[1, 3, 4, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-832442871-172.17.0.2-1599347876734:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-756dc9ef-aba5-4e7c-a239-15e1981b97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-69ed3105-c707-40e8-9cd9-914584154529,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-f8e6b1f0-777d-44fe-a1d8-3cbcbd3c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-9c29c0a4-04f6-4391-acaf-b83e138eefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-5a17e6f3-ffe5-4548-b2dd-32f62babafd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-e3468852-c863-4c15-80b5-11d492bd2ed6,DISK]]; indices=[1, 3, 4, 5, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-832442871-172.17.0.2-1599347876734:blk_-9223372036854775792_1001; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-756dc9ef-aba5-4e7c-a239-15e1981b97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-69ed3105-c707-40e8-9cd9-914584154529,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-f8e6b1f0-777d-44fe-a1d8-3cbcbd3c57ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-9c29c0a4-04f6-4391-acaf-b83e138eefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-5a17e6f3-ffe5-4548-b2dd-32f62babafd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-e3468852-c863-4c15-80b5-11d492bd2ed6,DISK]]; indices=[1, 3, 4, 5, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-818638103-172.17.0.2-1599349516154:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-0f3a0b38-758d-4536-a0c3-a101218df667,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0011800e-a6c8-41ca-986a-d0075b0bd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-85d41f7c-67d0-48cf-9543-2a0dc202af16,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-34dc883e-8aea-4d60-ab45-16a7adf4ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1c1562a3-0fcc-4e88-ac3d-5f6821a21170,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-1478750d-2c04-4241-be95-42bc4299bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-32dca230-24dd-4ab8-a966-902542c84be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-e0719b53-81f4-4867-b392-63ac8e100766,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-818638103-172.17.0.2-1599349516154:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-0f3a0b38-758d-4536-a0c3-a101218df667,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0011800e-a6c8-41ca-986a-d0075b0bd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-85d41f7c-67d0-48cf-9543-2a0dc202af16,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-34dc883e-8aea-4d60-ab45-16a7adf4ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1c1562a3-0fcc-4e88-ac3d-5f6821a21170,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-1478750d-2c04-4241-be95-42bc4299bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-32dca230-24dd-4ab8-a966-902542c84be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-e0719b53-81f4-4867-b392-63ac8e100766,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-818638103-172.17.0.2-1599349516154:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-0f3a0b38-758d-4536-a0c3-a101218df667,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0011800e-a6c8-41ca-986a-d0075b0bd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-85d41f7c-67d0-48cf-9543-2a0dc202af16,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-34dc883e-8aea-4d60-ab45-16a7adf4ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1c1562a3-0fcc-4e88-ac3d-5f6821a21170,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-1478750d-2c04-4241-be95-42bc4299bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-32dca230-24dd-4ab8-a966-902542c84be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-e0719b53-81f4-4867-b392-63ac8e100766,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-818638103-172.17.0.2-1599349516154:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-0f3a0b38-758d-4536-a0c3-a101218df667,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0011800e-a6c8-41ca-986a-d0075b0bd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-85d41f7c-67d0-48cf-9543-2a0dc202af16,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-34dc883e-8aea-4d60-ab45-16a7adf4ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1c1562a3-0fcc-4e88-ac3d-5f6821a21170,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-1478750d-2c04-4241-be95-42bc4299bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-32dca230-24dd-4ab8-a966-902542c84be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-e0719b53-81f4-4867-b392-63ac8e100766,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: null
stackTrace: java.lang.IllegalArgumentException
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:127)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.<init>(FsDatasetImplTestUtils.java:210)
	at org.apache.hadoop.hdfs.server.datanode.FsDatasetImplTestUtilsFactory.newInstance(FsDatasetImplTestUtilsFactory.java:30)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getFsDatasetTestUtils(MiniDFSCluster.java:1983)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2206)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2238)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData#testReadCorruptedDataByDeleting[5]
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-900971671-172.17.0.2-1599349893906:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-72675c70-fc32-4a2c-a15b-fa42eaf684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-52252df8-34ee-4ba6-9033-2381c9ddb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-92c03bb4-1858-4cf1-af7f-ebb55d871cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a32fd6a0-33b3-4809-b09d-9aef42247d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b220cbd2-91f6-4b9f-8d23-bc26f3ebaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-ff35205a-1b36-4ee3-932c-59df01df6478,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2a06525a-a3ed-4c62-b0e4-923ff2b63802,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-7088f9bb-e4d3-49c1-b344-57e1062bba0f,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-900971671-172.17.0.2-1599349893906:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-72675c70-fc32-4a2c-a15b-fa42eaf684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-52252df8-34ee-4ba6-9033-2381c9ddb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-92c03bb4-1858-4cf1-af7f-ebb55d871cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a32fd6a0-33b3-4809-b09d-9aef42247d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b220cbd2-91f6-4b9f-8d23-bc26f3ebaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-ff35205a-1b36-4ee3-932c-59df01df6478,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2a06525a-a3ed-4c62-b0e4-923ff2b63802,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-7088f9bb-e4d3-49c1-b344-57e1062bba0f,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=4194181, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165701;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-900971671-172.17.0.2-1599349893906:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-72675c70-fc32-4a2c-a15b-fa42eaf684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-52252df8-34ee-4ba6-9033-2381c9ddb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-92c03bb4-1858-4cf1-af7f-ebb55d871cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a32fd6a0-33b3-4809-b09d-9aef42247d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b220cbd2-91f6-4b9f-8d23-bc26f3ebaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-ff35205a-1b36-4ee3-932c-59df01df6478,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2a06525a-a3ed-4c62-b0e4-923ff2b63802,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-7088f9bb-e4d3-49c1-b344-57e1062bba0f,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-900971671-172.17.0.2-1599349893906:blk_-9223372036854775792_1002; getBlockSize()=25165701; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-72675c70-fc32-4a2c-a15b-fa42eaf684c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-52252df8-34ee-4ba6-9033-2381c9ddb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-92c03bb4-1858-4cf1-af7f-ebb55d871cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a32fd6a0-33b3-4809-b09d-9aef42247d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b220cbd2-91f6-4b9f-8d23-bc26f3ebaccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-ff35205a-1b36-4ee3-932c-59df01df6478,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2a06525a-a3ed-4c62-b0e4-923ff2b63802,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-7088f9bb-e4d3-49c1-b344-57e1062bba0f,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 8855
