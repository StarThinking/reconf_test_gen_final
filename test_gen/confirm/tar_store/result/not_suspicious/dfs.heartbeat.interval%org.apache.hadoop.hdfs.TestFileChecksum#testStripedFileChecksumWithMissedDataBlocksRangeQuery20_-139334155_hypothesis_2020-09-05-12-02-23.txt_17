reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998480851-172.17.0.5-1599307650325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42263,DS-0cb00368-3c90-4b39-ad6d-2be8a608f906,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-a41c7443-519d-4edd-a4ff-858f11702f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-284d6782-379c-4c0e-b8d2-ef44744de2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-3aabfff0-00f4-4bc3-9fd4-b1d2d6574a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-4ef3d7a5-5523-4b1e-b0b5-39aaf31b1d66,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5c76e460-4dde-42a4-8511-1f4757872936,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-96e4d00e-3dda-4b7a-b998-0ffb7b0109ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-5c5075c8-1f39-45e5-9391-94de4a804f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998480851-172.17.0.5-1599307650325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42263,DS-0cb00368-3c90-4b39-ad6d-2be8a608f906,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-a41c7443-519d-4edd-a4ff-858f11702f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-284d6782-379c-4c0e-b8d2-ef44744de2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-3aabfff0-00f4-4bc3-9fd4-b1d2d6574a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-4ef3d7a5-5523-4b1e-b0b5-39aaf31b1d66,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5c76e460-4dde-42a4-8511-1f4757872936,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-96e4d00e-3dda-4b7a-b998-0ffb7b0109ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-5c5075c8-1f39-45e5-9391-94de4a804f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821357650-172.17.0.5-1599307892919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-b2c29e07-6d73-4634-9359-d1fb8c24d70a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-68526486-2678-4014-8dc7-c103f63a6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9b6f0627-339f-4b42-be6a-40bd0966a932,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-77c3f13d-fbb7-4c4e-98b5-e48ccbf8947f,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-5fa2695d-ee1f-4d16-b49f-e5743aa99d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-baf23131-3c13-45ed-85dd-3970e9ccfe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-61fd395b-5ea9-494a-b9a3-b5dee66acbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-857b5ed1-4a7f-4695-add7-a568aca2bd2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821357650-172.17.0.5-1599307892919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-b2c29e07-6d73-4634-9359-d1fb8c24d70a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-68526486-2678-4014-8dc7-c103f63a6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9b6f0627-339f-4b42-be6a-40bd0966a932,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-77c3f13d-fbb7-4c4e-98b5-e48ccbf8947f,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-5fa2695d-ee1f-4d16-b49f-e5743aa99d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-baf23131-3c13-45ed-85dd-3970e9ccfe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-61fd395b-5ea9-494a-b9a3-b5dee66acbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-857b5ed1-4a7f-4695-add7-a568aca2bd2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632985226-172.17.0.5-1599308132375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-0fd7149e-fc59-4061-800b-1df0c4436970,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-bcf0ff14-9369-4fe5-8207-2a2f2603e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-9fd68d83-5f3f-4f7b-a5d2-5cfe9be56583,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-bc1e1a78-66ac-4641-a719-86b4fbc77b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-b3f07bdb-979b-4f70-9260-9750c5eae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-84d4775e-f04c-4966-bc13-dc68db9a886b,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a10aba36-4dc7-48e8-a59b-57b05a095deb,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-faaddd30-7961-4881-a678-ded645eab71f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632985226-172.17.0.5-1599308132375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-0fd7149e-fc59-4061-800b-1df0c4436970,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-bcf0ff14-9369-4fe5-8207-2a2f2603e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-9fd68d83-5f3f-4f7b-a5d2-5cfe9be56583,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-bc1e1a78-66ac-4641-a719-86b4fbc77b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-b3f07bdb-979b-4f70-9260-9750c5eae52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-84d4775e-f04c-4966-bc13-dc68db9a886b,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a10aba36-4dc7-48e8-a59b-57b05a095deb,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-faaddd30-7961-4881-a678-ded645eab71f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726553048-172.17.0.5-1599308454297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-54e2e516-538c-44ac-bfb9-81020a197fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c0f79cb3-ea93-49e5-a5bf-f16f4dd58199,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-30e46c76-579d-4ffa-8b18-473adcc5d5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-5d681364-2d42-46da-8765-75ce81100aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-b8dee7ec-0ef3-44ea-9f42-9b6d52a752c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-197893e1-b075-40a7-ab80-d5baa5577899,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dbd9c0d3-0903-4a6f-b104-7311ed5b52de,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-1ede8cab-1757-49f6-a09a-83adde34d7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726553048-172.17.0.5-1599308454297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-54e2e516-538c-44ac-bfb9-81020a197fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c0f79cb3-ea93-49e5-a5bf-f16f4dd58199,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-30e46c76-579d-4ffa-8b18-473adcc5d5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-5d681364-2d42-46da-8765-75ce81100aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-b8dee7ec-0ef3-44ea-9f42-9b6d52a752c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-197893e1-b075-40a7-ab80-d5baa5577899,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dbd9c0d3-0903-4a6f-b104-7311ed5b52de,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-1ede8cab-1757-49f6-a09a-83adde34d7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201179799-172.17.0.5-1599308483734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-2b1ec3eb-a043-4d17-b3d0-08daf0003184,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-487b9e9d-db40-4229-a2f3-b675e341b911,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-aa49e1a7-c3fe-4a51-8514-ce33ddfb6a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a187756c-3177-4154-affe-7aa509bb9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-9435323f-aa04-4068-bad3-eceba22461b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-908b7322-b941-451c-ab9d-785e1e1954d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-cac2fc0c-eb59-43e3-9a77-87195a9a01f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3ad92712-7bc1-4329-a7e4-54135771dfe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201179799-172.17.0.5-1599308483734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-2b1ec3eb-a043-4d17-b3d0-08daf0003184,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-487b9e9d-db40-4229-a2f3-b675e341b911,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-aa49e1a7-c3fe-4a51-8514-ce33ddfb6a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a187756c-3177-4154-affe-7aa509bb9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-9435323f-aa04-4068-bad3-eceba22461b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-908b7322-b941-451c-ab9d-785e1e1954d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-cac2fc0c-eb59-43e3-9a77-87195a9a01f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3ad92712-7bc1-4329-a7e4-54135771dfe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138760354-172.17.0.5-1599308742101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-c7c28ebb-2f6e-4589-a5f5-6141eeed09e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-d6a64f3d-c1e4-43fd-aee6-8d08a7402d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-555d3293-1223-498e-a0fb-ddae0d80105a,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-19ec2f4c-81f0-4600-92cd-2ed855d62a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e3bf5960-c5bc-4655-8899-e26627573e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-e5a121c9-08fb-441a-a615-789903513e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-e009ec34-cb97-4164-a5dc-af03874f5838,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-1bec7347-406d-4965-9e1a-0769f5159bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138760354-172.17.0.5-1599308742101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-c7c28ebb-2f6e-4589-a5f5-6141eeed09e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-d6a64f3d-c1e4-43fd-aee6-8d08a7402d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-555d3293-1223-498e-a0fb-ddae0d80105a,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-19ec2f4c-81f0-4600-92cd-2ed855d62a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e3bf5960-c5bc-4655-8899-e26627573e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-e5a121c9-08fb-441a-a615-789903513e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-e009ec34-cb97-4164-a5dc-af03874f5838,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-1bec7347-406d-4965-9e1a-0769f5159bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203393260-172.17.0.5-1599309367639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-d7dddb39-b5c5-4656-8f12-11886715de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-84542d46-6d50-4331-a7d8-77c36d8032d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fcbf59e4-be5d-4de8-be8b-d634a4fe0e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-7911243c-46d3-4ad4-9020-95fbecafbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-e9acb719-c1c9-4139-bef8-f28b42f03ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-267f8552-bed2-4744-a282-d893be4cf231,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-a106f500-1c12-43ea-a8d1-eb3ece0382d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c8c85a73-6f6b-468b-820f-057eb701ea37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203393260-172.17.0.5-1599309367639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-d7dddb39-b5c5-4656-8f12-11886715de1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-84542d46-6d50-4331-a7d8-77c36d8032d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-fcbf59e4-be5d-4de8-be8b-d634a4fe0e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-7911243c-46d3-4ad4-9020-95fbecafbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-e9acb719-c1c9-4139-bef8-f28b42f03ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-267f8552-bed2-4744-a282-d893be4cf231,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-a106f500-1c12-43ea-a8d1-eb3ece0382d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c8c85a73-6f6b-468b-820f-057eb701ea37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119201527-172.17.0.5-1599309583720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-9f1348e3-5548-42a5-bb8f-552e8a4af5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-9616f795-de82-4a93-9f1a-abdeed950d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-eef63a62-6f0f-4b47-bace-fb1978131804,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7b166aad-110a-4b11-9597-574ab97ee379,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-3932e65b-ce20-4806-8fa0-e4640f749877,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a97d2d76-fa0b-4ed4-87df-f18a1eadb190,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-18f37c84-ee39-4fa7-8716-8c8dfbdcdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-41e28bf9-2cee-449c-a973-6563e5d54796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119201527-172.17.0.5-1599309583720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45978,DS-9f1348e3-5548-42a5-bb8f-552e8a4af5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-9616f795-de82-4a93-9f1a-abdeed950d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-eef63a62-6f0f-4b47-bace-fb1978131804,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7b166aad-110a-4b11-9597-574ab97ee379,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-3932e65b-ce20-4806-8fa0-e4640f749877,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-a97d2d76-fa0b-4ed4-87df-f18a1eadb190,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-18f37c84-ee39-4fa7-8716-8c8dfbdcdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-41e28bf9-2cee-449c-a973-6563e5d54796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625758125-172.17.0.5-1599309708458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-e95b93b1-163a-4926-add3-70ba8f46661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-b2c5e730-2b9e-48a8-9082-c76c9f54c66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2e9fd4b7-a288-48f5-96bd-35e9d9169925,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-b55ee96e-cfe4-42fa-ad3c-9e4bfbb45df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fb01e243-79ec-4c9e-bbc2-c1c423283bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-8742aaa8-bd9c-4269-9518-0c3a81565039,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-f6e63d98-5ff9-43c3-b6cd-145ce083a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2555005e-18fc-4670-862e-1223d872793f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625758125-172.17.0.5-1599309708458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-e95b93b1-163a-4926-add3-70ba8f46661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-b2c5e730-2b9e-48a8-9082-c76c9f54c66c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2e9fd4b7-a288-48f5-96bd-35e9d9169925,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-b55ee96e-cfe4-42fa-ad3c-9e4bfbb45df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fb01e243-79ec-4c9e-bbc2-c1c423283bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-8742aaa8-bd9c-4269-9518-0c3a81565039,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-f6e63d98-5ff9-43c3-b6cd-145ce083a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2555005e-18fc-4670-862e-1223d872793f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420254240-172.17.0.5-1599309931936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-fbff34be-2a00-406d-8e87-3db114acfcff,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b37ff9b3-4af3-4f3c-8bb9-26a284a65060,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-603b82a7-ab30-4700-a52d-70c9fbb471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-78ebadde-96ac-4b12-b107-d0f0cd46de92,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1f451603-d552-4a83-af9d-3a92a0319a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ef1bc2a6-f5ec-4e56-8d4a-756777c727d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-a6d1bdde-e544-4f2f-b44c-7dbd627249cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c8253779-8252-43bf-a7cf-3c115127c40e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420254240-172.17.0.5-1599309931936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-fbff34be-2a00-406d-8e87-3db114acfcff,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b37ff9b3-4af3-4f3c-8bb9-26a284a65060,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-603b82a7-ab30-4700-a52d-70c9fbb471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-78ebadde-96ac-4b12-b107-d0f0cd46de92,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1f451603-d552-4a83-af9d-3a92a0319a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ef1bc2a6-f5ec-4e56-8d4a-756777c727d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-a6d1bdde-e544-4f2f-b44c-7dbd627249cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c8253779-8252-43bf-a7cf-3c115127c40e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623953622-172.17.0.5-1599309953881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-119c7b06-fe8e-4526-81d9-f47dda24ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-9fa850f9-32c5-4458-a16c-11713e1b3ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-a3c00b1c-8c99-4d4f-a046-eaf343f4a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-08608013-daad-405c-b30d-2485f03c11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-80158d12-9350-47f7-94cb-1cd5da8491d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-edd1205c-9707-44b6-b32b-60170e72cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-0822c1b7-c6da-425c-9ee9-32f52c35b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-7d76df39-f60e-4bdc-b6a0-91a78f567690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623953622-172.17.0.5-1599309953881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38417,DS-119c7b06-fe8e-4526-81d9-f47dda24ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-9fa850f9-32c5-4458-a16c-11713e1b3ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-a3c00b1c-8c99-4d4f-a046-eaf343f4a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-08608013-daad-405c-b30d-2485f03c11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-80158d12-9350-47f7-94cb-1cd5da8491d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-edd1205c-9707-44b6-b32b-60170e72cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-0822c1b7-c6da-425c-9ee9-32f52c35b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-7d76df39-f60e-4bdc-b6a0-91a78f567690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559529503-172.17.0.5-1599310499282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-2d4c9907-da33-4f9d-8d6c-5293bbeb97c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c0fcc521-9dc8-4424-8290-8686d76714b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-e519851b-3239-4869-9ed6-96d165ebcdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cf91ee31-cb98-40db-bf2c-25b1d56c169e,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-1a946274-292e-471f-8920-798ae48864c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-e4c4f2d8-4a9e-4109-959b-3feebe45fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-d504dda6-e6e2-44df-8598-45b3f9f5f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9c6ffeb7-5fec-4d05-925f-215bdcb3b859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559529503-172.17.0.5-1599310499282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-2d4c9907-da33-4f9d-8d6c-5293bbeb97c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c0fcc521-9dc8-4424-8290-8686d76714b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-e519851b-3239-4869-9ed6-96d165ebcdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cf91ee31-cb98-40db-bf2c-25b1d56c169e,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-1a946274-292e-471f-8920-798ae48864c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-e4c4f2d8-4a9e-4109-959b-3feebe45fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-d504dda6-e6e2-44df-8598-45b3f9f5f37a,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9c6ffeb7-5fec-4d05-925f-215bdcb3b859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434991380-172.17.0.5-1599310582249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-0c523374-5d0d-40a6-8934-0c2ad5c40f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-2cb86ade-f74d-44a7-aabf-a1bbd8340389,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-91063e3d-c337-4427-8cd1-0f01a1bdc271,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-d2187ff0-148b-4907-94c9-a1f6708f4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-9b3601e4-fc9d-4a10-99eb-56f1b2ab9f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ff54fc92-4ba1-4b16-a0bd-fcf66f640b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-9cb3fea5-1065-43cb-81a4-e1379b8ff016,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-8893d453-0f94-44c4-ae98-b6c32a67c0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434991380-172.17.0.5-1599310582249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-0c523374-5d0d-40a6-8934-0c2ad5c40f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-2cb86ade-f74d-44a7-aabf-a1bbd8340389,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-91063e3d-c337-4427-8cd1-0f01a1bdc271,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-d2187ff0-148b-4907-94c9-a1f6708f4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-9b3601e4-fc9d-4a10-99eb-56f1b2ab9f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ff54fc92-4ba1-4b16-a0bd-fcf66f640b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-9cb3fea5-1065-43cb-81a4-e1379b8ff016,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-8893d453-0f94-44c4-ae98-b6c32a67c0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735838928-172.17.0.5-1599311116576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-2f40c032-08da-4727-b310-33756089b359,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-c547ccdc-09e3-4e86-9c66-db34ef10f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-9e9311e4-f0f4-4604-8e82-66caeb5df7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-2d59e199-8c5f-4960-acec-3e9f5d625846,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-b655d753-db55-4845-97f6-74173c15289a,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-47d26e1d-42e0-422b-8af8-844f471e61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-c6032b54-9c21-407e-8637-16317b877f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-324d4d73-17c1-478b-98a8-99ccba4fe7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735838928-172.17.0.5-1599311116576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-2f40c032-08da-4727-b310-33756089b359,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-c547ccdc-09e3-4e86-9c66-db34ef10f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-9e9311e4-f0f4-4604-8e82-66caeb5df7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-2d59e199-8c5f-4960-acec-3e9f5d625846,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-b655d753-db55-4845-97f6-74173c15289a,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-47d26e1d-42e0-422b-8af8-844f471e61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-c6032b54-9c21-407e-8637-16317b877f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-324d4d73-17c1-478b-98a8-99ccba4fe7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871760289-172.17.0.5-1599311520164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-0790c1b4-be91-41bf-9c98-e2a16363bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-1e2c888c-1818-44de-a541-5a4ffe502172,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-01061134-a11f-44c9-a2e2-19b530fb20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c30658eb-d72f-4196-802d-449817c5f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-9bc1ebaf-039a-4222-b3a7-715f8647ad01,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-adbe6d48-f8f8-4c5d-9b54-4d0c24b9bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-54d6fb63-22c2-43de-bff7-4b9d5359b609,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-50b47c70-7c33-4a84-bee6-ded960428e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871760289-172.17.0.5-1599311520164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-0790c1b4-be91-41bf-9c98-e2a16363bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-1e2c888c-1818-44de-a541-5a4ffe502172,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-01061134-a11f-44c9-a2e2-19b530fb20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c30658eb-d72f-4196-802d-449817c5f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-9bc1ebaf-039a-4222-b3a7-715f8647ad01,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-adbe6d48-f8f8-4c5d-9b54-4d0c24b9bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-54d6fb63-22c2-43de-bff7-4b9d5359b609,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-50b47c70-7c33-4a84-bee6-ded960428e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4218
