reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107343503-172.17.0.20-1599353469415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-c5891501-db32-450c-99d2-23e4a68383ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-f2ebce2b-1352-4f27-b063-c21a1693a919,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-d7fe3789-2b38-42aa-abff-c7bb34b80128,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-6188d827-d59a-4437-9e9b-51e1f3f0e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-0faf18c8-807e-4253-b01e-8a5c6e778583,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a8479a68-590d-4687-9b1a-977181d13d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-ee9e60c2-6974-42b4-8021-0a6189d15a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-452783ed-69af-4c6d-b53e-1c9e308dbff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107343503-172.17.0.20-1599353469415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-c5891501-db32-450c-99d2-23e4a68383ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-f2ebce2b-1352-4f27-b063-c21a1693a919,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-d7fe3789-2b38-42aa-abff-c7bb34b80128,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-6188d827-d59a-4437-9e9b-51e1f3f0e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-0faf18c8-807e-4253-b01e-8a5c6e778583,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a8479a68-590d-4687-9b1a-977181d13d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-ee9e60c2-6974-42b4-8021-0a6189d15a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-452783ed-69af-4c6d-b53e-1c9e308dbff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876790384-172.17.0.20-1599353901063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-b420580b-6c65-4a07-bcc3-8660a5cc7d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-a9a6f933-734d-44af-a935-1a27142a68a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-def26ed8-8e16-43e1-923a-55c27c509dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-032340f0-dba5-4a13-b641-5cbda9aff636,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-c36c034d-db4b-4a49-933e-478861d83a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-5a08fa43-7004-4b56-9f38-41755544ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-d535dacc-f21e-44be-9916-3a71d9112fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-b90e30ab-064f-4c2b-b614-1d16dabd908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876790384-172.17.0.20-1599353901063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-b420580b-6c65-4a07-bcc3-8660a5cc7d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-a9a6f933-734d-44af-a935-1a27142a68a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-def26ed8-8e16-43e1-923a-55c27c509dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-032340f0-dba5-4a13-b641-5cbda9aff636,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-c36c034d-db4b-4a49-933e-478861d83a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-5a08fa43-7004-4b56-9f38-41755544ae33,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-d535dacc-f21e-44be-9916-3a71d9112fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-b90e30ab-064f-4c2b-b614-1d16dabd908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154045539-172.17.0.20-1599354184068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-1fe284d2-8cf9-4565-80b8-ba32b79a7303,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-eb0c999d-ff05-4671-97c5-0e752f4512e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-99b439f2-87e5-401e-828c-ce870ae65184,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-a75253c2-e203-4c5a-9d9c-1d5bb0ac7848,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-710cf686-7923-438e-b337-eb316e4509d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-829a3849-c0bb-4e66-b8aa-18d086c12e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-26f8eb86-4c3c-49ce-bb13-1e56149cdcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-0b6861bf-73cc-4f38-948a-88cfb01bead3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154045539-172.17.0.20-1599354184068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37081,DS-1fe284d2-8cf9-4565-80b8-ba32b79a7303,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-eb0c999d-ff05-4671-97c5-0e752f4512e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-99b439f2-87e5-401e-828c-ce870ae65184,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-a75253c2-e203-4c5a-9d9c-1d5bb0ac7848,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-710cf686-7923-438e-b337-eb316e4509d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-829a3849-c0bb-4e66-b8aa-18d086c12e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-26f8eb86-4c3c-49ce-bb13-1e56149cdcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-0b6861bf-73cc-4f38-948a-88cfb01bead3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890442514-172.17.0.20-1599354283040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-653ab4ae-e5b1-44d6-9d06-dca7cc78689a,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-87fd3aa3-9f9a-4048-b48a-4e728df1b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d705b3da-eea3-4e97-810e-f03565cba071,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-e1eaadf7-c5f7-4661-9c89-05b62d2f384a,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e1b898f6-6fea-4082-b7b7-8ff91f675e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-e8b1c197-ba1d-4b0f-bda4-7bce2bd84175,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-7f45697a-20fd-489c-a320-4c365afba358,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-e7abd816-6d36-4cf5-8868-4e7ab32aecda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890442514-172.17.0.20-1599354283040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-653ab4ae-e5b1-44d6-9d06-dca7cc78689a,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-87fd3aa3-9f9a-4048-b48a-4e728df1b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d705b3da-eea3-4e97-810e-f03565cba071,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-e1eaadf7-c5f7-4661-9c89-05b62d2f384a,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e1b898f6-6fea-4082-b7b7-8ff91f675e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-e8b1c197-ba1d-4b0f-bda4-7bce2bd84175,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-7f45697a-20fd-489c-a320-4c365afba358,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-e7abd816-6d36-4cf5-8868-4e7ab32aecda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583946950-172.17.0.20-1599354865304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-dc305bdc-f426-4bb0-a1d3-e20bd22a7f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-105086a0-a306-42ca-9143-80ebcdd0fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c2d864ff-ff7d-42d9-b5a9-10ef4d1432e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-bed0bc42-2213-4975-a572-8856f5cff799,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-32d4bd90-cccc-4bf5-b676-b79de66debb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-8fe39c08-c420-4207-a56f-fb4b62f13f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ce467249-baa2-404c-b274-9ae1e81c4de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-7d2c9e6f-18fa-467d-ad21-39c18b528a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583946950-172.17.0.20-1599354865304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-dc305bdc-f426-4bb0-a1d3-e20bd22a7f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-105086a0-a306-42ca-9143-80ebcdd0fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c2d864ff-ff7d-42d9-b5a9-10ef4d1432e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-bed0bc42-2213-4975-a572-8856f5cff799,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-32d4bd90-cccc-4bf5-b676-b79de66debb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-8fe39c08-c420-4207-a56f-fb4b62f13f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-ce467249-baa2-404c-b274-9ae1e81c4de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-7d2c9e6f-18fa-467d-ad21-39c18b528a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951179052-172.17.0.20-1599354979731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-be7ca355-5e80-469a-b228-f616ee7328f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-d379e1a9-cfc4-4cbb-843b-41cd2a812840,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-d255baee-83ca-4f72-86ef-6f6316163726,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d9cd05e6-3dab-4e0a-8cb9-3913e640acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-8081331e-9c38-46ad-a363-b15b6f8b9bda,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-de7490e5-453c-4060-bd4c-931dd2209bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-a8bfccf4-50c2-4857-aa19-7e9245fafd44,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-929058a1-66ff-4250-9f69-774d9d375806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951179052-172.17.0.20-1599354979731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-be7ca355-5e80-469a-b228-f616ee7328f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-d379e1a9-cfc4-4cbb-843b-41cd2a812840,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-d255baee-83ca-4f72-86ef-6f6316163726,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d9cd05e6-3dab-4e0a-8cb9-3913e640acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-8081331e-9c38-46ad-a363-b15b6f8b9bda,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-de7490e5-453c-4060-bd4c-931dd2209bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-a8bfccf4-50c2-4857-aa19-7e9245fafd44,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-929058a1-66ff-4250-9f69-774d9d375806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583284995-172.17.0.20-1599355208936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-184cf892-8701-46d2-a8b8-583b1013ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-dd32a5f8-0ab4-42e5-9d73-4f5713a1ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-7fc4f8c8-77eb-4fa6-817e-cad5a2c3fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-5ce15922-5e59-4249-96c3-e96cf5368c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-5a89448a-5d64-4e6d-80b4-97e21126b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-05141183-54d8-4bf0-8235-58297d51c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-49864ce4-893d-4df1-8901-85a3b360d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-446d3ee1-9909-4066-840d-11f54ec14215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583284995-172.17.0.20-1599355208936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-184cf892-8701-46d2-a8b8-583b1013ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-dd32a5f8-0ab4-42e5-9d73-4f5713a1ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-7fc4f8c8-77eb-4fa6-817e-cad5a2c3fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-5ce15922-5e59-4249-96c3-e96cf5368c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-5a89448a-5d64-4e6d-80b4-97e21126b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-05141183-54d8-4bf0-8235-58297d51c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-49864ce4-893d-4df1-8901-85a3b360d77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-446d3ee1-9909-4066-840d-11f54ec14215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622108802-172.17.0.20-1599355472729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-37275f86-96dc-4518-9c34-f206e6cb37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-06bfef8a-28a4-4df0-8e08-6c3cdd64070f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-d4765a3b-72a5-4125-ab0d-c120ef38c482,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-cf15bff6-75b5-4bfa-84d6-311eb3cadee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-18320ee2-cc11-4b6b-ae1a-6867ea818931,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-4682ee5e-6ad7-4328-a330-511950950032,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-e97408b8-99e3-40a4-a6e2-d2b0b5cf8979,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-519d22d2-1211-48a9-8fb6-5a0853290bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622108802-172.17.0.20-1599355472729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-37275f86-96dc-4518-9c34-f206e6cb37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-06bfef8a-28a4-4df0-8e08-6c3cdd64070f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-d4765a3b-72a5-4125-ab0d-c120ef38c482,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-cf15bff6-75b5-4bfa-84d6-311eb3cadee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-18320ee2-cc11-4b6b-ae1a-6867ea818931,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-4682ee5e-6ad7-4328-a330-511950950032,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-e97408b8-99e3-40a4-a6e2-d2b0b5cf8979,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-519d22d2-1211-48a9-8fb6-5a0853290bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935876491-172.17.0.20-1599356159058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-5d907025-747f-4c3e-8597-60587f65621d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-864654e2-63a5-4732-9c56-9d5ec3f95539,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-ad2d48ab-35cb-4832-824c-aa1bf2c025c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-ef201163-9535-4e0b-9a67-c820a201810b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-e49489ce-151c-41b0-bc64-4305d5f47f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-18fbe443-b7c8-4d19-9969-0f183f826422,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-112a620a-c295-4053-b833-99b60985dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-c1220282-2900-437b-b86a-22607f91c95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935876491-172.17.0.20-1599356159058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-5d907025-747f-4c3e-8597-60587f65621d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-864654e2-63a5-4732-9c56-9d5ec3f95539,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-ad2d48ab-35cb-4832-824c-aa1bf2c025c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-ef201163-9535-4e0b-9a67-c820a201810b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-e49489ce-151c-41b0-bc64-4305d5f47f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-18fbe443-b7c8-4d19-9969-0f183f826422,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-112a620a-c295-4053-b833-99b60985dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-c1220282-2900-437b-b86a-22607f91c95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614750157-172.17.0.20-1599356225939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-fecd2c0f-906f-404d-bbcc-a900e51c36f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-482381e7-d9ec-4d1b-aa95-78e836de4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-19058c8b-1b40-4ad6-aa1b-2ba0ca25ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-7e4ccf4b-8e60-487e-aba2-c1144362038a,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-ac28cc0b-7538-4b09-8327-5dd02ac3536b,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-d79f8350-002b-4a65-8d19-ff46c73d90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-0557d414-8210-4bc2-8a3f-39380da7a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-a7652db4-94af-4afd-9d6a-ae351f75361f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614750157-172.17.0.20-1599356225939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-fecd2c0f-906f-404d-bbcc-a900e51c36f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-482381e7-d9ec-4d1b-aa95-78e836de4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-19058c8b-1b40-4ad6-aa1b-2ba0ca25ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-7e4ccf4b-8e60-487e-aba2-c1144362038a,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-ac28cc0b-7538-4b09-8327-5dd02ac3536b,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-d79f8350-002b-4a65-8d19-ff46c73d90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-0557d414-8210-4bc2-8a3f-39380da7a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-a7652db4-94af-4afd-9d6a-ae351f75361f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859167297-172.17.0.20-1599356414128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-4ec539a5-f8f3-4448-94ea-e25dd387fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8bfec0d8-1b0d-43ef-9751-d2bce2b813ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-bc9af29c-a92e-4b88-ad40-a08112008e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-04ee530c-7c7b-4618-841c-8d748127a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-66d420df-5c91-454c-9278-014e4f5596c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-2bf2d7f5-540c-4e1d-9ef7-5d3a395cc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-889dc774-6172-4ee6-a86b-f911473bb8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-a6b0f1bd-d9b4-4242-89fe-42de5d4e6e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859167297-172.17.0.20-1599356414128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-4ec539a5-f8f3-4448-94ea-e25dd387fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8bfec0d8-1b0d-43ef-9751-d2bce2b813ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-bc9af29c-a92e-4b88-ad40-a08112008e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-04ee530c-7c7b-4618-841c-8d748127a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-66d420df-5c91-454c-9278-014e4f5596c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-2bf2d7f5-540c-4e1d-9ef7-5d3a395cc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-889dc774-6172-4ee6-a86b-f911473bb8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-a6b0f1bd-d9b4-4242-89fe-42de5d4e6e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078815879-172.17.0.20-1599357098766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-951a95d7-b888-426c-922a-a5d57f8104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-935188d8-77c6-4b07-964b-f7f329715a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-c69f40d4-b28a-4bb7-a2b0-5bcc12fdd0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-331acfcf-35fb-42b7-b4f7-957df9bc3691,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7a0a376b-27e1-47bf-8856-870f9a2b5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-0b1be668-5500-45b0-820b-9760ef317867,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-13b47237-8408-4507-8a43-55990bc90cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-c12329b3-0c7a-43d7-9e0d-89868e1f55a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078815879-172.17.0.20-1599357098766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-951a95d7-b888-426c-922a-a5d57f8104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-935188d8-77c6-4b07-964b-f7f329715a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-c69f40d4-b28a-4bb7-a2b0-5bcc12fdd0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-331acfcf-35fb-42b7-b4f7-957df9bc3691,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-7a0a376b-27e1-47bf-8856-870f9a2b5e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-0b1be668-5500-45b0-820b-9760ef317867,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-13b47237-8408-4507-8a43-55990bc90cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-c12329b3-0c7a-43d7-9e0d-89868e1f55a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486723178-172.17.0.20-1599357524126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-27c4b5c8-1438-4be7-85df-966149b3a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-3ac40688-3b9c-4728-b1e9-5bafad6115f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0ba9e9c6-cf47-40b2-91d1-65bf7d603023,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-9af2c4b5-f7c0-46f7-955c-1fba562dc226,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-19102b78-1a45-4ed0-949f-76bf3b4ed311,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9ef32cde-ff61-46ac-be34-a35a5f8a6709,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-0c20ff03-7c2f-48e8-8598-a48a66f33a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-62b9b5ce-5c1e-4756-94a4-8763eb704d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486723178-172.17.0.20-1599357524126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-27c4b5c8-1438-4be7-85df-966149b3a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-3ac40688-3b9c-4728-b1e9-5bafad6115f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0ba9e9c6-cf47-40b2-91d1-65bf7d603023,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-9af2c4b5-f7c0-46f7-955c-1fba562dc226,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-19102b78-1a45-4ed0-949f-76bf3b4ed311,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-9ef32cde-ff61-46ac-be34-a35a5f8a6709,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-0c20ff03-7c2f-48e8-8598-a48a66f33a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-62b9b5ce-5c1e-4756-94a4-8763eb704d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593118125-172.17.0.20-1599357972431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-ea59d27a-f4d6-4681-a478-f0c8a3162473,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-76993a22-2f7c-4971-9af3-e580cd26f165,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5087c4f4-c986-4b98-a29c-80f1d0276015,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-dfd3fd5a-496d-4290-b4ff-f956cff6ce86,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-23daa5fd-86da-41af-a710-21dbec335e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-44eafc60-438d-4da1-a7c6-2489c506af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-1a18449e-1028-4ae8-83b6-9424be464ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-05778fd4-bec3-4805-b9ec-bc6b34b78d1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593118125-172.17.0.20-1599357972431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-ea59d27a-f4d6-4681-a478-f0c8a3162473,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-76993a22-2f7c-4971-9af3-e580cd26f165,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5087c4f4-c986-4b98-a29c-80f1d0276015,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-dfd3fd5a-496d-4290-b4ff-f956cff6ce86,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-23daa5fd-86da-41af-a710-21dbec335e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-44eafc60-438d-4da1-a7c6-2489c506af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-1a18449e-1028-4ae8-83b6-9424be464ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-05778fd4-bec3-4805-b9ec-bc6b34b78d1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797063209-172.17.0.20-1599358490415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-8a64b84d-67e4-4610-9a8c-7652ce56132a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-7004a245-f767-45a9-af4c-1c74410211ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-9709609f-7ac4-4e76-9629-8bf0adc2fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-7306fab0-a93b-472e-8f83-95006d7d9de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-ac8e68f3-b225-4c24-bf19-90db3c3faed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-177c6537-f46f-4857-96be-cfbe08959228,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-e7980c7b-407d-4b52-a178-8b65b5df3348,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-a3a0a172-28c1-454a-bb1c-7341a3a95b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797063209-172.17.0.20-1599358490415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-8a64b84d-67e4-4610-9a8c-7652ce56132a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-7004a245-f767-45a9-af4c-1c74410211ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-9709609f-7ac4-4e76-9629-8bf0adc2fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-7306fab0-a93b-472e-8f83-95006d7d9de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-ac8e68f3-b225-4c24-bf19-90db3c3faed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-177c6537-f46f-4857-96be-cfbe08959228,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-e7980c7b-407d-4b52-a178-8b65b5df3348,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-a3a0a172-28c1-454a-bb1c-7341a3a95b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5450
