reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083365122-172.17.0.17-1599336232891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-d2ae99fb-c868-48cb-a23b-698825e6dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-864c1f4e-39f9-433c-8e58-f4420ac945ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-67655024-585d-4da7-8dd2-38fdf7f16ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-4a31ec99-5445-43d7-b243-534bb5592dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-16546972-9bd5-45aa-9006-b94714aa653d,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2f0013a1-8f39-4ea3-8863-4228383d2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-aac2e5a4-70a5-4c8a-8563-867e1c2cca18,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-4135bffb-d638-48a3-b639-4d877f16553f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083365122-172.17.0.17-1599336232891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-d2ae99fb-c868-48cb-a23b-698825e6dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-864c1f4e-39f9-433c-8e58-f4420ac945ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-67655024-585d-4da7-8dd2-38fdf7f16ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-4a31ec99-5445-43d7-b243-534bb5592dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-16546972-9bd5-45aa-9006-b94714aa653d,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2f0013a1-8f39-4ea3-8863-4228383d2aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-aac2e5a4-70a5-4c8a-8563-867e1c2cca18,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-4135bffb-d638-48a3-b639-4d877f16553f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439250303-172.17.0.17-1599336259399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-f666b49a-ab8e-4eb7-87eb-7d8ba8221d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-4fafdb21-9093-4028-8ec0-453f38def9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-9d1d8ab1-7ed9-4389-8148-bc155ff25102,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-8154c20f-9504-4aee-9bf7-c8399468623c,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-6b9347ab-0623-42ec-aa8e-2e34013f314b,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3720e8db-ae50-436b-873e-b47557fd901a,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-71352d3b-8ef6-4ba0-aecb-14a7ddb7bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-24514a5e-1185-4d59-8444-ea95d4e19a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439250303-172.17.0.17-1599336259399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-f666b49a-ab8e-4eb7-87eb-7d8ba8221d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-4fafdb21-9093-4028-8ec0-453f38def9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-9d1d8ab1-7ed9-4389-8148-bc155ff25102,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-8154c20f-9504-4aee-9bf7-c8399468623c,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-6b9347ab-0623-42ec-aa8e-2e34013f314b,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3720e8db-ae50-436b-873e-b47557fd901a,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-71352d3b-8ef6-4ba0-aecb-14a7ddb7bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-24514a5e-1185-4d59-8444-ea95d4e19a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929595242-172.17.0.17-1599336770083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-0c30f1ff-f5a6-4375-88da-325350d2e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-353cdd32-50fb-4b56-bee5-cb934d5c7049,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-72f23d7d-44c6-451e-94cf-8b5e95e38f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-ea1fdb60-869a-4f3d-8763-61da2059c57a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-790053fd-4aaf-47ed-b247-8ca1df738b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-e459598a-81fb-4984-b37f-cbd124181d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-3fc050a8-a9ea-4606-a61c-6d8d421d242c,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-2b6dd787-c91e-4230-abaa-5911abcf91cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929595242-172.17.0.17-1599336770083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-0c30f1ff-f5a6-4375-88da-325350d2e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-353cdd32-50fb-4b56-bee5-cb934d5c7049,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-72f23d7d-44c6-451e-94cf-8b5e95e38f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-ea1fdb60-869a-4f3d-8763-61da2059c57a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-790053fd-4aaf-47ed-b247-8ca1df738b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-e459598a-81fb-4984-b37f-cbd124181d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-3fc050a8-a9ea-4606-a61c-6d8d421d242c,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-2b6dd787-c91e-4230-abaa-5911abcf91cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618710284-172.17.0.17-1599336961262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35425,DS-fd91c1b4-81d8-4720-bcdd-a7c8a0aa9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-e926e2a7-67f2-4850-bb99-476736d4c092,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-acb2b8e3-f850-47a1-9ec6-ab471bfdbb26,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8d5572dc-4d62-480f-b961-be045df59016,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-815c8a4f-9912-4642-9316-e7a9a2156e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-ec9f1292-5158-4db5-b439-eb538df02ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-4506f314-8733-4c98-bc68-1fb6597ffbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-7c84f6a2-0558-413d-8739-3819f55511d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618710284-172.17.0.17-1599336961262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35425,DS-fd91c1b4-81d8-4720-bcdd-a7c8a0aa9ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-e926e2a7-67f2-4850-bb99-476736d4c092,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-acb2b8e3-f850-47a1-9ec6-ab471bfdbb26,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8d5572dc-4d62-480f-b961-be045df59016,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-815c8a4f-9912-4642-9316-e7a9a2156e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-ec9f1292-5158-4db5-b439-eb538df02ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-4506f314-8733-4c98-bc68-1fb6597ffbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-7c84f6a2-0558-413d-8739-3819f55511d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403109953-172.17.0.17-1599337237223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-df26ef4b-5fa5-4c7b-b798-790825b27012,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-623b76ac-cf64-42a6-be34-3406f5cdef91,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-569a4f83-5a3d-4f70-91d3-820cfb4b39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-afa1fb93-be6f-45cd-b511-e62d27c91c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-54dbf378-6feb-4b0f-b360-9b51c1b07eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-635b8d1d-5a64-465c-948d-cbeff235ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-fdc356c2-5602-4f52-a069-71f8737ebc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f495bb75-c7c6-431d-af96-ec6e308b8bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403109953-172.17.0.17-1599337237223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-df26ef4b-5fa5-4c7b-b798-790825b27012,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-623b76ac-cf64-42a6-be34-3406f5cdef91,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-569a4f83-5a3d-4f70-91d3-820cfb4b39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-afa1fb93-be6f-45cd-b511-e62d27c91c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-54dbf378-6feb-4b0f-b360-9b51c1b07eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-635b8d1d-5a64-465c-948d-cbeff235ac76,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-fdc356c2-5602-4f52-a069-71f8737ebc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f495bb75-c7c6-431d-af96-ec6e308b8bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692808595-172.17.0.17-1599337290879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43652,DS-e81eabcd-295c-47a1-af1b-7e2e4d0b72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-510adf59-cd05-4524-baaf-5c95b8379465,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-fe89ad45-234d-467b-bc06-9b5cfd86afca,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-dca7b59e-c32c-4b6f-bced-2825ad625c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-9a117f24-e392-46c9-8317-2a978547dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-18ea09de-65d0-4096-802f-b3e027ac4cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0d42ddb1-24aa-4ee4-abeb-08a39357ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-ccbf81d0-1da2-406a-9b2e-1015d388022f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692808595-172.17.0.17-1599337290879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43652,DS-e81eabcd-295c-47a1-af1b-7e2e4d0b72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-510adf59-cd05-4524-baaf-5c95b8379465,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-fe89ad45-234d-467b-bc06-9b5cfd86afca,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-dca7b59e-c32c-4b6f-bced-2825ad625c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-9a117f24-e392-46c9-8317-2a978547dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-18ea09de-65d0-4096-802f-b3e027ac4cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0d42ddb1-24aa-4ee4-abeb-08a39357ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-ccbf81d0-1da2-406a-9b2e-1015d388022f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742500206-172.17.0.17-1599337728859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-005e3168-fc11-4b62-b438-eaabd8505b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-660d67bf-2c7e-49a6-9510-0dec9b4cb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-fed10393-79b7-4f9b-b168-b59e8b98288a,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-1795809f-845d-478b-8cfc-5362649a85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-02d0089a-9e94-4b67-860f-4f9278c34c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-09ba3819-f056-4fc0-95be-348fc0833ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-263c224e-0f53-483b-b4a9-ca85d91439ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-70e48828-8e8b-40fb-b09f-571072ced215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742500206-172.17.0.17-1599337728859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-005e3168-fc11-4b62-b438-eaabd8505b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-660d67bf-2c7e-49a6-9510-0dec9b4cb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-fed10393-79b7-4f9b-b168-b59e8b98288a,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-1795809f-845d-478b-8cfc-5362649a85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-02d0089a-9e94-4b67-860f-4f9278c34c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-09ba3819-f056-4fc0-95be-348fc0833ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-263c224e-0f53-483b-b4a9-ca85d91439ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-70e48828-8e8b-40fb-b09f-571072ced215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474412419-172.17.0.17-1599338160841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-925bd646-84bd-442d-922c-ebb54e6b1841,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-35368370-950d-480c-9229-7c27e15a63f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-98dad677-1d3e-4f29-bc26-429540450f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-8d10a527-c8a6-4ee8-b2c8-213e160f0027,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-6dba4593-fd80-4bba-85e6-ef42dc869419,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-1660feb0-a98a-4b3a-984f-83b626603db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-fde8305c-f5e9-4509-bdfb-a034031a5304,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-39026ed6-356a-4ec9-a094-b3f9b2d2a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474412419-172.17.0.17-1599338160841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-925bd646-84bd-442d-922c-ebb54e6b1841,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-35368370-950d-480c-9229-7c27e15a63f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-98dad677-1d3e-4f29-bc26-429540450f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-8d10a527-c8a6-4ee8-b2c8-213e160f0027,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-6dba4593-fd80-4bba-85e6-ef42dc869419,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-1660feb0-a98a-4b3a-984f-83b626603db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-fde8305c-f5e9-4509-bdfb-a034031a5304,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-39026ed6-356a-4ec9-a094-b3f9b2d2a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124941098-172.17.0.17-1599338243326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-28241a99-5181-4d7d-8a5f-887293ce43dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-fb94f0d3-a5cb-4504-98fe-311fcf51cdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-f4a8786e-411f-4eb7-a6c7-4caada5e123b,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ed367219-0b65-426c-a4b4-0c6cf7fc696b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-be291e1e-23b2-467b-ad1f-95e12d425fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-f2574fa5-3dcb-4ed6-a86f-a05f8eb2f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-513f1d13-8b59-4937-a8b0-e64b823dc883,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-4b852854-3398-4429-b1c1-bf48f44823a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124941098-172.17.0.17-1599338243326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-28241a99-5181-4d7d-8a5f-887293ce43dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-fb94f0d3-a5cb-4504-98fe-311fcf51cdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-f4a8786e-411f-4eb7-a6c7-4caada5e123b,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ed367219-0b65-426c-a4b4-0c6cf7fc696b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-be291e1e-23b2-467b-ad1f-95e12d425fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-f2574fa5-3dcb-4ed6-a86f-a05f8eb2f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-513f1d13-8b59-4937-a8b0-e64b823dc883,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-4b852854-3398-4429-b1c1-bf48f44823a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363144075-172.17.0.17-1599338540714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-60f7a377-1f32-45a2-8ac3-4f786c822f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-b4000d25-f5eb-442f-b0bb-e5453c1601e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-6a449660-8472-499e-90bb-9775afa4b720,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-00ef9208-09a1-4fa6-a941-191a3bbb9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1de9bc3a-5af1-49c6-a717-b717b087b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-3feb4ab5-110d-4eca-8172-93ae7300f50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-1caee5c4-514e-4929-97ce-b145a6e9855b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-e3a5c47c-2e4a-45d4-b8c1-4dd192b79144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363144075-172.17.0.17-1599338540714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-60f7a377-1f32-45a2-8ac3-4f786c822f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-b4000d25-f5eb-442f-b0bb-e5453c1601e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-6a449660-8472-499e-90bb-9775afa4b720,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-00ef9208-09a1-4fa6-a941-191a3bbb9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1de9bc3a-5af1-49c6-a717-b717b087b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-3feb4ab5-110d-4eca-8172-93ae7300f50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-1caee5c4-514e-4929-97ce-b145a6e9855b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-e3a5c47c-2e4a-45d4-b8c1-4dd192b79144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015694785-172.17.0.17-1599338841433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-a8677e56-f1ff-4fb9-be19-8c9c6dcc2f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-d76a8a16-0e67-45ef-845c-2666ae03a3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-e3728f7f-4df1-4fe0-91ee-cf3372efc530,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-92dc7942-f0b9-41b1-81a0-c89b667b0390,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-c1ca81ea-2cb2-4d84-9b75-c0c6e25fc214,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-0971a584-61c5-4ea7-9137-4b876c6950f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-a229e594-6e89-467b-b9d5-8fe7584fabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-73abf0c4-1412-4144-93e5-da2469613489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015694785-172.17.0.17-1599338841433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-a8677e56-f1ff-4fb9-be19-8c9c6dcc2f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-d76a8a16-0e67-45ef-845c-2666ae03a3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-e3728f7f-4df1-4fe0-91ee-cf3372efc530,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-92dc7942-f0b9-41b1-81a0-c89b667b0390,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-c1ca81ea-2cb2-4d84-9b75-c0c6e25fc214,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-0971a584-61c5-4ea7-9137-4b876c6950f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-a229e594-6e89-467b-b9d5-8fe7584fabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-73abf0c4-1412-4144-93e5-da2469613489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127068047-172.17.0.17-1599338899856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-862f4c57-3b07-43b9-9205-e0dd3477aadc,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-3863b23e-8173-4cba-a9f4-c5246f79580a,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-52d8f0b4-1c56-4360-9d10-4aa5b1201486,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-a7a24f36-d59a-4687-bbc2-63f5d3832ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-54e03489-dd05-42c1-bd1a-5d2cf0cd2800,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-e71fa211-b6e3-4dfc-bf82-f63fcfd9a5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-f8435118-2e43-4378-ac9a-5acf2763c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-c49cb76a-3f7c-49d3-bba5-93f548e10f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127068047-172.17.0.17-1599338899856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-862f4c57-3b07-43b9-9205-e0dd3477aadc,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-3863b23e-8173-4cba-a9f4-c5246f79580a,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-52d8f0b4-1c56-4360-9d10-4aa5b1201486,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-a7a24f36-d59a-4687-bbc2-63f5d3832ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-54e03489-dd05-42c1-bd1a-5d2cf0cd2800,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-e71fa211-b6e3-4dfc-bf82-f63fcfd9a5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-f8435118-2e43-4378-ac9a-5acf2763c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-c49cb76a-3f7c-49d3-bba5-93f548e10f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119205656-172.17.0.17-1599339081440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-d88f0cfc-379a-41d3-bcf7-156eff66aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-cf8c78f8-6bb7-4c17-a885-c5a8fcb3da5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-5612cc65-84cf-4a61-bc4b-852b4f3cfe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-36c16c37-2f1a-4da5-8690-32487b38dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-17c75687-03d6-4601-9bd7-538aafc46060,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-4d40f873-d34b-4cf2-bfb2-486c29a914b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-372032ef-6689-4bd4-a54f-0f67acc1bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-7045fde0-7806-416f-b0a9-1db895196c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119205656-172.17.0.17-1599339081440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-d88f0cfc-379a-41d3-bcf7-156eff66aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-cf8c78f8-6bb7-4c17-a885-c5a8fcb3da5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-5612cc65-84cf-4a61-bc4b-852b4f3cfe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-36c16c37-2f1a-4da5-8690-32487b38dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-17c75687-03d6-4601-9bd7-538aafc46060,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-4d40f873-d34b-4cf2-bfb2-486c29a914b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-372032ef-6689-4bd4-a54f-0f67acc1bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-7045fde0-7806-416f-b0a9-1db895196c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085271728-172.17.0.17-1599339300994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-171e0f1d-abe8-4bdc-a866-32b5d2739b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-a5a04249-5e7b-45d2-91b4-7de3176be379,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-2b86cf96-a2d9-4c65-b22d-1cbad3cb02d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-dbaf4b87-682a-4726-a168-bb4c654efcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-d5de44fe-f2f3-4ecf-926a-df562c630e87,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-4ab0e979-e6ef-4636-9faf-eb4e25d2e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-761b0977-6326-4714-b9c7-ea43efdeab66,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-f364421a-d82a-4af4-ba9b-4ec1b4506b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085271728-172.17.0.17-1599339300994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-171e0f1d-abe8-4bdc-a866-32b5d2739b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-a5a04249-5e7b-45d2-91b4-7de3176be379,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-2b86cf96-a2d9-4c65-b22d-1cbad3cb02d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-dbaf4b87-682a-4726-a168-bb4c654efcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-d5de44fe-f2f3-4ecf-926a-df562c630e87,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-4ab0e979-e6ef-4636-9faf-eb4e25d2e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-761b0977-6326-4714-b9c7-ea43efdeab66,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-f364421a-d82a-4af4-ba9b-4ec1b4506b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292222655-172.17.0.17-1599339386769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-03f7e46a-817b-44e1-9ec8-a7292ee7f769,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-d67687fb-129b-4a3c-88a2-38f4a1a37ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-935482d8-4d15-4082-87b0-50dfa78df386,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e0b913a5-83bd-4be7-9474-cc03006b6928,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-fc338231-0a36-4927-bc71-3ff0b3fafba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-ad430e37-8db1-4074-8537-23bb2ba16f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-fa71467d-26a0-4d9f-a8f8-11f24f07675f,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-9b9ccf7f-bf27-4beb-8c1d-bdc3b2d58adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292222655-172.17.0.17-1599339386769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-03f7e46a-817b-44e1-9ec8-a7292ee7f769,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-d67687fb-129b-4a3c-88a2-38f4a1a37ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-935482d8-4d15-4082-87b0-50dfa78df386,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e0b913a5-83bd-4be7-9474-cc03006b6928,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-fc338231-0a36-4927-bc71-3ff0b3fafba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-ad430e37-8db1-4074-8537-23bb2ba16f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-fa71467d-26a0-4d9f-a8f8-11f24f07675f,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-9b9ccf7f-bf27-4beb-8c1d-bdc3b2d58adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949340900-172.17.0.17-1599339446598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-778fa0d9-16b2-4cc1-9b70-708bbefdf991,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-e515d583-1334-4f72-8c3a-bec8d8f73bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-8f85ce22-ee4f-4752-ba2d-af0f3feff6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-5290f933-5f7d-41aa-9ab4-f6a7e89cd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b8a590dd-f1dc-448b-b0c4-54c2672c5983,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-4fe8c684-ea96-4865-bc69-40b66c1e1100,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-6fe7fb58-1af2-47bb-98c5-d7a6e7274051,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-2e7b8113-034f-410c-8a2f-ec977f39520b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949340900-172.17.0.17-1599339446598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-778fa0d9-16b2-4cc1-9b70-708bbefdf991,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-e515d583-1334-4f72-8c3a-bec8d8f73bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-8f85ce22-ee4f-4752-ba2d-af0f3feff6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-5290f933-5f7d-41aa-9ab4-f6a7e89cd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b8a590dd-f1dc-448b-b0c4-54c2672c5983,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-4fe8c684-ea96-4865-bc69-40b66c1e1100,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-6fe7fb58-1af2-47bb-98c5-d7a6e7274051,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-2e7b8113-034f-410c-8a2f-ec977f39520b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952036172-172.17.0.17-1599339639161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-344c52d2-3871-4ff5-92cf-a029e46ce4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-83538f37-1e39-4152-82d7-dc59068bded2,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-66b70c29-0d1a-41ac-9fc4-47b287fb0c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-2a553340-d211-4cf9-8be1-74023d026317,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-3c40bd3e-8246-4d5c-8efa-0fa3bdf9d7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-edfa4911-f086-4b6b-8891-b86ba4422368,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-e29f41fb-cbad-4305-a08b-8d44df973bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-86588bb2-9586-48a4-bcb0-fd6bd4244229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952036172-172.17.0.17-1599339639161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-344c52d2-3871-4ff5-92cf-a029e46ce4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-83538f37-1e39-4152-82d7-dc59068bded2,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-66b70c29-0d1a-41ac-9fc4-47b287fb0c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-2a553340-d211-4cf9-8be1-74023d026317,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-3c40bd3e-8246-4d5c-8efa-0fa3bdf9d7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-edfa4911-f086-4b6b-8891-b86ba4422368,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-e29f41fb-cbad-4305-a08b-8d44df973bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-86588bb2-9586-48a4-bcb0-fd6bd4244229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124231994-172.17.0.17-1599339751659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45386,DS-21f4078e-2908-4c34-a88a-a47b75f2480a,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-71823618-47a3-4025-b528-682797bc0121,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-c05b8ee8-4e82-454f-8a24-2f3013406c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-fd8e6bb6-d474-40cd-8b3c-04ea1549381a,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-0de2328e-a69e-487f-a23e-caf9c5e254a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-468e8802-6c63-40dc-8d7a-39bf257fc7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-8d10815a-8a77-4f1b-b2f9-e9849a4797ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-9f6a742d-fedd-4319-ace0-737a423fc2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124231994-172.17.0.17-1599339751659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45386,DS-21f4078e-2908-4c34-a88a-a47b75f2480a,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-71823618-47a3-4025-b528-682797bc0121,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-c05b8ee8-4e82-454f-8a24-2f3013406c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-fd8e6bb6-d474-40cd-8b3c-04ea1549381a,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-0de2328e-a69e-487f-a23e-caf9c5e254a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-468e8802-6c63-40dc-8d7a-39bf257fc7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-8d10815a-8a77-4f1b-b2f9-e9849a4797ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-9f6a742d-fedd-4319-ace0-737a423fc2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886419878-172.17.0.17-1599339777259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-91221922-6230-4895-b3b9-59c520d26102,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-48806717-efdc-4363-b00f-b59d4a9d1028,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-d6ed390d-140c-42d9-b6b9-27b79ea5ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-515db5c3-5df9-4bb8-aa00-10e9f8a26670,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-ca024c96-027b-4b6d-abe8-74216da78c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-4940cb80-e0af-4ded-85c6-f53f3cf51ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-beea6b1c-b1bf-4735-ab0f-59903e554637,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-7a3a351a-aed3-4e54-9485-4e3bc43ba24f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886419878-172.17.0.17-1599339777259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40002,DS-91221922-6230-4895-b3b9-59c520d26102,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-48806717-efdc-4363-b00f-b59d4a9d1028,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-d6ed390d-140c-42d9-b6b9-27b79ea5ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-515db5c3-5df9-4bb8-aa00-10e9f8a26670,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-ca024c96-027b-4b6d-abe8-74216da78c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-4940cb80-e0af-4ded-85c6-f53f3cf51ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-beea6b1c-b1bf-4735-ab0f-59903e554637,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-7a3a351a-aed3-4e54-9485-4e3bc43ba24f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026067010-172.17.0.17-1599339805191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-d107b9a4-093f-4e82-bfc3-cccb5f598ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1aabb5af-caaf-4932-a907-286031e0e29e,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-513756b4-529c-49f5-8504-8cadb89255f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-35650c78-2c16-4d21-aa6f-138784f05d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-722833ce-fd91-41ad-b3bb-f52196963a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-87fbdb3d-7128-4f4f-9f0d-526b044bf8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-5a9fad2a-594b-4faa-9cee-8e0fa8e0dc27,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-93ac72df-eaa1-4dcd-999c-aafd01c0462f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026067010-172.17.0.17-1599339805191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-d107b9a4-093f-4e82-bfc3-cccb5f598ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1aabb5af-caaf-4932-a907-286031e0e29e,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-513756b4-529c-49f5-8504-8cadb89255f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-35650c78-2c16-4d21-aa6f-138784f05d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-722833ce-fd91-41ad-b3bb-f52196963a44,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-87fbdb3d-7128-4f4f-9f0d-526b044bf8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-5a9fad2a-594b-4faa-9cee-8e0fa8e0dc27,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-93ac72df-eaa1-4dcd-999c-aafd01c0462f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: authentication
v2: privacy
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644238895-172.17.0.17-1599340501940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-78f6b3e7-dbbd-4f08-b79a-0f5b7d8df4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-640717d0-7607-48f5-8389-5e7a010002f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-058de967-6110-457a-b77f-ec17592ccf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-4dcc8245-9262-4f2c-ab14-c9c08b416569,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-f3836956-6abf-4119-957e-492d3fce2107,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-8d6535bf-9777-4764-bdb9-d1b06855e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-b4aad93a-c732-4126-a126-60f34837b715,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-a872179e-5e98-491b-8c81-a5262e90e069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644238895-172.17.0.17-1599340501940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-78f6b3e7-dbbd-4f08-b79a-0f5b7d8df4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-640717d0-7607-48f5-8389-5e7a010002f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-058de967-6110-457a-b77f-ec17592ccf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-4dcc8245-9262-4f2c-ab14-c9c08b416569,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-f3836956-6abf-4119-957e-492d3fce2107,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-8d6535bf-9777-4764-bdb9-d1b06855e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-b4aad93a-c732-4126-a126-60f34837b715,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-a872179e-5e98-491b-8c81-a5262e90e069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4353
