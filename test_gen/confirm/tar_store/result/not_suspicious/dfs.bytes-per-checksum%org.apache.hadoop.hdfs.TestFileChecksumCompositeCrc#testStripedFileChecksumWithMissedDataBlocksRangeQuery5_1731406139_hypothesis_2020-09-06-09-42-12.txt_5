reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319043302-172.17.0.8-1599385609502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-9fcccb62-48d4-4918-8e12-4c01880fcbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-466ea4f5-fbf2-42f0-bee4-427d3cd19672,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e18c0ad0-b52d-4d4b-9007-8b1eeee12de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-28f3c671-5de8-4013-904c-397f657acbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-cd51a8f1-353b-45a6-b74d-c9ff17925743,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-35cf8142-d739-4d32-a5bd-75c920007704,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-36f33be0-05ea-4162-a2b0-be21e4b13150,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-2d638f8d-d950-4c7c-b331-4117e53c5102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319043302-172.17.0.8-1599385609502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-9fcccb62-48d4-4918-8e12-4c01880fcbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-466ea4f5-fbf2-42f0-bee4-427d3cd19672,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e18c0ad0-b52d-4d4b-9007-8b1eeee12de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-28f3c671-5de8-4013-904c-397f657acbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-cd51a8f1-353b-45a6-b74d-c9ff17925743,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-35cf8142-d739-4d32-a5bd-75c920007704,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-36f33be0-05ea-4162-a2b0-be21e4b13150,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-2d638f8d-d950-4c7c-b331-4117e53c5102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913546402-172.17.0.8-1599385872042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-7ff57e7a-e549-41f9-aca5-02ce8b3406a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-45b578f1-9612-42ad-b0fa-fb9bbd36e7df,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-36b70697-215f-4ffe-93e0-05aa6e6214b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-6181c41a-77b6-4dd7-b95b-fdbd703e5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-8d56758e-f9eb-4158-8242-a561e681813f,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-7a8872d9-1eba-45d3-8b01-cfbb7cd526ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-5ebb0c06-a6c1-4632-b307-a9095fc7f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-4213904c-1ef5-4291-b011-5dfbd666ef48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913546402-172.17.0.8-1599385872042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-7ff57e7a-e549-41f9-aca5-02ce8b3406a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-45b578f1-9612-42ad-b0fa-fb9bbd36e7df,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-36b70697-215f-4ffe-93e0-05aa6e6214b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-6181c41a-77b6-4dd7-b95b-fdbd703e5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-8d56758e-f9eb-4158-8242-a561e681813f,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-7a8872d9-1eba-45d3-8b01-cfbb7cd526ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-5ebb0c06-a6c1-4632-b307-a9095fc7f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-4213904c-1ef5-4291-b011-5dfbd666ef48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005087499-172.17.0.8-1599385927586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-2e1d426c-4a6e-474e-8cc4-688a00f62ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-3d7e842d-bcbe-44df-b0a4-76a9f87b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-3364af14-9658-40ef-948d-7b44630bbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-d7268391-f620-46b5-882d-edec9ca6d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-1d697383-9988-4f8a-b04c-2a3882d5bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d6f10c57-c006-4715-b115-4218dafd4620,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-f6f4e6fa-0877-4e97-8dcc-26b80217082f,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-9201cc2f-c018-4579-a453-7c5a21231c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005087499-172.17.0.8-1599385927586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-2e1d426c-4a6e-474e-8cc4-688a00f62ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-3d7e842d-bcbe-44df-b0a4-76a9f87b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-3364af14-9658-40ef-948d-7b44630bbef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-d7268391-f620-46b5-882d-edec9ca6d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-1d697383-9988-4f8a-b04c-2a3882d5bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d6f10c57-c006-4715-b115-4218dafd4620,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-f6f4e6fa-0877-4e97-8dcc-26b80217082f,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-9201cc2f-c018-4579-a453-7c5a21231c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154707355-172.17.0.8-1599386142010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-c80b333f-a4b8-4f30-bb17-3b9385a83c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-37e446a5-7cde-4101-b1b4-4d7982e381b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-9803adf8-2f21-493a-a690-b6f1845c61c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-aed1c8f2-8e34-4480-97c3-6ad1b81e780d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-9c284acc-836d-426f-ac1b-bbf341a0fcee,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-041fdce4-40e4-49ff-af6e-8570cf49103b,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-a1a8e969-29fb-4e61-a5ea-0c7b6ee2b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-265dc35c-94a0-4d60-9387-ff9fda7bdfde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154707355-172.17.0.8-1599386142010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-c80b333f-a4b8-4f30-bb17-3b9385a83c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-37e446a5-7cde-4101-b1b4-4d7982e381b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-9803adf8-2f21-493a-a690-b6f1845c61c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-aed1c8f2-8e34-4480-97c3-6ad1b81e780d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-9c284acc-836d-426f-ac1b-bbf341a0fcee,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-041fdce4-40e4-49ff-af6e-8570cf49103b,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-a1a8e969-29fb-4e61-a5ea-0c7b6ee2b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-265dc35c-94a0-4d60-9387-ff9fda7bdfde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60789288-172.17.0.8-1599386175754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-61f5d610-be7e-4f2e-9a5f-de17242872a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-455ed84b-04ff-4382-9852-5d9d44907eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-fa191fb3-9254-4be9-9238-9047bec935a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b92e698e-7bed-4ddc-bfee-0822191494d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-1250ad54-ec06-4a96-8bd0-66bee079f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-a645bf1f-d5e4-41e7-9850-957f5c2d9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-32dbbfa9-8b29-493c-b404-6293458a113f,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-f6a2a1ee-8119-4b20-9970-8c8bee00dbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60789288-172.17.0.8-1599386175754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-61f5d610-be7e-4f2e-9a5f-de17242872a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-455ed84b-04ff-4382-9852-5d9d44907eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-fa191fb3-9254-4be9-9238-9047bec935a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b92e698e-7bed-4ddc-bfee-0822191494d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-1250ad54-ec06-4a96-8bd0-66bee079f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-a645bf1f-d5e4-41e7-9850-957f5c2d9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-32dbbfa9-8b29-493c-b404-6293458a113f,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-f6a2a1ee-8119-4b20-9970-8c8bee00dbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782275005-172.17.0.8-1599386209508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-f660c52a-de55-4ffc-8559-bd75941f392b,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1b7e033f-96d9-405d-898a-91f94edc317c,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-438b13d0-5dd6-49b5-819c-8291851e4168,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-70f98a89-db21-4397-98ba-af96e026b4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1e246b42-1d66-410e-ae10-c7fe8a360278,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-be853cf6-830c-43aa-b00f-f7d0de820d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-d3b5e7e2-5333-4396-83fb-ae15d1a3e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-a47aa521-502e-4e22-a64f-8e51419eacf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782275005-172.17.0.8-1599386209508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-f660c52a-de55-4ffc-8559-bd75941f392b,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1b7e033f-96d9-405d-898a-91f94edc317c,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-438b13d0-5dd6-49b5-819c-8291851e4168,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-70f98a89-db21-4397-98ba-af96e026b4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1e246b42-1d66-410e-ae10-c7fe8a360278,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-be853cf6-830c-43aa-b00f-f7d0de820d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-d3b5e7e2-5333-4396-83fb-ae15d1a3e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-a47aa521-502e-4e22-a64f-8e51419eacf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534334148-172.17.0.8-1599386243028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-3bd88afb-9a48-4e5f-855e-a8670847b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-d239a480-aa47-4df2-aa66-72918fe7da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-761bd3fd-d10b-49dd-a34e-0d6e0dcff6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-7cac96ef-294b-4d16-a1da-c617bda5b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-6496f1ba-3b6d-4fcb-a6f6-09d0a094ceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-26b371ec-68f3-403b-bfc5-836f168c134f,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-a5bc39ba-ffb3-4231-acdd-a43e7db6b637,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-37c0037a-68bd-429e-9e05-e423256bac3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534334148-172.17.0.8-1599386243028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-3bd88afb-9a48-4e5f-855e-a8670847b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-d239a480-aa47-4df2-aa66-72918fe7da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-761bd3fd-d10b-49dd-a34e-0d6e0dcff6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-7cac96ef-294b-4d16-a1da-c617bda5b312,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-6496f1ba-3b6d-4fcb-a6f6-09d0a094ceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-26b371ec-68f3-403b-bfc5-836f168c134f,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-a5bc39ba-ffb3-4231-acdd-a43e7db6b637,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-37c0037a-68bd-429e-9e05-e423256bac3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377132565-172.17.0.8-1599386276683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-3c9fb93a-2993-4d9f-ba8f-39f76da4c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-297633e0-e421-4064-97cb-fd1b1e6269af,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-70c67f4f-913e-4377-aa55-7997f4dac295,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-78e39547-5684-4283-a055-78bd940cb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-972f2037-2f26-42f0-9ce6-c0a91f6806c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-ea23a277-b3f8-4bd8-a6e5-a6305c618b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-ad2c72bd-4be2-47cd-b941-63f75d2bf45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-a4545e93-84b6-4791-9a7e-8a1ad6332841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377132565-172.17.0.8-1599386276683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-3c9fb93a-2993-4d9f-ba8f-39f76da4c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-297633e0-e421-4064-97cb-fd1b1e6269af,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-70c67f4f-913e-4377-aa55-7997f4dac295,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-78e39547-5684-4283-a055-78bd940cb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-972f2037-2f26-42f0-9ce6-c0a91f6806c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-ea23a277-b3f8-4bd8-a6e5-a6305c618b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-ad2c72bd-4be2-47cd-b941-63f75d2bf45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-a4545e93-84b6-4791-9a7e-8a1ad6332841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816861203-172.17.0.8-1599386478834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-1b471ab9-7db8-4f7c-b353-2e100e5abee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-87ed8198-0796-4458-8772-59266cf0ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-3efd4b2d-417a-4e24-bd9c-bb2376d4c434,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-2f09d839-4cb5-45ce-8380-d1b795f9c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-52d56214-d27c-49a0-b072-f2a5e4b0d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-307f7ab0-b312-4872-b771-c59152f210ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-a273c6c2-431e-4676-8ce8-f9fd9e509a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d5830ba1-644c-4035-a239-e1afab2c162b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816861203-172.17.0.8-1599386478834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-1b471ab9-7db8-4f7c-b353-2e100e5abee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-87ed8198-0796-4458-8772-59266cf0ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-3efd4b2d-417a-4e24-bd9c-bb2376d4c434,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-2f09d839-4cb5-45ce-8380-d1b795f9c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-52d56214-d27c-49a0-b072-f2a5e4b0d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-307f7ab0-b312-4872-b771-c59152f210ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-a273c6c2-431e-4676-8ce8-f9fd9e509a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d5830ba1-644c-4035-a239-e1afab2c162b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438967573-172.17.0.8-1599386576787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-a68ccf3d-195d-4625-9a9e-a1252cbaae56,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-167873fb-882d-4f22-97e3-8fae9ca9cb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-87dd64ac-8e9f-4a3b-ac97-69daad806d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-d6df8188-9229-4c3a-96f4-5b5cae8eb2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-3147f05d-f8cb-4806-9def-56af299f163f,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-50bf4cd6-5584-4dd3-893f-e3b4f716dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-8bd3cf34-b3d8-40e6-a4c1-0cf104c75fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-8032560f-2b73-46c2-9db0-5a6b9c68b7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438967573-172.17.0.8-1599386576787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-a68ccf3d-195d-4625-9a9e-a1252cbaae56,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-167873fb-882d-4f22-97e3-8fae9ca9cb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-87dd64ac-8e9f-4a3b-ac97-69daad806d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-d6df8188-9229-4c3a-96f4-5b5cae8eb2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-3147f05d-f8cb-4806-9def-56af299f163f,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-50bf4cd6-5584-4dd3-893f-e3b4f716dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-8bd3cf34-b3d8-40e6-a4c1-0cf104c75fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-8032560f-2b73-46c2-9db0-5a6b9c68b7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184654673-172.17.0.8-1599386609418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-d8e5dbf5-decd-4be7-abe7-fbe6fcf52943,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-edcd26df-cce2-45a6-99c2-001ad1f1b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-4fab7087-190f-43bd-8581-26e278808b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-2b1a6448-e843-42af-8f04-edf51f8e8663,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-893ebb6a-948b-4976-85b5-ca74827b0e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-ab674a75-2262-49ac-a229-b73ac6b81872,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-a2dc8f8b-3158-498b-b9ad-c458f530f642,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-c9b61d6e-b946-49af-9046-294cfef2f039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184654673-172.17.0.8-1599386609418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-d8e5dbf5-decd-4be7-abe7-fbe6fcf52943,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-edcd26df-cce2-45a6-99c2-001ad1f1b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-4fab7087-190f-43bd-8581-26e278808b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-2b1a6448-e843-42af-8f04-edf51f8e8663,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-893ebb6a-948b-4976-85b5-ca74827b0e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-ab674a75-2262-49ac-a229-b73ac6b81872,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-a2dc8f8b-3158-498b-b9ad-c458f530f642,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-c9b61d6e-b946-49af-9046-294cfef2f039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478243767-172.17.0.8-1599386838644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38048,DS-69038d75-d452-473c-9320-f7a47bd4dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-bd7cdfde-eb53-4808-bc98-e13213b975d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-52cfb8a4-1566-4f5e-8725-981f85cc114c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-a4f63bdc-8dfa-43a1-a45f-4f3af682de99,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-0b35cd97-58cc-4fcc-87f4-091223da5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8610364f-7af9-4dd1-869f-9752eecf2387,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-21b0591e-ef64-43ec-bb95-c761f7eb8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b4cf0d27-66af-467c-9ba7-76c0339ac2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478243767-172.17.0.8-1599386838644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38048,DS-69038d75-d452-473c-9320-f7a47bd4dd81,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-bd7cdfde-eb53-4808-bc98-e13213b975d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-52cfb8a4-1566-4f5e-8725-981f85cc114c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-a4f63bdc-8dfa-43a1-a45f-4f3af682de99,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-0b35cd97-58cc-4fcc-87f4-091223da5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8610364f-7af9-4dd1-869f-9752eecf2387,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-21b0591e-ef64-43ec-bb95-c761f7eb8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-b4cf0d27-66af-467c-9ba7-76c0339ac2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912978288-172.17.0.8-1599386855293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-cede6868-423e-459c-a55e-a04894bbbd23,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-d04a13e8-b073-447b-9b14-acf027588f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-7fe1c27e-69c8-4905-bcbb-53d33bdac935,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-88822c20-e885-4bea-b27b-636041cabceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-9ddcfdd4-07e1-4dee-ac79-f741a084ee63,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-7af5f4ac-dbb3-47e2-9c5a-187d1327f8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-2d6d931d-d366-4ce6-9cf5-761555a6f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-2ec460a4-232a-439c-8fc7-91185a57ad3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912978288-172.17.0.8-1599386855293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-cede6868-423e-459c-a55e-a04894bbbd23,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-d04a13e8-b073-447b-9b14-acf027588f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-7fe1c27e-69c8-4905-bcbb-53d33bdac935,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-88822c20-e885-4bea-b27b-636041cabceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-9ddcfdd4-07e1-4dee-ac79-f741a084ee63,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-7af5f4ac-dbb3-47e2-9c5a-187d1327f8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-2d6d931d-d366-4ce6-9cf5-761555a6f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-2ec460a4-232a-439c-8fc7-91185a57ad3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822597396-172.17.0.8-1599386937689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-645a16bd-3bec-4cdc-becb-8df4b03926df,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-c409a11c-43a7-441c-9196-d2ebd862d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-4b33bdc8-3d4d-4def-9e5c-e59180a95c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-5b1f1750-e7df-40c5-9b20-55d6d9afa7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-26ceb4af-d7d8-4c26-9f22-4b121122c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-3724f697-a5d5-48f4-a1ab-d5e72f436a02,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-9d49e431-e464-43a8-a549-f5c54b71092f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-d4164561-0f3e-4ed2-9564-7e29cb4ded5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822597396-172.17.0.8-1599386937689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-645a16bd-3bec-4cdc-becb-8df4b03926df,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-c409a11c-43a7-441c-9196-d2ebd862d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-4b33bdc8-3d4d-4def-9e5c-e59180a95c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-5b1f1750-e7df-40c5-9b20-55d6d9afa7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-26ceb4af-d7d8-4c26-9f22-4b121122c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-3724f697-a5d5-48f4-a1ab-d5e72f436a02,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-9d49e431-e464-43a8-a549-f5c54b71092f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-d4164561-0f3e-4ed2-9564-7e29cb4ded5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273113005-172.17.0.8-1599387115727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-56162ca3-2fd1-4023-8471-6d17a0712e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-ba898b4a-12ce-43b9-bb0a-42780a1cea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-5e0ead63-755a-4981-aeae-1cbe84911d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-d1d48e01-2674-46e1-a9c3-0ea7dc6c9e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-78959231-1de6-46dc-9dd3-7bba26a366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-d45566d2-0e2e-4a9a-9f2e-14f96a92db3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-f2e8ff1f-32f9-42df-a84a-421a76bbd9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-72edd6b9-3ee5-407d-8025-642a3860f4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273113005-172.17.0.8-1599387115727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-56162ca3-2fd1-4023-8471-6d17a0712e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-ba898b4a-12ce-43b9-bb0a-42780a1cea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-5e0ead63-755a-4981-aeae-1cbe84911d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-d1d48e01-2674-46e1-a9c3-0ea7dc6c9e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-78959231-1de6-46dc-9dd3-7bba26a366f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-d45566d2-0e2e-4a9a-9f2e-14f96a92db3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-f2e8ff1f-32f9-42df-a84a-421a76bbd9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-72edd6b9-3ee5-407d-8025-642a3860f4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490490313-172.17.0.8-1599387132379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-5adecf12-1a9d-470b-9ca4-d6f9ab0ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d1fe31af-686c-4813-9f0b-8f54e17100d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b16cd88b-c8e4-4f4f-aad2-ed302cade809,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-9406a863-1026-4de9-8a72-65a6363434b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-ee57096f-ebba-40f5-a1d8-12c5b76daf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-2d1e587a-28b3-4a30-83c6-c198c58fd418,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-d6a09b7c-311c-4d58-a4a1-a34fff469e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-311d5a7f-b923-49f8-8845-f1d3e2c6b137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490490313-172.17.0.8-1599387132379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-5adecf12-1a9d-470b-9ca4-d6f9ab0ec8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d1fe31af-686c-4813-9f0b-8f54e17100d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b16cd88b-c8e4-4f4f-aad2-ed302cade809,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-9406a863-1026-4de9-8a72-65a6363434b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-ee57096f-ebba-40f5-a1d8-12c5b76daf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-2d1e587a-28b3-4a30-83c6-c198c58fd418,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-d6a09b7c-311c-4d58-a4a1-a34fff469e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-311d5a7f-b923-49f8-8845-f1d3e2c6b137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450943677-172.17.0.8-1599387278029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-ebcf8f1e-ad8b-4773-b926-cd988b336f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-ca1bc1d0-52f0-406c-92e5-5e1dbe766200,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-dddff5db-eb25-43d7-8120-13ff8c640a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-79cc8182-b10f-411e-b738-6784011d5863,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a7f2f238-2de2-4d30-a082-86cc1afb8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-3b8a3086-52ec-4c6d-9550-075ec0789d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a7c50bda-821c-479f-bef3-be729dc8e487,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-9d631b74-1fa5-4814-a1f7-c3f8a048c231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450943677-172.17.0.8-1599387278029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-ebcf8f1e-ad8b-4773-b926-cd988b336f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-ca1bc1d0-52f0-406c-92e5-5e1dbe766200,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-dddff5db-eb25-43d7-8120-13ff8c640a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-79cc8182-b10f-411e-b738-6784011d5863,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a7f2f238-2de2-4d30-a082-86cc1afb8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-3b8a3086-52ec-4c6d-9550-075ec0789d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a7c50bda-821c-479f-bef3-be729dc8e487,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-9d631b74-1fa5-4814-a1f7-c3f8a048c231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009519619-172.17.0.8-1599387411407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-a43dbec5-cfc6-4464-a20c-84d801458bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-264a2790-3022-4531-aad0-4e813823b059,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-eaa3805a-4b78-4010-af43-eb0acc2150bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-125d1091-abed-4956-b545-5bba04084459,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-4df25790-d315-4754-bc42-6c1db55f5286,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-c0aacd69-94db-4085-90e3-f26171be7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6ceb3abc-245e-42cb-8442-1fad39bba90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9b2a2b82-9bd6-43d2-85ef-a92664548582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009519619-172.17.0.8-1599387411407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-a43dbec5-cfc6-4464-a20c-84d801458bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-264a2790-3022-4531-aad0-4e813823b059,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-eaa3805a-4b78-4010-af43-eb0acc2150bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-125d1091-abed-4956-b545-5bba04084459,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-4df25790-d315-4754-bc42-6c1db55f5286,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-c0aacd69-94db-4085-90e3-f26171be7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6ceb3abc-245e-42cb-8442-1fad39bba90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9b2a2b82-9bd6-43d2-85ef-a92664548582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188167066-172.17.0.8-1599387510720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-660d9185-e9e8-4039-83f0-f470009f4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-732d632f-cbfc-4b53-970a-86dfaf5a461e,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7f02b0d6-baa2-4c16-b02d-d390dadc6327,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-e26ced54-6c9f-4eda-9531-29a0d09977d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-89edd699-33a8-4577-8439-9798bf1ebddf,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-dfcb06f9-0369-46fa-b9fc-b42605ff8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-ba876c1d-5b36-4b21-acb5-6461f54eff64,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-b4e38ad5-b6ae-4278-ada5-8db772696145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188167066-172.17.0.8-1599387510720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-660d9185-e9e8-4039-83f0-f470009f4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-732d632f-cbfc-4b53-970a-86dfaf5a461e,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7f02b0d6-baa2-4c16-b02d-d390dadc6327,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-e26ced54-6c9f-4eda-9531-29a0d09977d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-89edd699-33a8-4577-8439-9798bf1ebddf,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-dfcb06f9-0369-46fa-b9fc-b42605ff8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-ba876c1d-5b36-4b21-acb5-6461f54eff64,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-b4e38ad5-b6ae-4278-ada5-8db772696145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619575070-172.17.0.8-1599387853362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-610cfce6-dede-4c88-bed0-dfddc94e218e,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-5e891c41-04c0-479a-b6ff-1aeda64992af,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-cf4a91d2-92d7-423c-8f00-ecaf5d76aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-08c6104e-f8bd-4a16-b140-2162fdf43e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-5a8f8808-8f18-4146-9150-6f39454cd984,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-ae830b93-8ce7-4f97-bfd9-4a7e1973f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f08cd1b3-789e-4b70-af55-f1e5b8425b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-814434eb-01a7-4935-894c-e283f466d0af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619575070-172.17.0.8-1599387853362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-610cfce6-dede-4c88-bed0-dfddc94e218e,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-5e891c41-04c0-479a-b6ff-1aeda64992af,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-cf4a91d2-92d7-423c-8f00-ecaf5d76aeae,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-08c6104e-f8bd-4a16-b140-2162fdf43e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-5a8f8808-8f18-4146-9150-6f39454cd984,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-ae830b93-8ce7-4f97-bfd9-4a7e1973f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f08cd1b3-789e-4b70-af55-f1e5b8425b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-814434eb-01a7-4935-894c-e283f466d0af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306946358-172.17.0.8-1599387901873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-2a6015eb-f98d-4b92-beac-cf1459b68c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-7a8ad599-facf-4808-9498-7a0f94bcf728,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-e78baaa6-4d31-4a96-89b1-a564b26c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-6b9042ca-6795-4963-ad3a-0f9a76c1ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-0b5f4403-6d7d-4740-b9d6-ecc4ececf67a,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-3cd61e9f-db19-4e84-a7c9-f4208045fbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-075120b7-b6d2-4ac4-a6dd-9dbc9b22203b,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-87570d4d-f163-4dee-b23c-11e8a5500024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306946358-172.17.0.8-1599387901873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-2a6015eb-f98d-4b92-beac-cf1459b68c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-7a8ad599-facf-4808-9498-7a0f94bcf728,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-e78baaa6-4d31-4a96-89b1-a564b26c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-6b9042ca-6795-4963-ad3a-0f9a76c1ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-0b5f4403-6d7d-4740-b9d6-ecc4ececf67a,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-3cd61e9f-db19-4e84-a7c9-f4208045fbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-075120b7-b6d2-4ac4-a6dd-9dbc9b22203b,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-87570d4d-f163-4dee-b23c-11e8a5500024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990773240-172.17.0.8-1599387918411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-8da602b8-aad7-4284-833e-21d5e88e3e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-4f45f301-b81e-4431-9c1c-69038e7184ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-30907b54-80bc-427c-bc0d-9c410515e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1701adf-ad19-4302-b8ce-3a8dff280939,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-e02a487f-7a7e-4b82-b4fa-d30a683ab2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-109b3623-bb22-4d43-ab1e-ec211c506cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-1414f57c-94a2-4705-886c-138af91e6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-72329879-47bb-4a51-8ba4-ef55de255e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990773240-172.17.0.8-1599387918411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-8da602b8-aad7-4284-833e-21d5e88e3e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-4f45f301-b81e-4431-9c1c-69038e7184ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-30907b54-80bc-427c-bc0d-9c410515e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1701adf-ad19-4302-b8ce-3a8dff280939,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-e02a487f-7a7e-4b82-b4fa-d30a683ab2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-109b3623-bb22-4d43-ab1e-ec211c506cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-1414f57c-94a2-4705-886c-138af91e6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-72329879-47bb-4a51-8ba4-ef55de255e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208395543-172.17.0.8-1599387967514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41373,DS-aff8945d-f5db-49cd-8c7e-b2ac7a4e5820,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-2ff6f1e7-b471-4986-b9e5-c8687af4099e,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-c750fde9-2907-4df2-9df2-434e96404b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-151c70ad-3d50-450c-838f-e7fb5e31109a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0975419d-0cbf-4500-9e11-c25644122b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-6ec2e6fe-af0d-49ed-b01a-3382ea40bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-81a4bdf2-39c0-4c19-8b8d-5454da657d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-8d1306b3-10fc-4e59-83ba-0ade40837201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208395543-172.17.0.8-1599387967514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41373,DS-aff8945d-f5db-49cd-8c7e-b2ac7a4e5820,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-2ff6f1e7-b471-4986-b9e5-c8687af4099e,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-c750fde9-2907-4df2-9df2-434e96404b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-151c70ad-3d50-450c-838f-e7fb5e31109a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0975419d-0cbf-4500-9e11-c25644122b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-6ec2e6fe-af0d-49ed-b01a-3382ea40bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-81a4bdf2-39c0-4c19-8b8d-5454da657d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-8d1306b3-10fc-4e59-83ba-0ade40837201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 2726
