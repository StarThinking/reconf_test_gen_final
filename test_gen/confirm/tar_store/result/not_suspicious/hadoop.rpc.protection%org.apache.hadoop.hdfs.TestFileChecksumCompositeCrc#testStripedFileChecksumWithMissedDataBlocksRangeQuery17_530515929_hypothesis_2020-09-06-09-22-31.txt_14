reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37960929-172.17.0.5-1599384194775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-562129ba-f717-4a61-ae04-639eee6ae1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0b58f9bf-fee4-414a-896b-2adeaaec39d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d2c8b5e6-fa56-4c27-876c-925895b6a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ef7a9e89-e012-434f-b873-b6e2bfc94f69,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-99b541cf-4d0f-45e3-924c-909ff39790a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-a5a68c5a-aa08-4d6b-b987-37bad529ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-f834d27c-751c-4d7c-a39c-06c923b8d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-99c906b1-94bc-48df-a716-64b5c9090460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37960929-172.17.0.5-1599384194775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-562129ba-f717-4a61-ae04-639eee6ae1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0b58f9bf-fee4-414a-896b-2adeaaec39d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d2c8b5e6-fa56-4c27-876c-925895b6a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ef7a9e89-e012-434f-b873-b6e2bfc94f69,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-99b541cf-4d0f-45e3-924c-909ff39790a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-a5a68c5a-aa08-4d6b-b987-37bad529ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-f834d27c-751c-4d7c-a39c-06c923b8d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-99c906b1-94bc-48df-a716-64b5c9090460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067192975-172.17.0.5-1599384264403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-611b9423-b8f5-43ee-9725-d8c5c8c3e9af,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-12b42bd3-499f-41bd-a050-dc4475baa9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-08f0fa2f-3588-49f9-a621-29cbd47bc551,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d7d3daad-c159-4f93-87b7-8a71ceca2549,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-7a1a3735-f985-4502-b75f-58de2f87e770,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4733f32c-c613-4657-881b-35c155c229b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-d1e61cc7-2e1a-4025-8a1c-5bb44e1d008e,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-36a946b5-c8db-4dfd-8ce8-bf8d5def1f23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067192975-172.17.0.5-1599384264403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-611b9423-b8f5-43ee-9725-d8c5c8c3e9af,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-12b42bd3-499f-41bd-a050-dc4475baa9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-08f0fa2f-3588-49f9-a621-29cbd47bc551,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d7d3daad-c159-4f93-87b7-8a71ceca2549,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-7a1a3735-f985-4502-b75f-58de2f87e770,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4733f32c-c613-4657-881b-35c155c229b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-d1e61cc7-2e1a-4025-8a1c-5bb44e1d008e,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-36a946b5-c8db-4dfd-8ce8-bf8d5def1f23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447430062-172.17.0.5-1599384620699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-fcb727a7-6f84-4784-bae2-fac2d51b5924,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-28c20f76-80b2-4d6f-9094-353388226d54,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-d65db309-aad1-4680-9155-29f9457fa854,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-d5d26639-2127-453a-ae83-86e9d706c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-590e2356-e941-453a-aaec-10c453a0fc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-40454b1b-b8bd-4d3a-8f40-c00497bc1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-97bc5f74-d710-42d5-a7d7-d0c5f4b3ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-22b33b53-ca9c-4686-9cf2-eed2dab32e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447430062-172.17.0.5-1599384620699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-fcb727a7-6f84-4784-bae2-fac2d51b5924,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-28c20f76-80b2-4d6f-9094-353388226d54,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-d65db309-aad1-4680-9155-29f9457fa854,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-d5d26639-2127-453a-ae83-86e9d706c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-590e2356-e941-453a-aaec-10c453a0fc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-40454b1b-b8bd-4d3a-8f40-c00497bc1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-97bc5f74-d710-42d5-a7d7-d0c5f4b3ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-22b33b53-ca9c-4686-9cf2-eed2dab32e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838575937-172.17.0.5-1599384648103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-6fdc7544-b8c4-40ef-9871-e347f1c2fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-3bceb925-a809-4271-8f66-b304f011c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-7683fe05-e5e2-48d3-a357-939e4732c026,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-d72482b5-ba07-475f-ac53-ac3e4d557234,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-9c55e969-49bc-474c-930b-8901654b4394,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-d2006146-9c05-4a95-ac2d-95fe02e52e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-102b5693-7568-4470-8fc3-7a74ebaf5a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-818d5ac6-0f24-486d-b304-e135776193e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838575937-172.17.0.5-1599384648103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-6fdc7544-b8c4-40ef-9871-e347f1c2fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-3bceb925-a809-4271-8f66-b304f011c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-7683fe05-e5e2-48d3-a357-939e4732c026,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-d72482b5-ba07-475f-ac53-ac3e4d557234,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-9c55e969-49bc-474c-930b-8901654b4394,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-d2006146-9c05-4a95-ac2d-95fe02e52e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-102b5693-7568-4470-8fc3-7a74ebaf5a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-818d5ac6-0f24-486d-b304-e135776193e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058738481-172.17.0.5-1599384769813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-a9f156d5-78a7-4f3e-ab74-0e9f9c29ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2a2e685d-3451-4658-b5ba-753a709ef442,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-17c5347f-9e96-495f-98e1-c3961ce2fa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-66d63731-c6d8-45fb-a868-8a8d067d7b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d0e01e38-0dc6-4be6-86f1-3f2a5b6904e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-ea81b2b1-e8b1-4a55-b4f9-43eef4bd0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-646778d7-e4a6-44e3-973b-b7f5a073a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-a29870fc-7e57-4178-ae1a-f99a177d69ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058738481-172.17.0.5-1599384769813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-a9f156d5-78a7-4f3e-ab74-0e9f9c29ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2a2e685d-3451-4658-b5ba-753a709ef442,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-17c5347f-9e96-495f-98e1-c3961ce2fa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-66d63731-c6d8-45fb-a868-8a8d067d7b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d0e01e38-0dc6-4be6-86f1-3f2a5b6904e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-ea81b2b1-e8b1-4a55-b4f9-43eef4bd0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-646778d7-e4a6-44e3-973b-b7f5a073a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-a29870fc-7e57-4178-ae1a-f99a177d69ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084036325-172.17.0.5-1599384836825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-34019eef-61dd-4267-97bf-c65f811e3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-3e46e012-f14b-4186-82bf-dc47e3390f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f6cda2a8-5563-4e3a-af03-77086253c916,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e2047bcd-61bf-43ef-801c-2c9cf156131d,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-27bdcf11-86eb-4ece-9901-cc69debb9535,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-0e27948a-ab54-4567-b036-8c3199d70e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-f0374743-0b1c-4c68-bc17-29e5cc14eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-b6134821-e4d4-463f-b71a-c3d0fb57ba91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084036325-172.17.0.5-1599384836825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-34019eef-61dd-4267-97bf-c65f811e3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-3e46e012-f14b-4186-82bf-dc47e3390f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f6cda2a8-5563-4e3a-af03-77086253c916,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e2047bcd-61bf-43ef-801c-2c9cf156131d,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-27bdcf11-86eb-4ece-9901-cc69debb9535,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-0e27948a-ab54-4567-b036-8c3199d70e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-f0374743-0b1c-4c68-bc17-29e5cc14eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-b6134821-e4d4-463f-b71a-c3d0fb57ba91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982018319-172.17.0.5-1599385047422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-2644fc72-d649-45b3-b495-e548fb8eb6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-d67c8cfd-ac48-4d4e-846f-76f06f14d463,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-afab8557-b282-43a2-af5e-557b6940b03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-f31769b2-b784-43cb-88a7-4b98733742d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-549d1d6c-c4ac-4a7a-8d89-6eb47235b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-fbd5aa0a-2b23-49db-b4d7-177f97749789,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f584d7cb-95b6-4375-8ad3-9d5c4eb14bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-fd1c4bcb-3273-427d-99cf-e171b9320b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982018319-172.17.0.5-1599385047422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-2644fc72-d649-45b3-b495-e548fb8eb6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-d67c8cfd-ac48-4d4e-846f-76f06f14d463,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-afab8557-b282-43a2-af5e-557b6940b03c,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-f31769b2-b784-43cb-88a7-4b98733742d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-549d1d6c-c4ac-4a7a-8d89-6eb47235b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-fbd5aa0a-2b23-49db-b4d7-177f97749789,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f584d7cb-95b6-4375-8ad3-9d5c4eb14bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-fd1c4bcb-3273-427d-99cf-e171b9320b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113733181-172.17.0.5-1599385694317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-cff3822b-5ffa-48ba-8d2b-ad82f9b4eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-a6547b30-4b41-405c-8a22-95feae1d89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-2d814cf4-2c14-4b02-a14b-54bed2453c29,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-81680b32-5663-4fb5-91ce-dfe82f2e2f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-5d1418e1-e199-4117-a1c9-9ab6667bb562,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9bee3c5c-9345-49ae-bbc2-b599f57f0215,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-ea0f2c1b-3d5b-42e1-9335-d5e04520bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-77380bf3-71b3-4c79-85b5-6f1fa9c9c92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113733181-172.17.0.5-1599385694317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-cff3822b-5ffa-48ba-8d2b-ad82f9b4eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-a6547b30-4b41-405c-8a22-95feae1d89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-2d814cf4-2c14-4b02-a14b-54bed2453c29,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-81680b32-5663-4fb5-91ce-dfe82f2e2f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-5d1418e1-e199-4117-a1c9-9ab6667bb562,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9bee3c5c-9345-49ae-bbc2-b599f57f0215,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-ea0f2c1b-3d5b-42e1-9335-d5e04520bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-77380bf3-71b3-4c79-85b5-6f1fa9c9c92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883567059-172.17.0.5-1599385880434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-8080ec83-1501-4e86-8163-65620c8af370,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-f9357657-4034-46b8-8b7c-f9144b4cda23,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-7bac7088-45b0-4111-9b80-5352ac6098be,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-31508864-b9ea-4196-8bc6-056f62d80c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-0a398506-cf8a-4807-a026-bc095d05746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-d38f5b53-be78-4176-a72f-250c1fc4a506,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-6bec193b-1d5a-4736-92b3-5701f5873063,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-ef3f1d04-1c5d-4944-8348-2b593f826694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883567059-172.17.0.5-1599385880434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45559,DS-8080ec83-1501-4e86-8163-65620c8af370,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-f9357657-4034-46b8-8b7c-f9144b4cda23,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-7bac7088-45b0-4111-9b80-5352ac6098be,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-31508864-b9ea-4196-8bc6-056f62d80c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-0a398506-cf8a-4807-a026-bc095d05746c,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-d38f5b53-be78-4176-a72f-250c1fc4a506,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-6bec193b-1d5a-4736-92b3-5701f5873063,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-ef3f1d04-1c5d-4944-8348-2b593f826694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807486514-172.17.0.5-1599385949836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-02af9dba-2590-43ff-b2a8-2973f06efe51,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-3e14e26e-13d8-43d4-bb66-83b9bb4de607,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-adba592c-89fb-4e9e-a9dc-506f72516c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-a4d03a98-1b7a-42fe-b438-4163d5a10da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3d726768-94eb-45a8-be76-53f2dfd2a118,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-222c8510-0e6f-4bc3-990b-2834d17d57e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-cd5e66d1-e426-4651-be48-c39953189a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-dda2e716-330b-4426-ace1-87128dc8a9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807486514-172.17.0.5-1599385949836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-02af9dba-2590-43ff-b2a8-2973f06efe51,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-3e14e26e-13d8-43d4-bb66-83b9bb4de607,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-adba592c-89fb-4e9e-a9dc-506f72516c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-a4d03a98-1b7a-42fe-b438-4163d5a10da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3d726768-94eb-45a8-be76-53f2dfd2a118,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-222c8510-0e6f-4bc3-990b-2834d17d57e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-cd5e66d1-e426-4651-be48-c39953189a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-dda2e716-330b-4426-ace1-87128dc8a9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721137771-172.17.0.5-1599386005473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-781cf8d0-d2ed-4f19-a922-3be7a5d2afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-9c263d97-9d96-47c8-abf0-dc9462d6d801,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-00123830-8a81-4df5-86eb-556bbc3aa69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-fe26f30e-6f18-483c-afae-2dafe53730b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8d8fb1b7-67c5-4a58-8066-0bfe8050ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-33ac71c6-58d5-43a0-adb2-0622eaf9c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-dae5a97b-3ccf-4b0a-8bac-857a9d451e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-84919a14-129a-4b64-97ee-ddd13bb725da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721137771-172.17.0.5-1599386005473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-781cf8d0-d2ed-4f19-a922-3be7a5d2afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-9c263d97-9d96-47c8-abf0-dc9462d6d801,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-00123830-8a81-4df5-86eb-556bbc3aa69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-fe26f30e-6f18-483c-afae-2dafe53730b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8d8fb1b7-67c5-4a58-8066-0bfe8050ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-33ac71c6-58d5-43a0-adb2-0622eaf9c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-dae5a97b-3ccf-4b0a-8bac-857a9d451e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-84919a14-129a-4b64-97ee-ddd13bb725da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700288867-172.17.0.5-1599386118154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-7add0675-5a47-42ef-b20c-a159384844d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a03f769b-b6e7-4e86-8989-d48802adb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-6296cd55-e009-4856-9f53-55fa2d7865b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f8199f58-22b0-498e-af0a-7cc68e41a358,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-eddaa246-4a71-4df2-8fa3-d5aeca7dfd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-899888dd-09eb-4b25-b8b8-c17ab72afd27,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-f6511236-4473-4ee3-a31a-f1793d9557ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-91a6f777-df03-4233-9b5a-e3ad8ecd9468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700288867-172.17.0.5-1599386118154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-7add0675-5a47-42ef-b20c-a159384844d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a03f769b-b6e7-4e86-8989-d48802adb7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-6296cd55-e009-4856-9f53-55fa2d7865b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f8199f58-22b0-498e-af0a-7cc68e41a358,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-eddaa246-4a71-4df2-8fa3-d5aeca7dfd94,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-899888dd-09eb-4b25-b8b8-c17ab72afd27,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-f6511236-4473-4ee3-a31a-f1793d9557ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-91a6f777-df03-4233-9b5a-e3ad8ecd9468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358876345-172.17.0.5-1599386597092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-e6f1fb76-0f23-4e01-b9d9-b516a842db41,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9fe42340-66b0-464a-80d8-5a09e4611bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-61f1f2c7-f39b-460c-8b6e-6743a118b143,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-360bd1c9-6866-4c5e-bc15-0ea98aa9578d,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4a722742-da3b-4dac-9c97-3948d84a5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-90b8cf22-1c09-429f-abee-fed89a4d14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-82755656-fac6-43bf-8cd7-1e183b70a9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-63777982-f942-4d6d-8405-a11dc751c293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358876345-172.17.0.5-1599386597092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-e6f1fb76-0f23-4e01-b9d9-b516a842db41,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9fe42340-66b0-464a-80d8-5a09e4611bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-61f1f2c7-f39b-460c-8b6e-6743a118b143,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-360bd1c9-6866-4c5e-bc15-0ea98aa9578d,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4a722742-da3b-4dac-9c97-3948d84a5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-90b8cf22-1c09-429f-abee-fed89a4d14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-82755656-fac6-43bf-8cd7-1e183b70a9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-63777982-f942-4d6d-8405-a11dc751c293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777864752-172.17.0.5-1599386752896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-6c5f3265-96c7-4fba-9d33-af258508162d,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-25e58fcb-d831-4779-a60c-e62e6b922466,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-6f6bd6ed-dbd3-4279-87c1-1a10d53685d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-a64c2c1d-3753-4b54-8859-b388701c2a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-88649a92-7561-4a32-b2ce-8ca83df9b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-c5dcf131-c48a-45c3-8f16-abe6089d0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-960f764a-5f50-4547-9af0-9bd03e012f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-80b21f55-c8ef-4120-a35a-8c6819538dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777864752-172.17.0.5-1599386752896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-6c5f3265-96c7-4fba-9d33-af258508162d,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-25e58fcb-d831-4779-a60c-e62e6b922466,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-6f6bd6ed-dbd3-4279-87c1-1a10d53685d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-a64c2c1d-3753-4b54-8859-b388701c2a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-88649a92-7561-4a32-b2ce-8ca83df9b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-c5dcf131-c48a-45c3-8f16-abe6089d0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-960f764a-5f50-4547-9af0-9bd03e012f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-80b21f55-c8ef-4120-a35a-8c6819538dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357047728-172.17.0.5-1599387313966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-9cb44364-0cda-4f38-a172-76095d965f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f9e3b8e6-6a3e-4782-8113-dee3b05e3481,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2efc993f-6322-4ce0-94f4-5fc388b29aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-9ddbdd72-1385-4f2a-851b-79510204a950,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cc94ca03-3938-4fdc-beaa-68eb21074aab,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-4104cabd-05ae-4997-8fff-68414bd1944d,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-91b2561d-237c-4c5a-980a-0aa4ab4ff0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-7608bf18-55d9-4b86-9498-76808166377d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357047728-172.17.0.5-1599387313966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-9cb44364-0cda-4f38-a172-76095d965f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f9e3b8e6-6a3e-4782-8113-dee3b05e3481,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2efc993f-6322-4ce0-94f4-5fc388b29aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-9ddbdd72-1385-4f2a-851b-79510204a950,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cc94ca03-3938-4fdc-beaa-68eb21074aab,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-4104cabd-05ae-4997-8fff-68414bd1944d,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-91b2561d-237c-4c5a-980a-0aa4ab4ff0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-7608bf18-55d9-4b86-9498-76808166377d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483485803-172.17.0.5-1599387384405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-70ba711a-eaea-4e25-8d71-200785729e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-8e84cba1-a91e-41a8-8f3e-b3bb395e3357,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-78e6829b-fe78-4a36-8592-0fddc963ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6796e754-806e-4daa-9c25-e3e51ef74edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-08f62414-6db8-4d13-b769-07d8287591ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-d0292ece-f847-4915-8028-08341747d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-711520f6-f72c-422e-80bd-d69310a85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-dd6098ed-a274-4579-8e0d-ddc2ef911936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483485803-172.17.0.5-1599387384405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-70ba711a-eaea-4e25-8d71-200785729e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-8e84cba1-a91e-41a8-8f3e-b3bb395e3357,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-78e6829b-fe78-4a36-8592-0fddc963ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6796e754-806e-4daa-9c25-e3e51ef74edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-08f62414-6db8-4d13-b769-07d8287591ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-d0292ece-f847-4915-8028-08341747d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-711520f6-f72c-422e-80bd-d69310a85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-dd6098ed-a274-4579-8e0d-ddc2ef911936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.rpc.protection
component: hdfs:DataNode
v1: privacy
v2: authentication
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118577968-172.17.0.5-1599387537949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-e406b571-e34c-4165-b899-2f2ac7587c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7384043f-8d95-47ad-bb85-28f8b9593698,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-87a8f76e-90d8-4e2e-b0c5-dbabdeadda24,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-cbacf39f-6ba8-4adc-ae69-4e60bb0fc875,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-46f540d5-03df-4029-8dd1-92a6d54b9186,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-f97e6671-7586-49e5-b6ce-69f0b9432e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-46a309f0-ac79-4dc9-8f91-43bb86adc4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-c3d57ac5-f72d-40e4-bfe0-1660318893b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118577968-172.17.0.5-1599387537949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-e406b571-e34c-4165-b899-2f2ac7587c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7384043f-8d95-47ad-bb85-28f8b9593698,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-87a8f76e-90d8-4e2e-b0c5-dbabdeadda24,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-cbacf39f-6ba8-4adc-ae69-4e60bb0fc875,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-46f540d5-03df-4029-8dd1-92a6d54b9186,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-f97e6671-7586-49e5-b6ce-69f0b9432e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-46a309f0-ac79-4dc9-8f91-43bb86adc4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-c3d57ac5-f72d-40e4-bfe0-1660318893b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 3450
