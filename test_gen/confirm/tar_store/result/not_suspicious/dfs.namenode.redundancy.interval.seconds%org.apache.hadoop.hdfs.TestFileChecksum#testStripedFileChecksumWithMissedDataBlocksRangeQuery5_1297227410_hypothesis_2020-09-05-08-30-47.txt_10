reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190975700-172.17.0.11-1599294985791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-175a5850-8e71-4286-a925-f3349c59e947,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fa465bae-c94d-42e1-8b6c-c1b150ddf8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-98201c73-0fe2-48b1-b20e-3fcfd4dfa7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-1d213cc7-bf16-4280-988d-fdf4111d3468,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-114853f6-3540-4e2f-a661-c18ebcfdab86,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-5da0ef66-3716-47c6-a150-a0e72262eb95,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-970e1f87-500b-456e-85a6-21aba702c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-6360df69-17d7-4b2d-accb-d242378d1844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190975700-172.17.0.11-1599294985791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-175a5850-8e71-4286-a925-f3349c59e947,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fa465bae-c94d-42e1-8b6c-c1b150ddf8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-98201c73-0fe2-48b1-b20e-3fcfd4dfa7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-1d213cc7-bf16-4280-988d-fdf4111d3468,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-114853f6-3540-4e2f-a661-c18ebcfdab86,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-5da0ef66-3716-47c6-a150-a0e72262eb95,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-970e1f87-500b-456e-85a6-21aba702c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-6360df69-17d7-4b2d-accb-d242378d1844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767171999-172.17.0.11-1599295013246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-b2d0e766-f8cf-441f-afd4-7c35989e2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-8942bfbb-b06c-44cb-aab4-d6c699791767,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-faf84d7f-a075-448c-a9b8-e7e9b6549c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-ce14d48c-02d0-43e1-9d21-ab5dc823014c,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-f490ca25-20b3-41e9-a353-778741a69268,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4de284e3-a6d8-43b6-b732-997d9cdc221b,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-f60b33b3-048d-4cab-abdc-412cc03b5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2389f5ae-4366-456d-9c05-c306d584946d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767171999-172.17.0.11-1599295013246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-b2d0e766-f8cf-441f-afd4-7c35989e2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-8942bfbb-b06c-44cb-aab4-d6c699791767,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-faf84d7f-a075-448c-a9b8-e7e9b6549c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-ce14d48c-02d0-43e1-9d21-ab5dc823014c,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-f490ca25-20b3-41e9-a353-778741a69268,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4de284e3-a6d8-43b6-b732-997d9cdc221b,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-f60b33b3-048d-4cab-abdc-412cc03b5f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2389f5ae-4366-456d-9c05-c306d584946d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145431593-172.17.0.11-1599295266127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36974,DS-6abe8d3b-5072-4df9-bb99-9458badcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-aa35b78c-1275-45c5-82db-36733dcaca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a6a862d4-9495-41fd-8a19-e94e3a061526,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-c9cf4b7e-c230-46d8-9c31-7cba539c0a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-eb0f3ff8-2c1d-44e3-a8ce-3742d92f9a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-ab8f7880-7e77-40e1-ba6e-b7a0b47927fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-defbb124-71f1-4786-9ef3-9326aeca98af,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-dfbb6f66-5a46-4198-bbf9-0e6560396ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145431593-172.17.0.11-1599295266127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36974,DS-6abe8d3b-5072-4df9-bb99-9458badcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-aa35b78c-1275-45c5-82db-36733dcaca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a6a862d4-9495-41fd-8a19-e94e3a061526,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-c9cf4b7e-c230-46d8-9c31-7cba539c0a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-eb0f3ff8-2c1d-44e3-a8ce-3742d92f9a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-ab8f7880-7e77-40e1-ba6e-b7a0b47927fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-defbb124-71f1-4786-9ef3-9326aeca98af,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-dfbb6f66-5a46-4198-bbf9-0e6560396ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527502270-172.17.0.11-1599295632962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-c018096e-2b2a-4fd1-a8f9-57829c23f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-f08855e1-5365-43d9-ac85-793ac6d9fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d4efd0ea-e168-444f-bf51-2e78f535699c,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-fefe267d-016e-4118-8e99-6643a7458f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-62bb8386-59c0-488c-b833-08904394bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-cd63f4fd-ce1b-45af-a590-3e69f1c8109e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-7cacfe0f-9246-4adc-a816-a0e5982d2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3ee64e81-fab8-4e81-b206-409785255a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527502270-172.17.0.11-1599295632962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-c018096e-2b2a-4fd1-a8f9-57829c23f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-f08855e1-5365-43d9-ac85-793ac6d9fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d4efd0ea-e168-444f-bf51-2e78f535699c,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-fefe267d-016e-4118-8e99-6643a7458f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-62bb8386-59c0-488c-b833-08904394bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-cd63f4fd-ce1b-45af-a590-3e69f1c8109e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-7cacfe0f-9246-4adc-a816-a0e5982d2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3ee64e81-fab8-4e81-b206-409785255a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827719808-172.17.0.11-1599296180241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-d83eb5ac-8da3-470c-9e7c-768a3618d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-14dde498-80ae-4b25-960e-aea81072958b,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-48967242-2b16-4aab-b53c-e4059b003c66,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-2ab8b41f-bf6b-4e59-b2c3-31d9d78b0ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-471ec7f2-a737-4004-88d6-5c945b587c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-22c25a3f-fc28-4284-a230-e41c8e18c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-02a2c4da-094f-4cc7-b05a-c39fe3d684e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-b1589159-3a2d-4305-9518-39cfcaec55e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827719808-172.17.0.11-1599296180241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-d83eb5ac-8da3-470c-9e7c-768a3618d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-14dde498-80ae-4b25-960e-aea81072958b,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-48967242-2b16-4aab-b53c-e4059b003c66,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-2ab8b41f-bf6b-4e59-b2c3-31d9d78b0ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-471ec7f2-a737-4004-88d6-5c945b587c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-22c25a3f-fc28-4284-a230-e41c8e18c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-02a2c4da-094f-4cc7-b05a-c39fe3d684e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-b1589159-3a2d-4305-9518-39cfcaec55e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887949112-172.17.0.11-1599296296277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-7e1dc838-8b94-4fc9-85c6-6cfa0b7e5871,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-f81eaa80-5f80-4aa7-ac43-ab042af57363,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-9bb3fc03-7ed5-49bf-96ba-7374275d350f,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-af07de69-934b-4348-89fa-199c7362b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-a964b7b7-2b28-44c1-aeab-1b456c4eb661,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-7817fb04-5cd3-44e0-9327-535b8855095b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-47cf0ab3-5386-4bc6-a0e6-2ab729216ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fc0da439-c011-4741-bcff-4286611a14fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887949112-172.17.0.11-1599296296277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-7e1dc838-8b94-4fc9-85c6-6cfa0b7e5871,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-f81eaa80-5f80-4aa7-ac43-ab042af57363,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-9bb3fc03-7ed5-49bf-96ba-7374275d350f,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-af07de69-934b-4348-89fa-199c7362b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-a964b7b7-2b28-44c1-aeab-1b456c4eb661,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-7817fb04-5cd3-44e0-9327-535b8855095b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-47cf0ab3-5386-4bc6-a0e6-2ab729216ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fc0da439-c011-4741-bcff-4286611a14fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970877525-172.17.0.11-1599296694094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-b452e1a8-c112-413e-bcbe-697591689397,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-8d33e9c4-c2ec-4bee-8e2a-c8256372b885,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e5252e30-d2c7-4c78-95ac-b75b4b23a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-27a3a030-3941-4d08-a3c1-42567f360d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4c67baaa-a3bf-4a65-9390-413e8694d424,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-dc3e0ce7-6655-4cb3-80db-9009a3c42e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-8dcffeec-991a-4774-986f-2302c3fa4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-66c4b89a-8d1c-46da-b8ec-5819d3573f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970877525-172.17.0.11-1599296694094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-b452e1a8-c112-413e-bcbe-697591689397,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-8d33e9c4-c2ec-4bee-8e2a-c8256372b885,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-e5252e30-d2c7-4c78-95ac-b75b4b23a65f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-27a3a030-3941-4d08-a3c1-42567f360d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4c67baaa-a3bf-4a65-9390-413e8694d424,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-dc3e0ce7-6655-4cb3-80db-9009a3c42e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-8dcffeec-991a-4774-986f-2302c3fa4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-66c4b89a-8d1c-46da-b8ec-5819d3573f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254194436-172.17.0.11-1599296721067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-ec7a77b4-803f-4fde-98d0-bef11ad8c672,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-2a436f3c-daba-43e6-9b86-79a7f071498b,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-108f9050-1b2b-45e7-a5e3-7ee7069728b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-1b52c1bc-77cb-41e5-b8f1-2819ac7fc072,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-3703ea56-c306-430d-82c4-4a106fd53516,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-f9ab652a-3a2f-4314-8511-902874f9adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-fa9a25d8-fbe1-45bb-9676-8733e9c7a60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-143b4150-47c8-4389-b556-3c42355b87c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254194436-172.17.0.11-1599296721067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-ec7a77b4-803f-4fde-98d0-bef11ad8c672,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-2a436f3c-daba-43e6-9b86-79a7f071498b,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-108f9050-1b2b-45e7-a5e3-7ee7069728b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-1b52c1bc-77cb-41e5-b8f1-2819ac7fc072,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-3703ea56-c306-430d-82c4-4a106fd53516,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-f9ab652a-3a2f-4314-8511-902874f9adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-fa9a25d8-fbe1-45bb-9676-8733e9c7a60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-143b4150-47c8-4389-b556-3c42355b87c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223431370-172.17.0.11-1599297022945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-088f5cdc-7382-483f-b9b0-872336c12acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-5388029d-0b55-446d-829e-82c5ca76218e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8785376f-6da1-4b5c-88cd-af5e55a4176a,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-e4c62322-654b-4739-844e-b20485d5c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-fb3ccf5b-9cd9-461e-896d-18c67f54ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-48874fa4-de58-461a-a0d4-412402f9b379,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b73bb476-641d-4254-9710-38904009934b,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-4ea9e450-4e74-409d-aa70-f824fb45232e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223431370-172.17.0.11-1599297022945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46110,DS-088f5cdc-7382-483f-b9b0-872336c12acc,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-5388029d-0b55-446d-829e-82c5ca76218e,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8785376f-6da1-4b5c-88cd-af5e55a4176a,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-e4c62322-654b-4739-844e-b20485d5c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-fb3ccf5b-9cd9-461e-896d-18c67f54ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-48874fa4-de58-461a-a0d4-412402f9b379,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b73bb476-641d-4254-9710-38904009934b,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-4ea9e450-4e74-409d-aa70-f824fb45232e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617386467-172.17.0.11-1599297103002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-8641916d-1e9e-4e46-a260-847327fb2762,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-d1556ce1-44bd-499a-9144-0592739c9551,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-4243a125-58c5-4016-8d74-15d6dd27bb13,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a6e90e1a-1ec9-4732-9a62-08cd698acf26,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4f863722-4eee-4d47-b4ae-fd50623c7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-70a8d9a4-eeeb-409e-a120-5a7af2ea5d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-79e6da02-dee0-44f7-9126-0150d76cd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0458ba28-ce53-44fa-8422-334ca063f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617386467-172.17.0.11-1599297103002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33825,DS-8641916d-1e9e-4e46-a260-847327fb2762,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-d1556ce1-44bd-499a-9144-0592739c9551,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-4243a125-58c5-4016-8d74-15d6dd27bb13,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a6e90e1a-1ec9-4732-9a62-08cd698acf26,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4f863722-4eee-4d47-b4ae-fd50623c7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-70a8d9a4-eeeb-409e-a120-5a7af2ea5d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-79e6da02-dee0-44f7-9126-0150d76cd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0458ba28-ce53-44fa-8422-334ca063f076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155725207-172.17.0.11-1599297133092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-89141d44-de45-40d7-87c1-d8087cfce6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-412fdc04-fbee-4361-858c-c2a1b726d70c,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-1f7985b2-4f1d-4f9c-825b-31abb568e28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-d539fea9-4894-4d31-915a-ecb6ef710422,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-0e626766-cab4-40c6-bb0b-4c4d120ce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-386baea6-1b3b-4a28-b496-754fd84a2fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-825a2f6e-fb95-4cf1-9d51-48928946fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-0d82d1f1-d536-4bd6-97e2-cd04b751f68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155725207-172.17.0.11-1599297133092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-89141d44-de45-40d7-87c1-d8087cfce6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-412fdc04-fbee-4361-858c-c2a1b726d70c,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-1f7985b2-4f1d-4f9c-825b-31abb568e28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-d539fea9-4894-4d31-915a-ecb6ef710422,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-0e626766-cab4-40c6-bb0b-4c4d120ce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-386baea6-1b3b-4a28-b496-754fd84a2fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-825a2f6e-fb95-4cf1-9d51-48928946fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-0d82d1f1-d536-4bd6-97e2-cd04b751f68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347079945-172.17.0.11-1599297357537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-2fd4c37b-6304-4238-a3a3-44f5ef9366c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-42ff8c64-65d4-48f1-b664-92f01fa8b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-1446b02a-691a-465f-85dc-7a347b213a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ab88c6ae-1f7a-4d63-8fd8-f0d8e79a754b,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-4c7dc05f-6e4a-4959-9430-13a621ec6995,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-d1683217-0b50-4160-9618-585314e2c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-0e8756f3-d6a5-45f8-93ab-2e945d169414,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-298e71c3-b5a9-4605-9c9c-ee62a0e2b48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347079945-172.17.0.11-1599297357537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-2fd4c37b-6304-4238-a3a3-44f5ef9366c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-42ff8c64-65d4-48f1-b664-92f01fa8b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-1446b02a-691a-465f-85dc-7a347b213a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ab88c6ae-1f7a-4d63-8fd8-f0d8e79a754b,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-4c7dc05f-6e4a-4959-9430-13a621ec6995,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-d1683217-0b50-4160-9618-585314e2c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-0e8756f3-d6a5-45f8-93ab-2e945d169414,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-298e71c3-b5a9-4605-9c9c-ee62a0e2b48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179321859-172.17.0.11-1599297578979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-6d335a5b-246b-4615-8bb4-bc64ee203b60,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-b71730ca-470d-4d40-9633-e0b22543f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-dccf1e81-a2e8-4e95-bae3-78c3e23d171a,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-a3e41f67-935f-448d-b772-d303bdf75312,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-19daef4e-1739-4721-9f71-729a922f8440,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-22171d69-9355-4cee-b584-94d0ec8bad17,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-4fc615c0-1f58-4d42-af5f-c3a4216a07d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-092c5c00-6182-4ecc-a779-a51004abd8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179321859-172.17.0.11-1599297578979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-6d335a5b-246b-4615-8bb4-bc64ee203b60,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-b71730ca-470d-4d40-9633-e0b22543f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-dccf1e81-a2e8-4e95-bae3-78c3e23d171a,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-a3e41f67-935f-448d-b772-d303bdf75312,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-19daef4e-1739-4721-9f71-729a922f8440,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-22171d69-9355-4cee-b584-94d0ec8bad17,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-4fc615c0-1f58-4d42-af5f-c3a4216a07d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-092c5c00-6182-4ecc-a779-a51004abd8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385984892-172.17.0.11-1599297688236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34997,DS-88c46f49-96e3-40fd-89ce-c8b87e3de3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-c341758d-60cd-4489-a39f-ae7786632629,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-297fe411-21be-45de-a084-c4ad62c9bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7cc8f717-89c3-4871-8851-815000327f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-7306c7ff-38a5-4dd5-9bb3-32007f91952f,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-981669d3-07e8-4f1d-b652-251308640515,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c447f57b-bf4f-4149-8548-999d7afd0623,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-65cb2ccc-8e0c-4e5b-82aa-9e5d0875bc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385984892-172.17.0.11-1599297688236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34997,DS-88c46f49-96e3-40fd-89ce-c8b87e3de3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-c341758d-60cd-4489-a39f-ae7786632629,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-297fe411-21be-45de-a084-c4ad62c9bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-7cc8f717-89c3-4871-8851-815000327f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-7306c7ff-38a5-4dd5-9bb3-32007f91952f,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-981669d3-07e8-4f1d-b652-251308640515,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c447f57b-bf4f-4149-8548-999d7afd0623,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-65cb2ccc-8e0c-4e5b-82aa-9e5d0875bc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154259292-172.17.0.11-1599297714913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-55c0e06e-991d-46fb-a28a-ab19e402ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-74d00d97-32c2-4aa2-90c9-de2c10aae888,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-4439ad86-7635-42d6-a4ad-3257fda084fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-52af718e-086c-4fb4-a926-b3938707ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-209d2752-941d-4ba2-a3e1-2b4b203483b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d77d9e21-5148-44df-9d7e-b62598fbab98,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-326b309d-64f3-47d9-a052-3bddbe47166e,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-9e06d6a0-58c8-4b52-9a39-bdb41bb1f35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154259292-172.17.0.11-1599297714913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-55c0e06e-991d-46fb-a28a-ab19e402ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-74d00d97-32c2-4aa2-90c9-de2c10aae888,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-4439ad86-7635-42d6-a4ad-3257fda084fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-52af718e-086c-4fb4-a926-b3938707ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-209d2752-941d-4ba2-a3e1-2b4b203483b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d77d9e21-5148-44df-9d7e-b62598fbab98,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-326b309d-64f3-47d9-a052-3bddbe47166e,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-9e06d6a0-58c8-4b52-9a39-bdb41bb1f35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51779306-172.17.0.11-1599297967312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-75e3e6f0-9ecb-4fd6-8f91-d72b90d81434,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5a386f8c-71c7-416c-a361-8de7f362860e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-d4e59e0b-0399-4976-8a0a-d75689b024a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-57c4cf99-af4d-4e7b-ac98-9a8b53848d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f9d80117-0ebc-45fb-806f-57a70c9daeae,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-b87bdd4b-37c4-4a5b-8cb6-0ba5c9a74d35,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-f49537e6-c2a7-4877-8631-b79df9cfd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-000e986d-f50d-417f-bc7b-bea14fa5dd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51779306-172.17.0.11-1599297967312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-75e3e6f0-9ecb-4fd6-8f91-d72b90d81434,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5a386f8c-71c7-416c-a361-8de7f362860e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-d4e59e0b-0399-4976-8a0a-d75689b024a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-57c4cf99-af4d-4e7b-ac98-9a8b53848d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f9d80117-0ebc-45fb-806f-57a70c9daeae,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-b87bdd4b-37c4-4a5b-8cb6-0ba5c9a74d35,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-f49537e6-c2a7-4877-8631-b79df9cfd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-000e986d-f50d-417f-bc7b-bea14fa5dd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375305896-172.17.0.11-1599298110396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35947,DS-bc3bcd57-047c-4447-8029-9a4dc854dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-0ed714aa-01ed-421a-9e8a-57e471f394d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-ab241ed2-e95d-4536-9fc0-c2c224b4ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-68d57606-2a63-456a-a089-8e524c757998,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-6427d1a9-6b58-4f9e-b48e-738aff7c06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-57a665ee-66ee-426a-90d9-ffc57eb42066,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-b2f10d98-1394-4ce2-a8e6-bf406dc7c5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-4818e421-98f6-4b0c-9579-96555b87c4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375305896-172.17.0.11-1599298110396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35947,DS-bc3bcd57-047c-4447-8029-9a4dc854dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-0ed714aa-01ed-421a-9e8a-57e471f394d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-ab241ed2-e95d-4536-9fc0-c2c224b4ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-68d57606-2a63-456a-a089-8e524c757998,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-6427d1a9-6b58-4f9e-b48e-738aff7c06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-57a665ee-66ee-426a-90d9-ffc57eb42066,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-b2f10d98-1394-4ce2-a8e6-bf406dc7c5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-4818e421-98f6-4b0c-9579-96555b87c4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677016671-172.17.0.11-1599298492522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-c0047021-0471-4e83-8093-ea79ce60af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-3b23eb0e-02a6-4c0c-a8d1-02503c768f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-54953042-a8b0-493f-90b3-d31d05bcf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-3c9806b5-7071-4f1a-82b8-df518169648d,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-bbcf215f-1e96-40b4-84f9-4e9aa0ec3a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-797c0933-64ed-4af9-af9d-02c4d6f2ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-0f42b065-ebd0-4ee8-8096-8de51cab0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-00bd37a5-2d29-4811-a88e-17a4b961099f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677016671-172.17.0.11-1599298492522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-c0047021-0471-4e83-8093-ea79ce60af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-3b23eb0e-02a6-4c0c-a8d1-02503c768f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-54953042-a8b0-493f-90b3-d31d05bcf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-3c9806b5-7071-4f1a-82b8-df518169648d,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-bbcf215f-1e96-40b4-84f9-4e9aa0ec3a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-797c0933-64ed-4af9-af9d-02c4d6f2ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-0f42b065-ebd0-4ee8-8096-8de51cab0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-00bd37a5-2d29-4811-a88e-17a4b961099f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4339
