reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-658655c7-563e-4e76-a144-c5c42c418d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-54ae608b-daad-4235-a323-b5ad6192ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dd31617a-696a-4d38-95bf-c81e239d00d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-6477899c-d1f5-4500-a5b7-9e4163760428,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-bc3fdc14-9111-425c-8b67-5c577dc818f1,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-ac057552-3b59-43b2-80d6-78eb452be2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f2924587-ffe1-4cec-8dba-d4bacffab986,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-1bf22872-a1a9-4c52-b4f2-4007ed6231b4,DISK]]; indices=[0, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-ac057552-3b59-43b2-80d6-78eb452be2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f2924587-ffe1-4cec-8dba-d4bacffab986,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-1bf22872-a1a9-4c52-b4f2-4007ed6231b4,DISK]]; indices=[0, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-658655c7-563e-4e76-a144-c5c42c418d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-54ae608b-daad-4235-a323-b5ad6192ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dd31617a-696a-4d38-95bf-c81e239d00d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-6477899c-d1f5-4500-a5b7-9e4163760428,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-bc3fdc14-9111-425c-8b67-5c577dc818f1,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-ac057552-3b59-43b2-80d6-78eb452be2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f2924587-ffe1-4cec-8dba-d4bacffab986,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-1bf22872-a1a9-4c52-b4f2-4007ed6231b4,DISK]]; indices=[0, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-164260780-172.17.0.14-1599303437756:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-ac057552-3b59-43b2-80d6-78eb452be2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-f2924587-ffe1-4cec-8dba-d4bacffab986,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-1bf22872-a1a9-4c52-b4f2-4007ed6231b4,DISK]]; indices=[0, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:197)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:339)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-981e0c34-c347-4c39-b95c-f6ba37fa5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-53e20934-c188-4241-83b0-774e9db0fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-00b90b78-7743-421e-837e-b0c31ecaca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-d7ae8826-8be1-4d7c-a65c-9d145e667cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-dfc02267-38cd-45ca-889f-85f200196449,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-48cbc0a8-c33f-4e75-b21c-045c0b61feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d38b757d-75a5-4eab-a8b9-fd8adf7164e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5cb2b74d-d181-4998-b47d-e7cd99643be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5206b913-d5a3-4b00-9b1b-9f9a0ba88e7a,DISK]]; indices=[0, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-48cbc0a8-c33f-4e75-b21c-045c0b61feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d38b757d-75a5-4eab-a8b9-fd8adf7164e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5cb2b74d-d181-4998-b47d-e7cd99643be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5206b913-d5a3-4b00-9b1b-9f9a0ba88e7a,DISK]]; indices=[0, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-981e0c34-c347-4c39-b95c-f6ba37fa5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-53e20934-c188-4241-83b0-774e9db0fc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-00b90b78-7743-421e-837e-b0c31ecaca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-d7ae8826-8be1-4d7c-a65c-9d145e667cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-dfc02267-38cd-45ca-889f-85f200196449,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-48cbc0a8-c33f-4e75-b21c-045c0b61feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d38b757d-75a5-4eab-a8b9-fd8adf7164e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5cb2b74d-d181-4998-b47d-e7cd99643be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5206b913-d5a3-4b00-9b1b-9f9a0ba88e7a,DISK]]; indices=[0, 6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1821529676-172.17.0.14-1599318244410:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-48cbc0a8-c33f-4e75-b21c-045c0b61feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d38b757d-75a5-4eab-a8b9-fd8adf7164e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5cb2b74d-d181-4998-b47d-e7cd99643be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5206b913-d5a3-4b00-9b1b-9f9a0ba88e7a,DISK]]; indices=[0, 6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:197)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:339)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-a668be0b-2d88-431a-84c4-34db3f0e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-50037412-5023-4adb-bc98-7e016659789e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-49192d34-52f2-4e23-b87e-8f72b1e71c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-15af0f9c-810b-46eb-baae-d96177f1708a,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0d6794a1-f97d-40e4-8bab-92f4b7ddedef,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a7405638-9b60-4424-af2b-56d1483722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-ceb172df-93a3-4961-b09e-76ad2399cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4facd473-1aff-45d1-ad0a-d63437e1d2cf,DISK]]; indices=[0, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a7405638-9b60-4424-af2b-56d1483722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-ceb172df-93a3-4961-b09e-76ad2399cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4facd473-1aff-45d1-ad0a-d63437e1d2cf,DISK]]; indices=[0, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-a668be0b-2d88-431a-84c4-34db3f0e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-50037412-5023-4adb-bc98-7e016659789e,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-49192d34-52f2-4e23-b87e-8f72b1e71c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-15af0f9c-810b-46eb-baae-d96177f1708a,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0d6794a1-f97d-40e4-8bab-92f4b7ddedef,DISK]]; indices=[4, 5, 6, 7, 8]}, LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a7405638-9b60-4424-af2b-56d1483722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-ceb172df-93a3-4961-b09e-76ad2399cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4facd473-1aff-45d1-ad0a-d63437e1d2cf,DISK]]; indices=[0, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-541973875-172.17.0.14-1599319742096:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a7405638-9b60-4424-af2b-56d1483722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-ceb172df-93a3-4961-b09e-76ad2399cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4facd473-1aff-45d1-ad0a-d63437e1d2cf,DISK]]; indices=[0, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readDataForDecoding(StripeReader.java:197)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:339)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45442,DS-57bbf5be-aae0-4304-adb0-a0d46f0fe822,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-11b3bd60-e415-4581-8b12-4ecfdab3efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-fbb5aef8-11c1-4f0f-99e6-5085281cc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-0d325aed-8a21-46a6-9358-3abc0ed2451f,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-58c0d55b-c15c-4f99-bf3f-e84e3d793747,DISK]]; indices=[3, 4, 5, 6, 8]}, LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-cb802846-293f-4145-813a-0e15eb11a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-bbff0489-91f1-4821-8af7-495cd61e15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-0e2f2749-b004-48d3-b956-0cd00d34cf1c,DISK]]; indices=[0, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-cb802846-293f-4145-813a-0e15eb11a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-bbff0489-91f1-4821-8af7-495cd61e15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-0e2f2749-b004-48d3-b956-0cd00d34cf1c,DISK]]; indices=[0, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45442,DS-57bbf5be-aae0-4304-adb0-a0d46f0fe822,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-11b3bd60-e415-4581-8b12-4ecfdab3efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-fbb5aef8-11c1-4f0f-99e6-5085281cc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-0d325aed-8a21-46a6-9358-3abc0ed2451f,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-58c0d55b-c15c-4f99-bf3f-e84e3d793747,DISK]]; indices=[3, 4, 5, 6, 8]}, LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-cb802846-293f-4145-813a-0e15eb11a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-bbff0489-91f1-4821-8af7-495cd61e15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-0e2f2749-b004-48d3-b956-0cd00d34cf1c,DISK]]; indices=[0, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-677895158-172.17.0.14-1599324845141:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-cb802846-293f-4145-813a-0e15eb11a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-bbff0489-91f1-4821-8af7-495cd61e15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-0e2f2749-b004-48d3-b956-0cd00d34cf1c,DISK]]; indices=[0, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097213, length=1048515, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-32e04c75-f240-453f-bcd8-a1fe12c1f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-b2afeea7-6b02-4262-8e6c-3033beae43b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-0bd7f8ce-d27c-4027-b321-557fbd7c155c,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-e4fd08f9-a15c-450a-9236-0698cc3ab80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-d022b977-8943-4b14-9883-0104588f7c23,DISK]]; indices=[1, 2, 3, 4, 5]}, LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-4e1f8c71-c64e-4cbd-9419-ee476b86fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-f72820b1-f8e1-4776-8149-e519d0550602,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b316e799-b1d5-40ef-ae61-30eb84374af3,DISK]]; indices=[0, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-4e1f8c71-c64e-4cbd-9419-ee476b86fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-f72820b1-f8e1-4776-8149-e519d0550602,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b316e799-b1d5-40ef-ae61-30eb84374af3,DISK]]; indices=[0, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097213, length=1048515, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-32e04c75-f240-453f-bcd8-a1fe12c1f7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-b2afeea7-6b02-4262-8e6c-3033beae43b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-0bd7f8ce-d27c-4027-b321-557fbd7c155c,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-e4fd08f9-a15c-450a-9236-0698cc3ab80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-d022b977-8943-4b14-9883-0104588f7c23,DISK]]; indices=[1, 2, 3, 4, 5]}, LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-4e1f8c71-c64e-4cbd-9419-ee476b86fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-f72820b1-f8e1-4776-8149-e519d0550602,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b316e799-b1d5-40ef-ae61-30eb84374af3,DISK]]; indices=[0, 6, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-232055772-172.17.0.14-1599333898652:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44612,DS-4e1f8c71-c64e-4cbd-9419-ee476b86fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-f72820b1-f8e1-4776-8149-e519d0550602,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-b316e799-b1d5-40ef-ae61-30eb84374af3,DISK]]; indices=[0, 6, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: -1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 33828
