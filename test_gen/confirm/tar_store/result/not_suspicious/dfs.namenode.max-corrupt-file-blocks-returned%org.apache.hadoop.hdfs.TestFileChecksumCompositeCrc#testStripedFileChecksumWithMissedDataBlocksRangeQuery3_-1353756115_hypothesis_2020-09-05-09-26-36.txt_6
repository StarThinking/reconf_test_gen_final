reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420301460-172.17.0.8-1599298016377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-ed05c1bf-6e5b-4f1a-ba4a-6fb4d5457772,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-5eac909b-96a7-47c3-9ceb-e7ba2191b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-3ce1214e-2b97-4477-b00c-187247ad72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-b584b55b-09b0-435f-92d4-6355d0ad11ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-d9dbbaf0-1cf4-4e64-b5ea-25d5eb4c2b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fcdf7d1a-bb1d-410d-a08f-10b80317fc63,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ad9c2d7b-8097-4bc9-9b25-0967d56b8713,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-7cf21ef1-506b-4aa8-8063-2cd4d085bc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420301460-172.17.0.8-1599298016377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-ed05c1bf-6e5b-4f1a-ba4a-6fb4d5457772,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-5eac909b-96a7-47c3-9ceb-e7ba2191b06c,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-3ce1214e-2b97-4477-b00c-187247ad72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-b584b55b-09b0-435f-92d4-6355d0ad11ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-d9dbbaf0-1cf4-4e64-b5ea-25d5eb4c2b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fcdf7d1a-bb1d-410d-a08f-10b80317fc63,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ad9c2d7b-8097-4bc9-9b25-0967d56b8713,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-7cf21ef1-506b-4aa8-8063-2cd4d085bc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151320139-172.17.0.8-1599298263831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-bf1db67c-e980-4982-aa7e-d8048ecf7ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-83ca629c-c2da-4680-a9be-36a5a28aa4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-ce9b54fc-d8d3-43bb-9659-1023412b910e,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-bddc9fb0-b66f-4ec4-8f8e-0bea55374c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ca36bbee-a1c0-4c96-886d-47d60f2048da,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-bf496dc7-98bb-4cdb-8e23-a291cf2ca0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b80206fc-8f65-4ace-8c48-ab8a0d8e4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-cf8f7aac-166d-42b2-867f-8b92cee97b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151320139-172.17.0.8-1599298263831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-bf1db67c-e980-4982-aa7e-d8048ecf7ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-83ca629c-c2da-4680-a9be-36a5a28aa4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-ce9b54fc-d8d3-43bb-9659-1023412b910e,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-bddc9fb0-b66f-4ec4-8f8e-0bea55374c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-ca36bbee-a1c0-4c96-886d-47d60f2048da,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-bf496dc7-98bb-4cdb-8e23-a291cf2ca0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b80206fc-8f65-4ace-8c48-ab8a0d8e4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-cf8f7aac-166d-42b2-867f-8b92cee97b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011862874-172.17.0.8-1599298619361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35492,DS-248d6c35-854d-441e-bbc6-0023e82d8937,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-baae234e-9f7a-44f4-9bfb-c1f74862bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-9005910c-da67-475b-87ef-44edb221c370,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-6d8663bf-99eb-4c0c-8df3-544f534b0b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-94780179-4599-4a83-8ba3-f870b2ff1039,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-00907f49-4540-45a8-9300-fcd503e8eddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-5658d6b0-2b16-43d0-ae5f-8711001a94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-e8b5288b-a89c-4de5-aca1-a9befbb891b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011862874-172.17.0.8-1599298619361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35492,DS-248d6c35-854d-441e-bbc6-0023e82d8937,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-baae234e-9f7a-44f4-9bfb-c1f74862bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-9005910c-da67-475b-87ef-44edb221c370,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-6d8663bf-99eb-4c0c-8df3-544f534b0b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-94780179-4599-4a83-8ba3-f870b2ff1039,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-00907f49-4540-45a8-9300-fcd503e8eddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-5658d6b0-2b16-43d0-ae5f-8711001a94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-e8b5288b-a89c-4de5-aca1-a9befbb891b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026027121-172.17.0.8-1599298739993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-cff16c85-dbca-4f80-be01-6521070e9014,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e193452b-d6b0-4a7f-bf63-4d0458e364f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-6b4bed2e-d58b-45ac-b3c4-742ca51dcbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-21c1a962-62bf-4846-b1fd-346af5d3cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-324e92d6-e70e-42ee-a697-ad467742c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-29f733a2-cb96-4fc3-9a2e-5933e9c05b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-1d024175-c3a0-4ce7-b753-7bfa7a3fe640,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-d3107c67-66ab-46f4-a6b3-1d0bdd81926d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026027121-172.17.0.8-1599298739993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-cff16c85-dbca-4f80-be01-6521070e9014,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e193452b-d6b0-4a7f-bf63-4d0458e364f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-6b4bed2e-d58b-45ac-b3c4-742ca51dcbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-21c1a962-62bf-4846-b1fd-346af5d3cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-324e92d6-e70e-42ee-a697-ad467742c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-29f733a2-cb96-4fc3-9a2e-5933e9c05b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-1d024175-c3a0-4ce7-b753-7bfa7a3fe640,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-d3107c67-66ab-46f4-a6b3-1d0bdd81926d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193323821-172.17.0.8-1599299182562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-06bb9dda-0e88-43e3-959b-183ff3baf9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-6637d777-dda5-47c9-8670-fd30632601b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-8f69d5e7-874c-43e7-afcf-5d3c08dc3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-c8c17a4c-83df-4bb6-b997-6c298dc1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-1be4b211-5536-473b-b24f-a01223adf8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-73e73d91-0eec-475a-ad00-f660f1fa7020,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-82a96d2e-aef7-4531-8b84-2c949687867c,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-7288764d-81e7-4eea-87f7-c66256b9354e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193323821-172.17.0.8-1599299182562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-06bb9dda-0e88-43e3-959b-183ff3baf9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-6637d777-dda5-47c9-8670-fd30632601b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-8f69d5e7-874c-43e7-afcf-5d3c08dc3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-c8c17a4c-83df-4bb6-b997-6c298dc1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-1be4b211-5536-473b-b24f-a01223adf8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-73e73d91-0eec-475a-ad00-f660f1fa7020,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-82a96d2e-aef7-4531-8b84-2c949687867c,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-7288764d-81e7-4eea-87f7-c66256b9354e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752312446-172.17.0.8-1599299634555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35740,DS-5494fea7-ad5c-4656-a6f6-b19150728c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-21f8822e-57ee-4749-aaed-d226188528b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1fdeeec7-0154-4b81-9a18-87d9cba8be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-480e4136-00cc-426f-9da8-243e0fffc1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-10a089d8-b108-445c-805d-83539486ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-dbd1f072-9f0f-4141-bf35-8434dd1c4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-dde17b19-8c22-44b4-9685-8a8688e6eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-71f1acdf-8168-4030-9a9f-6abf02ed20ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752312446-172.17.0.8-1599299634555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35740,DS-5494fea7-ad5c-4656-a6f6-b19150728c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-21f8822e-57ee-4749-aaed-d226188528b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1fdeeec7-0154-4b81-9a18-87d9cba8be2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-480e4136-00cc-426f-9da8-243e0fffc1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-10a089d8-b108-445c-805d-83539486ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-dbd1f072-9f0f-4141-bf35-8434dd1c4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-dde17b19-8c22-44b4-9685-8a8688e6eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-71f1acdf-8168-4030-9a9f-6abf02ed20ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382836771-172.17.0.8-1599299981888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-16b262d3-4df2-44c6-ae7c-6fc484fec365,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-5097e377-d65f-485e-a44c-0f600a748de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-1a8dcebb-89e5-40cc-838f-61166f0eebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-2f20d542-8c6f-4744-8836-f723b209762c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d804aeab-071a-4e4e-85e2-97c2ec728fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-53f7bc74-7552-4370-b2af-05b22b71c0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-8c6bf31c-b625-4d57-b3d9-1a007f575f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-abe14ed5-a316-4f3b-ae03-77f9297d542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382836771-172.17.0.8-1599299981888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-16b262d3-4df2-44c6-ae7c-6fc484fec365,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-5097e377-d65f-485e-a44c-0f600a748de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-1a8dcebb-89e5-40cc-838f-61166f0eebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-2f20d542-8c6f-4744-8836-f723b209762c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d804aeab-071a-4e4e-85e2-97c2ec728fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-53f7bc74-7552-4370-b2af-05b22b71c0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-8c6bf31c-b625-4d57-b3d9-1a007f575f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-abe14ed5-a316-4f3b-ae03-77f9297d542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413731007-172.17.0.8-1599300298330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33312,DS-3888d45f-1610-4607-bc59-1d35dc34c8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-048e019b-1a2e-49d5-920c-35ec465ad0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-a260f2e7-b7f7-4fa3-a829-d721da498cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-80c9d274-dd5e-4ea1-af54-e7d6053db2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-92c9e9bb-7a61-4231-b6fb-972a2b198cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-5569d47f-7157-4976-a0dc-b134572430aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-2cf1cf8b-9981-49bc-b113-e3ef2664f327,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-63199c3f-2c51-46de-a830-532b5d8e3a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413731007-172.17.0.8-1599300298330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33312,DS-3888d45f-1610-4607-bc59-1d35dc34c8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-048e019b-1a2e-49d5-920c-35ec465ad0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-a260f2e7-b7f7-4fa3-a829-d721da498cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-80c9d274-dd5e-4ea1-af54-e7d6053db2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-92c9e9bb-7a61-4231-b6fb-972a2b198cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-5569d47f-7157-4976-a0dc-b134572430aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-2cf1cf8b-9981-49bc-b113-e3ef2664f327,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-63199c3f-2c51-46de-a830-532b5d8e3a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394541145-172.17.0.8-1599300328525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-abeb5669-aa46-4ed6-bd4a-09bbd245060b,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-26e86eb0-916a-4976-9573-e097489107d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-8575c0c1-43e3-404b-b5d2-0e9514db29e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-a78b3c76-8c12-4433-b94b-6984fafc1474,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-c1e39cf6-06c9-47fa-9aa7-a5532ba7988f,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-a8d34241-8ffb-4dc5-9574-dad361c3d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-fd7acf70-e479-48a3-b14d-844fd1ecdd97,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-46d8b6f0-40f7-4320-b1bb-0c47b36b623c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394541145-172.17.0.8-1599300328525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-abeb5669-aa46-4ed6-bd4a-09bbd245060b,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-26e86eb0-916a-4976-9573-e097489107d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-8575c0c1-43e3-404b-b5d2-0e9514db29e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-a78b3c76-8c12-4433-b94b-6984fafc1474,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-c1e39cf6-06c9-47fa-9aa7-a5532ba7988f,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-a8d34241-8ffb-4dc5-9574-dad361c3d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-fd7acf70-e479-48a3-b14d-844fd1ecdd97,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-46d8b6f0-40f7-4320-b1bb-0c47b36b623c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86028099-172.17.0.8-1599300564714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-7bad7290-5f73-4fa8-a1b4-f22ab9458dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-40d1a394-d6d3-4718-b934-1b2a70e7cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-a600afd3-faa8-431e-9d05-7ac02cae3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-55482281-1e58-485b-a13c-b81cbbda2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-95419ccc-b001-4dca-85cd-a1386599360f,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-82c3e730-0353-45db-af79-b30cff58756e,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-f0476e13-4765-4ce9-9587-076f5731ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-f0170856-f0e8-4897-a94e-2d4f19220d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86028099-172.17.0.8-1599300564714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-7bad7290-5f73-4fa8-a1b4-f22ab9458dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-40d1a394-d6d3-4718-b934-1b2a70e7cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-a600afd3-faa8-431e-9d05-7ac02cae3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-55482281-1e58-485b-a13c-b81cbbda2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-95419ccc-b001-4dca-85cd-a1386599360f,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-82c3e730-0353-45db-af79-b30cff58756e,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-f0476e13-4765-4ce9-9587-076f5731ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-f0170856-f0e8-4897-a94e-2d4f19220d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864477302-172.17.0.8-1599301487994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-408f14d7-45c2-44cd-b3e5-cc0fc5906e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-8f5e92b2-6de4-4748-8781-352197a5d9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-e1f0d2c5-c269-4c9f-8265-abf81e685149,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-4afa0816-dd4f-4043-a710-2931d0dc90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-852be788-d5c6-448a-ae9f-279de30f91e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8a39ec24-badc-419c-8ef6-69983aa56ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-43d017af-afc3-4dba-8a0b-ba1896b91f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-d7d54c52-7db9-43a0-8e4d-8c0fef3fda81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864477302-172.17.0.8-1599301487994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-408f14d7-45c2-44cd-b3e5-cc0fc5906e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-8f5e92b2-6de4-4748-8781-352197a5d9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-e1f0d2c5-c269-4c9f-8265-abf81e685149,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-4afa0816-dd4f-4043-a710-2931d0dc90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-852be788-d5c6-448a-ae9f-279de30f91e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8a39ec24-badc-419c-8ef6-69983aa56ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-43d017af-afc3-4dba-8a0b-ba1896b91f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-d7d54c52-7db9-43a0-8e4d-8c0fef3fda81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68789214-172.17.0.8-1599301527696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-ad1454aa-89ac-45fd-8a31-8bae43d42d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b6ac3cd5-4fb9-45f4-9df0-3f3c00f331a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-94fb34a1-f13c-4a49-846e-0286d125249c,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c7c54f53-917a-4d41-9f55-30b175cff3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-8a94b4cc-fc36-4a12-ab96-6faa37fb1595,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-827c5653-7860-4c04-83ee-a0b173e9e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-47ef9cda-82bb-46a7-857a-f9e6ac7ad10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-a257d30f-0900-4877-b974-4ef63aededca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68789214-172.17.0.8-1599301527696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-ad1454aa-89ac-45fd-8a31-8bae43d42d40,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b6ac3cd5-4fb9-45f4-9df0-3f3c00f331a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-94fb34a1-f13c-4a49-846e-0286d125249c,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c7c54f53-917a-4d41-9f55-30b175cff3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-8a94b4cc-fc36-4a12-ab96-6faa37fb1595,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-827c5653-7860-4c04-83ee-a0b173e9e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-47ef9cda-82bb-46a7-857a-f9e6ac7ad10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-a257d30f-0900-4877-b974-4ef63aededca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930260186-172.17.0.8-1599301842376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-60719837-bce1-4c70-8c17-42fa8ab2c791,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b9f32dcc-fba4-4734-8551-c28b4224843a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-de1c1079-98da-4306-bb9e-3996e9ff587b,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-89ba568e-dd29-4942-ad56-701b5de8dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-b82c2f3d-c4d0-48a5-9550-cffde19519e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-15bd3e01-479e-4da8-bffb-bc1df6e7e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-f128a579-6daf-40e6-9de3-f9a92185bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-d5c42d4e-3634-427c-bcf2-6923a68f889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930260186-172.17.0.8-1599301842376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-60719837-bce1-4c70-8c17-42fa8ab2c791,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b9f32dcc-fba4-4734-8551-c28b4224843a,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-de1c1079-98da-4306-bb9e-3996e9ff587b,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-89ba568e-dd29-4942-ad56-701b5de8dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-b82c2f3d-c4d0-48a5-9550-cffde19519e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-15bd3e01-479e-4da8-bffb-bc1df6e7e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-f128a579-6daf-40e6-9de3-f9a92185bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-d5c42d4e-3634-427c-bcf2-6923a68f889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641531117-172.17.0.8-1599302193510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-c659299a-0fe0-48c5-b9ba-b1deae91bf65,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-dc62af35-825e-4b47-a93c-51fbd989efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-234dbe16-2d92-4374-8322-b64547463d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-47c43a9b-02c3-4884-8b1c-8ccaa6c80b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-d7b96a10-fafc-4ee0-9194-6a7fe448d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-6081b18b-cb70-412c-a4b0-f3dee196e731,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-f2c82858-26db-4371-92d3-b70fec784fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-5dc2a37f-d8ad-4d19-ae18-841e664d7991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641531117-172.17.0.8-1599302193510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-c659299a-0fe0-48c5-b9ba-b1deae91bf65,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-dc62af35-825e-4b47-a93c-51fbd989efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-234dbe16-2d92-4374-8322-b64547463d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-47c43a9b-02c3-4884-8b1c-8ccaa6c80b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-d7b96a10-fafc-4ee0-9194-6a7fe448d6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-6081b18b-cb70-412c-a4b0-f3dee196e731,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-f2c82858-26db-4371-92d3-b70fec784fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-5dc2a37f-d8ad-4d19-ae18-841e664d7991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16937941-172.17.0.8-1599302504629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-f3abdf51-0618-4114-a8d6-87241c93a38c,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-70030f2b-3caf-4126-8400-cbcb9af98cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b4c3eee9-d0de-4989-bc56-7d0c132c9767,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-e725c555-0310-4835-b1b8-bb1ad261f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-cc5ca76b-4320-4d56-b3c4-6171302f2689,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-b5d4d480-4d96-4417-b533-f3ae3155f511,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-b891dcd5-580a-4480-adf3-e70b1789463f,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-7d0bb83b-468d-4702-b8d9-7bb910b7c61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16937941-172.17.0.8-1599302504629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-f3abdf51-0618-4114-a8d6-87241c93a38c,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-70030f2b-3caf-4126-8400-cbcb9af98cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b4c3eee9-d0de-4989-bc56-7d0c132c9767,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-e725c555-0310-4835-b1b8-bb1ad261f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-cc5ca76b-4320-4d56-b3c4-6171302f2689,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-b5d4d480-4d96-4417-b533-f3ae3155f511,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-b891dcd5-580a-4480-adf3-e70b1789463f,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-7d0bb83b-468d-4702-b8d9-7bb910b7c61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129994518-172.17.0.8-1599302536394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-a9384f22-c18d-420a-9eb5-933f0078519a,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-243658b7-3e2b-4eda-a8a8-c45e0aae5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-11864bba-761d-4912-9c9a-9f8625e280ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-17dfc09b-b25c-4533-a3c5-844dea91be8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-668fa3e2-cbb4-487e-aad1-a52cf757de11,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-9a7d0c90-0969-4c4b-85b4-856aa26c878c,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-e0c54ea6-94a6-40e0-8c49-f7c34f66df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-1e51dbb6-a8b6-48df-9aee-0c9e21997e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129994518-172.17.0.8-1599302536394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-a9384f22-c18d-420a-9eb5-933f0078519a,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-243658b7-3e2b-4eda-a8a8-c45e0aae5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-11864bba-761d-4912-9c9a-9f8625e280ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-17dfc09b-b25c-4533-a3c5-844dea91be8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-668fa3e2-cbb4-487e-aad1-a52cf757de11,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-9a7d0c90-0969-4c4b-85b4-856aa26c878c,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-e0c54ea6-94a6-40e0-8c49-f7c34f66df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-1e51dbb6-a8b6-48df-9aee-0c9e21997e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155875955-172.17.0.8-1599302821321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-dabeb779-3d93-4846-8208-6435d3398f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-c6d98cbb-565c-4f0b-bbb2-e892f5c27200,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-dc179731-77b1-41e2-80ab-fbdd09c16c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-f37537eb-0703-415a-a0bf-875e2b37ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-7726a3a8-1339-47fe-9e0c-192570fd4f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-a31b33db-c312-4a14-8018-dc1ca7b3c74d,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-53d2589a-d51a-4135-96c4-a14616dd9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-78b988ec-24c4-4385-a6b3-54e39b5d273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155875955-172.17.0.8-1599302821321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-dabeb779-3d93-4846-8208-6435d3398f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-c6d98cbb-565c-4f0b-bbb2-e892f5c27200,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-dc179731-77b1-41e2-80ab-fbdd09c16c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-f37537eb-0703-415a-a0bf-875e2b37ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-7726a3a8-1339-47fe-9e0c-192570fd4f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-a31b33db-c312-4a14-8018-dc1ca7b3c74d,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-53d2589a-d51a-4135-96c4-a14616dd9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-78b988ec-24c4-4385-a6b3-54e39b5d273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5723
