reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042677911-172.17.0.2-1599289922984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-0998ef06-e6de-41aa-8093-4bc331ba4ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-a0a466b1-9105-4275-993c-54e1fc9da46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a4378476-672a-4b68-abc1-8839f67cf50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-19cb58f9-3ab4-4a3d-9544-bb7b6d594333,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-afb71068-d5a5-4672-ad2d-a1bab5a800ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-15a6b1e7-450b-4d55-a871-ed0d7dea5c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-4fee427f-0776-4d9f-81e5-cbc22ad49e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-30d28163-e9c2-43c3-88f7-aac9812ea9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042677911-172.17.0.2-1599289922984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-0998ef06-e6de-41aa-8093-4bc331ba4ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-a0a466b1-9105-4275-993c-54e1fc9da46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a4378476-672a-4b68-abc1-8839f67cf50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-19cb58f9-3ab4-4a3d-9544-bb7b6d594333,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-afb71068-d5a5-4672-ad2d-a1bab5a800ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-15a6b1e7-450b-4d55-a871-ed0d7dea5c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-4fee427f-0776-4d9f-81e5-cbc22ad49e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-30d28163-e9c2-43c3-88f7-aac9812ea9bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706347581-172.17.0.2-1599290181029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-6a0df17c-4f3f-48dc-bf1b-f36637a2c784,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-08920192-6edb-415a-bd76-c8dc32c1050e,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-2f4c51d2-d5b4-42e3-9e4c-fb3e4ea92ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-3861f0bc-2c7b-4a22-9780-ed46faf13462,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-88e28b4e-5c47-47f1-a7c5-a5ba1222baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-dbb1ec17-9155-4b65-84db-c85247e18e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7bc06a8c-4fb5-4b8c-93f3-f5d05973f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-b69ab2ab-2c24-4f97-b334-b093a080d9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706347581-172.17.0.2-1599290181029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-6a0df17c-4f3f-48dc-bf1b-f36637a2c784,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-08920192-6edb-415a-bd76-c8dc32c1050e,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-2f4c51d2-d5b4-42e3-9e4c-fb3e4ea92ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-3861f0bc-2c7b-4a22-9780-ed46faf13462,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-88e28b4e-5c47-47f1-a7c5-a5ba1222baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-dbb1ec17-9155-4b65-84db-c85247e18e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7bc06a8c-4fb5-4b8c-93f3-f5d05973f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-b69ab2ab-2c24-4f97-b334-b093a080d9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7863638-172.17.0.2-1599290376745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45587,DS-5580d330-b894-487f-8c19-e8f9dfe3bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d196eca4-7e43-40ae-b661-5923216d0906,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-324758bf-7c70-4911-b050-354023cf8239,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-a7d71b5f-ecef-457a-b116-d9566ce842cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-29cf2be4-d686-4b6b-8945-3e3f18b6b701,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1261eaf2-5948-42f8-87b7-06e66b69e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-d57df66f-227d-4e25-8e3e-33349b930c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-ef6933d2-dd6f-49fe-ba2f-fe5fb9ca5815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7863638-172.17.0.2-1599290376745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45587,DS-5580d330-b894-487f-8c19-e8f9dfe3bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-d196eca4-7e43-40ae-b661-5923216d0906,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-324758bf-7c70-4911-b050-354023cf8239,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-a7d71b5f-ecef-457a-b116-d9566ce842cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-29cf2be4-d686-4b6b-8945-3e3f18b6b701,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1261eaf2-5948-42f8-87b7-06e66b69e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-d57df66f-227d-4e25-8e3e-33349b930c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-ef6933d2-dd6f-49fe-ba2f-fe5fb9ca5815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059161218-172.17.0.2-1599290488310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-366c131c-e286-4f3f-9ff1-094afb87dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-412e1b03-5100-4ecb-9de3-9c037356c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-ff1c4dfa-beac-422c-8a80-e43b07f07ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-93114665-ec52-429d-959d-6c17f788f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-e892d779-dbba-4e68-a4ad-da22fa49c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-198b3f50-9342-405a-ab05-16cff7c357f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-9b1ad6c7-a943-4579-9a64-948776bacb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-52ce7a55-6464-4823-a822-9a22cf079bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059161218-172.17.0.2-1599290488310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-366c131c-e286-4f3f-9ff1-094afb87dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-412e1b03-5100-4ecb-9de3-9c037356c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-ff1c4dfa-beac-422c-8a80-e43b07f07ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-93114665-ec52-429d-959d-6c17f788f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-e892d779-dbba-4e68-a4ad-da22fa49c16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-198b3f50-9342-405a-ab05-16cff7c357f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-9b1ad6c7-a943-4579-9a64-948776bacb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-52ce7a55-6464-4823-a822-9a22cf079bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183908250-172.17.0.2-1599290737780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-5e097faf-ab03-4c96-8256-0f10a27d6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-fdb48f06-23f2-4f15-b60e-0997c2782610,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-27409f05-1b8f-4d0b-add6-47a0931de86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-da54ca35-c414-4249-8bb9-5e76a6b9089d,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-32e4c52b-89f3-4d54-9e5d-4b893c622059,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f21bda9a-85ce-463b-ab7f-540968e7e064,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-62336886-f0ae-421c-843a-ad4689ce7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-1819be89-b993-48dc-83b6-766e9921f977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183908250-172.17.0.2-1599290737780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-5e097faf-ab03-4c96-8256-0f10a27d6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-fdb48f06-23f2-4f15-b60e-0997c2782610,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-27409f05-1b8f-4d0b-add6-47a0931de86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-da54ca35-c414-4249-8bb9-5e76a6b9089d,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-32e4c52b-89f3-4d54-9e5d-4b893c622059,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f21bda9a-85ce-463b-ab7f-540968e7e064,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-62336886-f0ae-421c-843a-ad4689ce7ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-1819be89-b993-48dc-83b6-766e9921f977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261739825-172.17.0.2-1599291477406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-b7764fee-98a7-4389-94e8-5ffd4a4aa965,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-e03f86a5-9cac-4d3e-b8c9-fa975bb5015b,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ca85867b-4566-4e37-9add-7c3e6cd926ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0846fa17-c8a0-472b-a28d-67f40eb7102e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6bde666d-6829-48fd-95ea-e74d76d0ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-b4bef95b-48bd-4373-9953-555662acdc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-d4a75563-5618-49c9-a147-cee2ad21da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-94d357f6-01c5-4226-88f2-fa0d65fb8cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261739825-172.17.0.2-1599291477406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-b7764fee-98a7-4389-94e8-5ffd4a4aa965,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-e03f86a5-9cac-4d3e-b8c9-fa975bb5015b,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ca85867b-4566-4e37-9add-7c3e6cd926ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0846fa17-c8a0-472b-a28d-67f40eb7102e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6bde666d-6829-48fd-95ea-e74d76d0ef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-b4bef95b-48bd-4373-9953-555662acdc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-d4a75563-5618-49c9-a147-cee2ad21da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-94d357f6-01c5-4226-88f2-fa0d65fb8cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857719301-172.17.0.2-1599292116004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37840,DS-5b3a0990-47fa-486d-9bdb-cf9631e975c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-0a3e7a07-b12b-4fb8-b244-61fb88ea1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-b76b6ecf-4309-47e7-ab1b-423f1f2e3465,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-6533621d-3b8a-478a-8441-22f817ec7191,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-e3a4c4c6-6c38-4ce6-b899-e75b3552db01,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-586a23cd-1738-4d8b-bc68-2639a46a171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-9f07940e-be71-48f7-a49b-2369363296b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5951e7ff-000e-4bf2-853a-d2c1e1b3dd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857719301-172.17.0.2-1599292116004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37840,DS-5b3a0990-47fa-486d-9bdb-cf9631e975c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-0a3e7a07-b12b-4fb8-b244-61fb88ea1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-b76b6ecf-4309-47e7-ab1b-423f1f2e3465,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-6533621d-3b8a-478a-8441-22f817ec7191,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-e3a4c4c6-6c38-4ce6-b899-e75b3552db01,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-586a23cd-1738-4d8b-bc68-2639a46a171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-9f07940e-be71-48f7-a49b-2369363296b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5951e7ff-000e-4bf2-853a-d2c1e1b3dd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050870472-172.17.0.2-1599292513847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45611,DS-1ef5de17-ec63-4119-88d2-78488a903d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-0dc4468c-ac9d-408c-b5f4-248d4c786c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-4e0df3f5-cbdb-4995-a8be-82a15289c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-00894628-5271-4685-b5f3-7eec894eefbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-08b6ca88-2257-4b9e-afaa-aed086df9157,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ad494efa-3554-4b60-b0f7-4c178728e570,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-1fa6557a-83b4-474f-b336-6fed1b22d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6c29ab2c-5da3-4d4e-aa4f-51b790567cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050870472-172.17.0.2-1599292513847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45611,DS-1ef5de17-ec63-4119-88d2-78488a903d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-0dc4468c-ac9d-408c-b5f4-248d4c786c39,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-4e0df3f5-cbdb-4995-a8be-82a15289c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-00894628-5271-4685-b5f3-7eec894eefbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-08b6ca88-2257-4b9e-afaa-aed086df9157,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ad494efa-3554-4b60-b0f7-4c178728e570,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-1fa6557a-83b4-474f-b336-6fed1b22d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6c29ab2c-5da3-4d4e-aa4f-51b790567cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731366750-172.17.0.2-1599293308825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-9b8b67aa-66e2-415c-b077-0c92ba9ef9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-42ef51fb-c11c-4632-83cb-4de9161d3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-bd809a4f-f13c-45fa-b4d3-3245c8cc9478,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-f5df44d0-4f88-4a82-b81f-8cdf9b9c9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-881b1329-ce38-40ab-a981-2104f3045098,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-6d26cabd-1661-48fb-b372-4fc5b3cb3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-7fa0d566-56c3-4677-a7bb-b2352fca2452,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-0770635a-2a74-4d9f-ab9b-35c2802f00cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731366750-172.17.0.2-1599293308825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-9b8b67aa-66e2-415c-b077-0c92ba9ef9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-42ef51fb-c11c-4632-83cb-4de9161d3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-bd809a4f-f13c-45fa-b4d3-3245c8cc9478,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-f5df44d0-4f88-4a82-b81f-8cdf9b9c9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-881b1329-ce38-40ab-a981-2104f3045098,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-6d26cabd-1661-48fb-b372-4fc5b3cb3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-7fa0d566-56c3-4677-a7bb-b2352fca2452,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-0770635a-2a74-4d9f-ab9b-35c2802f00cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201403428-172.17.0.2-1599293384800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-05c0d550-2752-488b-b6b6-3ca9e366bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-f46f25aa-194e-4c2b-b7df-1199aaaf2a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-6328d541-c5f2-4fae-a9e8-46f607519e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-48984c64-4dc6-43c5-953c-d0857d7de010,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-3fc969a1-c8a4-4e70-9b74-28aa79555246,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-631c2aa9-b074-49be-9e9f-faec62ee68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-1a627cf5-a37f-4868-9a14-e48dd528844c,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-d1abf6f0-63d9-4edf-994d-44e9ab054a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201403428-172.17.0.2-1599293384800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-05c0d550-2752-488b-b6b6-3ca9e366bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-f46f25aa-194e-4c2b-b7df-1199aaaf2a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-6328d541-c5f2-4fae-a9e8-46f607519e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-48984c64-4dc6-43c5-953c-d0857d7de010,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-3fc969a1-c8a4-4e70-9b74-28aa79555246,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-631c2aa9-b074-49be-9e9f-faec62ee68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-1a627cf5-a37f-4868-9a14-e48dd528844c,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-d1abf6f0-63d9-4edf-994d-44e9ab054a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807511074-172.17.0.2-1599294185255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-82c2f3c1-b5e2-4164-8790-df9df061471c,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-884accdb-e1ab-46cf-bf28-32449de32a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-2ae470c3-2d94-4f49-a322-b788e02698ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-d1b0d89f-5537-42c9-a982-bf98b6812d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-3b170db7-56cc-4e39-900f-4c0c60fa38ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-e9ded570-97c1-4f34-9987-8b2da25bca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-4bfaeb74-0288-4ae4-9124-12bab18202b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-a088290e-d864-4743-8832-dac3e2d53f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807511074-172.17.0.2-1599294185255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-82c2f3c1-b5e2-4164-8790-df9df061471c,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-884accdb-e1ab-46cf-bf28-32449de32a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-2ae470c3-2d94-4f49-a322-b788e02698ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-d1b0d89f-5537-42c9-a982-bf98b6812d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-3b170db7-56cc-4e39-900f-4c0c60fa38ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-e9ded570-97c1-4f34-9987-8b2da25bca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-4bfaeb74-0288-4ae4-9124-12bab18202b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-a088290e-d864-4743-8832-dac3e2d53f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697629455-172.17.0.2-1599294730876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-359123f7-1ded-4347-b51b-c0171241d02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-ef805bc2-da80-45ab-af15-30d7ca580a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-d5e285f7-1200-42a6-9918-52db63ecf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4b084bee-620a-4721-9d62-79174ef81522,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-133a332a-e51b-4608-b21a-20dd3970873d,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-1b26c573-c259-40db-872b-de007b75ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-32be3371-f422-4b86-8798-215ed2670a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-4934608e-cb8d-466c-a3aa-b26fcd0309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697629455-172.17.0.2-1599294730876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-359123f7-1ded-4347-b51b-c0171241d02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-ef805bc2-da80-45ab-af15-30d7ca580a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-d5e285f7-1200-42a6-9918-52db63ecf8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4b084bee-620a-4721-9d62-79174ef81522,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-133a332a-e51b-4608-b21a-20dd3970873d,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-1b26c573-c259-40db-872b-de007b75ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-32be3371-f422-4b86-8798-215ed2670a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-4934608e-cb8d-466c-a3aa-b26fcd0309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 3000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994173048-172.17.0.2-1599295086010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-5e2be463-59f2-49af-a428-d8b0d088c070,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d006fc67-87e9-4bfa-9ac9-a06cec8bd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-756d1169-eae3-4903-be6b-83b99b96ed0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-83c96faf-07c9-413c-9d49-fc1937c1ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-01bf5880-0087-4b11-87cb-6858674c6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-9dee2cc1-7036-4a94-98c1-cf0671c2ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-04e03eba-4496-4d44-adf3-182450c37e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-938bbf8b-e016-449a-9e9f-340fa4747843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994173048-172.17.0.2-1599295086010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-5e2be463-59f2-49af-a428-d8b0d088c070,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d006fc67-87e9-4bfa-9ac9-a06cec8bd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-756d1169-eae3-4903-be6b-83b99b96ed0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-83c96faf-07c9-413c-9d49-fc1937c1ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-01bf5880-0087-4b11-87cb-6858674c6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-9dee2cc1-7036-4a94-98c1-cf0671c2ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-04e03eba-4496-4d44-adf3-182450c37e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-938bbf8b-e016-449a-9e9f-340fa4747843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5672
