reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005623518-172.17.0.11-1599336863359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-2559340b-0dff-4a53-8b70-6c779fdf95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-8dfe15c2-c811-472f-b2b6-002efa85164f,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-e46fed69-d944-4d59-97b3-3867b832ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2e071cc0-370d-4fde-8861-4b8c9dc453e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-f6f379ae-e9ea-445d-bfb1-477b6b88451c,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ed41808a-0ec3-4dde-80b9-b036da1c9102,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-108e9f0c-6e92-4748-a377-24f0f896587a,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-4e4cfe44-6457-4e8a-ac01-956afa52b13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005623518-172.17.0.11-1599336863359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-2559340b-0dff-4a53-8b70-6c779fdf95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-8dfe15c2-c811-472f-b2b6-002efa85164f,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-e46fed69-d944-4d59-97b3-3867b832ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2e071cc0-370d-4fde-8861-4b8c9dc453e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-f6f379ae-e9ea-445d-bfb1-477b6b88451c,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ed41808a-0ec3-4dde-80b9-b036da1c9102,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-108e9f0c-6e92-4748-a377-24f0f896587a,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-4e4cfe44-6457-4e8a-ac01-956afa52b13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121060848-172.17.0.11-1599337062602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-dc0c4407-8112-44a0-8557-79342af4560f,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-092b6a58-e7ce-4fa7-90d4-31cf60106aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-4d9f43c0-77e9-4fbf-b750-4badad166a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-2c41397b-ef35-4c58-98da-8bd51eb6d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-dfc933b0-786d-4fdf-ba24-048d48971d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-64a05fdb-440d-4ea5-99c2-f850e250da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-b9e81f32-3624-41b3-868f-14c38a1a3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-6cfc1541-d275-4e1e-bb29-276f57c45a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121060848-172.17.0.11-1599337062602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46657,DS-dc0c4407-8112-44a0-8557-79342af4560f,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-092b6a58-e7ce-4fa7-90d4-31cf60106aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-4d9f43c0-77e9-4fbf-b750-4badad166a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-2c41397b-ef35-4c58-98da-8bd51eb6d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-dfc933b0-786d-4fdf-ba24-048d48971d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-64a05fdb-440d-4ea5-99c2-f850e250da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-b9e81f32-3624-41b3-868f-14c38a1a3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-6cfc1541-d275-4e1e-bb29-276f57c45a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961780418-172.17.0.11-1599337140663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-ee5f6beb-a03d-4c64-8b6a-e1d3f15e77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-4e4f8a42-2c31-4126-b1fe-2b427e498c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-1328aa41-bedb-4346-8841-4169d6c8cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-74421264-171e-49d4-963f-7bf5fae8c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-66e67158-ab28-4bcd-a101-634b483b15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-fe438f79-a851-4fee-92c4-57701b6632f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-c99ed1b8-94ea-4da5-a0fd-5ac9eeedeaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-889e5443-9e18-4672-8866-c913f3e9fa6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961780418-172.17.0.11-1599337140663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-ee5f6beb-a03d-4c64-8b6a-e1d3f15e77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-4e4f8a42-2c31-4126-b1fe-2b427e498c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-1328aa41-bedb-4346-8841-4169d6c8cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-74421264-171e-49d4-963f-7bf5fae8c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-66e67158-ab28-4bcd-a101-634b483b15f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-fe438f79-a851-4fee-92c4-57701b6632f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-c99ed1b8-94ea-4da5-a0fd-5ac9eeedeaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-889e5443-9e18-4672-8866-c913f3e9fa6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968358223-172.17.0.11-1599337182215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-c0702e36-f43f-4a1c-91ef-01ddd6cf9803,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a98b5be3-a0d7-4d1e-bc88-5a353253efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-30ebc166-90f0-473d-9909-980150aaa820,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-1373850c-9ef6-4afb-a503-ae1b07c7db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-5fc3913c-2286-4c31-9742-624803731c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6aa85edc-34e0-49fc-b1d5-d1e881ec30de,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-2dafc709-7fb7-4bd4-a73a-6c11edabe55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-3ae26e5a-221a-42ba-a512-f35e3109150f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968358223-172.17.0.11-1599337182215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-c0702e36-f43f-4a1c-91ef-01ddd6cf9803,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a98b5be3-a0d7-4d1e-bc88-5a353253efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-30ebc166-90f0-473d-9909-980150aaa820,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-1373850c-9ef6-4afb-a503-ae1b07c7db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-5fc3913c-2286-4c31-9742-624803731c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6aa85edc-34e0-49fc-b1d5-d1e881ec30de,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-2dafc709-7fb7-4bd4-a73a-6c11edabe55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-3ae26e5a-221a-42ba-a512-f35e3109150f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240323521-172.17.0.11-1599337220676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44876,DS-7e03d8a6-4464-4b86-879a-ccf9ea731250,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-a01dfc23-a918-4396-a9b0-05808d573a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-a32f13d4-15cb-46a6-85b4-0b20e6c047d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-9f2ccf43-c5ee-4447-bf4c-d1e133d6e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c51534de-bb95-4c2d-93b2-cf948b4135fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3815f411-b2d1-4fbc-a2aa-fcf4c5d54fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-825cd445-5284-4b0b-95c3-04d1dd17099d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-549738cf-18d3-472b-b094-8ef22b1dde1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240323521-172.17.0.11-1599337220676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44876,DS-7e03d8a6-4464-4b86-879a-ccf9ea731250,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-a01dfc23-a918-4396-a9b0-05808d573a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-a32f13d4-15cb-46a6-85b4-0b20e6c047d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-9f2ccf43-c5ee-4447-bf4c-d1e133d6e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c51534de-bb95-4c2d-93b2-cf948b4135fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3815f411-b2d1-4fbc-a2aa-fcf4c5d54fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-825cd445-5284-4b0b-95c3-04d1dd17099d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-549738cf-18d3-472b-b094-8ef22b1dde1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789291855-172.17.0.11-1599337293755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-1716021a-11dc-4e51-b1eb-534bdf1e7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-a514f48b-da94-4d54-804d-4aacf6796d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-847a081e-1423-4abe-ba80-ee03faffc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-e7268ce8-1d1f-490e-a297-aec169b8685e,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-e57409c4-8d61-4002-b2c1-6e6a1d1d09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-762e7a74-fcc8-45e7-a2f4-8970798e37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-43294182-66e5-4a46-b097-25d71dbee6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-0d552e7e-881a-4d95-a5cf-8ba41f7bb910,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789291855-172.17.0.11-1599337293755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-1716021a-11dc-4e51-b1eb-534bdf1e7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-a514f48b-da94-4d54-804d-4aacf6796d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-847a081e-1423-4abe-ba80-ee03faffc12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-e7268ce8-1d1f-490e-a297-aec169b8685e,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-e57409c4-8d61-4002-b2c1-6e6a1d1d09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-762e7a74-fcc8-45e7-a2f4-8970798e37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-43294182-66e5-4a46-b097-25d71dbee6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-0d552e7e-881a-4d95-a5cf-8ba41f7bb910,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673399553-172.17.0.11-1599337321258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-4493ebc5-3d0e-4757-96d5-fd2c2a6a75df,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-5d5929bc-9410-4e4a-be99-e69d15435406,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-841e5640-3014-465a-8608-adb74382b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-77fb86f1-c036-4ede-9d8c-7dd8e079c435,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-b5843128-ad6a-4ab5-ba3c-1cc794a9c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-56c9fd62-1433-4be2-b061-8d1a6a9f27e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-8844233e-25d7-4cd5-9ad9-f291d3337b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-e042d684-01b6-468f-8c49-125c8d1622ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673399553-172.17.0.11-1599337321258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-4493ebc5-3d0e-4757-96d5-fd2c2a6a75df,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-5d5929bc-9410-4e4a-be99-e69d15435406,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-841e5640-3014-465a-8608-adb74382b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-77fb86f1-c036-4ede-9d8c-7dd8e079c435,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-b5843128-ad6a-4ab5-ba3c-1cc794a9c75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-56c9fd62-1433-4be2-b061-8d1a6a9f27e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-8844233e-25d7-4cd5-9ad9-f291d3337b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-e042d684-01b6-468f-8c49-125c8d1622ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224311754-172.17.0.11-1599337453257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-0d172601-3944-43f6-9b55-28919c685774,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-77adb51b-3cda-47c4-b5f1-049e7c4d8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e08ad423-4965-49a5-bc06-b3c094dfb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-362df569-db72-418d-b110-06c9354eb91c,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-b561b1b7-5aa9-414e-bc56-73c16e59a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c946ea8f-3719-4700-9c1d-b85556be48ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ec3c89e0-836b-4007-8f84-cd3f11e94474,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-11aed305-d69f-4b96-ae2f-7456d252b31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224311754-172.17.0.11-1599337453257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-0d172601-3944-43f6-9b55-28919c685774,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-77adb51b-3cda-47c4-b5f1-049e7c4d8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-e08ad423-4965-49a5-bc06-b3c094dfb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-362df569-db72-418d-b110-06c9354eb91c,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-b561b1b7-5aa9-414e-bc56-73c16e59a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c946ea8f-3719-4700-9c1d-b85556be48ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ec3c89e0-836b-4007-8f84-cd3f11e94474,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-11aed305-d69f-4b96-ae2f-7456d252b31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615449176-172.17.0.11-1599337732052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-41c5eb1b-4bb2-43c7-8039-c71f927a81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-441bdc32-ed91-4f91-adfa-63bd79591469,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-386254eb-0a7c-48ef-98f7-9e84a2831b97,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-fb9d558c-4f72-44a2-b7b8-0cf323fe3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c98f7f5f-7c9f-44b1-b56a-d2357dbccc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-32c2ef86-0b47-4ec1-b9dc-ac0a77fc4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-2d11fda9-64bd-4f51-823a-baf9aba34e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-a0608f8b-aad4-484d-9bee-318f0b72ee84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615449176-172.17.0.11-1599337732052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-41c5eb1b-4bb2-43c7-8039-c71f927a81c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-441bdc32-ed91-4f91-adfa-63bd79591469,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-386254eb-0a7c-48ef-98f7-9e84a2831b97,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-fb9d558c-4f72-44a2-b7b8-0cf323fe3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c98f7f5f-7c9f-44b1-b56a-d2357dbccc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-32c2ef86-0b47-4ec1-b9dc-ac0a77fc4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-2d11fda9-64bd-4f51-823a-baf9aba34e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-a0608f8b-aad4-484d-9bee-318f0b72ee84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287569064-172.17.0.11-1599337806352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-aa4155e2-05ac-4293-9359-d14938a1a743,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-78665fc3-86c0-4a86-ad9f-13e0aa62e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-baa39754-f6b3-42b3-a44e-8dda223d6d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-38fc309c-bf98-4e3c-a552-4924a3b2ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-919b02ca-a592-4166-90a0-3c0b1cfa7604,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-4719d78b-6326-4d3b-b839-c65616e36f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-fbce52c0-6d49-419d-95d7-aec8dc4e718a,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-aaa58253-c3ef-468a-ae13-2e5c10efb4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287569064-172.17.0.11-1599337806352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-aa4155e2-05ac-4293-9359-d14938a1a743,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-78665fc3-86c0-4a86-ad9f-13e0aa62e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-baa39754-f6b3-42b3-a44e-8dda223d6d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-38fc309c-bf98-4e3c-a552-4924a3b2ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-919b02ca-a592-4166-90a0-3c0b1cfa7604,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-4719d78b-6326-4d3b-b839-c65616e36f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-fbce52c0-6d49-419d-95d7-aec8dc4e718a,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-aaa58253-c3ef-468a-ae13-2e5c10efb4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53947495-172.17.0.11-1599338056212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-9541800a-0d09-4276-a164-4a430451dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-5db48057-0058-4c76-b819-fb383dc3796e,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0557d8b0-079d-46ad-bcec-1a11e9b146d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-e13da61a-1871-45e2-9732-3578fa6cf290,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-fe9e6bff-f4c2-459f-8471-d5c96f7ada64,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-8ce1bb1a-411a-49af-8623-14217b916a55,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-30467791-64bb-4cb3-ab8b-2968ff5c1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-521afd1f-b2a6-4fb4-92da-0afe107eea76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53947495-172.17.0.11-1599338056212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-9541800a-0d09-4276-a164-4a430451dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-5db48057-0058-4c76-b819-fb383dc3796e,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0557d8b0-079d-46ad-bcec-1a11e9b146d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-e13da61a-1871-45e2-9732-3578fa6cf290,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-fe9e6bff-f4c2-459f-8471-d5c96f7ada64,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-8ce1bb1a-411a-49af-8623-14217b916a55,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-30467791-64bb-4cb3-ab8b-2968ff5c1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-521afd1f-b2a6-4fb4-92da-0afe107eea76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891089377-172.17.0.11-1599338425741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-59935c88-2668-4d50-a15a-acb5585ac4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-5042f1ed-6085-465b-a803-34cf7d87aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-30526bb2-9c60-403d-a5aa-4bad61366ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-fedf4beb-633b-4293-8bd3-ca349f783578,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-8269744a-8363-46c5-878d-608d719433ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-685da72c-55b3-4b36-a6b2-bd261b0705a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-ce06d715-da67-465c-a33a-58bfebf110e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-cfba3d9e-c891-4d6e-89d4-43d8aeaba3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891089377-172.17.0.11-1599338425741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-59935c88-2668-4d50-a15a-acb5585ac4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-5042f1ed-6085-465b-a803-34cf7d87aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-30526bb2-9c60-403d-a5aa-4bad61366ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-fedf4beb-633b-4293-8bd3-ca349f783578,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-8269744a-8363-46c5-878d-608d719433ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-685da72c-55b3-4b36-a6b2-bd261b0705a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-ce06d715-da67-465c-a33a-58bfebf110e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-cfba3d9e-c891-4d6e-89d4-43d8aeaba3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347147819-172.17.0.11-1599338463414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-0415c1fa-cabe-48c3-91b0-bc26b0df8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-f61bd66c-a2b6-402e-bd73-76c1f77d824d,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-5c7d1c8d-6836-4440-b69f-2ba18e9c70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0447d653-5c34-43fd-8d96-d50c2560ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-54b39c70-52b4-4979-9e1b-71beb6c546e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6437fd14-6ea9-4550-a588-1e525d237017,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-77b6d584-647e-4d01-9e87-78d8af39e357,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-727b15e1-a216-4556-bd3f-80a9c1eb138f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347147819-172.17.0.11-1599338463414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-0415c1fa-cabe-48c3-91b0-bc26b0df8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-f61bd66c-a2b6-402e-bd73-76c1f77d824d,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-5c7d1c8d-6836-4440-b69f-2ba18e9c70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0447d653-5c34-43fd-8d96-d50c2560ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-54b39c70-52b4-4979-9e1b-71beb6c546e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6437fd14-6ea9-4550-a588-1e525d237017,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-77b6d584-647e-4d01-9e87-78d8af39e357,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-727b15e1-a216-4556-bd3f-80a9c1eb138f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666451054-172.17.0.11-1599338576070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-e7c6cbdc-368d-416f-bece-769c5b48c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-ef939afe-9712-44b2-a9ab-3609daf35262,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-4851aa97-f70d-4785-b9b1-f102a6c4feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-2ee6c889-04ff-44e6-a7f2-deded0e77669,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c6abbec8-2eee-4096-aea0-cdf88c5f8881,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a9e11f4c-8033-45ce-923a-569378d87810,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-cb6f3815-6424-45fe-b5a2-abeb2081f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-4775ac4e-f5a5-4198-bde7-516ae15de3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666451054-172.17.0.11-1599338576070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-e7c6cbdc-368d-416f-bece-769c5b48c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-ef939afe-9712-44b2-a9ab-3609daf35262,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-4851aa97-f70d-4785-b9b1-f102a6c4feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-2ee6c889-04ff-44e6-a7f2-deded0e77669,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c6abbec8-2eee-4096-aea0-cdf88c5f8881,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a9e11f4c-8033-45ce-923a-569378d87810,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-cb6f3815-6424-45fe-b5a2-abeb2081f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-4775ac4e-f5a5-4198-bde7-516ae15de3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800135551-172.17.0.11-1599338610650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-b9c0ff17-9e39-43f8-a39d-57382b1fc58d,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4bb2dbab-3e05-409a-a377-a6d20d31e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-8148f961-9ec6-4c2c-bcd5-63e783f32b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-4c88ab05-f548-4cdb-9c37-84b2eb528844,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-66166f0b-07fa-4acf-ba55-0807e92fd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-7322c5f6-9772-49de-a3bf-df17c19d91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-66bafb76-1a2a-40fc-bdb7-2c984707f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2f17b86a-ef80-4ba1-b12c-01a60ab138ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800135551-172.17.0.11-1599338610650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-b9c0ff17-9e39-43f8-a39d-57382b1fc58d,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4bb2dbab-3e05-409a-a377-a6d20d31e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-8148f961-9ec6-4c2c-bcd5-63e783f32b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-4c88ab05-f548-4cdb-9c37-84b2eb528844,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-66166f0b-07fa-4acf-ba55-0807e92fd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-7322c5f6-9772-49de-a3bf-df17c19d91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-66bafb76-1a2a-40fc-bdb7-2c984707f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2f17b86a-ef80-4ba1-b12c-01a60ab138ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595238689-172.17.0.11-1599338709115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-60f8a43f-7262-449e-a20c-ccfcce648622,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-7a041153-a50a-4be3-aaff-f44493d15e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-05af11f8-b6f9-4c9d-b89d-13ff59761264,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-06675ba2-df30-4580-9b7e-0eed61720706,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-ec0cab3c-b480-4e21-8856-76c1b811ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-a8cbad2f-efd5-4cdd-b68b-73c935872ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-2a8cbaba-e08a-417f-9048-0aa5d9aa539c,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-ca044d53-a4ca-46b3-99eb-64adeea2d3ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595238689-172.17.0.11-1599338709115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-60f8a43f-7262-449e-a20c-ccfcce648622,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-7a041153-a50a-4be3-aaff-f44493d15e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-05af11f8-b6f9-4c9d-b89d-13ff59761264,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-06675ba2-df30-4580-9b7e-0eed61720706,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-ec0cab3c-b480-4e21-8856-76c1b811ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-a8cbad2f-efd5-4cdd-b68b-73c935872ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-2a8cbaba-e08a-417f-9048-0aa5d9aa539c,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-ca044d53-a4ca-46b3-99eb-64adeea2d3ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566459727-172.17.0.11-1599338840001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36050,DS-51c6aa23-e0f0-41fb-b033-93e4e55d0fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-109fc0c8-5538-42b5-bef4-2069d5e2f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-70604514-49fa-4ac8-ae71-65a9bbd94025,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-52121548-e8fb-4b40-be92-ff231c9cb630,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-854f3268-2b35-4ce8-a6f1-c9d14efe4232,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-aa5fb1cb-bade-4e9a-97b6-6519dc265ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-a5cd5df4-6683-4517-a0b2-5410e5bcd3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-7ae05de5-7268-42dd-a077-ef5a6258d5f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566459727-172.17.0.11-1599338840001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36050,DS-51c6aa23-e0f0-41fb-b033-93e4e55d0fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-109fc0c8-5538-42b5-bef4-2069d5e2f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-70604514-49fa-4ac8-ae71-65a9bbd94025,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-52121548-e8fb-4b40-be92-ff231c9cb630,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-854f3268-2b35-4ce8-a6f1-c9d14efe4232,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-aa5fb1cb-bade-4e9a-97b6-6519dc265ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-a5cd5df4-6683-4517-a0b2-5410e5bcd3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-7ae05de5-7268-42dd-a077-ef5a6258d5f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068467578-172.17.0.11-1599338871680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45791,DS-0da465e1-d790-4f7e-9374-07e60a68335c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-7d13ada2-f5f7-483b-9d55-e9945d74fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-062c5e6f-578f-4a46-9000-b457f0b1711d,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f60768cd-7c99-431e-bbe3-e0b256f1766e,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-dc08128e-fae2-4ea4-b9f9-a42267c22a85,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-defc29b6-283e-4d86-8131-4f93cb9fe0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-32c57d99-cc6f-46df-b146-75b0c385aeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-f919ad34-fc7b-4bc1-b9c3-2f2b9e293795,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068467578-172.17.0.11-1599338871680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45791,DS-0da465e1-d790-4f7e-9374-07e60a68335c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-7d13ada2-f5f7-483b-9d55-e9945d74fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-062c5e6f-578f-4a46-9000-b457f0b1711d,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f60768cd-7c99-431e-bbe3-e0b256f1766e,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-dc08128e-fae2-4ea4-b9f9-a42267c22a85,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-defc29b6-283e-4d86-8131-4f93cb9fe0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-32c57d99-cc6f-46df-b146-75b0c385aeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-f919ad34-fc7b-4bc1-b9c3-2f2b9e293795,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179277219-172.17.0.11-1599338913039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-368738c6-926c-4070-bd47-39a6d11b49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-0d655762-7cf1-460f-a2b4-92047dcb916f,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-48a186db-1faa-4ba3-bdbb-0e17403ff993,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-cc1dde35-c52e-446e-8b0e-ff231e0b6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-784c4e87-d23e-4f68-a140-9ed5106540bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-3497cd22-4274-45d3-b0e9-3e1f37fb1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-371bdb5d-31b8-48a1-a517-5375ec506847,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-28001850-8b5b-4ac9-81bf-6251ed5632b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179277219-172.17.0.11-1599338913039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-368738c6-926c-4070-bd47-39a6d11b49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-0d655762-7cf1-460f-a2b4-92047dcb916f,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-48a186db-1faa-4ba3-bdbb-0e17403ff993,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-cc1dde35-c52e-446e-8b0e-ff231e0b6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-784c4e87-d23e-4f68-a140-9ed5106540bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-3497cd22-4274-45d3-b0e9-3e1f37fb1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-371bdb5d-31b8-48a1-a517-5375ec506847,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-28001850-8b5b-4ac9-81bf-6251ed5632b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441948071-172.17.0.11-1599339018768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f99021ac-e485-4174-8293-6d525c6bb6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-65503e07-cbaf-4d53-8b05-07299bc1ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-6bb0e3ca-15ad-4b99-9640-b44ca1df9979,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-ba9323e5-b9b7-41b2-9596-af2cfe263d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-7f9bf0a4-dc13-4752-83d2-4b4103594b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-f4db256e-5ab6-4419-a8c7-3d1946a05524,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-50e8a732-3cc8-46c1-a414-1e722bed56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-d7bb3f20-a131-4286-8c07-00e5ed3d5c26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-441948071-172.17.0.11-1599339018768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-f99021ac-e485-4174-8293-6d525c6bb6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-65503e07-cbaf-4d53-8b05-07299bc1ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-6bb0e3ca-15ad-4b99-9640-b44ca1df9979,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-ba9323e5-b9b7-41b2-9596-af2cfe263d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-7f9bf0a4-dc13-4752-83d2-4b4103594b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-f4db256e-5ab6-4419-a8c7-3d1946a05524,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-50e8a732-3cc8-46c1-a414-1e722bed56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-d7bb3f20-a131-4286-8c07-00e5ed3d5c26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012090969-172.17.0.11-1599339375579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-f4d8e152-37b9-40cf-a304-1136a0e9424d,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-4ea739fe-1841-430b-a1d8-bf7979d9192c,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a34b2df3-2f33-4e63-b49d-54581d2a5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-54886c08-2789-442b-a959-0f8b9508abea,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4955c08f-f1dc-4d48-83a8-44fe9661d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-96bcbf4d-4500-45b2-acfb-19fea39dc964,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-ec277dcd-9a04-4099-8574-18157bbaf614,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-b3e539be-7306-4b2d-83eb-1c69efa40eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012090969-172.17.0.11-1599339375579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34600,DS-f4d8e152-37b9-40cf-a304-1136a0e9424d,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-4ea739fe-1841-430b-a1d8-bf7979d9192c,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a34b2df3-2f33-4e63-b49d-54581d2a5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-54886c08-2789-442b-a959-0f8b9508abea,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4955c08f-f1dc-4d48-83a8-44fe9661d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-96bcbf4d-4500-45b2-acfb-19fea39dc964,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-ec277dcd-9a04-4099-8574-18157bbaf614,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-b3e539be-7306-4b2d-83eb-1c69efa40eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186282964-172.17.0.11-1599339496727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-49db61fe-0625-4812-acd7-d69d42d2faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-30adaf75-8dbc-4317-bbcf-e079ed39dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-5c8b0c15-4ba8-45a8-b80b-8e744430e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-5b1cbcd0-868d-42c6-ae83-44d803ca8657,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-69972f4c-8ae1-4375-b726-2f211292d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-bff4ea67-4b3f-46f2-847b-248a34b2c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-d4e6aee3-658b-489c-9141-e2b08aabcdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-94db1112-2d39-4be1-8f1c-a085d3a1797e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186282964-172.17.0.11-1599339496727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-49db61fe-0625-4812-acd7-d69d42d2faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-30adaf75-8dbc-4317-bbcf-e079ed39dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-5c8b0c15-4ba8-45a8-b80b-8e744430e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-5b1cbcd0-868d-42c6-ae83-44d803ca8657,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-69972f4c-8ae1-4375-b726-2f211292d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-bff4ea67-4b3f-46f2-847b-248a34b2c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-d4e6aee3-658b-489c-9141-e2b08aabcdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-94db1112-2d39-4be1-8f1c-a085d3a1797e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407323284-172.17.0.11-1599339694912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39345,DS-29490515-9f5d-428d-8143-d1829da72d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-9a290824-7772-41d2-aa92-7506cf2488ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-7f64ed05-9b42-40ae-a4fe-8152a93582be,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-426e9dd2-24a2-409d-bfa4-d98cb6609f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-50f27667-ce10-4bda-bd27-512bb238e021,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-c0cdf5d8-61d3-4f81-a871-c980e579fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-2e6d8297-9ff7-4942-ac9b-5f401d698ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-3bbeff7b-4c5c-4446-9620-9f1765a093ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407323284-172.17.0.11-1599339694912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39345,DS-29490515-9f5d-428d-8143-d1829da72d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-9a290824-7772-41d2-aa92-7506cf2488ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-7f64ed05-9b42-40ae-a4fe-8152a93582be,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-426e9dd2-24a2-409d-bfa4-d98cb6609f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-50f27667-ce10-4bda-bd27-512bb238e021,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-c0cdf5d8-61d3-4f81-a871-c980e579fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-2e6d8297-9ff7-4942-ac9b-5f401d698ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-3bbeff7b-4c5c-4446-9620-9f1765a093ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776809684-172.17.0.11-1599339759125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33190,DS-b86b6217-59b3-4cd2-ad7c-dea8ea5cf885,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-984de7ce-bf77-4bbe-bf17-493151471b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-a1af75a2-ee0b-4d79-ac1b-de7585b46528,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-3587296c-3b96-4ddb-b617-1a70cbecfc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-fd00b88a-a353-428d-899d-e0579fc8cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-b2143bc9-85a3-448c-a4ef-11d4d43d2551,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-e6f3b33c-88b9-47f6-a203-862b83daf54c,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-dd2d6d99-33de-48f3-8744-b928dadee895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776809684-172.17.0.11-1599339759125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33190,DS-b86b6217-59b3-4cd2-ad7c-dea8ea5cf885,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-984de7ce-bf77-4bbe-bf17-493151471b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-a1af75a2-ee0b-4d79-ac1b-de7585b46528,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-3587296c-3b96-4ddb-b617-1a70cbecfc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-fd00b88a-a353-428d-899d-e0579fc8cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-b2143bc9-85a3-448c-a4ef-11d4d43d2551,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-e6f3b33c-88b9-47f6-a203-862b83daf54c,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-dd2d6d99-33de-48f3-8744-b928dadee895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138106915-172.17.0.11-1599339968564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-0f26ed66-209f-492d-baad-6139336bddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-eb4f2537-9215-44b9-8a1d-87dbeda393b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-f4da67dd-f607-450f-b301-af3e58623234,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-edf29218-a57a-4496-b97e-528037759286,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-492fd8eb-f46e-477a-a89e-9051e7472a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-2259c8c8-0265-4dbc-a484-7c01a5d7b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-10e80f15-ce27-4608-8602-79d2ca20aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-aae9f0c8-3d9a-41a5-92f9-d597f14760a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138106915-172.17.0.11-1599339968564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-0f26ed66-209f-492d-baad-6139336bddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-eb4f2537-9215-44b9-8a1d-87dbeda393b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-f4da67dd-f607-450f-b301-af3e58623234,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-edf29218-a57a-4496-b97e-528037759286,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-492fd8eb-f46e-477a-a89e-9051e7472a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-2259c8c8-0265-4dbc-a484-7c01a5d7b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-10e80f15-ce27-4608-8602-79d2ca20aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-aae9f0c8-3d9a-41a5-92f9-d597f14760a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74956295-172.17.0.11-1599340199418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-2aa32b38-257e-4d89-9c0d-c84d9e232325,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-98eaa7ab-4635-438b-842c-7cbdfc339b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-fac45fec-6488-46de-b470-1f14d81b86fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-1c21d477-b2f5-4595-bfa2-06d63734a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-7031da4e-2f78-41d0-b731-0ef41d93cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-5e5f30fa-f4ad-47c6-89a5-39b0aadaf678,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-f7715427-20da-4070-a65b-8f2c809c2467,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-0e1251be-e115-4f0d-a46a-472ad6e3d98e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74956295-172.17.0.11-1599340199418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-2aa32b38-257e-4d89-9c0d-c84d9e232325,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-98eaa7ab-4635-438b-842c-7cbdfc339b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-fac45fec-6488-46de-b470-1f14d81b86fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-1c21d477-b2f5-4595-bfa2-06d63734a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-7031da4e-2f78-41d0-b731-0ef41d93cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-5e5f30fa-f4ad-47c6-89a5-39b0aadaf678,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-f7715427-20da-4070-a65b-8f2c809c2467,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-0e1251be-e115-4f0d-a46a-472ad6e3d98e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522938784-172.17.0.11-1599340340074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-99918e4c-1484-41c7-acd7-8e7d6923a664,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-38291394-5d8c-4a0a-97ba-d24197f2f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-a7cc5fd0-7a85-485f-82c8-a665ea114adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-4331a5b0-50a8-43f2-9ea4-49fd7b8fc8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-b8bbbeae-1f6f-4317-8ff7-22aa16d30bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6ad2b7b0-14c8-4f31-8476-3c0e23d466fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-011eb371-fa16-44ac-8465-1e1d8dca65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-e38ae81e-c911-4224-8bcc-337592ec0149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522938784-172.17.0.11-1599340340074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-99918e4c-1484-41c7-acd7-8e7d6923a664,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-38291394-5d8c-4a0a-97ba-d24197f2f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-a7cc5fd0-7a85-485f-82c8-a665ea114adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-4331a5b0-50a8-43f2-9ea4-49fd7b8fc8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-b8bbbeae-1f6f-4317-8ff7-22aa16d30bea,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6ad2b7b0-14c8-4f31-8476-3c0e23d466fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-011eb371-fa16-44ac-8465-1e1d8dca65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-e38ae81e-c911-4224-8bcc-337592ec0149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72824734-172.17.0.11-1599340424038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-48361435-8ab5-43a1-ab74-6b23a08f4be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-b2131b44-bbb9-44c1-8879-9ed8394c632e,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-416e85ee-9b6e-4616-82dc-becbb5c3a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-4112fac4-9c5f-483b-83d6-25851bda1bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-4dd22d09-698a-4563-a697-c61e4dae1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-f21f2f93-337b-4783-915c-590b1380d678,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-f0fa7147-c36d-4288-b3e0-a1875a9ccf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-5138b92e-a7ab-408d-96e7-3c8e541300de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72824734-172.17.0.11-1599340424038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-48361435-8ab5-43a1-ab74-6b23a08f4be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-b2131b44-bbb9-44c1-8879-9ed8394c632e,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-416e85ee-9b6e-4616-82dc-becbb5c3a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-4112fac4-9c5f-483b-83d6-25851bda1bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-4dd22d09-698a-4563-a697-c61e4dae1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-f21f2f93-337b-4783-915c-590b1380d678,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-f0fa7147-c36d-4288-b3e0-a1875a9ccf69,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-5138b92e-a7ab-408d-96e7-3c8e541300de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738005695-172.17.0.11-1599340507971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-6643d459-7593-42f2-be67-836e3d8bf2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-f11b48b2-539f-49d2-903d-197bf792e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-59bca0ce-c783-4349-af31-a5acf2af0223,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-b72d61e2-49ff-42f6-91f6-bc0bf590f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-882fd92a-a906-498d-877b-feccbfee15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-34a7f256-06fb-427b-b271-8da58b659431,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-d3ff29cd-2973-4ba9-a9bf-0386f1ba6c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-11528e6d-0194-4128-b10c-5de87e65fbd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738005695-172.17.0.11-1599340507971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44416,DS-6643d459-7593-42f2-be67-836e3d8bf2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-f11b48b2-539f-49d2-903d-197bf792e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-59bca0ce-c783-4349-af31-a5acf2af0223,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-b72d61e2-49ff-42f6-91f6-bc0bf590f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-882fd92a-a906-498d-877b-feccbfee15e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-34a7f256-06fb-427b-b271-8da58b659431,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-d3ff29cd-2973-4ba9-a9bf-0386f1ba6c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-11528e6d-0194-4128-b10c-5de87e65fbd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053327126-172.17.0.11-1599340614189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-105ec381-f4ac-4c86-8cfc-dd8935f61fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-4eebd271-f7d9-4d8e-80ca-0cd7b5b10334,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-67e8819f-dd23-4d82-b10b-cabf7c76fa72,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-42de6090-3cfa-42aa-9fef-5bd991b2c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-34b501ca-d7dd-4968-9a22-5e2bc8020f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-2a506f07-690a-478b-bcf4-a53540590dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-555e51a7-60a4-4728-9009-5761087465bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-394802f5-32db-4718-ab3a-a8344b2f1ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053327126-172.17.0.11-1599340614189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-105ec381-f4ac-4c86-8cfc-dd8935f61fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-4eebd271-f7d9-4d8e-80ca-0cd7b5b10334,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-67e8819f-dd23-4d82-b10b-cabf7c76fa72,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-42de6090-3cfa-42aa-9fef-5bd991b2c2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-34b501ca-d7dd-4968-9a22-5e2bc8020f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-2a506f07-690a-478b-bcf4-a53540590dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-555e51a7-60a4-4728-9009-5761087465bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-394802f5-32db-4718-ab3a-a8344b2f1ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952821807-172.17.0.11-1599341040804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-c1a88ada-6cff-47f8-8bc4-01d755556d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1cf596ef-2721-4473-8b02-bcc0237656ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-1be9f3ce-0a52-41e1-8ef7-95fe91da6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-7992aafb-b540-43b3-b60f-db81670cae51,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-04a533cd-c77f-46a9-8dac-821ca16208d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-d1bac2bf-9e33-42b3-9145-ebc524c5c232,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-0a6f5d30-d749-4c6f-9a0d-c47d2b662025,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-cd99d73e-1617-4fe6-901e-a38481b1fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952821807-172.17.0.11-1599341040804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-c1a88ada-6cff-47f8-8bc4-01d755556d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1cf596ef-2721-4473-8b02-bcc0237656ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-1be9f3ce-0a52-41e1-8ef7-95fe91da6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-7992aafb-b540-43b3-b60f-db81670cae51,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-04a533cd-c77f-46a9-8dac-821ca16208d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-d1bac2bf-9e33-42b3-9145-ebc524c5c232,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-0a6f5d30-d749-4c6f-9a0d-c47d2b662025,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-cd99d73e-1617-4fe6-901e-a38481b1fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563037029-172.17.0.11-1599341316771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-5ae05b9f-d879-4a5f-aae1-c43903d072fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-1ae9f18a-501c-4790-a664-d5cf8a31c364,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-c16675ba-c655-44a6-8987-bc07ab2e140d,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-eab6e3ed-2dd2-46f2-814a-73a5274e0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-b297049e-0caf-4c60-b817-0c971753ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d6ef1209-0a79-45c6-82a8-4fcbc7c0211a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-51f62221-b248-468f-8d57-8e0907dd502f,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-1f7a094f-6918-4ef4-adc5-e1e473eefcb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563037029-172.17.0.11-1599341316771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-5ae05b9f-d879-4a5f-aae1-c43903d072fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-1ae9f18a-501c-4790-a664-d5cf8a31c364,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-c16675ba-c655-44a6-8987-bc07ab2e140d,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-eab6e3ed-2dd2-46f2-814a-73a5274e0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-b297049e-0caf-4c60-b817-0c971753ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d6ef1209-0a79-45c6-82a8-4fcbc7c0211a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-51f62221-b248-468f-8d57-8e0907dd502f,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-1f7a094f-6918-4ef4-adc5-e1e473eefcb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299461540-172.17.0.11-1599341475764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-a71ccf18-646c-4a82-bd34-efff0cb99dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8a2dc2a1-6e51-4dcd-9365-9d8d2b2b1ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-16397c3b-6d97-4d23-9bc5-4a84161d12f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-fc9de029-1453-4aa5-9b2c-3e99944ebb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-2a04bc7e-8bed-42ff-8f6a-49273d0b1614,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-04486884-342c-491f-a984-489c4f55b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f9a26461-a53c-407a-b0cd-a8d033aeed61,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-f17f19ad-c6af-45db-b84e-98cccfd37f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299461540-172.17.0.11-1599341475764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-a71ccf18-646c-4a82-bd34-efff0cb99dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8a2dc2a1-6e51-4dcd-9365-9d8d2b2b1ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-16397c3b-6d97-4d23-9bc5-4a84161d12f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-fc9de029-1453-4aa5-9b2c-3e99944ebb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-2a04bc7e-8bed-42ff-8f6a-49273d0b1614,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-04486884-342c-491f-a984-489c4f55b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f9a26461-a53c-407a-b0cd-a8d033aeed61,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-f17f19ad-c6af-45db-b84e-98cccfd37f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234707469-172.17.0.11-1599341741663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-004e7688-da8b-4c02-9fff-eb6409b8f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-95a5ee29-1b76-426c-b4d3-383abef1f64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-a2bb9082-45d5-4a28-97f9-76201d70f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-c5186a59-c39d-4d8b-95fd-2ec8f9632994,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-e4acb890-9213-496e-81e2-fbc01a7947bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-aa7a30aa-b582-42e3-9e07-cdcd9259a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-430713cc-29a0-478c-8333-6d39a033d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-8836f4f6-7155-4e3a-8c10-4879b40572d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234707469-172.17.0.11-1599341741663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-004e7688-da8b-4c02-9fff-eb6409b8f15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-95a5ee29-1b76-426c-b4d3-383abef1f64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-a2bb9082-45d5-4a28-97f9-76201d70f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-c5186a59-c39d-4d8b-95fd-2ec8f9632994,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-e4acb890-9213-496e-81e2-fbc01a7947bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-aa7a30aa-b582-42e3-9e07-cdcd9259a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-430713cc-29a0-478c-8333-6d39a033d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-8836f4f6-7155-4e3a-8c10-4879b40572d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762520171-172.17.0.11-1599341848769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-6a6562b0-71c6-46dc-b28b-fe853e6fdc83,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-49637d49-45ef-4959-bb1b-a39cb47c8671,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-810178c3-b755-4c88-8aea-d8703713632a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-31fa766a-a495-4f36-92d9-4f06763acf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-55274505-de6d-47a4-a275-2fb3c6d0a171,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-266d8b7e-30ad-4d0e-a63a-2337ba62e401,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-f3d8674b-0170-432b-aa47-92b0fbb11d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1104151d-a4a7-4974-a6ac-caacab12fb28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762520171-172.17.0.11-1599341848769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-6a6562b0-71c6-46dc-b28b-fe853e6fdc83,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-49637d49-45ef-4959-bb1b-a39cb47c8671,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-810178c3-b755-4c88-8aea-d8703713632a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-31fa766a-a495-4f36-92d9-4f06763acf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-55274505-de6d-47a4-a275-2fb3c6d0a171,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-266d8b7e-30ad-4d0e-a63a-2337ba62e401,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-f3d8674b-0170-432b-aa47-92b0fbb11d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1104151d-a4a7-4974-a6ac-caacab12fb28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 524288
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704920006-172.17.0.11-1599342080541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-e1d70f5a-a519-4f14-950c-b7120f6b2911,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-6e1f5c3b-9286-4e89-a11f-747329eef1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-e1cfd668-756e-4346-bddc-ae3eaccae5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-72c6d14f-da29-4950-a01d-3cb63c77fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-10aa2ba6-c843-4711-b12d-286071732791,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-f40e041a-b87c-48cb-80fe-1bdd52b8d027,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-e9c9ea67-dc2f-4f3d-b501-3410dbb7958b,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-f6909725-94fe-4227-9b47-85c05297037d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704920006-172.17.0.11-1599342080541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-e1d70f5a-a519-4f14-950c-b7120f6b2911,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-6e1f5c3b-9286-4e89-a11f-747329eef1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-e1cfd668-756e-4346-bddc-ae3eaccae5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-72c6d14f-da29-4950-a01d-3cb63c77fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-10aa2ba6-c843-4711-b12d-286071732791,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-f40e041a-b87c-48cb-80fe-1bdd52b8d027,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-e9c9ea67-dc2f-4f3d-b501-3410dbb7958b,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-f6909725-94fe-4227-9b47-85c05297037d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5457
