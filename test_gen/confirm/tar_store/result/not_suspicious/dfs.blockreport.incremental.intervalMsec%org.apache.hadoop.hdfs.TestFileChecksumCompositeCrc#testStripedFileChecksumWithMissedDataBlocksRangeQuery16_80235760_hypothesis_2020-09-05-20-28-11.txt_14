reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382220992-172.17.0.15-1599337747781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34010,DS-cfbe32cc-8e10-4953-b538-91f7445f79de,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-8ee0615e-4786-4e71-9a2e-214bb34546d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-da8cfcf1-b03b-412d-905c-1755dbc4a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-4c62d350-15bc-4a4e-b8b5-27f7c2d39b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-4fecc743-ee3d-4210-8d06-867f14a6f492,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-16f84c86-e862-4327-9d86-ad0704cb9540,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-80a4b4c1-2af4-45bd-91c2-2ebe2606a1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-94840282-2019-4c7f-b04b-ee2e8e9c4963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382220992-172.17.0.15-1599337747781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34010,DS-cfbe32cc-8e10-4953-b538-91f7445f79de,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-8ee0615e-4786-4e71-9a2e-214bb34546d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-da8cfcf1-b03b-412d-905c-1755dbc4a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-4c62d350-15bc-4a4e-b8b5-27f7c2d39b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-4fecc743-ee3d-4210-8d06-867f14a6f492,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-16f84c86-e862-4327-9d86-ad0704cb9540,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-80a4b4c1-2af4-45bd-91c2-2ebe2606a1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-94840282-2019-4c7f-b04b-ee2e8e9c4963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690388077-172.17.0.15-1599338569346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-6b2b0768-52d3-4dba-aa9f-15d1ce744dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-e9d1cf8a-ec49-4821-8b07-8b144f78cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-1deab217-e0a5-46f8-8751-10abdb788d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-b787f9fb-cae4-4530-af4e-140c93de35cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-d6598953-9da5-454b-9075-f6bae079f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-09b202f8-d081-45f4-a6ef-e749dcc98a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-42bf95a6-3bd2-4448-bb6f-8591dff62c48,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-1b69d517-463d-44c9-8b72-575c2818c84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690388077-172.17.0.15-1599338569346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-6b2b0768-52d3-4dba-aa9f-15d1ce744dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-e9d1cf8a-ec49-4821-8b07-8b144f78cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-1deab217-e0a5-46f8-8751-10abdb788d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-b787f9fb-cae4-4530-af4e-140c93de35cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-d6598953-9da5-454b-9075-f6bae079f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-09b202f8-d081-45f4-a6ef-e749dcc98a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-42bf95a6-3bd2-4448-bb6f-8591dff62c48,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-1b69d517-463d-44c9-8b72-575c2818c84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048870370-172.17.0.15-1599338650143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-5f79a518-ed6d-4f83-8b63-c0996dfc3745,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4b46e0d4-0be1-4205-aad8-0c8f9793fe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-50d2bf24-734d-4fc2-ad96-d48afebd6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-878f939b-9150-4dbd-9d94-d8a8b326fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-83f76efa-4436-4067-b73d-1ee6d98b11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-ee8a3f80-9f4e-4e29-8d17-42c66006425d,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-19629d1b-ebf2-4d72-818e-0469bef91b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-54445473-d3c3-43e5-bb9c-f30a0f1a4faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048870370-172.17.0.15-1599338650143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-5f79a518-ed6d-4f83-8b63-c0996dfc3745,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4b46e0d4-0be1-4205-aad8-0c8f9793fe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-50d2bf24-734d-4fc2-ad96-d48afebd6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-878f939b-9150-4dbd-9d94-d8a8b326fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-83f76efa-4436-4067-b73d-1ee6d98b11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-ee8a3f80-9f4e-4e29-8d17-42c66006425d,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-19629d1b-ebf2-4d72-818e-0469bef91b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-54445473-d3c3-43e5-bb9c-f30a0f1a4faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735785907-172.17.0.15-1599338726590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-52661593-8df6-4de8-ab47-b041cfd1d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-dab1bf4d-2180-4197-a861-e178ce5087f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-d30adbc0-1204-46d0-ae34-62303239f289,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-603f5b40-9116-4363-8f6a-f2f2c2212c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-e5f17825-8abe-4923-b944-7f26fe4c5168,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-aab4fd32-efe8-466b-9e43-13b6f33f3720,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-a1b29e8a-26fb-4454-aa8a-13de382a6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-8b090ccc-63a8-4f69-bd9a-9f2b65f236bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735785907-172.17.0.15-1599338726590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-52661593-8df6-4de8-ab47-b041cfd1d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-dab1bf4d-2180-4197-a861-e178ce5087f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-d30adbc0-1204-46d0-ae34-62303239f289,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-603f5b40-9116-4363-8f6a-f2f2c2212c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-e5f17825-8abe-4923-b944-7f26fe4c5168,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-aab4fd32-efe8-466b-9e43-13b6f33f3720,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-a1b29e8a-26fb-4454-aa8a-13de382a6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-8b090ccc-63a8-4f69-bd9a-9f2b65f236bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76881755-172.17.0.15-1599338853783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-a72234bc-e688-4fed-8a16-fd5be741ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-e3cc82d4-f715-4fcd-8f5e-87229fa28804,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-7866bf6a-3173-4894-88a1-f3648510acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-b75bb4c3-03c1-435c-bd14-6fd38daa8692,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-41add7b6-5767-4dd8-aada-b373c6727858,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-44589c35-7630-40ab-b63d-cbec5745724f,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-91194d66-0596-4d8b-8882-3430fa829269,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-49926705-f127-4219-a3fe-3ef1fa0e94e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76881755-172.17.0.15-1599338853783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-a72234bc-e688-4fed-8a16-fd5be741ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-e3cc82d4-f715-4fcd-8f5e-87229fa28804,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-7866bf6a-3173-4894-88a1-f3648510acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-b75bb4c3-03c1-435c-bd14-6fd38daa8692,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-41add7b6-5767-4dd8-aada-b373c6727858,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-44589c35-7630-40ab-b63d-cbec5745724f,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-91194d66-0596-4d8b-8882-3430fa829269,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-49926705-f127-4219-a3fe-3ef1fa0e94e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734825175-172.17.0.15-1599339402314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-3652909d-f20a-4081-ad49-900f4d19db29,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6b53db5a-4b27-4043-b975-946580726c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-22e03036-8dea-4d48-a5c4-2e8e11d7a6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-a6ccec22-69c1-45ee-a291-79f12443fb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-5387773f-fc6b-4127-b08b-7875c15f6561,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-415518a4-28ec-439f-a832-65b00e711bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-f68194a3-8803-49bc-9b9b-45c038860285,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ed355179-6121-49a7-9af2-7922d30c8712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734825175-172.17.0.15-1599339402314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42209,DS-3652909d-f20a-4081-ad49-900f4d19db29,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6b53db5a-4b27-4043-b975-946580726c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-22e03036-8dea-4d48-a5c4-2e8e11d7a6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-a6ccec22-69c1-45ee-a291-79f12443fb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-5387773f-fc6b-4127-b08b-7875c15f6561,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-415518a4-28ec-439f-a832-65b00e711bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-f68194a3-8803-49bc-9b9b-45c038860285,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ed355179-6121-49a7-9af2-7922d30c8712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783525417-172.17.0.15-1599339814033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-d0d99a53-4934-4710-91ae-a8ddaf5199cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-2d3fa43d-43a1-4635-9765-6825c358d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-a7957187-dd35-447f-b465-9eb94f0f32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-4795e0ff-6e21-4e2d-9814-5183244ef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-b7e279ac-3661-4a65-a965-c8dab2eaf8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-cf7dde8c-03a9-49d9-9260-83668e323a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1392fa0e-30a0-42e2-bc26-1ee43504d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-bbf14ee9-b56e-4e78-9e1c-987369c009cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783525417-172.17.0.15-1599339814033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-d0d99a53-4934-4710-91ae-a8ddaf5199cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-2d3fa43d-43a1-4635-9765-6825c358d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-a7957187-dd35-447f-b465-9eb94f0f32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-4795e0ff-6e21-4e2d-9814-5183244ef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-b7e279ac-3661-4a65-a965-c8dab2eaf8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-cf7dde8c-03a9-49d9-9260-83668e323a61,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1392fa0e-30a0-42e2-bc26-1ee43504d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-bbf14ee9-b56e-4e78-9e1c-987369c009cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433394039-172.17.0.15-1599339968842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-0c8e06ac-ffd3-4484-8df6-6fa61b2933b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-4acb5939-36da-4748-a2e3-221693dc70de,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-766f55c9-dc0f-48a7-8f0a-a71482691ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8ca292c7-ad16-465d-a5a2-db849ef6d923,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-151d95f0-3ae1-4e26-bfe7-98e1b3d73b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-00138b6c-85e9-44d1-a5f2-e51ce85aab44,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-c6d4a8b3-c76b-4556-9f00-7e97309a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-c9876eed-d884-4a71-bb50-373444b384fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433394039-172.17.0.15-1599339968842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-0c8e06ac-ffd3-4484-8df6-6fa61b2933b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-4acb5939-36da-4748-a2e3-221693dc70de,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-766f55c9-dc0f-48a7-8f0a-a71482691ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8ca292c7-ad16-465d-a5a2-db849ef6d923,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-151d95f0-3ae1-4e26-bfe7-98e1b3d73b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-00138b6c-85e9-44d1-a5f2-e51ce85aab44,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-c6d4a8b3-c76b-4556-9f00-7e97309a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-c9876eed-d884-4a71-bb50-373444b384fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968449844-172.17.0.15-1599340294584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-25978881-50b9-4b65-b595-783b1c8fbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-28316b64-5cd0-47be-8a1a-3ffb6bb23b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-8bbf1312-4606-41cd-b350-8ac91bbcee93,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-143dfe69-2a4e-4baf-8d23-bdad6389ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-793301c1-34e7-4db3-ad87-0cea08767040,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-777948ed-c48b-4e1e-9bf9-93a4b3246e52,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-2dfa78b8-3665-45ce-b0ed-b454c5574831,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-dd15d9a8-749f-4f87-b667-6ec46fb82a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968449844-172.17.0.15-1599340294584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-25978881-50b9-4b65-b595-783b1c8fbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-28316b64-5cd0-47be-8a1a-3ffb6bb23b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-8bbf1312-4606-41cd-b350-8ac91bbcee93,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-143dfe69-2a4e-4baf-8d23-bdad6389ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-793301c1-34e7-4db3-ad87-0cea08767040,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-777948ed-c48b-4e1e-9bf9-93a4b3246e52,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-2dfa78b8-3665-45ce-b0ed-b454c5574831,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-dd15d9a8-749f-4f87-b667-6ec46fb82a3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810963360-172.17.0.15-1599340732128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-acfeca51-6998-458d-974e-878d4be9f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-de96ca45-bd78-4b76-95d4-a7030f4a2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-3febf736-3405-44b0-92b8-6fb37f1ed3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-bd750630-f181-4f1a-ab67-a52b2fa1775a,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-022dc3f5-aa63-4e5f-8cab-f3d4af5c16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-5c6bc907-127d-401e-8b00-31bb7e55c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bd977f1d-61fc-4d09-983a-6f006afa0174,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-0b8b7a79-3808-4184-ac9e-af5fca1e1080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810963360-172.17.0.15-1599340732128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-acfeca51-6998-458d-974e-878d4be9f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-de96ca45-bd78-4b76-95d4-a7030f4a2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-3febf736-3405-44b0-92b8-6fb37f1ed3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-bd750630-f181-4f1a-ab67-a52b2fa1775a,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-022dc3f5-aa63-4e5f-8cab-f3d4af5c16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-5c6bc907-127d-401e-8b00-31bb7e55c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bd977f1d-61fc-4d09-983a-6f006afa0174,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-0b8b7a79-3808-4184-ac9e-af5fca1e1080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684784980-172.17.0.15-1599340829055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-bd910c11-caf0-4e83-9c74-a0cd0f35d393,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-f087b8e3-203d-4804-a2b7-03f6b9c84418,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-f0818fec-3f7f-4106-a7cf-ac26a8cac613,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-d7587365-f514-472e-92d8-99f2fa5475b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-4176db8b-ef3d-4129-ae50-b331b7f72d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-cf2c061e-0b43-46bb-83fd-7aed6f35f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-61cbbc1e-b716-4ce8-aad6-a0547cc5e383,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-5ced8e14-44b2-420a-94aa-28cb7163f93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684784980-172.17.0.15-1599340829055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-bd910c11-caf0-4e83-9c74-a0cd0f35d393,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-f087b8e3-203d-4804-a2b7-03f6b9c84418,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-f0818fec-3f7f-4106-a7cf-ac26a8cac613,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-d7587365-f514-472e-92d8-99f2fa5475b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-4176db8b-ef3d-4129-ae50-b331b7f72d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-cf2c061e-0b43-46bb-83fd-7aed6f35f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-61cbbc1e-b716-4ce8-aad6-a0547cc5e383,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-5ced8e14-44b2-420a-94aa-28cb7163f93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734962102-172.17.0.15-1599341064914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-2f97f9a0-40e0-44e5-8fcf-75eddc429a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-f69eb6bc-80c7-4d36-9020-a008a375708e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-6fd265d3-851a-4070-b9ae-7bedd2ee44a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-b44062a3-347a-4684-b346-fe912ac987a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-caa8fca1-e6c5-40fd-b3a0-03bb715da52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ede668da-f455-418e-89fd-470260ea1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-f8b83d3b-4e5f-4d55-b801-6632d5699ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-ca49915c-d326-4348-b923-6350a6e91304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734962102-172.17.0.15-1599341064914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-2f97f9a0-40e0-44e5-8fcf-75eddc429a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-f69eb6bc-80c7-4d36-9020-a008a375708e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-6fd265d3-851a-4070-b9ae-7bedd2ee44a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-b44062a3-347a-4684-b346-fe912ac987a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-caa8fca1-e6c5-40fd-b3a0-03bb715da52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-ede668da-f455-418e-89fd-470260ea1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-f8b83d3b-4e5f-4d55-b801-6632d5699ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-ca49915c-d326-4348-b923-6350a6e91304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537595873-172.17.0.15-1599341747148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-d6048df2-ecd0-483b-8e6d-9f510b6c3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-82a43cb3-36fa-400a-9a96-1a1cae01e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-ab62d62d-dbb2-463e-af98-ab2538f83b64,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-df52ef7c-117b-4580-9072-22afe3690bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-0345aaf4-3c38-471a-aaf6-4afc1f2aec99,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-4b08b40d-6bac-428e-a669-a04e1573c324,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-d8899de2-c372-4d92-bc13-6007d14ca36c,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-87cacbd2-ac38-40a5-acde-7b2e25b4eb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537595873-172.17.0.15-1599341747148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-d6048df2-ecd0-483b-8e6d-9f510b6c3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-82a43cb3-36fa-400a-9a96-1a1cae01e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-ab62d62d-dbb2-463e-af98-ab2538f83b64,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-df52ef7c-117b-4580-9072-22afe3690bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-0345aaf4-3c38-471a-aaf6-4afc1f2aec99,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-4b08b40d-6bac-428e-a669-a04e1573c324,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-d8899de2-c372-4d92-bc13-6007d14ca36c,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-87cacbd2-ac38-40a5-acde-7b2e25b4eb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447688747-172.17.0.15-1599341855231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-7ac3ccc3-24aa-4467-b7bd-86fc726b478d,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9b5e92f6-af3b-4f5d-a2f8-d265f1e0ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-88672ddc-2e62-4da8-bc2e-b6c05cd09653,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-c35c4e5f-847d-4e23-a570-858a891af52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-20ca7f08-f65c-4767-a622-32082d3fed08,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-fe6261cc-8433-4be6-81ec-e8f7b41a9d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-d2de8884-32e1-4d95-bb58-98920f758477,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b2e814d2-f08c-481f-a4c8-d9274fce9098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447688747-172.17.0.15-1599341855231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-7ac3ccc3-24aa-4467-b7bd-86fc726b478d,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9b5e92f6-af3b-4f5d-a2f8-d265f1e0ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-88672ddc-2e62-4da8-bc2e-b6c05cd09653,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-c35c4e5f-847d-4e23-a570-858a891af52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-20ca7f08-f65c-4767-a622-32082d3fed08,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-fe6261cc-8433-4be6-81ec-e8f7b41a9d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-d2de8884-32e1-4d95-bb58-98920f758477,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b2e814d2-f08c-481f-a4c8-d9274fce9098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899730442-172.17.0.15-1599342059870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-f04b8af0-1dda-493f-aa28-18327b92882f,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-68bc46a7-e521-49b8-ab5d-515c3111ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-859f6400-1b43-4891-9b45-19120188d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-c45b0e7b-d57a-4ca1-b362-5678752c2853,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-fb6e83a8-ab57-40ad-a018-f2a5963d15d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-4b71341b-7805-401b-be87-edfb98104103,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-55f3187f-d8a3-49ed-964f-f9eea04d3c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-5b497753-5af2-4ae9-a6d7-5b7cfec66c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899730442-172.17.0.15-1599342059870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-f04b8af0-1dda-493f-aa28-18327b92882f,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-68bc46a7-e521-49b8-ab5d-515c3111ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-859f6400-1b43-4891-9b45-19120188d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-c45b0e7b-d57a-4ca1-b362-5678752c2853,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-fb6e83a8-ab57-40ad-a018-f2a5963d15d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-4b71341b-7805-401b-be87-edfb98104103,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-55f3187f-d8a3-49ed-964f-f9eea04d3c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-5b497753-5af2-4ae9-a6d7-5b7cfec66c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762161777-172.17.0.15-1599342164295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39301,DS-444e888e-53fd-4829-a89e-96b3c8d0186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-b6c96e7f-6825-41f8-83c8-c3700b360433,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-384e44fc-61cd-457b-bde6-01777d95dff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-de2d2a5c-4046-4c95-8bc8-357802b240b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0551dbb6-41be-4246-86db-4d451bc49f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-d8eea635-d868-426a-ab87-2327be49993d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-ee48794f-bb0a-47cf-a615-93d9139a172d,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fef45fdc-1fae-44f4-82d0-700428b6c040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762161777-172.17.0.15-1599342164295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39301,DS-444e888e-53fd-4829-a89e-96b3c8d0186e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-b6c96e7f-6825-41f8-83c8-c3700b360433,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-384e44fc-61cd-457b-bde6-01777d95dff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-de2d2a5c-4046-4c95-8bc8-357802b240b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0551dbb6-41be-4246-86db-4d451bc49f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-d8eea635-d868-426a-ab87-2327be49993d,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-ee48794f-bb0a-47cf-a615-93d9139a172d,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fef45fdc-1fae-44f4-82d0-700428b6c040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944331488-172.17.0.15-1599342197871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-4bcadb70-5b4d-441d-b0e8-0e9ffe2d4e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-91d923b5-6b92-48e8-b69c-56b665f5105e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-89c160f3-ca16-4d91-b096-b024f5d6636f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-75c3f06a-9d8e-4c30-bb93-7e05773d69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-b27bc644-ee9e-4760-9fb1-b9e2645379b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-c6c7260e-08d8-4120-b404-ee38343173cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-c34fee54-8fb1-438c-af43-4c20894ec15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-93ee9a48-c65f-4293-8c7c-5157b2e8cc69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944331488-172.17.0.15-1599342197871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-4bcadb70-5b4d-441d-b0e8-0e9ffe2d4e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-91d923b5-6b92-48e8-b69c-56b665f5105e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-89c160f3-ca16-4d91-b096-b024f5d6636f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-75c3f06a-9d8e-4c30-bb93-7e05773d69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-b27bc644-ee9e-4760-9fb1-b9e2645379b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-c6c7260e-08d8-4120-b404-ee38343173cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-c34fee54-8fb1-438c-af43-4c20894ec15c,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-93ee9a48-c65f-4293-8c7c-5157b2e8cc69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087505196-172.17.0.15-1599342399124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-9b0d1eb3-6640-4827-a78f-edf51bb78cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-9ff2c009-054c-413b-8ea6-7ee784a8fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-397e8b50-43db-451b-b4c8-515b84090344,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3ceace9e-239e-476a-9805-dd0f2e80a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-48cdac84-7c99-4b50-89a3-40adbe4c7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-b7e0454d-4919-4a2b-a39b-dff25c0b2025,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d1db8dd7-24ce-4e32-8253-cb5aa9e0a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7134e836-540c-4193-9e7b-6bef1e22a297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087505196-172.17.0.15-1599342399124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-9b0d1eb3-6640-4827-a78f-edf51bb78cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-9ff2c009-054c-413b-8ea6-7ee784a8fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-397e8b50-43db-451b-b4c8-515b84090344,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3ceace9e-239e-476a-9805-dd0f2e80a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-48cdac84-7c99-4b50-89a3-40adbe4c7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-b7e0454d-4919-4a2b-a39b-dff25c0b2025,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d1db8dd7-24ce-4e32-8253-cb5aa9e0a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7134e836-540c-4193-9e7b-6bef1e22a297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786841206-172.17.0.15-1599342549430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-75f7898d-600e-48c1-9eba-c108fc87c772,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-6d37a747-be06-4d28-a78a-28619a911212,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-c4de5596-26c2-4f30-90b6-42a7f2714851,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-406d3772-f61b-4aa0-948a-42daedb54c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-a130268c-87b1-4842-9b98-47e5f2a4b904,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-8619deb9-7913-459a-b825-d82abe9ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-d900c698-c680-4f35-b751-d71c0d11a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-89979c72-7f40-41ed-b5c7-8855dd4a1b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786841206-172.17.0.15-1599342549430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-75f7898d-600e-48c1-9eba-c108fc87c772,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-6d37a747-be06-4d28-a78a-28619a911212,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-c4de5596-26c2-4f30-90b6-42a7f2714851,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-406d3772-f61b-4aa0-948a-42daedb54c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-a130268c-87b1-4842-9b98-47e5f2a4b904,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-8619deb9-7913-459a-b825-d82abe9ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-d900c698-c680-4f35-b751-d71c0d11a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-89979c72-7f40-41ed-b5c7-8855dd4a1b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136770145-172.17.0.15-1599342729654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-6705bd08-1338-4ac6-ab8f-5bfb4053adc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-7f4f3023-dfe7-43fa-97bd-533e7e99ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-264ec029-2c55-4abe-b483-9c1478042edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-2c581dfc-d4ba-43f4-bab4-e7462436301e,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-f4a9aab9-24aa-4276-a5fe-5d1673928514,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-9616361e-059a-405a-9094-4f892c884cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-4f0c3b09-a765-4c54-ad4b-488707ac1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-dd1e35da-3f7a-4d30-bb30-4e764e10a530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136770145-172.17.0.15-1599342729654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-6705bd08-1338-4ac6-ab8f-5bfb4053adc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-7f4f3023-dfe7-43fa-97bd-533e7e99ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-264ec029-2c55-4abe-b483-9c1478042edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-2c581dfc-d4ba-43f4-bab4-e7462436301e,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-f4a9aab9-24aa-4276-a5fe-5d1673928514,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-9616361e-059a-405a-9094-4f892c884cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-4f0c3b09-a765-4c54-ad4b-488707ac1aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-dd1e35da-3f7a-4d30-bb30-4e764e10a530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213116892-172.17.0.15-1599342770969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-ed97271c-e592-4442-9042-0f2a33c6418d,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-5f68d696-1d4d-4e41-b53d-e50d3ce61d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-36d368b5-4b94-48b6-b5e8-dad18174dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-d898291a-7d20-4489-934b-d19cc9ff2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b090d2b7-b70a-49c1-8c88-de0b545a150f,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-8fdfb4c3-511b-4012-a264-827b57b5d130,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-0dfdac85-03b6-4317-a07b-e15c2f247ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-eebbaaca-9fb0-4e2a-b0a4-d4cc557ec35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213116892-172.17.0.15-1599342770969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-ed97271c-e592-4442-9042-0f2a33c6418d,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-5f68d696-1d4d-4e41-b53d-e50d3ce61d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-36d368b5-4b94-48b6-b5e8-dad18174dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-d898291a-7d20-4489-934b-d19cc9ff2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b090d2b7-b70a-49c1-8c88-de0b545a150f,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-8fdfb4c3-511b-4012-a264-827b57b5d130,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-0dfdac85-03b6-4317-a07b-e15c2f247ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-eebbaaca-9fb0-4e2a-b0a4-d4cc557ec35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077660527-172.17.0.15-1599342811799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38151,DS-f203fdaf-93b5-459c-bb8f-ef4a3efc2e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-1a47e06f-5a5e-4468-a5f9-8f7f02f73a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-f24aaa88-9e04-46a2-823e-e5de59a9c8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-d675c969-6412-49db-bc65-88d00d259581,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-f482f0b5-f193-4d55-b3fe-a00285fc48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7e654815-0746-445e-b700-0b28323e5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-267a29ee-4cd8-4151-9b56-b81e3cb2450d,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-aec8d133-f980-4e2b-bf56-aa73845edc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077660527-172.17.0.15-1599342811799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38151,DS-f203fdaf-93b5-459c-bb8f-ef4a3efc2e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-1a47e06f-5a5e-4468-a5f9-8f7f02f73a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-f24aaa88-9e04-46a2-823e-e5de59a9c8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-d675c969-6412-49db-bc65-88d00d259581,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-f482f0b5-f193-4d55-b3fe-a00285fc48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-7e654815-0746-445e-b700-0b28323e5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-267a29ee-4cd8-4151-9b56-b81e3cb2450d,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-aec8d133-f980-4e2b-bf56-aa73845edc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5501
