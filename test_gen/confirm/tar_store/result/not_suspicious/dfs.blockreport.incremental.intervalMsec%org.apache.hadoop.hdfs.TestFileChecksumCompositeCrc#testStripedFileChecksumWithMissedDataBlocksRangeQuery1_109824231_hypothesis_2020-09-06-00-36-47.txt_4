reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339031294-172.17.0.8-1599352950716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-c6120266-e4c0-429c-a5fb-6af1d1169ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-1c89fcc1-f465-47e6-977e-e4a57688927e,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-425d5ba3-993c-47b7-93fd-c43f9eea278b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-96c341d6-435b-4886-8f71-0a23ef1fb630,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-8c156199-7c13-4acf-8a32-be46417b8afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-913d2069-fbfb-4505-a009-d35c8248bebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-910c89d2-b384-4591-a2d4-138a99b8b474,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-9a3fa5ce-5de1-44fb-8062-6117286322c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339031294-172.17.0.8-1599352950716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-c6120266-e4c0-429c-a5fb-6af1d1169ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-1c89fcc1-f465-47e6-977e-e4a57688927e,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-425d5ba3-993c-47b7-93fd-c43f9eea278b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-96c341d6-435b-4886-8f71-0a23ef1fb630,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-8c156199-7c13-4acf-8a32-be46417b8afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-913d2069-fbfb-4505-a009-d35c8248bebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-910c89d2-b384-4591-a2d4-138a99b8b474,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-9a3fa5ce-5de1-44fb-8062-6117286322c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239626281-172.17.0.8-1599353031955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-c4b2b6a4-b981-44d4-a30d-1d993306ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-2aac02c3-27da-4fe3-bc20-a22157c2035d,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-391268f1-a4ce-4eea-bf2e-091cd5071864,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ddda7357-1b0f-4887-ac53-b0e7a609bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-ae48c963-ce2f-4eaa-8f80-b708a3afd537,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-1d4a5dab-eecf-4db7-a664-ed62a3be79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-adbe970e-ff60-40cd-ab6d-b1ce8438d944,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-85ad5645-439a-4c52-8f9b-cf99803a131e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239626281-172.17.0.8-1599353031955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-c4b2b6a4-b981-44d4-a30d-1d993306ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-2aac02c3-27da-4fe3-bc20-a22157c2035d,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-391268f1-a4ce-4eea-bf2e-091cd5071864,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ddda7357-1b0f-4887-ac53-b0e7a609bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-ae48c963-ce2f-4eaa-8f80-b708a3afd537,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-1d4a5dab-eecf-4db7-a664-ed62a3be79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-adbe970e-ff60-40cd-ab6d-b1ce8438d944,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-85ad5645-439a-4c52-8f9b-cf99803a131e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429945094-172.17.0.8-1599353338614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-3ea11052-1c58-4845-9d1a-cedbd2abd104,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3ff313fa-3727-40ed-bd5f-76210b7f62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b7194a1a-5394-4045-914b-34ad5b083c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-24513287-fab3-4fae-8280-8da771ac9b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-f01bbb19-9258-44f3-b3f8-0c689f62b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4b6c1280-2ac9-421c-870b-9f083b6876b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-6038e33d-5108-4c53-b707-04d27a0a9fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-2fe3fbe4-49f9-4798-a2ec-6ce8bcf84be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429945094-172.17.0.8-1599353338614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-3ea11052-1c58-4845-9d1a-cedbd2abd104,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-3ff313fa-3727-40ed-bd5f-76210b7f62ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b7194a1a-5394-4045-914b-34ad5b083c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-24513287-fab3-4fae-8280-8da771ac9b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-f01bbb19-9258-44f3-b3f8-0c689f62b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4b6c1280-2ac9-421c-870b-9f083b6876b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-6038e33d-5108-4c53-b707-04d27a0a9fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-2fe3fbe4-49f9-4798-a2ec-6ce8bcf84be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618656654-172.17.0.8-1599353563685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-3d6e8c76-d8d7-4abb-b57c-c342a086077f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-3c1a7a6c-7ff1-4c0c-b850-d58b6f0e128a,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-3c83ea7b-c62f-433e-9b75-fd989d1ec466,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-f00cb648-5e97-4e98-99b1-6d07fe09b486,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-46f50a3f-7c66-494c-b9e3-33ce2d707a60,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-735ff17e-df1b-4953-93ef-3ac4a7e298ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-ea2f08c6-0a0a-44f7-b028-2c839ca7c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3c499fc9-3e81-434b-9b2d-2e70bbd9a62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618656654-172.17.0.8-1599353563685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42388,DS-3d6e8c76-d8d7-4abb-b57c-c342a086077f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-3c1a7a6c-7ff1-4c0c-b850-d58b6f0e128a,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-3c83ea7b-c62f-433e-9b75-fd989d1ec466,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-f00cb648-5e97-4e98-99b1-6d07fe09b486,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-46f50a3f-7c66-494c-b9e3-33ce2d707a60,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-735ff17e-df1b-4953-93ef-3ac4a7e298ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-ea2f08c6-0a0a-44f7-b028-2c839ca7c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3c499fc9-3e81-434b-9b2d-2e70bbd9a62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640560700-172.17.0.8-1599354023496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-4b977475-3d9d-4026-bba5-fba21093afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2bfcb681-bfc1-47a6-bacf-5f73dd9dc709,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-08b809e5-36f2-46ab-9dcd-f7c6e0338887,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-d23adbcc-7870-4f8d-bebe-46893daf813b,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-2a5fd24a-2f7d-4f8c-b7d5-2182def1649e,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-867ef679-d3f1-4b31-99b0-921e0192b4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-60abac8a-1c36-4f9b-8ee5-6f5a4f4a8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-21dd87ff-a97f-4816-8c21-a97df30ecfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640560700-172.17.0.8-1599354023496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-4b977475-3d9d-4026-bba5-fba21093afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2bfcb681-bfc1-47a6-bacf-5f73dd9dc709,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-08b809e5-36f2-46ab-9dcd-f7c6e0338887,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-d23adbcc-7870-4f8d-bebe-46893daf813b,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-2a5fd24a-2f7d-4f8c-b7d5-2182def1649e,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-867ef679-d3f1-4b31-99b0-921e0192b4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-60abac8a-1c36-4f9b-8ee5-6f5a4f4a8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-21dd87ff-a97f-4816-8c21-a97df30ecfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892480922-172.17.0.8-1599354349073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-763ac8c6-6555-4f8e-b876-64592f24270a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-3530b573-1745-4270-b4d5-04ffc48c0a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-92ce7938-c5dc-4f36-a141-48cf64231a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-9f2ab474-3bce-4b09-aeae-b3c6ef8b2003,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-869e9431-e892-48b3-b33b-7b8117deb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-c6accf5b-4747-4870-8214-96e624092804,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-27606f7f-019b-455f-ad71-42dc269360c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-4361f091-8682-4901-9349-cec2829fe955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892480922-172.17.0.8-1599354349073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-763ac8c6-6555-4f8e-b876-64592f24270a,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-3530b573-1745-4270-b4d5-04ffc48c0a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-92ce7938-c5dc-4f36-a141-48cf64231a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-9f2ab474-3bce-4b09-aeae-b3c6ef8b2003,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-869e9431-e892-48b3-b33b-7b8117deb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-c6accf5b-4747-4870-8214-96e624092804,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-27606f7f-019b-455f-ad71-42dc269360c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-4361f091-8682-4901-9349-cec2829fe955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603166302-172.17.0.8-1599354379597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-339858ef-c4ed-48ab-aaa8-0ea5ad294dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-8fbe57a0-11e8-45c4-b030-35c7a610bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-c8d82738-4daf-43e3-bdfc-fbcd65e8f3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-6a8eb073-5cab-4196-8d0b-46cad1aa2b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-8df24e5e-2c3b-4444-9e77-e733e1b3e272,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-c1b3fb53-8085-4e26-8ff2-54c1d8d8c383,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-01afbb5c-1439-420e-bae6-b2b076048266,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e5c89628-4ed3-4f64-98ae-6ed8c73ad80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603166302-172.17.0.8-1599354379597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-339858ef-c4ed-48ab-aaa8-0ea5ad294dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-8fbe57a0-11e8-45c4-b030-35c7a610bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-c8d82738-4daf-43e3-bdfc-fbcd65e8f3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-6a8eb073-5cab-4196-8d0b-46cad1aa2b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-8df24e5e-2c3b-4444-9e77-e733e1b3e272,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-c1b3fb53-8085-4e26-8ff2-54c1d8d8c383,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-01afbb5c-1439-420e-bae6-b2b076048266,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e5c89628-4ed3-4f64-98ae-6ed8c73ad80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284370050-172.17.0.8-1599354709047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-1e756818-f531-477f-9f8c-b4cfa608a972,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-64baf52a-dd9b-48c2-b15a-67dea399cde0,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b9d1fd37-7af2-44a2-8b4b-0daed8c0b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-c75d6d9e-31b7-49ea-bc8e-32b488229ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-2c3cb0dc-9ddd-43f2-b67c-5cee6f400bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-6b6a792d-7282-413f-b2f1-f649d29ba82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6b374f08-37b0-40c3-977d-7b384dd27952,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-1aff1c87-fa6b-47a6-bfce-56860bfd3f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284370050-172.17.0.8-1599354709047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-1e756818-f531-477f-9f8c-b4cfa608a972,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-64baf52a-dd9b-48c2-b15a-67dea399cde0,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b9d1fd37-7af2-44a2-8b4b-0daed8c0b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-c75d6d9e-31b7-49ea-bc8e-32b488229ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-2c3cb0dc-9ddd-43f2-b67c-5cee6f400bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-6b6a792d-7282-413f-b2f1-f649d29ba82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6b374f08-37b0-40c3-977d-7b384dd27952,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-1aff1c87-fa6b-47a6-bfce-56860bfd3f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488693855-172.17.0.8-1599355499121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-936f2974-b3f4-44bf-871b-c489e1085003,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-2ed7d497-2751-4260-91ae-f2b3d0aac7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-93c7090d-7c79-4c48-8b0d-7a83c8860a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-c8b29cff-b821-464a-b176-30cb1b38a676,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-9d84dc4a-4af2-4554-9afe-8afd89326c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-5a6b43a4-37aa-47ea-99b3-0f599a603780,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-de4d5b0f-3c64-4b28-b17b-ab08585e934e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-49b552cf-b18c-4c9b-b7d4-9f5f17fe1754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488693855-172.17.0.8-1599355499121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-936f2974-b3f4-44bf-871b-c489e1085003,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-2ed7d497-2751-4260-91ae-f2b3d0aac7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-93c7090d-7c79-4c48-8b0d-7a83c8860a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-c8b29cff-b821-464a-b176-30cb1b38a676,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-9d84dc4a-4af2-4554-9afe-8afd89326c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-5a6b43a4-37aa-47ea-99b3-0f599a603780,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-de4d5b0f-3c64-4b28-b17b-ab08585e934e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-49b552cf-b18c-4c9b-b7d4-9f5f17fe1754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533926201-172.17.0.8-1599355893382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-17c9cd80-b04e-4e9d-a2df-a90269de5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-d984ee27-fa61-41ec-9119-5074c9dd849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-6eace85b-579e-4b87-84ab-dbcc75fda9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-889fb814-5068-4d5c-8202-d9a5bde20638,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-b460d4d5-391a-4b5e-ab7e-12bee1b9302f,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-75470448-eafd-47bc-afbd-667ed7d0a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-3a52e687-43ac-43be-8d02-d7a10eb9f571,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-a6235967-8138-4bef-b529-d7bbb91f9404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533926201-172.17.0.8-1599355893382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-17c9cd80-b04e-4e9d-a2df-a90269de5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-d984ee27-fa61-41ec-9119-5074c9dd849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-6eace85b-579e-4b87-84ab-dbcc75fda9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-889fb814-5068-4d5c-8202-d9a5bde20638,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-b460d4d5-391a-4b5e-ab7e-12bee1b9302f,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-75470448-eafd-47bc-afbd-667ed7d0a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-3a52e687-43ac-43be-8d02-d7a10eb9f571,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-a6235967-8138-4bef-b529-d7bbb91f9404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361647397-172.17.0.8-1599356025502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-4ce12032-40ac-4333-9b5f-db91505c9abc,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c01200c0-8088-4e2e-8472-6314e8fd67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-de1ef97d-c2a7-4e73-ad42-4e5767a0a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-db25b213-4cd4-4fba-a455-ef4f4e210fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-763d6dc8-d165-4cf6-9ec2-2d0741198405,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b6866d7c-496f-47b5-9142-8a7b6ae0db12,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-83beb851-6a3d-4e11-82ec-ed894c93d924,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-51c87afe-dbbc-4dc6-a656-5260ea93185f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361647397-172.17.0.8-1599356025502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-4ce12032-40ac-4333-9b5f-db91505c9abc,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c01200c0-8088-4e2e-8472-6314e8fd67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-de1ef97d-c2a7-4e73-ad42-4e5767a0a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-db25b213-4cd4-4fba-a455-ef4f4e210fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-763d6dc8-d165-4cf6-9ec2-2d0741198405,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b6866d7c-496f-47b5-9142-8a7b6ae0db12,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-83beb851-6a3d-4e11-82ec-ed894c93d924,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-51c87afe-dbbc-4dc6-a656-5260ea93185f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922031887-172.17.0.8-1599356413103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-d98c2f5e-6936-45be-8998-8f30cac1590e,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-355faeb8-9c3d-43d6-be2b-8c08f87232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-36278287-e053-4a2a-bf99-6aa5291f9b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-5b4e3a64-f8b0-4399-bdf9-0231ab3569d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-43f019e3-bfa2-4f2d-b1ca-163c0ddd12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-7ea65684-a5e6-4865-a9b4-387ced7e2d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-d440c7a5-ceef-4fd3-bdd5-ad736f72db66,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-757e6dd8-21b2-443e-9186-1edce626b3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922031887-172.17.0.8-1599356413103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-d98c2f5e-6936-45be-8998-8f30cac1590e,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-355faeb8-9c3d-43d6-be2b-8c08f87232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-36278287-e053-4a2a-bf99-6aa5291f9b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-5b4e3a64-f8b0-4399-bdf9-0231ab3569d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-43f019e3-bfa2-4f2d-b1ca-163c0ddd12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-7ea65684-a5e6-4865-a9b4-387ced7e2d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-d440c7a5-ceef-4fd3-bdd5-ad736f72db66,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-757e6dd8-21b2-443e-9186-1edce626b3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324069587-172.17.0.8-1599356648559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-dd7fd6c7-ced2-43f4-8fa3-3655214d36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-ac201049-f7d0-44e3-8920-c25c6c8c2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-410d3bba-0ea6-4be3-9e36-0d90eddbfcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-5fc35a6b-0a6b-4d91-9262-c9c60734c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-d2121696-d0ef-4e6b-8483-268c9994e870,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-8727f107-028c-484e-84cb-b6c204f6c617,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-78203633-d0e6-4568-a70c-ba8dac138ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-349383e6-e4e0-4943-a2f3-d609985ca7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324069587-172.17.0.8-1599356648559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40436,DS-dd7fd6c7-ced2-43f4-8fa3-3655214d36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-ac201049-f7d0-44e3-8920-c25c6c8c2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-410d3bba-0ea6-4be3-9e36-0d90eddbfcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-5fc35a6b-0a6b-4d91-9262-c9c60734c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-d2121696-d0ef-4e6b-8483-268c9994e870,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-8727f107-028c-484e-84cb-b6c204f6c617,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-78203633-d0e6-4568-a70c-ba8dac138ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-349383e6-e4e0-4943-a2f3-d609985ca7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53190431-172.17.0.8-1599356726793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-627b2ed2-38d3-49e9-9a6e-5db832cee13b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-ce01db92-b7fa-4461-b849-5743547ea305,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-32d5b4a1-1746-4d6a-ac00-2336e1037a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d441d51a-c576-435b-8146-51bb30d44682,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-bbcbf68d-1a21-4426-bba1-e6d080ae3555,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-ea219592-be42-4603-a419-fc849c4d7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-acdabc95-fa18-4356-a3f1-d039fe940537,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-9579d749-3ced-499c-91b5-ff2cc3911fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53190431-172.17.0.8-1599356726793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-627b2ed2-38d3-49e9-9a6e-5db832cee13b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-ce01db92-b7fa-4461-b849-5743547ea305,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-32d5b4a1-1746-4d6a-ac00-2336e1037a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d441d51a-c576-435b-8146-51bb30d44682,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-bbcbf68d-1a21-4426-bba1-e6d080ae3555,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-ea219592-be42-4603-a419-fc849c4d7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-acdabc95-fa18-4356-a3f1-d039fe940537,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-9579d749-3ced-499c-91b5-ff2cc3911fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736135220-172.17.0.8-1599356797268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-f2dcc981-48d6-4cd9-940f-761ddacd0006,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-4548fcfe-8feb-4351-9741-25b95382e725,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-7f80cda4-5528-4110-8aeb-1d491ea370b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-5e0ef09c-f15d-4a32-89f7-10648b79170d,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6e75601f-63ff-4292-bdab-cd5864f50ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-1b0804f3-e9a9-4e62-85de-ea9a402a8342,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2449348e-9079-48d8-b183-626e774ba2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f1adf99a-9e62-4776-aac2-d6fd27800a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736135220-172.17.0.8-1599356797268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-f2dcc981-48d6-4cd9-940f-761ddacd0006,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-4548fcfe-8feb-4351-9741-25b95382e725,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-7f80cda4-5528-4110-8aeb-1d491ea370b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-5e0ef09c-f15d-4a32-89f7-10648b79170d,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6e75601f-63ff-4292-bdab-cd5864f50ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-1b0804f3-e9a9-4e62-85de-ea9a402a8342,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2449348e-9079-48d8-b183-626e774ba2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f1adf99a-9e62-4776-aac2-d6fd27800a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243984249-172.17.0.8-1599356884433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-f63ef7fa-202f-47f3-aaf8-8984066e2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-51373c1e-ac8b-4634-8c8a-0a6bf6a8160d,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-a6f261d8-5a72-47e7-a951-557c9fbd111e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-36574b99-8bd0-4ab2-954a-f503cc1160b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-becee2ea-59b9-40ec-92d4-856f97347038,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-7374f2ad-259d-4cc9-a522-99a28ea6f1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-ddb156a3-7330-47fd-ad78-cf72d52359fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-ee1d4071-8d3c-498c-8191-9445f77411c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243984249-172.17.0.8-1599356884433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38254,DS-f63ef7fa-202f-47f3-aaf8-8984066e2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-51373c1e-ac8b-4634-8c8a-0a6bf6a8160d,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-a6f261d8-5a72-47e7-a951-557c9fbd111e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-36574b99-8bd0-4ab2-954a-f503cc1160b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-becee2ea-59b9-40ec-92d4-856f97347038,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-7374f2ad-259d-4cc9-a522-99a28ea6f1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-ddb156a3-7330-47fd-ad78-cf72d52359fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-ee1d4071-8d3c-498c-8191-9445f77411c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302781949-172.17.0.8-1599357931571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-3ea7cced-97c6-426c-9c20-4fe1acf8420f,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-64907791-8f75-46cf-902f-03a70e9aca23,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-2e645fc0-3a76-4dcb-bb78-6f0746a2d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-32ad394c-0db4-4fcb-9e63-f88c3220a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-eb3ad60a-fd34-4691-abf2-93eb23a94619,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-67d194b2-e207-42ba-b5f7-8d70baeea864,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-4d03e0e5-7b2f-4df3-87a8-31934db81a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-cee1648f-2f81-4899-9294-7c25b29204da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302781949-172.17.0.8-1599357931571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-3ea7cced-97c6-426c-9c20-4fe1acf8420f,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-64907791-8f75-46cf-902f-03a70e9aca23,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-2e645fc0-3a76-4dcb-bb78-6f0746a2d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-32ad394c-0db4-4fcb-9e63-f88c3220a4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-eb3ad60a-fd34-4691-abf2-93eb23a94619,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-67d194b2-e207-42ba-b5f7-8d70baeea864,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-4d03e0e5-7b2f-4df3-87a8-31934db81a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-cee1648f-2f81-4899-9294-7c25b29204da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204778119-172.17.0.8-1599357959164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-e8fe7a8f-ef67-47cb-ac62-2463ffda395d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-cce4da76-cc0b-4e05-af83-5df3ab9f71c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-5bdd1769-c44e-4a66-b1a3-a3f4d8b9ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-29d38e26-36c1-43cb-84f4-261d6546c242,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-ff52417e-a456-4b01-a198-03c49409451a,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-9f452236-77c0-40e4-8131-eb5fa9715d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-75217920-d703-40f6-b2ea-2414e1bf4802,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-a61fda69-fa1d-4a13-add9-d0033029010d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204778119-172.17.0.8-1599357959164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-e8fe7a8f-ef67-47cb-ac62-2463ffda395d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-cce4da76-cc0b-4e05-af83-5df3ab9f71c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-5bdd1769-c44e-4a66-b1a3-a3f4d8b9ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-29d38e26-36c1-43cb-84f4-261d6546c242,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-ff52417e-a456-4b01-a198-03c49409451a,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-9f452236-77c0-40e4-8131-eb5fa9715d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-75217920-d703-40f6-b2ea-2414e1bf4802,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-a61fda69-fa1d-4a13-add9-d0033029010d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5814
