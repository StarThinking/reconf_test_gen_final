reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518746682-172.17.0.16-1599384690178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-b69edc3e-34a9-4c29-a546-665dea05d228,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-df64b153-e9ff-47a3-a908-ee419312df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-f7db7537-3e46-4080-9458-ea557eac9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-e7f7e4d4-2a5a-4c11-ade9-a95986451eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-1346e1a2-adf0-4aba-9764-1e9984a8e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-5982a3b7-62b5-4148-b839-0a30938c0946,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e6ea1a94-7677-4969-afba-07cee7d59794,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-cd2e977f-94dc-44e2-af7a-8d3c9a0220b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518746682-172.17.0.16-1599384690178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-b69edc3e-34a9-4c29-a546-665dea05d228,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-df64b153-e9ff-47a3-a908-ee419312df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-f7db7537-3e46-4080-9458-ea557eac9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-e7f7e4d4-2a5a-4c11-ade9-a95986451eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-1346e1a2-adf0-4aba-9764-1e9984a8e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-5982a3b7-62b5-4148-b839-0a30938c0946,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e6ea1a94-7677-4969-afba-07cee7d59794,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-cd2e977f-94dc-44e2-af7a-8d3c9a0220b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319454541-172.17.0.16-1599384991208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-90940cf5-6092-4c99-9fb6-82c0488b7bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-f4a230b4-c291-484c-9823-f42390184b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-752c8068-09ce-4383-96e7-bae80f71df30,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-9da4bbcf-9e53-40ab-968a-ee718e9a5870,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-db54090a-0d26-47c4-b8cd-3b765ae701c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-195b1786-f6b9-436e-8b68-327b2299a151,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-479632aa-0435-469c-a1bc-beebbfedf795,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-13b173a6-b0b5-44e7-8278-5cba65f70e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319454541-172.17.0.16-1599384991208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-90940cf5-6092-4c99-9fb6-82c0488b7bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-f4a230b4-c291-484c-9823-f42390184b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-752c8068-09ce-4383-96e7-bae80f71df30,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-9da4bbcf-9e53-40ab-968a-ee718e9a5870,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-db54090a-0d26-47c4-b8cd-3b765ae701c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-195b1786-f6b9-436e-8b68-327b2299a151,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-479632aa-0435-469c-a1bc-beebbfedf795,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-13b173a6-b0b5-44e7-8278-5cba65f70e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794743310-172.17.0.16-1599385365266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-68119753-2072-4ac3-9fb5-48e916b0331c,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-cc7fe928-5982-4546-99e4-a5a9d29ca2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-47b6d674-4dc2-4237-8005-4e4a7a9744e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-33b312a8-fde5-4576-917c-fd905ab8fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-71a7b15e-c593-449f-bd56-599791207c23,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-55ecb497-3f7b-44bc-95cf-5e560c05852f,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-2abbe84f-c7a2-4ed4-ab42-884cef7d789d,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-0690e299-6730-4f0e-b3a6-f9266c4692c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794743310-172.17.0.16-1599385365266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-68119753-2072-4ac3-9fb5-48e916b0331c,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-cc7fe928-5982-4546-99e4-a5a9d29ca2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-47b6d674-4dc2-4237-8005-4e4a7a9744e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-33b312a8-fde5-4576-917c-fd905ab8fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-71a7b15e-c593-449f-bd56-599791207c23,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-55ecb497-3f7b-44bc-95cf-5e560c05852f,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-2abbe84f-c7a2-4ed4-ab42-884cef7d789d,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-0690e299-6730-4f0e-b3a6-f9266c4692c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197237982-172.17.0.16-1599385769932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-f32644b3-bbfc-4a08-b16f-a5aa89d6de52,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-c2822fc1-4365-4af7-b7e5-d969f4481f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-e0170fef-fe56-4e5a-b471-5de1f6f09bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-53374857-e9af-451e-a5f4-8261090c3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-95ffa1e9-8394-4f3e-9c9e-052b227ded6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-cd8e6cb8-8b3c-4e98-8198-77836fcbc6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-ef42b691-72a6-4fad-9a76-4bfbd51dae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-913bd3ff-ea6e-4c15-ba3e-2c24614ed5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197237982-172.17.0.16-1599385769932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-f32644b3-bbfc-4a08-b16f-a5aa89d6de52,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-c2822fc1-4365-4af7-b7e5-d969f4481f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-e0170fef-fe56-4e5a-b471-5de1f6f09bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-53374857-e9af-451e-a5f4-8261090c3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-95ffa1e9-8394-4f3e-9c9e-052b227ded6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-cd8e6cb8-8b3c-4e98-8198-77836fcbc6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-ef42b691-72a6-4fad-9a76-4bfbd51dae13,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-913bd3ff-ea6e-4c15-ba3e-2c24614ed5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732353960-172.17.0.16-1599386185899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-3d114a9b-8db4-4318-bb8d-1030d9a718cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-8473f485-cfab-4845-ab71-8892cc9f7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-5126a758-51f0-41ff-8ead-b3e286afd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-08429c5e-45cc-43e8-8079-ae4eab16c066,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-39ee5c66-cc96-4f34-9239-93d106dd04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-05e18ddb-981d-4727-b937-17b8105adaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-1a6484db-fd45-4b78-bbc2-a2b4c7227f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-dbbe5748-5f21-4dde-ae3e-c1425c83c34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732353960-172.17.0.16-1599386185899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-3d114a9b-8db4-4318-bb8d-1030d9a718cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-8473f485-cfab-4845-ab71-8892cc9f7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-5126a758-51f0-41ff-8ead-b3e286afd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-08429c5e-45cc-43e8-8079-ae4eab16c066,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-39ee5c66-cc96-4f34-9239-93d106dd04f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-05e18ddb-981d-4727-b937-17b8105adaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-1a6484db-fd45-4b78-bbc2-a2b4c7227f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-dbbe5748-5f21-4dde-ae3e-c1425c83c34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492696134-172.17.0.16-1599386256151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-9017aeee-2e3d-4f9c-bedb-be58e9213719,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-d6285a54-8e22-41fe-abaa-d3691d1ba4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-35db79ce-85f0-4248-a38b-69161717d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-fffaf98a-da5b-4dce-a6b1-912afefafa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-d761631a-5724-4dea-a14c-02e32bd01f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-3d9fb07b-9969-4a43-a50d-fe47ff270c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-136bf1a4-2c1b-4750-ad24-d2d7f57da0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-b0979db2-a3b8-47a9-a646-de826bb9349d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492696134-172.17.0.16-1599386256151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-9017aeee-2e3d-4f9c-bedb-be58e9213719,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-d6285a54-8e22-41fe-abaa-d3691d1ba4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-35db79ce-85f0-4248-a38b-69161717d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-fffaf98a-da5b-4dce-a6b1-912afefafa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-d761631a-5724-4dea-a14c-02e32bd01f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-3d9fb07b-9969-4a43-a50d-fe47ff270c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-136bf1a4-2c1b-4750-ad24-d2d7f57da0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-b0979db2-a3b8-47a9-a646-de826bb9349d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892817046-172.17.0.16-1599386599898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35918,DS-33590ea9-209f-4869-9e18-79cf611d7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-4f5c1038-75db-400d-bd73-304f9832bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-add35949-0b11-4d45-9fae-5b43b81a7785,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-0148c871-3bd7-4d28-86e6-7700a4be5874,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-3613ea35-06e0-477c-a2d2-a0dedd57a6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-de490618-f216-469c-822c-9fe26918dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-44ac173d-c0d3-4eb5-af32-6fc906687180,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-731f3381-9b6b-4ff3-a66d-ebd352daaca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892817046-172.17.0.16-1599386599898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35918,DS-33590ea9-209f-4869-9e18-79cf611d7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-4f5c1038-75db-400d-bd73-304f9832bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-add35949-0b11-4d45-9fae-5b43b81a7785,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-0148c871-3bd7-4d28-86e6-7700a4be5874,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-3613ea35-06e0-477c-a2d2-a0dedd57a6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-de490618-f216-469c-822c-9fe26918dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-44ac173d-c0d3-4eb5-af32-6fc906687180,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-731f3381-9b6b-4ff3-a66d-ebd352daaca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293938553-172.17.0.16-1599386988016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-249aae65-529c-4625-b612-6bd1f288f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-b853e927-6452-42da-9cf7-c2c5b22843fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1b1a7234-2ba1-4673-8eb0-c0f54e8e39ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-edf0129e-3841-4aeb-9ae9-953b16e9a023,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-29da328f-8ed8-4a7c-8b98-032953b15fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-ec153177-442e-49df-93f3-cc40f18a1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-61c924fd-9061-4d41-89de-6534009d2152,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-bce76559-4f3e-4038-af4c-179b25dc6811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293938553-172.17.0.16-1599386988016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-249aae65-529c-4625-b612-6bd1f288f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-b853e927-6452-42da-9cf7-c2c5b22843fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1b1a7234-2ba1-4673-8eb0-c0f54e8e39ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-edf0129e-3841-4aeb-9ae9-953b16e9a023,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-29da328f-8ed8-4a7c-8b98-032953b15fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-ec153177-442e-49df-93f3-cc40f18a1d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-61c924fd-9061-4d41-89de-6534009d2152,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-bce76559-4f3e-4038-af4c-179b25dc6811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080024157-172.17.0.16-1599387862994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40489,DS-3386e503-be97-4372-b28f-d4cffbe32738,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-d56f48c5-e35f-41ed-9738-c515a8bc5407,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-5141d149-0846-4a80-88af-eea8c9ef8e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-63c66465-7648-402d-bfe3-79cf6558413c,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-deefbd9d-455a-4916-8818-d81178223aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-4ca2c100-fede-449e-8d71-cfb2e5cac4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-5fa65141-ec73-45df-8d5d-ce9048596b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-c32dd553-6b7d-42b3-b2cf-ad7790faefa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080024157-172.17.0.16-1599387862994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40489,DS-3386e503-be97-4372-b28f-d4cffbe32738,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-d56f48c5-e35f-41ed-9738-c515a8bc5407,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-5141d149-0846-4a80-88af-eea8c9ef8e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-63c66465-7648-402d-bfe3-79cf6558413c,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-deefbd9d-455a-4916-8818-d81178223aad,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-4ca2c100-fede-449e-8d71-cfb2e5cac4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-5fa65141-ec73-45df-8d5d-ce9048596b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-c32dd553-6b7d-42b3-b2cf-ad7790faefa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147600528-172.17.0.16-1599388145100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-1d2ef73e-1013-4dd5-9997-070567c4e064,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-db676448-13ba-473d-843b-3fdf9d4d933f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-336cd708-f092-45f7-b2b8-5889f6654ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-71494e87-2102-4a6b-99f7-f7877ee6e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-cfa25151-96e6-417e-ab0c-e6daeea9f922,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-91d3092e-931f-4bd8-9880-bcd7baad52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-a5fbada3-4fd5-40db-94c1-ccc106859a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-3c1cabbf-ade1-4cf1-b7d3-471636df3eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147600528-172.17.0.16-1599388145100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-1d2ef73e-1013-4dd5-9997-070567c4e064,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-db676448-13ba-473d-843b-3fdf9d4d933f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-336cd708-f092-45f7-b2b8-5889f6654ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-71494e87-2102-4a6b-99f7-f7877ee6e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-cfa25151-96e6-417e-ab0c-e6daeea9f922,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-91d3092e-931f-4bd8-9880-bcd7baad52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-a5fbada3-4fd5-40db-94c1-ccc106859a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-3c1cabbf-ade1-4cf1-b7d3-471636df3eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167456522-172.17.0.16-1599388413879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-ffbf6df1-8c35-4f0a-8d24-08eb86aef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ef187f13-c8fd-484b-a31a-f39b83ab3079,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ad770b58-b307-4177-9baf-dc4c4c2e0bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-4e40708e-c09c-4b84-abf7-fa2bc71a6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-bbc657a4-a336-4740-8bc0-7f3970fa037a,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-e5fefd36-3ce1-4f62-8d8e-e8e4f93ac30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-3d154f3a-d55e-443b-9b06-3f5104dc1613,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-dca2c506-b26a-48ff-9874-b5655d390b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167456522-172.17.0.16-1599388413879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-ffbf6df1-8c35-4f0a-8d24-08eb86aef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-ef187f13-c8fd-484b-a31a-f39b83ab3079,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-ad770b58-b307-4177-9baf-dc4c4c2e0bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-4e40708e-c09c-4b84-abf7-fa2bc71a6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-bbc657a4-a336-4740-8bc0-7f3970fa037a,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-e5fefd36-3ce1-4f62-8d8e-e8e4f93ac30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-3d154f3a-d55e-443b-9b06-3f5104dc1613,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-dca2c506-b26a-48ff-9874-b5655d390b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715231135-172.17.0.16-1599388497598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-1aebb140-d5b1-4fae-8dbe-3b25c1fa6bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-0469ec35-8940-4d7b-8ba9-59a6fd47ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-fd77b4af-11cd-4c1b-90e9-259bf18ea533,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-3c6bb86a-506d-42c9-a3ba-c44a02698397,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-001262e5-b4ca-4ccc-8014-f13f16f883b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b14977f8-87a6-4b3a-bcd4-b8d082f01ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-b1f533ac-f759-479d-bd89-f925fd2f5bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-8f5e4663-b5ab-46eb-965e-c2bc95df24ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715231135-172.17.0.16-1599388497598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-1aebb140-d5b1-4fae-8dbe-3b25c1fa6bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-0469ec35-8940-4d7b-8ba9-59a6fd47ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-fd77b4af-11cd-4c1b-90e9-259bf18ea533,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-3c6bb86a-506d-42c9-a3ba-c44a02698397,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-001262e5-b4ca-4ccc-8014-f13f16f883b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-b14977f8-87a6-4b3a-bcd4-b8d082f01ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-b1f533ac-f759-479d-bd89-f925fd2f5bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-8f5e4663-b5ab-46eb-965e-c2bc95df24ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123875937-172.17.0.16-1599388710561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-42f0cddf-5d3c-4974-83c8-9fd9047f98ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-52b672b6-db21-45da-ac31-2c850233c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-45bfd3e0-1461-41f9-bd66-3924a02a12f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-37db3a26-8ded-4046-954c-1107a3abe041,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-9405f70a-cae2-49a1-abc0-9d9f66fe13cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cbdb795b-c659-4ddb-9d81-9aedf939b895,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-d6c9ea51-fd8e-44e2-a3f4-5f119b8a7253,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-1e403b32-ae44-4b78-a162-14848ec1695b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123875937-172.17.0.16-1599388710561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-42f0cddf-5d3c-4974-83c8-9fd9047f98ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-52b672b6-db21-45da-ac31-2c850233c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-45bfd3e0-1461-41f9-bd66-3924a02a12f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-37db3a26-8ded-4046-954c-1107a3abe041,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-9405f70a-cae2-49a1-abc0-9d9f66fe13cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-cbdb795b-c659-4ddb-9d81-9aedf939b895,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-d6c9ea51-fd8e-44e2-a3f4-5f119b8a7253,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-1e403b32-ae44-4b78-a162-14848ec1695b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874039863-172.17.0.16-1599389298696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-ea635fa5-ad57-4499-b1e8-a205c8e79481,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-b3925c03-fd16-4455-88ff-6fe903dda600,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7f57778a-18c6-4b52-8199-fdac68a812db,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-cf408fdf-f416-47ef-a1de-553e1eecf6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-40b12cb9-7bd8-420f-954d-885acf3f4bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-ca1ec9ce-5c19-4be5-bb91-ff459385d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-9031ef81-ca66-467e-ae86-00692c10aa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-911ecb78-1e59-4eb5-bed3-b8c12e83d04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874039863-172.17.0.16-1599389298696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-ea635fa5-ad57-4499-b1e8-a205c8e79481,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-b3925c03-fd16-4455-88ff-6fe903dda600,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7f57778a-18c6-4b52-8199-fdac68a812db,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-cf408fdf-f416-47ef-a1de-553e1eecf6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-40b12cb9-7bd8-420f-954d-885acf3f4bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-ca1ec9ce-5c19-4be5-bb91-ff459385d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-9031ef81-ca66-467e-ae86-00692c10aa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-911ecb78-1e59-4eb5-bed3-b8c12e83d04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4735
