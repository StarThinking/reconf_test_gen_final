reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948081432-172.17.0.6-1599392007447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-2b44229d-e6d5-4bb0-8755-9466c160560c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-6842d419-5b81-4994-9800-3c90300192f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-40180f1f-a84e-4520-90bc-c1217b92d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-2abba031-0a21-41b4-bfb2-a8ba1d492373,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-5858da57-cd10-45da-9acb-79f780a1e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-1a04e821-1799-46b3-a3af-9927c760fdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-38411958-a7f1-477a-a417-2ebe902cd511,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-b8dfa795-ad46-46f2-b731-127a9d82990b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948081432-172.17.0.6-1599392007447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-2b44229d-e6d5-4bb0-8755-9466c160560c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-6842d419-5b81-4994-9800-3c90300192f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-40180f1f-a84e-4520-90bc-c1217b92d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-2abba031-0a21-41b4-bfb2-a8ba1d492373,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-5858da57-cd10-45da-9acb-79f780a1e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-1a04e821-1799-46b3-a3af-9927c760fdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-38411958-a7f1-477a-a417-2ebe902cd511,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-b8dfa795-ad46-46f2-b731-127a9d82990b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707594504-172.17.0.6-1599392044354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46486,DS-baffd3f4-f574-436f-b0ae-3080bd547a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-36cb5348-58e4-4744-8516-66032c627e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-b9d4f745-0e50-40a0-b6d5-06e5c8cbefb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-fa6b633a-d642-46e4-bf6f-380aeda372ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-c7113a1c-7d9d-40c8-a89e-3db8ed70347c,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-7af01e34-f61f-487d-bc64-fc421cf8da81,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-39911da4-9f6f-48ad-baee-bf271eaa6bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-f241177b-7fe2-430a-b00d-53d38d79efd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707594504-172.17.0.6-1599392044354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46486,DS-baffd3f4-f574-436f-b0ae-3080bd547a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-36cb5348-58e4-4744-8516-66032c627e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-b9d4f745-0e50-40a0-b6d5-06e5c8cbefb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-fa6b633a-d642-46e4-bf6f-380aeda372ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-c7113a1c-7d9d-40c8-a89e-3db8ed70347c,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-7af01e34-f61f-487d-bc64-fc421cf8da81,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-39911da4-9f6f-48ad-baee-bf271eaa6bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-f241177b-7fe2-430a-b00d-53d38d79efd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857285633-172.17.0.6-1599392120919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-9b06053e-e96a-467d-b945-d502debf05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-1017fce2-f976-46f9-b26f-47d5833ee661,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2b6f5ea5-f6d9-4d6c-b45a-da9aa2f49be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-c8e2040d-6716-4f7f-9680-af31f4928e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-dcba7a2f-075c-43f2-8f4c-0cc2c2e3d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-a2962d12-d422-4baf-8c1e-356555282be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-31ebb38f-1e48-457e-a0e6-53092b0d4158,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-a9a1088d-b553-49a8-a890-40c2eeaaf460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857285633-172.17.0.6-1599392120919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-9b06053e-e96a-467d-b945-d502debf05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-1017fce2-f976-46f9-b26f-47d5833ee661,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2b6f5ea5-f6d9-4d6c-b45a-da9aa2f49be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-c8e2040d-6716-4f7f-9680-af31f4928e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-dcba7a2f-075c-43f2-8f4c-0cc2c2e3d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-a2962d12-d422-4baf-8c1e-356555282be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-31ebb38f-1e48-457e-a0e6-53092b0d4158,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-a9a1088d-b553-49a8-a890-40c2eeaaf460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756355360-172.17.0.6-1599392279340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-fec318df-08e8-48bf-b895-f79155dbed4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-007473b8-3b9d-47ba-b433-7bbc78d961a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-ecc1d132-ba1e-4215-b063-adb3988f85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-247e3bda-a495-467d-b2ef-79caa62fb4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-c6c7bba7-c554-4770-ba5d-c42be3a80997,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-9de45b8d-0f46-4fa6-8850-90fcea69b066,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a9c912b5-83d0-4cb0-bc12-81822418fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-327fd850-568f-4e81-a226-54867d65bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756355360-172.17.0.6-1599392279340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-fec318df-08e8-48bf-b895-f79155dbed4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-007473b8-3b9d-47ba-b433-7bbc78d961a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-ecc1d132-ba1e-4215-b063-adb3988f85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-247e3bda-a495-467d-b2ef-79caa62fb4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-c6c7bba7-c554-4770-ba5d-c42be3a80997,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-9de45b8d-0f46-4fa6-8850-90fcea69b066,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a9c912b5-83d0-4cb0-bc12-81822418fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-327fd850-568f-4e81-a226-54867d65bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628808339-172.17.0.6-1599392319581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5eb998d9-95b3-48c5-adf6-fb3dbaa575a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-fe97dbda-8332-4afc-8173-b9df8c4d911e,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-2724495b-3cad-45e8-86e6-5339b42f187f,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-d762105c-fdc2-4b4a-b763-8dc8cee0059f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-bca5dc77-5b90-4861-9282-cdd8e7fea60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-09b78b98-ce51-43b7-a26a-87d12158577c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e5b64f5a-d83c-442f-a4ad-deadba25a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-9c0acea3-b054-4b43-9ece-1f96e3723b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628808339-172.17.0.6-1599392319581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-5eb998d9-95b3-48c5-adf6-fb3dbaa575a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-fe97dbda-8332-4afc-8173-b9df8c4d911e,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-2724495b-3cad-45e8-86e6-5339b42f187f,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-d762105c-fdc2-4b4a-b763-8dc8cee0059f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-bca5dc77-5b90-4861-9282-cdd8e7fea60b,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-09b78b98-ce51-43b7-a26a-87d12158577c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e5b64f5a-d83c-442f-a4ad-deadba25a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-9c0acea3-b054-4b43-9ece-1f96e3723b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654930872-172.17.0.6-1599392539350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-827151f0-8ee4-49f4-919a-12d7eee4467e,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-394fbc00-39a3-4fc6-8a2c-eaf2a8db7762,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-16b96736-e542-4006-8b1d-650272670774,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-9478f7d3-99af-4f99-a576-ed6fb1d62487,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-161fe34e-7e57-4c71-b795-1dd40b6b1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-834f4467-9c57-457f-a2ae-0df9985ed934,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-efaa3567-9852-46b5-91ba-0f4adaacb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-da733014-fd7c-412d-84cb-ba37c6141812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654930872-172.17.0.6-1599392539350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-827151f0-8ee4-49f4-919a-12d7eee4467e,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-394fbc00-39a3-4fc6-8a2c-eaf2a8db7762,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-16b96736-e542-4006-8b1d-650272670774,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-9478f7d3-99af-4f99-a576-ed6fb1d62487,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-161fe34e-7e57-4c71-b795-1dd40b6b1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-834f4467-9c57-457f-a2ae-0df9985ed934,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-efaa3567-9852-46b5-91ba-0f4adaacb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-da733014-fd7c-412d-84cb-ba37c6141812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391667171-172.17.0.6-1599392659174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33392,DS-5fe1d617-50cd-438b-901a-590aa89e3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-c879b9d2-dc76-41a1-886d-39734f6d5543,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-95579948-9c27-45fe-81fe-779e6ea8c910,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-95a98472-1a77-4663-a9f5-86e680415ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-b9a4273f-e979-4be8-974a-edb33efba990,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-6f2dff6e-5a02-4d93-8d1a-932f119188ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-17e4ece7-7992-421c-8145-526abd2628ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b413f65b-6422-4315-bb81-cd68b5bec190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391667171-172.17.0.6-1599392659174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33392,DS-5fe1d617-50cd-438b-901a-590aa89e3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-c879b9d2-dc76-41a1-886d-39734f6d5543,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-95579948-9c27-45fe-81fe-779e6ea8c910,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-95a98472-1a77-4663-a9f5-86e680415ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-b9a4273f-e979-4be8-974a-edb33efba990,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-6f2dff6e-5a02-4d93-8d1a-932f119188ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-17e4ece7-7992-421c-8145-526abd2628ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b413f65b-6422-4315-bb81-cd68b5bec190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90085559-172.17.0.6-1599392679561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-90fd78d3-07bc-4ce1-af12-bc7b2e2066e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-a2a305b3-376b-4e00-9d37-a16279d94d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-39f21ba4-55a7-4603-88cd-cb542fbb7860,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-1ac569bc-9f73-416e-a803-2d8a7c035d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-c4111217-f272-44a3-9a7d-09e65d630718,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-00b14e34-122f-49ad-a617-da8ed68a542d,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-0aed2342-a975-49a1-9629-e3d67c87813b,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-c4aca09d-a88c-4362-904b-eaf40b8f5681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90085559-172.17.0.6-1599392679561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-90fd78d3-07bc-4ce1-af12-bc7b2e2066e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-a2a305b3-376b-4e00-9d37-a16279d94d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-39f21ba4-55a7-4603-88cd-cb542fbb7860,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-1ac569bc-9f73-416e-a803-2d8a7c035d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-c4111217-f272-44a3-9a7d-09e65d630718,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-00b14e34-122f-49ad-a617-da8ed68a542d,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-0aed2342-a975-49a1-9629-e3d67c87813b,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-c4aca09d-a88c-4362-904b-eaf40b8f5681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257392889-172.17.0.6-1599392778207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-8967c529-c3e0-4203-8023-ec667acc0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-94b24e41-cabe-4b61-856a-7cb6d751d025,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-b67b0463-ee84-48f6-8385-b602ab8b3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-f10227eb-c77d-470e-b611-e88374787eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-6a20a2f2-2c35-451e-a7cd-2ffcff1aec14,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-e42627eb-901d-48db-8882-98c86eaa4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-2f33452a-a738-4ca8-bc14-adc05242ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-202840d1-bed7-45f2-a990-d1b08a0abb2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257392889-172.17.0.6-1599392778207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-8967c529-c3e0-4203-8023-ec667acc0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-94b24e41-cabe-4b61-856a-7cb6d751d025,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-b67b0463-ee84-48f6-8385-b602ab8b3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-f10227eb-c77d-470e-b611-e88374787eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-6a20a2f2-2c35-451e-a7cd-2ffcff1aec14,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-e42627eb-901d-48db-8882-98c86eaa4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-2f33452a-a738-4ca8-bc14-adc05242ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-202840d1-bed7-45f2-a990-d1b08a0abb2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: File /striped/stripedFileChecksum3 could only be written to 3 of the 6 required nodes for RS-6-3-1024k. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /striped/stripedFileChecksum3 could only be written to 3 of the 6 required nodes for RS-6-3-1024k. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock(DFSStripedOutputStream.java:480)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:526)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848260273-172.17.0.6-1599393295858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-d8de53ce-ba99-4046-b1e1-0e426b0b932e,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-1dff67a0-b4f0-419a-b81d-c56facb5380b,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-8d3d8e5b-1cff-4301-af79-8ba84f6b7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-772ed30d-288b-49d7-826d-3047c312f894,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-32e37b9b-e8d0-4eba-963d-2f4a4272b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-3da963e9-ae72-4b99-8783-d8364da23001,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-13216bfe-20fa-421e-9ad1-46549345b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b3e47600-296a-4a97-b100-ef6906aa651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848260273-172.17.0.6-1599393295858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-d8de53ce-ba99-4046-b1e1-0e426b0b932e,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-1dff67a0-b4f0-419a-b81d-c56facb5380b,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-8d3d8e5b-1cff-4301-af79-8ba84f6b7efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-772ed30d-288b-49d7-826d-3047c312f894,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-32e37b9b-e8d0-4eba-963d-2f4a4272b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-3da963e9-ae72-4b99-8783-d8364da23001,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-13216bfe-20fa-421e-9ad1-46549345b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b3e47600-296a-4a97-b100-ef6906aa651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977237791-172.17.0.6-1599393461426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-d1301bdc-2314-4270-8bea-053281b3e503,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-7e1066eb-4244-4f49-909a-39a40831bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-49d472ca-98a6-43fb-a2fd-8aa713cf41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-dce60af9-c9bf-44fd-a0a7-eb9b291b4c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-31067be4-f6e6-440f-b8ad-b12e130cc25f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-20df5587-e964-4730-bb6d-bf0df218986e,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-82e27143-fbe7-4714-bd56-847a51e1f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-759e91ae-45ba-46b8-aebd-835e64b31e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977237791-172.17.0.6-1599393461426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-d1301bdc-2314-4270-8bea-053281b3e503,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-7e1066eb-4244-4f49-909a-39a40831bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-49d472ca-98a6-43fb-a2fd-8aa713cf41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-dce60af9-c9bf-44fd-a0a7-eb9b291b4c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-31067be4-f6e6-440f-b8ad-b12e130cc25f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-20df5587-e964-4730-bb6d-bf0df218986e,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-82e27143-fbe7-4714-bd56-847a51e1f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-759e91ae-45ba-46b8-aebd-835e64b31e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137202498-172.17.0.6-1599393608660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-38ab8136-90ed-4b1b-8b04-38eff845d0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-25ba1953-aec1-4d8d-bf03-270afda3b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-640fcdb8-3199-4d7b-9a55-627e2377b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-95ed498d-1487-446b-be7e-f2ca71fc3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4585ac38-1ec7-4c47-856a-031be1d2edb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-5e9251b8-fd43-4a1f-a1e4-2f5431428751,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-f198af08-cc2b-4133-a959-085aa49365cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6d1c4b27-53b9-4a19-a9f7-a487b222f6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137202498-172.17.0.6-1599393608660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-38ab8136-90ed-4b1b-8b04-38eff845d0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-25ba1953-aec1-4d8d-bf03-270afda3b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-640fcdb8-3199-4d7b-9a55-627e2377b51c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-95ed498d-1487-446b-be7e-f2ca71fc3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4585ac38-1ec7-4c47-856a-031be1d2edb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-5e9251b8-fd43-4a1f-a1e4-2f5431428751,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-f198af08-cc2b-4133-a959-085aa49365cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6d1c4b27-53b9-4a19-a9f7-a487b222f6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037170380-172.17.0.6-1599393627248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-31911d02-eda0-4403-a7e3-4e8dc4c8f270,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-d57158ca-2f3e-4a83-add6-df41043edb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-3a36eb31-6a9f-41ce-981d-94722a48f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-757ad7e5-252c-4975-8aad-c13c3382000c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-4448bab5-44f6-4a68-983f-92e8cb45b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-742572b5-a470-44ed-9b89-cd297b768c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-b77f2dfd-c54e-4652-bfa4-62c6f36e39c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-d53e20a8-2f0d-4ea5-b43d-b59c28fb5765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037170380-172.17.0.6-1599393627248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41636,DS-31911d02-eda0-4403-a7e3-4e8dc4c8f270,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-d57158ca-2f3e-4a83-add6-df41043edb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-3a36eb31-6a9f-41ce-981d-94722a48f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-757ad7e5-252c-4975-8aad-c13c3382000c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-4448bab5-44f6-4a68-983f-92e8cb45b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-742572b5-a470-44ed-9b89-cd297b768c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-b77f2dfd-c54e-4652-bfa4-62c6f36e39c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-d53e20a8-2f0d-4ea5-b43d-b59c28fb5765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44212898-172.17.0.6-1599393662723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-8354c2b5-bf06-4df0-8e66-36349800874e,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-7df646f0-4350-4e6c-b6ba-f5705903079e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-df19f56d-38bf-4c08-822a-ab5fc8d0196b,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-2bd770e3-4ebe-4fb2-ac09-afa325c93d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-e2fe9a9b-d217-42a1-9adc-8b13e07c7c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-1372385b-3e15-443f-91f3-022a348dc216,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-a0977088-b902-4373-96c3-6dbbe24dc665,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ba8ebe57-b009-4b81-9184-7417f1a1fab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44212898-172.17.0.6-1599393662723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-8354c2b5-bf06-4df0-8e66-36349800874e,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-7df646f0-4350-4e6c-b6ba-f5705903079e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-df19f56d-38bf-4c08-822a-ab5fc8d0196b,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-2bd770e3-4ebe-4fb2-ac09-afa325c93d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-e2fe9a9b-d217-42a1-9adc-8b13e07c7c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-1372385b-3e15-443f-91f3-022a348dc216,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-a0977088-b902-4373-96c3-6dbbe24dc665,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ba8ebe57-b009-4b81-9184-7417f1a1fab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995839580-172.17.0.6-1599393700695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-a3905c4e-780c-492f-ba07-ab072df56ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-1ecf25a0-118d-41c8-b368-d9c7ec9b534c,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-99613ab5-6328-47aa-9d6b-87730f9b5f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-cb69c17d-3b52-4be8-9587-4e7e3a594a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-be4602ce-ad17-4bba-b242-6c3091fd3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-ed0b7114-bc09-4c23-8e19-4acb7ca8b456,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-07aae82f-0f96-44d8-8fac-da4d904abf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-c4fb4b36-e995-4f91-84a9-55383755e600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995839580-172.17.0.6-1599393700695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-a3905c4e-780c-492f-ba07-ab072df56ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-1ecf25a0-118d-41c8-b368-d9c7ec9b534c,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-99613ab5-6328-47aa-9d6b-87730f9b5f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-cb69c17d-3b52-4be8-9587-4e7e3a594a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-be4602ce-ad17-4bba-b242-6c3091fd3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-ed0b7114-bc09-4c23-8e19-4acb7ca8b456,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-07aae82f-0f96-44d8-8fac-da4d904abf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-c4fb4b36-e995-4f91-84a9-55383755e600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997380708-172.17.0.6-1599393793148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-97fcf38e-9e3c-4579-8d41-d52354e94f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2c75bf55-00fd-4ac5-9ba2-70d890c2d3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-dccbc28c-8b83-423e-886b-1e0d60d5b994,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-9c4a0e76-c2e1-4b31-9b26-69b21e5527c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-89ad53fa-0627-4b2e-975b-886dd64d724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-aeb6c669-4279-4468-a841-25b5b9f1b843,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-ba3d9a19-5832-4b0c-87e4-9a7fe0854113,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-fd617d8f-8b52-46bd-bcfd-db842a91d306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997380708-172.17.0.6-1599393793148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-97fcf38e-9e3c-4579-8d41-d52354e94f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2c75bf55-00fd-4ac5-9ba2-70d890c2d3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-dccbc28c-8b83-423e-886b-1e0d60d5b994,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-9c4a0e76-c2e1-4b31-9b26-69b21e5527c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-89ad53fa-0627-4b2e-975b-886dd64d724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-aeb6c669-4279-4468-a841-25b5b9f1b843,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-ba3d9a19-5832-4b0c-87e4-9a7fe0854113,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-fd617d8f-8b52-46bd-bcfd-db842a91d306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96409879-172.17.0.6-1599393904064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-f161a873-a82f-42d8-a803-8185c51bc64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-7e546c53-a060-4ea8-bf47-5c03bae2527c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-30258040-8d1b-4730-a8e4-8020511307ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-ec8b0e21-ae21-486f-8e08-95fb92b81e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-a86a091c-443c-43ce-a027-e21f5407a370,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-1cac3eb1-dc9a-482d-8a9a-fb2ca9dc3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-e0d47645-49c9-4304-b477-87cd234c9399,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-b29fe14a-4379-4880-9aef-9ce8c960274c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96409879-172.17.0.6-1599393904064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-f161a873-a82f-42d8-a803-8185c51bc64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-7e546c53-a060-4ea8-bf47-5c03bae2527c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-30258040-8d1b-4730-a8e4-8020511307ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-ec8b0e21-ae21-486f-8e08-95fb92b81e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-a86a091c-443c-43ce-a027-e21f5407a370,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-1cac3eb1-dc9a-482d-8a9a-fb2ca9dc3ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-e0d47645-49c9-4304-b477-87cd234c9399,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-b29fe14a-4379-4880-9aef-9ce8c960274c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: File /striped/stripedFileChecksum3 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /striped/stripedFileChecksum3 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock(DFSStripedOutputStream.java:480)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:526)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531061545-172.17.0.6-1599394008323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-42b4c190-389b-4c3a-a072-015d7b4de279,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-e8eb38d4-b1bf-49f3-82f5-b3188c32a164,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-41579f51-5d83-4802-ab3e-1fa72ecc3b85,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-35c1e0f9-4593-40d0-a29e-857abdb80281,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-65d582a9-e5ca-4324-8b3d-08c8d00d039d,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-90f11ab3-894f-45db-bf1f-e043a9b069ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-1cf42d52-5652-4c0c-b83f-32dfb0d1a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-03ca5da9-38f0-4a67-a7c1-5b123ebb31b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531061545-172.17.0.6-1599394008323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-42b4c190-389b-4c3a-a072-015d7b4de279,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-e8eb38d4-b1bf-49f3-82f5-b3188c32a164,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-41579f51-5d83-4802-ab3e-1fa72ecc3b85,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-35c1e0f9-4593-40d0-a29e-857abdb80281,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-65d582a9-e5ca-4324-8b3d-08c8d00d039d,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-90f11ab3-894f-45db-bf1f-e043a9b069ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-1cf42d52-5652-4c0c-b83f-32dfb0d1a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-03ca5da9-38f0-4a67-a7c1-5b123ebb31b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81966259-172.17.0.6-1599394046411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-b1433123-3bc1-420b-983b-9fb5b641e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-dda4ebdd-b9c3-4ea4-acf9-451e1550e094,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-5af61ca7-5e12-4668-b25c-525c4ef8235e,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-07206d00-98b2-4920-b895-e0f26532fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-6aebf592-0812-45b6-8088-a6c404cbd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-d0d0d65e-3db4-4307-b6fb-860d18d830c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-04ea8b71-83a9-4837-9978-85b9c7975529,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-d747e708-74a0-4402-9a87-94d396eaf0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81966259-172.17.0.6-1599394046411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-b1433123-3bc1-420b-983b-9fb5b641e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-dda4ebdd-b9c3-4ea4-acf9-451e1550e094,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-5af61ca7-5e12-4668-b25c-525c4ef8235e,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-07206d00-98b2-4920-b895-e0f26532fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-6aebf592-0812-45b6-8088-a6c404cbd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-d0d0d65e-3db4-4307-b6fb-860d18d830c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-04ea8b71-83a9-4837-9978-85b9c7975529,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-d747e708-74a0-4402-9a87-94d396eaf0e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438811408-172.17.0.6-1599394119087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-7a575d1c-5413-4e88-b7d3-f1632890d232,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-ffb1eecf-a267-46b5-9b46-79d742eb7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-8711ebab-9b56-476d-a372-762566f6e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-9abbca7b-b669-4704-a83b-9beaf1ecf129,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-aeffea7f-2dde-495a-b59a-a492e6935d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-b60edb33-e31d-490e-bf0b-5d42c0b57421,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6b128362-dede-4df4-bf53-72c9edcb8b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-df92f8c0-dd3f-4fa6-9a26-f2639d8b0546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438811408-172.17.0.6-1599394119087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-7a575d1c-5413-4e88-b7d3-f1632890d232,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-ffb1eecf-a267-46b5-9b46-79d742eb7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-8711ebab-9b56-476d-a372-762566f6e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-9abbca7b-b669-4704-a83b-9beaf1ecf129,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-aeffea7f-2dde-495a-b59a-a492e6935d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-b60edb33-e31d-490e-bf0b-5d42c0b57421,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6b128362-dede-4df4-bf53-72c9edcb8b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-df92f8c0-dd3f-4fa6-9a26-f2639d8b0546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127689958-172.17.0.6-1599394137459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43889,DS-1192322f-cfcc-4c05-ba0f-ae7215a5a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5b7a6378-681a-456c-917e-6207540f5378,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-3d301dd9-1b33-43d2-8e94-bdf876dea872,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-0753387a-1100-4399-a6a9-05645ff3bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0ee21a9d-6cb7-4d26-9c7d-ec3f6e185384,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-19648505-05c8-46fe-84b2-345ecb7fbf43,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0775e499-dcf4-47d7-9f6d-dd05ba1877b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-c67eee65-3021-4c5d-a90d-e33e8426b51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127689958-172.17.0.6-1599394137459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43889,DS-1192322f-cfcc-4c05-ba0f-ae7215a5a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5b7a6378-681a-456c-917e-6207540f5378,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-3d301dd9-1b33-43d2-8e94-bdf876dea872,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-0753387a-1100-4399-a6a9-05645ff3bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0ee21a9d-6cb7-4d26-9c7d-ec3f6e185384,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-19648505-05c8-46fe-84b2-345ecb7fbf43,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0775e499-dcf4-47d7-9f6d-dd05ba1877b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-c67eee65-3021-4c5d-a90d-e33e8426b51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770484729-172.17.0.6-1599394245270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-8c8143a2-d0de-4c40-8a2f-1a44c84772b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-61d28d08-0db8-4172-9c89-aed2d2c51879,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-21904354-fd0e-4699-b1d3-80cf99fcbc69,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d97839a0-893f-481f-a091-c070d2f4f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-8ef0daf2-db30-4bad-8510-e97e220866b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1f5894a5-08c8-4726-a2d9-208476722e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-3790ef1a-d837-4cef-928b-6872ac953798,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-96ccc2ee-dfbf-46bc-af47-fba0d1b348a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770484729-172.17.0.6-1599394245270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-8c8143a2-d0de-4c40-8a2f-1a44c84772b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-61d28d08-0db8-4172-9c89-aed2d2c51879,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-21904354-fd0e-4699-b1d3-80cf99fcbc69,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d97839a0-893f-481f-a091-c070d2f4f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-8ef0daf2-db30-4bad-8510-e97e220866b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-1f5894a5-08c8-4726-a2d9-208476722e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-3790ef1a-d837-4cef-928b-6872ac953798,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-96ccc2ee-dfbf-46bc-af47-fba0d1b348a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149987418-172.17.0.6-1599394300224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38644,DS-931d3cb0-05dd-4b65-b44c-ed55c659333f,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-f08dc233-c5ed-4a06-a052-f31db52f9d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1172d1d8-70f6-4898-9e2f-58198cf41ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-851dd764-e9e7-4064-b980-e41238604091,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-976305c3-bdb5-4a9e-9403-31bc68264c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-8beec995-562d-4a16-aba5-3532983893fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-ce2b5ce7-055c-4573-872d-34a503a6e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-c4c09d2a-3ef3-447a-aa65-29be85836b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149987418-172.17.0.6-1599394300224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38644,DS-931d3cb0-05dd-4b65-b44c-ed55c659333f,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-f08dc233-c5ed-4a06-a052-f31db52f9d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1172d1d8-70f6-4898-9e2f-58198cf41ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-851dd764-e9e7-4064-b980-e41238604091,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-976305c3-bdb5-4a9e-9403-31bc68264c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-8beec995-562d-4a16-aba5-3532983893fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-ce2b5ce7-055c-4573-872d-34a503a6e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-c4c09d2a-3ef3-447a-aa65-29be85836b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1062132711-172.17.0.6-1599394371497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42392,DS-85825756-61f9-4c06-90e2-d0158d639ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-5ff80c87-efd1-4a09-b683-55a73bea37db,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-3f7f70fc-b704-4670-b838-1c2e7b4d634d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-1a01917e-60dc-4cc5-a9f0-ccced5c2253c,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-1cd46a6c-e70d-4561-93cc-550fdfa64caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9e2645b7-d5c0-437d-9587-01b075387a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-eb51c2a6-de96-469a-861d-28948e653b82,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-4fd23d4e-3bbc-4096-b9c2-d0561715f161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1062132711-172.17.0.6-1599394371497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42392,DS-85825756-61f9-4c06-90e2-d0158d639ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-5ff80c87-efd1-4a09-b683-55a73bea37db,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-3f7f70fc-b704-4670-b838-1c2e7b4d634d,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-1a01917e-60dc-4cc5-a9f0-ccced5c2253c,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-1cd46a6c-e70d-4561-93cc-550fdfa64caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-9e2645b7-d5c0-437d-9587-01b075387a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-eb51c2a6-de96-469a-861d-28948e653b82,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-4fd23d4e-3bbc-4096-b9c2-d0561715f161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: File /striped/stripedFileChecksum3 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /striped/stripedFileChecksum3 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy29.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock(DFSStripedOutputStream.java:480)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:526)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:866)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765508865-172.17.0.6-1599394418996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-023eb806-81dc-4931-94b1-5881c723afba,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-e3c3258a-7087-4442-ac17-0864a1d2ce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-114c1679-3649-4f9f-8043-47f194099972,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-b7cf1f17-9743-49a2-af23-4404fca63cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-105de5e7-6e5f-4220-a991-4dde46040af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-50e5e380-3274-4b10-bb9d-b708a89c978b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-3a61f910-57cc-4b83-a108-dac2d857e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-cae3e576-d22f-439c-86a1-9a10a71c47a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765508865-172.17.0.6-1599394418996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-023eb806-81dc-4931-94b1-5881c723afba,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-e3c3258a-7087-4442-ac17-0864a1d2ce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-114c1679-3649-4f9f-8043-47f194099972,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-b7cf1f17-9743-49a2-af23-4404fca63cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-105de5e7-6e5f-4220-a991-4dde46040af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-50e5e380-3274-4b10-bb9d-b708a89c978b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-3a61f910-57cc-4b83-a108-dac2d857e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-cae3e576-d22f-439c-86a1-9a10a71c47a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.allow.snap-root-descendant
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967047563-172.17.0.6-1599394487861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-4fffbdf0-1774-4714-9f5c-8ae1fb5c87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-c9777322-2143-4cee-8e5b-0b0e708ecb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-5125550f-f181-4c53-b8a1-3f1705f66cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-a54e6366-30e6-406c-8514-68f92ca33b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-d26b258e-4c1c-4028-8bf2-9a4190403330,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-5d6121bb-0272-45c3-aa4e-bc50472b8acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-1c2bc119-465d-4ef3-9410-a6bdb0f13e15,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9f5d26c8-7627-4356-a1ba-710b90ca927c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967047563-172.17.0.6-1599394487861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46591,DS-4fffbdf0-1774-4714-9f5c-8ae1fb5c87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-c9777322-2143-4cee-8e5b-0b0e708ecb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-5125550f-f181-4c53-b8a1-3f1705f66cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-a54e6366-30e6-406c-8514-68f92ca33b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-d26b258e-4c1c-4028-8bf2-9a4190403330,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-5d6121bb-0272-45c3-aa4e-bc50472b8acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-1c2bc119-465d-4ef3-9410-a6bdb0f13e15,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-9f5d26c8-7627-4356-a1ba-710b90ca927c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 3124
