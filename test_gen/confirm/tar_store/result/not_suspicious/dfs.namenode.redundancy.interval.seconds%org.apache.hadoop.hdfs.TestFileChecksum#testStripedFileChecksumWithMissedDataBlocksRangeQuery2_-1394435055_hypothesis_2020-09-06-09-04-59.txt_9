reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830057623-172.17.0.9-1599383113760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-76e2f98c-871a-4052-ba41-c78635be4259,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-050faa4e-a1dd-48dd-a86c-bac5151023ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-64273a11-17b5-4c39-9c2f-842145ec7dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-61bbf8fc-c9cd-4227-9db6-0a3b21d5dd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6d1eb9f1-0dbb-42c5-8049-ac2522bfffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-df5a4563-99a4-4362-9315-f21a1e4755f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-27f187de-ff0f-4026-a923-f04d34dac7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0721f3a6-f86a-4644-8bf2-6e575c26b9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830057623-172.17.0.9-1599383113760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-76e2f98c-871a-4052-ba41-c78635be4259,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-050faa4e-a1dd-48dd-a86c-bac5151023ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-64273a11-17b5-4c39-9c2f-842145ec7dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-61bbf8fc-c9cd-4227-9db6-0a3b21d5dd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6d1eb9f1-0dbb-42c5-8049-ac2522bfffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-df5a4563-99a4-4362-9315-f21a1e4755f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-27f187de-ff0f-4026-a923-f04d34dac7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0721f3a6-f86a-4644-8bf2-6e575c26b9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647796369-172.17.0.9-1599383425155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-01039399-5a54-42af-8e66-435b862a5134,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-2d524c15-f72f-40cf-99a4-40d48d379dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-8e0f8a8a-1395-4082-b12a-ea7db2e596e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-74ae20bc-9c39-4379-a1c6-f6015b128000,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-02b9469d-aeb8-4a5a-aa09-1235ab370d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-15f24a4e-6e52-48e5-99ea-de0ccfa662e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-c90dbd5a-eb4a-4758-aff5-b2e6ea89300d,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-f331e984-cc33-472b-a585-807de2c521ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647796369-172.17.0.9-1599383425155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-01039399-5a54-42af-8e66-435b862a5134,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-2d524c15-f72f-40cf-99a4-40d48d379dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-8e0f8a8a-1395-4082-b12a-ea7db2e596e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-74ae20bc-9c39-4379-a1c6-f6015b128000,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-02b9469d-aeb8-4a5a-aa09-1235ab370d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-15f24a4e-6e52-48e5-99ea-de0ccfa662e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-c90dbd5a-eb4a-4758-aff5-b2e6ea89300d,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-f331e984-cc33-472b-a585-807de2c521ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528425522-172.17.0.9-1599383538654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-ad87ae7b-0771-498f-abc8-fbba1b87e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-2eec73a9-bbeb-4cca-a256-44b65659e030,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-db8d7c7e-0610-41a7-99aa-f45199aa49ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-de85081e-838c-4057-ade1-8e008c2aa591,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-a4402bf5-5d60-4ddf-9216-eb03c9c0d717,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-0bbc5067-767f-4fc2-88af-b5b4d6248ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-5e1b72a3-1ed2-46d5-b1eb-954d40dbbefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c19bb66e-47ce-4418-8804-b30974996f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528425522-172.17.0.9-1599383538654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-ad87ae7b-0771-498f-abc8-fbba1b87e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-2eec73a9-bbeb-4cca-a256-44b65659e030,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-db8d7c7e-0610-41a7-99aa-f45199aa49ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-de85081e-838c-4057-ade1-8e008c2aa591,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-a4402bf5-5d60-4ddf-9216-eb03c9c0d717,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-0bbc5067-767f-4fc2-88af-b5b4d6248ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-5e1b72a3-1ed2-46d5-b1eb-954d40dbbefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c19bb66e-47ce-4418-8804-b30974996f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946683492-172.17.0.9-1599383779129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-4af153ed-4672-4503-a3b5-d3f4d5ee7936,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-589b3687-8156-483f-a657-356ed98667c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-a0877081-9c4e-4e2c-9f29-1e10c7e92167,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-7c4d075d-0281-4ea0-928f-dbd84bae27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-8fc9b5ec-8259-4d69-b2d8-7e1b23ca775e,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-4327d46f-add5-4f4d-bf71-beeffde28c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-bc741843-bb72-4b21-91cc-5739d41ed699,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-454be00e-dc79-47b7-9115-8f4884d35692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946683492-172.17.0.9-1599383779129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33121,DS-4af153ed-4672-4503-a3b5-d3f4d5ee7936,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-589b3687-8156-483f-a657-356ed98667c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-a0877081-9c4e-4e2c-9f29-1e10c7e92167,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-7c4d075d-0281-4ea0-928f-dbd84bae27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-8fc9b5ec-8259-4d69-b2d8-7e1b23ca775e,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-4327d46f-add5-4f4d-bf71-beeffde28c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-bc741843-bb72-4b21-91cc-5739d41ed699,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-454be00e-dc79-47b7-9115-8f4884d35692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864365088-172.17.0.9-1599383816176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-00db751b-cf4b-427d-8c7d-f74f3171d066,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a8d6265f-8a08-4c68-bfa8-1b99fa44d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-47405b3c-0469-4948-91fc-55b7a071abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-0b4ec62d-da31-44ea-a8c6-4b984b6d811f,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-d21a45d9-b241-4130-b334-6d15445f1d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-bb16e437-c9eb-44e4-8710-deb8ea59cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-8b22286b-6701-40d5-8d0d-57be5603334b,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-19f3062f-eebe-4e9e-b6fe-4ac0dc7519dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864365088-172.17.0.9-1599383816176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-00db751b-cf4b-427d-8c7d-f74f3171d066,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-a8d6265f-8a08-4c68-bfa8-1b99fa44d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-47405b3c-0469-4948-91fc-55b7a071abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-0b4ec62d-da31-44ea-a8c6-4b984b6d811f,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-d21a45d9-b241-4130-b334-6d15445f1d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-bb16e437-c9eb-44e4-8710-deb8ea59cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-8b22286b-6701-40d5-8d0d-57be5603334b,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-19f3062f-eebe-4e9e-b6fe-4ac0dc7519dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053761216-172.17.0.9-1599384090702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-bd4aae39-1c23-408b-a3c0-cbe960997adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-174f76d1-e2dc-44fd-aeed-e1592225af42,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-33d96fbc-193c-4c26-8092-76a08323cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-df5c2a0c-bfec-46c9-93db-d4cb71cdf102,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-801e859f-8a54-48df-89d2-884542aa46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-2d3dd4a6-9c08-4940-9e91-e3af95d58e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-0eaf2967-1925-4a12-bd65-758c7ee718b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-9b1c85ee-aaa6-4520-9377-2feb9c9e0dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053761216-172.17.0.9-1599384090702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-bd4aae39-1c23-408b-a3c0-cbe960997adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-174f76d1-e2dc-44fd-aeed-e1592225af42,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-33d96fbc-193c-4c26-8092-76a08323cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-df5c2a0c-bfec-46c9-93db-d4cb71cdf102,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-801e859f-8a54-48df-89d2-884542aa46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-2d3dd4a6-9c08-4940-9e91-e3af95d58e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-0eaf2967-1925-4a12-bd65-758c7ee718b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-9b1c85ee-aaa6-4520-9377-2feb9c9e0dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038868709-172.17.0.9-1599384162798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-97161d8d-bc7e-4c3e-902f-94b5f5b7a942,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-eda88a37-42c4-46ad-ad83-bdeef5886561,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-f232ac38-fc38-48a7-ab69-41bd656acaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-029ccf40-97e9-43b0-8bd2-baa56ba36b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-30a3dd5c-1877-423f-8a31-66a5901ece56,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5fe5fdf5-04a5-4273-8eaa-0875aae57b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-84904507-f6c8-42bf-a43b-f3e2784a60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-b2d154e7-95dc-4165-b5b0-cd17c5050493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038868709-172.17.0.9-1599384162798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-97161d8d-bc7e-4c3e-902f-94b5f5b7a942,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-eda88a37-42c4-46ad-ad83-bdeef5886561,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-f232ac38-fc38-48a7-ab69-41bd656acaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-029ccf40-97e9-43b0-8bd2-baa56ba36b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-30a3dd5c-1877-423f-8a31-66a5901ece56,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5fe5fdf5-04a5-4273-8eaa-0875aae57b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-84904507-f6c8-42bf-a43b-f3e2784a60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-b2d154e7-95dc-4165-b5b0-cd17c5050493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945066045-172.17.0.9-1599384427054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-d28429d1-2dc8-4854-ad44-d00813ba75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-c6736877-113f-4c94-bed7-a3b74c70bb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-ed33d771-74c6-4e33-a9a4-5a72ea413a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-270eca71-5376-44df-986f-af2522272e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5d1860c4-35f1-471f-9e56-d2c1d26b6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-d81d4780-06bb-4757-9dd9-44ffacbd0926,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-c5974093-780c-46fd-8fba-acb01db2bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-439b2a8d-e2aa-4f96-90f4-cb6884195fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945066045-172.17.0.9-1599384427054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-d28429d1-2dc8-4854-ad44-d00813ba75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-c6736877-113f-4c94-bed7-a3b74c70bb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-ed33d771-74c6-4e33-a9a4-5a72ea413a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-270eca71-5376-44df-986f-af2522272e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5d1860c4-35f1-471f-9e56-d2c1d26b6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-d81d4780-06bb-4757-9dd9-44ffacbd0926,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-c5974093-780c-46fd-8fba-acb01db2bf34,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-439b2a8d-e2aa-4f96-90f4-cb6884195fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234722851-172.17.0.9-1599384521288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41470,DS-6380fbd7-5a5f-4912-b97b-58d3a2fcf80e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-25f63aa6-8469-4382-88b1-0548032b90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-8a33f10e-5d62-477a-bffa-c2bcb196aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-41d2c321-d28e-4e56-8ae5-16c715bf7def,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-50d2ad28-b36c-4d04-b77f-a76e61b7dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-6788a163-023c-4814-88f5-b624f6b975e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-d32c8abc-2a88-424a-a358-5001dd8d7435,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-a6db6182-4030-462c-b06a-e706111198cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234722851-172.17.0.9-1599384521288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41470,DS-6380fbd7-5a5f-4912-b97b-58d3a2fcf80e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-25f63aa6-8469-4382-88b1-0548032b90bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-8a33f10e-5d62-477a-bffa-c2bcb196aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-41d2c321-d28e-4e56-8ae5-16c715bf7def,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-50d2ad28-b36c-4d04-b77f-a76e61b7dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-6788a163-023c-4814-88f5-b624f6b975e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-d32c8abc-2a88-424a-a358-5001dd8d7435,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-a6db6182-4030-462c-b06a-e706111198cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082732270-172.17.0.9-1599384568538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35523,DS-14ae4438-6fb0-47c8-ae59-6fc8cc3e0399,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-88390e87-1ba2-44e3-bbab-dc1c1f59890a,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-212035f5-c178-425f-99f9-9c695cb15ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-266b72b8-52fa-4e30-a704-07efd2d7b969,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-3fbdd6d9-2b35-4d58-b3d8-3fe9953c1674,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-98fa9636-86a3-4c6d-8313-4e62c37c9b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-9cf92e7d-1482-4174-b4d6-95f7c4343932,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-532f0a1b-5f46-482c-bdc1-beec3baa4d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082732270-172.17.0.9-1599384568538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35523,DS-14ae4438-6fb0-47c8-ae59-6fc8cc3e0399,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-88390e87-1ba2-44e3-bbab-dc1c1f59890a,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-212035f5-c178-425f-99f9-9c695cb15ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-266b72b8-52fa-4e30-a704-07efd2d7b969,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-3fbdd6d9-2b35-4d58-b3d8-3fe9953c1674,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-98fa9636-86a3-4c6d-8313-4e62c37c9b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-9cf92e7d-1482-4174-b4d6-95f7c4343932,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-532f0a1b-5f46-482c-bdc1-beec3baa4d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707136327-172.17.0.9-1599384662640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-93996d2a-74ab-44d6-af01-d078f99f3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-26a40aba-1002-4deb-a78f-108e23ff202b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-7efa06b5-81b0-4295-9e53-d1d2c8f11bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-25c39c90-9aea-4d74-8e21-0d2192676833,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-db4ebbc2-7e2e-4d67-a3b1-72b2e1435752,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-c379c5d7-63f7-4749-976a-9ba3a0bb39e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d29c8b20-4c09-4543-99df-8658b997afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-ddf344b1-ee5a-430a-a7d4-1a68d9b0880c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707136327-172.17.0.9-1599384662640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-93996d2a-74ab-44d6-af01-d078f99f3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-26a40aba-1002-4deb-a78f-108e23ff202b,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-7efa06b5-81b0-4295-9e53-d1d2c8f11bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-25c39c90-9aea-4d74-8e21-0d2192676833,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-db4ebbc2-7e2e-4d67-a3b1-72b2e1435752,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-c379c5d7-63f7-4749-976a-9ba3a0bb39e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-d29c8b20-4c09-4543-99df-8658b997afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-ddf344b1-ee5a-430a-a7d4-1a68d9b0880c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759473319-172.17.0.9-1599384708999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-671c8959-a3be-49b1-8641-bcace4568db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-c5b87e83-35cb-4ac0-a789-eb9169a08ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-da77fb5c-65a5-4d69-8e06-ba291e3ecfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-5c777b3e-d0b7-4914-b1a6-79d721376775,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-db3e24c0-86c5-4d71-91e8-0a087550178f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-ae425d82-1d0d-472d-9889-823d16da3cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-9c274c08-f60e-498d-bfb4-af5095927215,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-31abe8f0-6edf-4518-81cc-9a34b47db9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759473319-172.17.0.9-1599384708999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35088,DS-671c8959-a3be-49b1-8641-bcace4568db0,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-c5b87e83-35cb-4ac0-a789-eb9169a08ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-da77fb5c-65a5-4d69-8e06-ba291e3ecfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-5c777b3e-d0b7-4914-b1a6-79d721376775,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-db3e24c0-86c5-4d71-91e8-0a087550178f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-ae425d82-1d0d-472d-9889-823d16da3cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-9c274c08-f60e-498d-bfb4-af5095927215,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-31abe8f0-6edf-4518-81cc-9a34b47db9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147531344-172.17.0.9-1599384786530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-1972aace-a314-492f-9118-bed3eb395389,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7309b24f-16ae-4c03-9329-8f6d45968488,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-15612cad-80a9-4ea3-956b-279daa30c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-2cc34dbd-ef9c-4ad4-93fb-1cacfdb53469,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-21ba8aff-0c52-4bc4-90d0-84b12bdbefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-69719b49-a44b-407b-825c-7ac2e05e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-056c87bf-ba06-4345-8537-1ad372de3b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-8b24bdd3-e2ea-4fb5-a3ba-8544cc40dc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147531344-172.17.0.9-1599384786530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-1972aace-a314-492f-9118-bed3eb395389,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7309b24f-16ae-4c03-9329-8f6d45968488,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-15612cad-80a9-4ea3-956b-279daa30c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-2cc34dbd-ef9c-4ad4-93fb-1cacfdb53469,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-21ba8aff-0c52-4bc4-90d0-84b12bdbefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-69719b49-a44b-407b-825c-7ac2e05e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-056c87bf-ba06-4345-8537-1ad372de3b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-8b24bdd3-e2ea-4fb5-a3ba-8544cc40dc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040685436-172.17.0.9-1599384929691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-0fa750ab-91a2-4c5c-87d7-dc004aec4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-c11ea78c-9f3f-4795-8e03-76fe994bb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-ce8cd19b-1b86-4714-88cd-fa7d672b41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-adc5aa86-3e9a-44b6-93f0-caa60db56064,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-f7cef7f8-fb56-44fc-bade-3e014189872f,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-8e1f81bf-5be5-425d-a550-2ea446b7829a,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-462fdd86-6979-4cb0-a252-bbd28496c874,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-0e0e8e29-adf0-4153-8bc0-9d6ded55bcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040685436-172.17.0.9-1599384929691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-0fa750ab-91a2-4c5c-87d7-dc004aec4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-c11ea78c-9f3f-4795-8e03-76fe994bb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-ce8cd19b-1b86-4714-88cd-fa7d672b41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-adc5aa86-3e9a-44b6-93f0-caa60db56064,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-f7cef7f8-fb56-44fc-bade-3e014189872f,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-8e1f81bf-5be5-425d-a550-2ea446b7829a,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-462fdd86-6979-4cb0-a252-bbd28496c874,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-0e0e8e29-adf0-4153-8bc0-9d6ded55bcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164224097-172.17.0.9-1599385211388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44503,DS-ff32cb52-d6b7-4335-a964-8563e057bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-bf8a9766-ad1f-4416-850b-24b0c6b232fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-5b73eef6-4825-481c-9690-c6c50f573071,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-e45bd406-f294-4e75-b6c2-cbbd32e70498,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-72c52d4e-d0da-4f41-baa1-5f35b28e8138,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-8d01686b-1e8a-4152-85b2-aaacefdd2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-85802967-2453-4935-b88d-e2775481f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-a8b951bc-6471-4799-a049-72e2ee462184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164224097-172.17.0.9-1599385211388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44503,DS-ff32cb52-d6b7-4335-a964-8563e057bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-bf8a9766-ad1f-4416-850b-24b0c6b232fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-5b73eef6-4825-481c-9690-c6c50f573071,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-e45bd406-f294-4e75-b6c2-cbbd32e70498,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-72c52d4e-d0da-4f41-baa1-5f35b28e8138,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-8d01686b-1e8a-4152-85b2-aaacefdd2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-85802967-2453-4935-b88d-e2775481f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-a8b951bc-6471-4799-a049-72e2ee462184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271568744-172.17.0.9-1599385646284:blk_-9223372036854775792_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33847,DS-b9139ae3-fe55-4cea-a993-c5b8ba15018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-cf9daf01-6927-4bdf-9f82-736aa07db301,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4d525d73-7801-47ec-b7d2-d039cc1b312f,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2d7bfcf8-1215-4139-b089-fada19bcee76,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-63d2de50-adaa-43e3-a672-a13a9e034a9c,DISK]]; indices=[1, 2, 3, 4, 5]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271568744-172.17.0.9-1599385646284:blk_-9223372036854775792_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33847,DS-b9139ae3-fe55-4cea-a993-c5b8ba15018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-cf9daf01-6927-4bdf-9f82-736aa07db301,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4d525d73-7801-47ec-b7d2-d039cc1b312f,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2d7bfcf8-1215-4139-b089-fada19bcee76,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-63d2de50-adaa-43e3-a672-a13a9e034a9c,DISK]]; indices=[1, 2, 3, 4, 5]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 2911
