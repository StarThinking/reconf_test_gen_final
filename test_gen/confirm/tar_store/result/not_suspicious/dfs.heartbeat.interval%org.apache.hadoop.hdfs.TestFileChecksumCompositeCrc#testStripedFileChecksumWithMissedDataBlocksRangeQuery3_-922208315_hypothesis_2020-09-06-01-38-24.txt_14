reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59203416-172.17.0.15-1599356322341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-86c49507-2334-43ff-9f98-075a3b294111,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-92c69ffd-598c-4daf-8021-991be98f73de,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-af0372da-135a-4240-a8f6-b4958f6a2a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-a54e5723-44f9-4b75-9893-ff0d7174f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-65dba297-f187-4b7c-bc8f-275d0d516161,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9a8a9187-aa46-465b-9fba-a510796e4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-fae087fb-714d-401e-9cac-e7071163a16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-d9e32fed-bbdb-4e37-9dd2-0b20fbd4b5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59203416-172.17.0.15-1599356322341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-86c49507-2334-43ff-9f98-075a3b294111,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-92c69ffd-598c-4daf-8021-991be98f73de,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-af0372da-135a-4240-a8f6-b4958f6a2a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-a54e5723-44f9-4b75-9893-ff0d7174f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-65dba297-f187-4b7c-bc8f-275d0d516161,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9a8a9187-aa46-465b-9fba-a510796e4b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-fae087fb-714d-401e-9cac-e7071163a16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-d9e32fed-bbdb-4e37-9dd2-0b20fbd4b5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823214648-172.17.0.15-1599356387314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-2f4f7a2f-2631-4c02-847a-c273bcee44ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-bcfda0d4-7cf9-49d3-a11f-98bb91777268,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-be334d8a-55cb-42df-91eb-e70337879a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-4114056a-2422-43d5-9d5c-718d12284666,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-aa817db7-a010-4f7d-8959-2a7626fd6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-207e6f18-91be-4a81-a4cc-78dd2bff2341,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3010df80-f656-46a7-aac7-a1cb89bb9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-492e1f5a-c451-4524-9567-f7ae7ab6d1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823214648-172.17.0.15-1599356387314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-2f4f7a2f-2631-4c02-847a-c273bcee44ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-bcfda0d4-7cf9-49d3-a11f-98bb91777268,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-be334d8a-55cb-42df-91eb-e70337879a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-4114056a-2422-43d5-9d5c-718d12284666,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-aa817db7-a010-4f7d-8959-2a7626fd6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-207e6f18-91be-4a81-a4cc-78dd2bff2341,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3010df80-f656-46a7-aac7-a1cb89bb9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-492e1f5a-c451-4524-9567-f7ae7ab6d1fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063098475-172.17.0.15-1599356425254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-d437dc85-fafa-4f46-8818-cb3d7925a343,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-9584b542-8d18-42f3-b156-1d7bea5655d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2a1801e5-1cc7-4efa-b3b4-627e4e42a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-fdfeb5a5-39c8-47b6-b9ad-267a3f39d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-ab82781d-ae6d-447b-8713-8590a668e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-6499c819-a51a-4e80-a81d-970dd11ae9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c93450a5-6cab-4c5f-b652-e9b8e31cd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-781685cb-1fdb-48df-a44d-ae2c6e1fcf9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063098475-172.17.0.15-1599356425254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-d437dc85-fafa-4f46-8818-cb3d7925a343,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-9584b542-8d18-42f3-b156-1d7bea5655d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-2a1801e5-1cc7-4efa-b3b4-627e4e42a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-fdfeb5a5-39c8-47b6-b9ad-267a3f39d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-ab82781d-ae6d-447b-8713-8590a668e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-6499c819-a51a-4e80-a81d-970dd11ae9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c93450a5-6cab-4c5f-b652-e9b8e31cd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-781685cb-1fdb-48df-a44d-ae2c6e1fcf9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160140737-172.17.0.15-1599356615626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-11b14229-527c-4e4b-9cce-8712241b1615,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-df432749-97ba-4afd-a894-7db1515ffed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-475bef23-5cca-4487-9463-e1470e381500,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-1804a431-eaee-4247-b7ff-93cfc38a1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-056eccda-d5c2-42a3-9a1f-814cc72ee407,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b8080e33-13ad-4a01-9684-0d9d540a4680,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-d5ec2d6b-fdc1-42e6-bb86-e91abc40b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-5703e06a-cf0a-4752-9af4-d6affb245e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160140737-172.17.0.15-1599356615626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-11b14229-527c-4e4b-9cce-8712241b1615,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-df432749-97ba-4afd-a894-7db1515ffed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-475bef23-5cca-4487-9463-e1470e381500,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-1804a431-eaee-4247-b7ff-93cfc38a1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-056eccda-d5c2-42a3-9a1f-814cc72ee407,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b8080e33-13ad-4a01-9684-0d9d540a4680,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-d5ec2d6b-fdc1-42e6-bb86-e91abc40b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-5703e06a-cf0a-4752-9af4-d6affb245e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113682233-172.17.0.15-1599356919754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45868,DS-3e21a782-d01d-467b-bf61-8e0873d43988,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-ee22cdc1-af68-4365-ac79-03ff73266b46,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-73437207-8b6a-46e0-be34-1d0d8b80e620,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-52a05a6c-b9c4-426b-9ae5-102228a3aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-b918f830-d7a8-4c5c-b262-c0feeda3f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-d2c58f07-f55b-491a-be5c-38de99c2f561,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ab85bf59-e750-4478-92ea-1a203370554c,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-c5721a79-77f5-492d-ab9c-716ccb1f670a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113682233-172.17.0.15-1599356919754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45868,DS-3e21a782-d01d-467b-bf61-8e0873d43988,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-ee22cdc1-af68-4365-ac79-03ff73266b46,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-73437207-8b6a-46e0-be34-1d0d8b80e620,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-52a05a6c-b9c4-426b-9ae5-102228a3aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-b918f830-d7a8-4c5c-b262-c0feeda3f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-d2c58f07-f55b-491a-be5c-38de99c2f561,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ab85bf59-e750-4478-92ea-1a203370554c,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-c5721a79-77f5-492d-ab9c-716ccb1f670a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429360568-172.17.0.15-1599357033301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-d239e1aa-3999-4cf1-a99d-978e368418b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-d0072fc3-488a-4b9d-bf8a-6c71ecfed39a,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-aed4d4d0-3d28-4dac-8386-91653fe1a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-449fbdc4-ffd7-4f32-915f-acace929c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-7bc8b9ef-e388-4be1-b873-da087bc4369b,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-04a568af-5937-45c7-9eee-b7ea7a5e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-07054f20-679b-4361-8023-d6c35dbb09b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-71a2cb9f-a09f-4895-8f84-f95f5744889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429360568-172.17.0.15-1599357033301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-d239e1aa-3999-4cf1-a99d-978e368418b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-d0072fc3-488a-4b9d-bf8a-6c71ecfed39a,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-aed4d4d0-3d28-4dac-8386-91653fe1a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-449fbdc4-ffd7-4f32-915f-acace929c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-7bc8b9ef-e388-4be1-b873-da087bc4369b,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-04a568af-5937-45c7-9eee-b7ea7a5e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-07054f20-679b-4361-8023-d6c35dbb09b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-71a2cb9f-a09f-4895-8f84-f95f5744889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097133708-172.17.0.15-1599357115873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37450,DS-a6cfc629-dc13-4bff-8ed9-56ad90186b69,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-a3d3bed4-11ed-4716-93f0-f97178544e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-1602516b-3d32-4792-8b9f-46bb06d42277,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-c855ac04-4694-4229-ad4b-ce2a5294e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-fc6e0e60-a1e2-4505-9c79-d8a2250c3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-47ebd08e-70e2-47ea-bab3-a8ced6a376cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-48f63f2f-82ab-4614-a410-d0eff352fbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-4fc34e69-f853-4221-a5f0-dea2596e298c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097133708-172.17.0.15-1599357115873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37450,DS-a6cfc629-dc13-4bff-8ed9-56ad90186b69,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-a3d3bed4-11ed-4716-93f0-f97178544e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-1602516b-3d32-4792-8b9f-46bb06d42277,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-c855ac04-4694-4229-ad4b-ce2a5294e8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-fc6e0e60-a1e2-4505-9c79-d8a2250c3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-47ebd08e-70e2-47ea-bab3-a8ced6a376cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-48f63f2f-82ab-4614-a410-d0eff352fbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-4fc34e69-f853-4221-a5f0-dea2596e298c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673357423-172.17.0.15-1599357392503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-042f2198-9e0f-4054-8632-a76e91c279c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-2d216413-9f5f-4d44-9ed6-919721072251,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-2bdb542a-eb23-4fca-8713-84bc40bb7c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-ee36b597-364d-4c8e-9f75-7771ebb1bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-0a0119ac-090d-4cc2-937b-fd5106819766,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-abc74bf5-2d4c-4bbd-bf6b-048f11d6b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-2e5a0502-5e4f-4602-baa7-aa2ca596695e,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-6ce3359b-2b96-4a8c-bf95-a727ce60bad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673357423-172.17.0.15-1599357392503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-042f2198-9e0f-4054-8632-a76e91c279c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-2d216413-9f5f-4d44-9ed6-919721072251,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-2bdb542a-eb23-4fca-8713-84bc40bb7c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-ee36b597-364d-4c8e-9f75-7771ebb1bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-0a0119ac-090d-4cc2-937b-fd5106819766,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-abc74bf5-2d4c-4bbd-bf6b-048f11d6b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-2e5a0502-5e4f-4602-baa7-aa2ca596695e,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-6ce3359b-2b96-4a8c-bf95-a727ce60bad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486688776-172.17.0.15-1599357529714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-4223d06e-f224-4c3e-a36e-d2a56570b867,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-30dbd57c-91ff-43c7-aa92-78200954056f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-0c6b8ea3-6414-4bd8-9535-94ff4f0aa0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-6373298a-02a0-4090-8ea1-fcc701a2eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1c86801e-0dd9-42ce-9f39-9419340d9cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-103297a7-6b51-4999-8c85-46f4a6317758,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-9eb74614-0449-4209-9c83-bb4b3cfdbeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-353aaa26-350c-4dc1-8b94-b8d63333d127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486688776-172.17.0.15-1599357529714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37815,DS-4223d06e-f224-4c3e-a36e-d2a56570b867,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-30dbd57c-91ff-43c7-aa92-78200954056f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-0c6b8ea3-6414-4bd8-9535-94ff4f0aa0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-6373298a-02a0-4090-8ea1-fcc701a2eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1c86801e-0dd9-42ce-9f39-9419340d9cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-103297a7-6b51-4999-8c85-46f4a6317758,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-9eb74614-0449-4209-9c83-bb4b3cfdbeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-353aaa26-350c-4dc1-8b94-b8d63333d127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841796154-172.17.0.15-1599357641546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-324eb832-9c80-4838-ad43-0f5e3a01a2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-a0710736-e44d-4f89-95eb-a36f9d802a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-ffd65256-bfc5-4680-8669-2a3c296bcf61,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-83a54a71-0c4d-46b8-ae55-e2d410cf67b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-87ae0425-1b05-4107-8659-a79c72c80b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-817bf85b-50fb-4b01-b9df-dbdc59f05df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-245aa8db-ec58-4266-85a4-7b9a1ecc05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-c9ecb446-c125-4dc1-84dc-7ee9148a1a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841796154-172.17.0.15-1599357641546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-324eb832-9c80-4838-ad43-0f5e3a01a2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-a0710736-e44d-4f89-95eb-a36f9d802a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-ffd65256-bfc5-4680-8669-2a3c296bcf61,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-83a54a71-0c4d-46b8-ae55-e2d410cf67b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-87ae0425-1b05-4107-8659-a79c72c80b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-817bf85b-50fb-4b01-b9df-dbdc59f05df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-245aa8db-ec58-4266-85a4-7b9a1ecc05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-c9ecb446-c125-4dc1-84dc-7ee9148a1a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643181937-172.17.0.15-1599357902469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-7181c4c0-cbc8-4d81-b726-e1d79b3f453e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-0c3cd5cb-c818-460e-8dad-32f605734826,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-4c7e306c-0adf-4b7a-8f44-88a447040161,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-5d5e43ca-d222-4f15-aa28-b635d7340665,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-19e89cf9-41db-4ec1-9707-b1166c1a80d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-b434a585-2f97-404e-81b1-2fb525f30b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-00173196-6028-4c53-bc16-404960492498,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-a35d3ef4-2f72-44af-8dcd-ee88c50f2580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643181937-172.17.0.15-1599357902469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-7181c4c0-cbc8-4d81-b726-e1d79b3f453e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-0c3cd5cb-c818-460e-8dad-32f605734826,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-4c7e306c-0adf-4b7a-8f44-88a447040161,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-5d5e43ca-d222-4f15-aa28-b635d7340665,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-19e89cf9-41db-4ec1-9707-b1166c1a80d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-b434a585-2f97-404e-81b1-2fb525f30b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-00173196-6028-4c53-bc16-404960492498,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-a35d3ef4-2f72-44af-8dcd-ee88c50f2580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031141895-172.17.0.15-1599358132711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-ba28cb92-dc6d-4f9d-b11d-b5d773dedce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c2099c61-8e69-41a0-94ca-954e93b487ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-e90d02a8-2210-4d68-b3ff-d56561bcc4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-2625f66b-7452-4fb3-8da0-433b7f1de834,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-9d5abeef-b0d6-41e3-a908-e6e73c78866d,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-dc255f1b-2ccd-4af9-b3da-f4040f8e626e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-331583c4-77de-4a0d-ab33-0fc3ec28edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-e10273d7-9635-41ee-a0c7-cd53b7bc8a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031141895-172.17.0.15-1599358132711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-ba28cb92-dc6d-4f9d-b11d-b5d773dedce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c2099c61-8e69-41a0-94ca-954e93b487ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-e90d02a8-2210-4d68-b3ff-d56561bcc4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-2625f66b-7452-4fb3-8da0-433b7f1de834,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-9d5abeef-b0d6-41e3-a908-e6e73c78866d,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-dc255f1b-2ccd-4af9-b3da-f4040f8e626e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-331583c4-77de-4a0d-ab33-0fc3ec28edd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-e10273d7-9635-41ee-a0c7-cd53b7bc8a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026478067-172.17.0.15-1599358291121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-49aacb00-8eff-404b-a0c5-decff52e7337,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-06476558-e9bd-480c-9692-596957c66341,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-a358a71e-0e6b-4dfb-9f16-7499385a62db,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-d7a70154-85d1-4050-8b05-5a21d1cbaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-05543e02-2f45-42b4-88e9-a3850ac6aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-a77a41b9-9643-48bb-af70-f4592e1b31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-02a59342-a6b8-4ff5-a29d-eccffc2c6453,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-fcdc3762-44a3-46ca-8f27-2a648dd90958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026478067-172.17.0.15-1599358291121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-49aacb00-8eff-404b-a0c5-decff52e7337,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-06476558-e9bd-480c-9692-596957c66341,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-a358a71e-0e6b-4dfb-9f16-7499385a62db,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-d7a70154-85d1-4050-8b05-5a21d1cbaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-05543e02-2f45-42b4-88e9-a3850ac6aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-a77a41b9-9643-48bb-af70-f4592e1b31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-02a59342-a6b8-4ff5-a29d-eccffc2c6453,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-fcdc3762-44a3-46ca-8f27-2a648dd90958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118652332-172.17.0.15-1599358584277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-025bd415-a86c-4649-9da1-302d6f523fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-45e04f31-c245-4cca-9ca7-8a7c0bc04711,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-5b47601c-bf67-4894-97ca-c92d08f2934e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c295285c-4108-4a91-8634-ca9275777399,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-752bcad5-c741-477e-b717-634f5f96aeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-581f9349-1148-4b79-84b9-de4b2d2a3e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-f5ca2380-0db3-4daa-a05b-9c5e3aaee84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-5d05b273-5f1b-456a-ad8d-06474373c02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118652332-172.17.0.15-1599358584277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-025bd415-a86c-4649-9da1-302d6f523fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-45e04f31-c245-4cca-9ca7-8a7c0bc04711,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-5b47601c-bf67-4894-97ca-c92d08f2934e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c295285c-4108-4a91-8634-ca9275777399,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-752bcad5-c741-477e-b717-634f5f96aeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-581f9349-1148-4b79-84b9-de4b2d2a3e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-f5ca2380-0db3-4daa-a05b-9c5e3aaee84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-5d05b273-5f1b-456a-ad8d-06474373c02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931601172-172.17.0.15-1599358815044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-871eaa93-5d46-4804-b3f2-4071577d587e,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6a324b4-4f5b-4e26-b10b-df90d3215803,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-9bbdef03-b2f5-45df-b20f-27e7e121c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-abcdc2e9-4955-4759-919d-c176a69d9ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-ebcbc994-590b-4824-b6ca-763170bbd2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-0cde58b7-c0a4-41e0-ba9b-a173408467bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-3544ca37-011b-446c-b29c-604f95cb489a,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-079c7c26-6224-4d1f-89b9-c52cc86637eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931601172-172.17.0.15-1599358815044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-871eaa93-5d46-4804-b3f2-4071577d587e,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6a324b4-4f5b-4e26-b10b-df90d3215803,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-9bbdef03-b2f5-45df-b20f-27e7e121c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-abcdc2e9-4955-4759-919d-c176a69d9ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-ebcbc994-590b-4824-b6ca-763170bbd2be,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-0cde58b7-c0a4-41e0-ba9b-a173408467bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-3544ca37-011b-446c-b29c-604f95cb489a,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-079c7c26-6224-4d1f-89b9-c52cc86637eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629546319-172.17.0.15-1599359380107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-6527e13e-7da2-40ab-abd0-a8528283dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-dcdf2a30-423b-444a-855c-430a15d3b892,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-7f1fa841-12c1-4ed6-b84a-e70a99c8d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-4c97d09a-3e1c-4415-a3a3-d849eab01c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c396152c-1e9c-45f5-bb48-1ee7f9c92a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-43bc1d6b-91b6-400a-8e15-8c9e347f0546,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-168c194f-e388-419c-b6db-70d8dc54da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-da112504-7553-4328-a23f-059e42cdeb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629546319-172.17.0.15-1599359380107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-6527e13e-7da2-40ab-abd0-a8528283dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-dcdf2a30-423b-444a-855c-430a15d3b892,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-7f1fa841-12c1-4ed6-b84a-e70a99c8d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-4c97d09a-3e1c-4415-a3a3-d849eab01c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c396152c-1e9c-45f5-bb48-1ee7f9c92a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-43bc1d6b-91b6-400a-8e15-8c9e347f0546,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-168c194f-e388-419c-b6db-70d8dc54da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-da112504-7553-4328-a23f-059e42cdeb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800349405-172.17.0.15-1599359652171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-3c01ff99-196e-4ac6-b756-bccfc52e8da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-e422309c-cf97-4f1a-9c87-c76a5951dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-45f4bf72-0c63-402d-87a4-383b747ea96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-1ebd43e8-a568-47c0-98d9-5dc1becc279d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-5a29bb74-dabb-411e-8f0f-198ef7d1eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-5646d197-763b-4078-8b3e-afa7dfe297a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-d34ad3f8-eecb-4931-a1bc-608b4b5a376b,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-ae38d1d9-7c83-41e5-a402-edc11adf2a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800349405-172.17.0.15-1599359652171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-3c01ff99-196e-4ac6-b756-bccfc52e8da6,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-e422309c-cf97-4f1a-9c87-c76a5951dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-45f4bf72-0c63-402d-87a4-383b747ea96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-1ebd43e8-a568-47c0-98d9-5dc1becc279d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-5a29bb74-dabb-411e-8f0f-198ef7d1eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-5646d197-763b-4078-8b3e-afa7dfe297a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-d34ad3f8-eecb-4931-a1bc-608b4b5a376b,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-ae38d1d9-7c83-41e5-a402-edc11adf2a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124972600-172.17.0.15-1599359754611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-5218c7f6-e246-4930-aa65-11a4e26a3248,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0dcc5b95-3ff4-404d-8dfa-a66eae83ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-846458e2-0c60-4c96-9156-15a0eb5b66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-efe71bad-e0bd-4836-902e-70fbc408adad,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-5778f621-b640-4e88-a0c8-73e4056768b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-a4aa607c-a056-4157-aea3-cbc2a3b977b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-5ab0753e-d0a7-44d2-9571-9258723f592f,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-3f9cb507-3b2d-4d01-8560-689ae2dff038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124972600-172.17.0.15-1599359754611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-5218c7f6-e246-4930-aa65-11a4e26a3248,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0dcc5b95-3ff4-404d-8dfa-a66eae83ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-846458e2-0c60-4c96-9156-15a0eb5b66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-efe71bad-e0bd-4836-902e-70fbc408adad,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-5778f621-b640-4e88-a0c8-73e4056768b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-a4aa607c-a056-4157-aea3-cbc2a3b977b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-5ab0753e-d0a7-44d2-9571-9258723f592f,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-3f9cb507-3b2d-4d01-8560-689ae2dff038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178437260-172.17.0.15-1599360358386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-ec995367-3937-4d3b-8f01-0bd7203fd6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-2ddad1aa-1bb9-4678-b939-f55bde4e72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-33edaec4-37e1-449f-a1f8-0f285a2ec7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-65650fe7-bf73-43fc-873b-5aad518ab9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b332a41c-c178-4c42-ba2f-51e809da5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-d54e343c-b832-492b-bbb4-ffc7465f1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-543bb36c-d471-4de1-a576-05ad3f02ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-eb26920e-9619-49ac-a6f7-a6220818123c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178437260-172.17.0.15-1599360358386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-ec995367-3937-4d3b-8f01-0bd7203fd6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-2ddad1aa-1bb9-4678-b939-f55bde4e72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-33edaec4-37e1-449f-a1f8-0f285a2ec7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-65650fe7-bf73-43fc-873b-5aad518ab9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-b332a41c-c178-4c42-ba2f-51e809da5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-d54e343c-b832-492b-bbb4-ffc7465f1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-543bb36c-d471-4de1-a576-05ad3f02ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-eb26920e-9619-49ac-a6f7-a6220818123c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317205296-172.17.0.15-1599360465921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-c022127e-adf8-44eb-863b-3c921db87335,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-f7dbdc7b-2529-4b33-95c6-3415d51bf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-15de220b-de2f-41ad-a26f-17bdbab96c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-1f0355e0-3da7-45f5-8ce7-5da862962cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-e1200589-6373-4ae8-b526-20be6f696cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-30ec3d9e-4f80-4fa7-a70a-3ed2964130d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-f1cd0325-a103-44d1-a9ee-961f458b5e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-00d09ed3-df44-457a-8905-d1b44f5eb174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317205296-172.17.0.15-1599360465921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-c022127e-adf8-44eb-863b-3c921db87335,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-f7dbdc7b-2529-4b33-95c6-3415d51bf4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-15de220b-de2f-41ad-a26f-17bdbab96c56,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-1f0355e0-3da7-45f5-8ce7-5da862962cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-e1200589-6373-4ae8-b526-20be6f696cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-30ec3d9e-4f80-4fa7-a70a-3ed2964130d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-f1cd0325-a103-44d1-a9ee-961f458b5e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-00d09ed3-df44-457a-8905-d1b44f5eb174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268637792-172.17.0.15-1599360827238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-07092bef-9e94-4b19-9760-f385dd48630f,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3bc056b3-44c3-4362-82a7-a35722282e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-953b138c-dd01-4322-a710-c5dad8952262,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-c873d78a-ee2a-4fd8-a31b-8976fae21f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c2421532-269e-4551-a84d-535c7d75647f,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-cfac4720-8ebf-4218-a64f-0471d28af282,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-04389da3-d140-4548-8e0b-837df2397ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-f8efd92a-f471-4ffa-b103-06a46541822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268637792-172.17.0.15-1599360827238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-07092bef-9e94-4b19-9760-f385dd48630f,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3bc056b3-44c3-4362-82a7-a35722282e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-953b138c-dd01-4322-a710-c5dad8952262,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-c873d78a-ee2a-4fd8-a31b-8976fae21f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c2421532-269e-4551-a84d-535c7d75647f,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-cfac4720-8ebf-4218-a64f-0471d28af282,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-04389da3-d140-4548-8e0b-837df2397ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-f8efd92a-f471-4ffa-b103-06a46541822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498208736-172.17.0.15-1599360892681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43951,DS-e5269f67-e7c6-48aa-94e7-b57fcbe2042f,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-9ebed066-769f-4b24-8833-14b6b1c35d36,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-8354f998-3bfb-41c2-b1df-781f9ccbc879,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9cbcaa1d-8998-40bd-b750-20c67e3eecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-03e1991b-a21e-4c45-b06b-0c397f765dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a16e0a0b-6f47-4593-a7fe-682c1c67f817,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-f6b1eb09-8a6f-4f10-ad06-694e13f660fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-2c59125c-42d7-48ea-8eb9-fb4535188019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498208736-172.17.0.15-1599360892681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43951,DS-e5269f67-e7c6-48aa-94e7-b57fcbe2042f,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-9ebed066-769f-4b24-8833-14b6b1c35d36,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-8354f998-3bfb-41c2-b1df-781f9ccbc879,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9cbcaa1d-8998-40bd-b750-20c67e3eecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-03e1991b-a21e-4c45-b06b-0c397f765dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a16e0a0b-6f47-4593-a7fe-682c1c67f817,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-f6b1eb09-8a6f-4f10-ad06-694e13f660fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-2c59125c-42d7-48ea-8eb9-fb4535188019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311916495-172.17.0.15-1599361032900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-65687ebe-852c-4e3b-b0cd-388b0ce4fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-f13e68db-0aae-48ba-8e9f-a31b036f8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-8a03eb53-7d5b-4bb0-a3be-55eea163c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-96cc515d-26cb-43ec-a552-c5354779a457,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-10348208-e8d3-402f-be62-2e4ffcc89b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-b8afded5-8f5d-42f5-8a65-858f39143109,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-13780510-fe2c-486e-ab69-45dcacd5a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-8177fad4-f70d-4fd0-b5aa-893c16c819fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311916495-172.17.0.15-1599361032900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-65687ebe-852c-4e3b-b0cd-388b0ce4fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-f13e68db-0aae-48ba-8e9f-a31b036f8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-8a03eb53-7d5b-4bb0-a3be-55eea163c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-96cc515d-26cb-43ec-a552-c5354779a457,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-10348208-e8d3-402f-be62-2e4ffcc89b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-b8afded5-8f5d-42f5-8a65-858f39143109,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-13780510-fe2c-486e-ab69-45dcacd5a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-8177fad4-f70d-4fd0-b5aa-893c16c819fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281907470-172.17.0.15-1599361135202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a326385-2d87-45b5-acf0-d95a33b5d324,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-510a5faf-f73a-4144-bd46-b6ead70a67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4228e92c-fdfe-4274-b04c-6f4e15f4cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-bcd64d92-fb04-4108-a037-253cf8d6fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-ea592b7f-c67f-4ffa-9b01-ce100206f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-e027fb59-a873-46a9-9f69-d827a3e995da,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-0157aea6-f4e8-484e-8167-042931f8093d,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-6d5c52ed-d90a-4cbc-bce9-1b302d8ba6ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281907470-172.17.0.15-1599361135202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a326385-2d87-45b5-acf0-d95a33b5d324,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-510a5faf-f73a-4144-bd46-b6ead70a67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4228e92c-fdfe-4274-b04c-6f4e15f4cd84,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-bcd64d92-fb04-4108-a037-253cf8d6fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-ea592b7f-c67f-4ffa-9b01-ce100206f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-e027fb59-a873-46a9-9f69-d827a3e995da,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-0157aea6-f4e8-484e-8167-042931f8093d,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-6d5c52ed-d90a-4cbc-bce9-1b302d8ba6ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 4986
