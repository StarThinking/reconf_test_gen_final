reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289279643-172.17.0.14-1599290164911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33031,DS-11cbfe2b-15ce-4f90-8812-98a9dcb5ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-f0491fd2-148a-4059-b6c9-7889357054fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-0205f1c8-80e9-42ad-8c81-a373ad4771ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-e7dc8d25-d91e-43dc-afbf-d22396a2e016,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-8920cfd8-2182-42be-8884-f9a83061ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-010e70b4-9df3-494b-81e4-a885d8956794,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-90bea5d0-7317-4ca9-bee4-b5800e636a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-0a28637c-2395-4e13-b4c8-70e2ccd84c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289279643-172.17.0.14-1599290164911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33031,DS-11cbfe2b-15ce-4f90-8812-98a9dcb5ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-f0491fd2-148a-4059-b6c9-7889357054fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-0205f1c8-80e9-42ad-8c81-a373ad4771ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-e7dc8d25-d91e-43dc-afbf-d22396a2e016,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-8920cfd8-2182-42be-8884-f9a83061ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-010e70b4-9df3-494b-81e4-a885d8956794,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-90bea5d0-7317-4ca9-bee4-b5800e636a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-0a28637c-2395-4e13-b4c8-70e2ccd84c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273730935-172.17.0.14-1599290362774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-1aa897b5-9801-4986-b8c5-495fe9cd8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-25932e75-1af0-4957-bf76-d2208158dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0c2c705b-0398-4956-826a-312719cd4cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-6875a845-c347-4c9c-a9e5-7c3ab088b964,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-afa8913c-11e4-4203-b94c-eafe8d428391,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-3d0a8f07-2a4e-4445-b631-d0d1d442accc,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-8c4160e7-51b8-4821-8ddc-f6723b39be12,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-4d3dde33-db50-413b-8cff-9bc1cd839588,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273730935-172.17.0.14-1599290362774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-1aa897b5-9801-4986-b8c5-495fe9cd8a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-25932e75-1af0-4957-bf76-d2208158dc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0c2c705b-0398-4956-826a-312719cd4cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-6875a845-c347-4c9c-a9e5-7c3ab088b964,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-afa8913c-11e4-4203-b94c-eafe8d428391,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-3d0a8f07-2a4e-4445-b631-d0d1d442accc,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-8c4160e7-51b8-4821-8ddc-f6723b39be12,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-4d3dde33-db50-413b-8cff-9bc1cd839588,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555337905-172.17.0.14-1599290404694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-da20508e-34d5-4744-9aa5-80f3b93a6fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-b9308602-b248-4f5c-abaa-90399e8db346,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-c6442f43-8cb0-4ac6-a8a2-fdb966e409c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-921bebc6-70a4-4ca0-a4a5-d71fc0684447,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-63cc9e0c-47bc-480d-a994-1d7bd0b5bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-21cfc300-1eae-47ac-920c-6335ba64ab29,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-5f6828ce-6dc7-4493-872a-7ecae87e37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-2521ea79-2eab-4274-b04e-82b29f569128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555337905-172.17.0.14-1599290404694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-da20508e-34d5-4744-9aa5-80f3b93a6fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-b9308602-b248-4f5c-abaa-90399e8db346,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-c6442f43-8cb0-4ac6-a8a2-fdb966e409c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-921bebc6-70a4-4ca0-a4a5-d71fc0684447,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-63cc9e0c-47bc-480d-a994-1d7bd0b5bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-21cfc300-1eae-47ac-920c-6335ba64ab29,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-5f6828ce-6dc7-4493-872a-7ecae87e37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-2521ea79-2eab-4274-b04e-82b29f569128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266493877-172.17.0.14-1599290443680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-38c54490-e14b-4797-8cf0-79e085ec0673,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-dc42b04c-8ad5-48e6-aa23-026091bb1f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-342f4a00-f220-43a1-9121-981c71582414,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1c6ac59f-010e-4fd3-acec-80ce61d0c789,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-f6ee7858-fc6a-4353-9533-db96b45f287d,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-1d342c3e-ffa8-4cc2-8b5a-bff99144087e,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-5ba209a9-8473-42d9-b237-f0f7afa2c890,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c9b7f232-db73-41ea-9f08-55093db0757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266493877-172.17.0.14-1599290443680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-38c54490-e14b-4797-8cf0-79e085ec0673,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-dc42b04c-8ad5-48e6-aa23-026091bb1f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-342f4a00-f220-43a1-9121-981c71582414,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1c6ac59f-010e-4fd3-acec-80ce61d0c789,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-f6ee7858-fc6a-4353-9533-db96b45f287d,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-1d342c3e-ffa8-4cc2-8b5a-bff99144087e,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-5ba209a9-8473-42d9-b237-f0f7afa2c890,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-c9b7f232-db73-41ea-9f08-55093db0757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231534199-172.17.0.14-1599291001499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-843289d4-5b78-4874-80f3-30671dd70dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-05fce39f-fbc2-4b7f-92fe-4ecad1e455fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-db74f117-410e-4a22-bf9d-d7ffd3057345,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-e63bdc4f-63e3-4bf9-9355-ee77a82b3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-1fabc300-8463-47a8-bebb-e19a847a9638,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-f7d71704-1336-43f1-a184-a222240602a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-df5dcfbc-80d4-4002-893e-b0e07be8ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-15cdbe47-336c-4a8c-a7cd-d55242ecb4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231534199-172.17.0.14-1599291001499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-843289d4-5b78-4874-80f3-30671dd70dac,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-05fce39f-fbc2-4b7f-92fe-4ecad1e455fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-db74f117-410e-4a22-bf9d-d7ffd3057345,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-e63bdc4f-63e3-4bf9-9355-ee77a82b3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-1fabc300-8463-47a8-bebb-e19a847a9638,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-f7d71704-1336-43f1-a184-a222240602a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-df5dcfbc-80d4-4002-893e-b0e07be8ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-15cdbe47-336c-4a8c-a7cd-d55242ecb4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502575971-172.17.0.14-1599291229097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-fb0bd2ea-1f71-4f74-899b-5658c61233f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-6831c366-6a18-4164-a700-06b50f767429,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-cca38452-8dbd-495f-88d6-cca7c78161d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-4805a80d-0a28-4bd4-9a5f-c36e7f2c1e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-ef2de61c-2ccc-4ad2-aa36-5ab969867c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-829fc560-38bb-48c1-9a93-ca06bfe85aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-df535538-b663-41d9-880a-77c59268a4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-3189a8d5-0733-4bda-aeeb-fdbf56680f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502575971-172.17.0.14-1599291229097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-fb0bd2ea-1f71-4f74-899b-5658c61233f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-6831c366-6a18-4164-a700-06b50f767429,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-cca38452-8dbd-495f-88d6-cca7c78161d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-4805a80d-0a28-4bd4-9a5f-c36e7f2c1e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-ef2de61c-2ccc-4ad2-aa36-5ab969867c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-829fc560-38bb-48c1-9a93-ca06bfe85aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-df535538-b663-41d9-880a-77c59268a4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-3189a8d5-0733-4bda-aeeb-fdbf56680f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295208231-172.17.0.14-1599291273039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-b3103d59-412b-4802-8e30-c4f80cf7e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-13c03243-8c36-4ebc-a70f-236a76b4e185,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-79d526f5-579e-49bf-acea-d92d91bec8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-dbb15651-1c41-4849-a366-57203c89b2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-720824a2-7317-4b6d-8f3d-7a75c203cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-dce78bd7-c029-4d36-a86f-e4f1c63c6c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-f6d68362-8fb0-4d15-9a77-3a38abdec780,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-4bac7a17-907b-42d7-b515-087234b9f786,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295208231-172.17.0.14-1599291273039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-b3103d59-412b-4802-8e30-c4f80cf7e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-13c03243-8c36-4ebc-a70f-236a76b4e185,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-79d526f5-579e-49bf-acea-d92d91bec8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-dbb15651-1c41-4849-a366-57203c89b2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-720824a2-7317-4b6d-8f3d-7a75c203cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-dce78bd7-c029-4d36-a86f-e4f1c63c6c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-f6d68362-8fb0-4d15-9a77-3a38abdec780,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-4bac7a17-907b-42d7-b515-087234b9f786,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690814939-172.17.0.14-1599291377523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-e699e65e-a7d6-4745-8c66-501a4eed1d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-4b918a84-075f-4ae1-8ccc-7fa4e194e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-0a3b06d1-b099-45aa-9618-9083ebc146d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-c1bc77ba-8bdb-4a12-9340-aa61ae990673,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-1cbf6f1c-a4cb-4718-a45a-3fff8dfb9944,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-011d8da7-6ed6-47b6-8292-f9bd3983e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-f27584ff-cb44-481c-8884-de55b2956f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-073fc31e-78b7-40a8-92ce-dd8c1e585d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690814939-172.17.0.14-1599291377523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-e699e65e-a7d6-4745-8c66-501a4eed1d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-4b918a84-075f-4ae1-8ccc-7fa4e194e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-0a3b06d1-b099-45aa-9618-9083ebc146d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-c1bc77ba-8bdb-4a12-9340-aa61ae990673,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-1cbf6f1c-a4cb-4718-a45a-3fff8dfb9944,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-011d8da7-6ed6-47b6-8292-f9bd3983e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-f27584ff-cb44-481c-8884-de55b2956f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-073fc31e-78b7-40a8-92ce-dd8c1e585d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268606387-172.17.0.14-1599291671206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-769262a0-dd6e-4c59-8641-a595d5fd2741,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-eaf3876d-e8b7-4a31-82dc-fbece30030ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-1e45ca93-df67-401e-94bf-77b33e47945f,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-937adff8-5f31-424f-8aa5-81e439061b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-d16990d2-ffaa-4b1f-9712-16e74440c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-d53dcc8e-f508-4fcc-980f-88dba044bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-1021f295-ad36-4070-b6cc-4935939688b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-50c0c71f-38ab-4be2-bec5-f3c308bb5595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268606387-172.17.0.14-1599291671206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-769262a0-dd6e-4c59-8641-a595d5fd2741,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-eaf3876d-e8b7-4a31-82dc-fbece30030ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-1e45ca93-df67-401e-94bf-77b33e47945f,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-937adff8-5f31-424f-8aa5-81e439061b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-d16990d2-ffaa-4b1f-9712-16e74440c99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-d53dcc8e-f508-4fcc-980f-88dba044bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-1021f295-ad36-4070-b6cc-4935939688b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-50c0c71f-38ab-4be2-bec5-f3c308bb5595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278670647-172.17.0.14-1599291788685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-ef49fafb-4286-4679-8df3-530f5e00d563,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-ffb8bd2c-30c5-478e-87e4-82f486208af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-f6e638b6-cb9c-4aac-80bc-c844a0e8c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-051fd4d2-5626-4658-89ad-658479e60998,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bcad6dc0-59d3-4f5a-94e4-a53f21466219,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-97f2e5a4-6693-47ed-8131-744e21c8f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-fceff658-3f64-41d4-87d3-1aa7f15cd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-25252a05-f3c6-4f3a-9819-d27af41a2483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278670647-172.17.0.14-1599291788685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-ef49fafb-4286-4679-8df3-530f5e00d563,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-ffb8bd2c-30c5-478e-87e4-82f486208af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-f6e638b6-cb9c-4aac-80bc-c844a0e8c9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-051fd4d2-5626-4658-89ad-658479e60998,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bcad6dc0-59d3-4f5a-94e4-a53f21466219,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-97f2e5a4-6693-47ed-8131-744e21c8f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-fceff658-3f64-41d4-87d3-1aa7f15cd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-25252a05-f3c6-4f3a-9819-d27af41a2483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772280426-172.17.0.14-1599291846377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-f564d139-0599-4102-b2cf-45f1d17a594e,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-39f7f834-4bed-4879-b923-58d45dfd9442,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-49795d85-182a-48b4-8b2e-6c761b7d33a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f7bc0a6a-2760-4cee-ae97-44ce4d54fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1e305da5-ef6f-4660-8d6f-c094e4c54f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-86c9e7de-cf5b-4609-bfb4-db803b8021f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-7057f117-9ddf-4aa6-ac3c-4838bb5a1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-7d3b50c2-dde7-4f85-95b8-3e233347e9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772280426-172.17.0.14-1599291846377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-f564d139-0599-4102-b2cf-45f1d17a594e,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-39f7f834-4bed-4879-b923-58d45dfd9442,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-49795d85-182a-48b4-8b2e-6c761b7d33a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f7bc0a6a-2760-4cee-ae97-44ce4d54fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1e305da5-ef6f-4660-8d6f-c094e4c54f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-86c9e7de-cf5b-4609-bfb4-db803b8021f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-7057f117-9ddf-4aa6-ac3c-4838bb5a1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-7d3b50c2-dde7-4f85-95b8-3e233347e9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33391421-172.17.0.14-1599292001362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-60c7c6da-a60d-40ff-abbd-8b1704c7acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-02a934c7-943b-4440-8fd0-c308455d93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-8796f51c-a3f1-4c45-ac9c-bd4a61443cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d49bc882-f21b-4d3c-b7df-e9a7fa607cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-c3f9e9ce-5b8e-4d8c-b30f-31e1112f7fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-49204400-33f3-4854-9f41-4686334d0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-4eef077f-3fae-4011-8886-ca74da9bd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-1a728868-11d9-43f8-b090-c4c379d0c01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33391421-172.17.0.14-1599292001362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-60c7c6da-a60d-40ff-abbd-8b1704c7acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-02a934c7-943b-4440-8fd0-c308455d93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-8796f51c-a3f1-4c45-ac9c-bd4a61443cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d49bc882-f21b-4d3c-b7df-e9a7fa607cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-c3f9e9ce-5b8e-4d8c-b30f-31e1112f7fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-49204400-33f3-4854-9f41-4686334d0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-4eef077f-3fae-4011-8886-ca74da9bd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-1a728868-11d9-43f8-b090-c4c379d0c01e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327271297-172.17.0.14-1599292137265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-cbfe2a01-b143-4054-8e98-045cd08fe41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-eb83d9f9-4b47-4225-aa0e-30036e943fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-54f8189d-387e-45d4-a3ca-796be3bd60c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-e8a33fe5-2b2d-42f4-8b89-a6002accefe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-141c040d-b09e-468d-aa8c-70ce73dcbd29,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-730f4527-5e8e-4ede-81f0-267daf8436b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-585c831e-9985-4b67-9834-2d850ac6eadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a8f169db-b77a-4cb7-8c7a-7dea93030eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327271297-172.17.0.14-1599292137265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-cbfe2a01-b143-4054-8e98-045cd08fe41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-eb83d9f9-4b47-4225-aa0e-30036e943fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-54f8189d-387e-45d4-a3ca-796be3bd60c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-e8a33fe5-2b2d-42f4-8b89-a6002accefe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-141c040d-b09e-468d-aa8c-70ce73dcbd29,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-730f4527-5e8e-4ede-81f0-267daf8436b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-585c831e-9985-4b67-9834-2d850ac6eadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a8f169db-b77a-4cb7-8c7a-7dea93030eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719574860-172.17.0.14-1599292239450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-f4eee7cf-9315-41e4-bb0d-e316a371e592,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-c116809a-67d4-44de-80d4-94ffff47766a,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-0ad7ef8d-e4e7-4ab6-9d60-60b81c3723b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-e648fd5b-b69e-49c4-a5e7-c53d9f7f75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-c951b526-2f1b-46c0-8d3e-99796a92ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-ed54c844-6afe-416f-b7f3-43480ccce0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-e4b2287d-ef42-413a-b0dc-b4a324c1c509,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-b1c9d627-9f04-489e-b17e-f89cabe1561a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719574860-172.17.0.14-1599292239450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-f4eee7cf-9315-41e4-bb0d-e316a371e592,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-c116809a-67d4-44de-80d4-94ffff47766a,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-0ad7ef8d-e4e7-4ab6-9d60-60b81c3723b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-e648fd5b-b69e-49c4-a5e7-c53d9f7f75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-c951b526-2f1b-46c0-8d3e-99796a92ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-ed54c844-6afe-416f-b7f3-43480ccce0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-e4b2287d-ef42-413a-b0dc-b4a324c1c509,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-b1c9d627-9f04-489e-b17e-f89cabe1561a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644112790-172.17.0.14-1599292737691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-a2f5a909-7bca-4de8-845c-12211a9a2598,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-6b673771-eb6d-4952-a7f2-41975e981fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c4d9d11c-cfcf-4d94-befd-087652b68f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-58281375-1f74-41ed-afc7-867d3002ffdd,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-c8978d3c-c54c-41e0-bbd1-77235aa3ad64,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3c9465e3-0e3f-438a-9bfd-50a93e955fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-840e6ec3-9163-4872-b313-8d1e973e0ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-0ccd0dc7-9eb2-4143-815c-e03b5c1c1582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644112790-172.17.0.14-1599292737691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-a2f5a909-7bca-4de8-845c-12211a9a2598,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-6b673771-eb6d-4952-a7f2-41975e981fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c4d9d11c-cfcf-4d94-befd-087652b68f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-58281375-1f74-41ed-afc7-867d3002ffdd,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-c8978d3c-c54c-41e0-bbd1-77235aa3ad64,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-3c9465e3-0e3f-438a-9bfd-50a93e955fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-840e6ec3-9163-4872-b313-8d1e973e0ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-0ccd0dc7-9eb2-4143-815c-e03b5c1c1582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919488470-172.17.0.14-1599292777999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-453319c1-8c24-4932-9649-58eff976076b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8d39ad49-df84-4c5b-8791-1ebdabd5de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-cc77cfdd-0a46-4a3f-a6b1-4499ba2c2253,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-04083ce7-9efa-4dd3-b6e9-3124ef7eecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-b0f2861a-6a8c-418e-bf81-8d0ec28d6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-58880e5c-31cf-41cc-be44-d4c4d89b984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-34c63a6a-e3af-4cdf-8601-1d67204e065a,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-ae866774-d998-46d0-a0dd-76071a0cb5c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919488470-172.17.0.14-1599292777999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-453319c1-8c24-4932-9649-58eff976076b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8d39ad49-df84-4c5b-8791-1ebdabd5de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-cc77cfdd-0a46-4a3f-a6b1-4499ba2c2253,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-04083ce7-9efa-4dd3-b6e9-3124ef7eecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-b0f2861a-6a8c-418e-bf81-8d0ec28d6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-58880e5c-31cf-41cc-be44-d4c4d89b984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-34c63a6a-e3af-4cdf-8601-1d67204e065a,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-ae866774-d998-46d0-a0dd-76071a0cb5c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023784526-172.17.0.14-1599292900289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-709a45d7-2fbb-4d0c-abdf-a02f72cd93c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-f34780df-d452-4490-8d9e-1a856e9907ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-f6fcfcd5-61ff-4a33-9399-a30f2996f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-aa866599-6189-4e0d-a24a-45d495136a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-c1eab981-9cf0-4431-b672-503ede89c155,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-f99d8412-27e2-4ca2-98f8-a8e12b3f3213,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-5a17e8b9-113a-4684-b6a4-150854c41b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-cf109115-9451-4eaf-a8c4-66e10466209c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023784526-172.17.0.14-1599292900289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-709a45d7-2fbb-4d0c-abdf-a02f72cd93c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-f34780df-d452-4490-8d9e-1a856e9907ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-f6fcfcd5-61ff-4a33-9399-a30f2996f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-aa866599-6189-4e0d-a24a-45d495136a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-c1eab981-9cf0-4431-b672-503ede89c155,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-f99d8412-27e2-4ca2-98f8-a8e12b3f3213,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-5a17e8b9-113a-4684-b6a4-150854c41b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-cf109115-9451-4eaf-a8c4-66e10466209c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627078424-172.17.0.14-1599293223868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-a5f82e1c-44c3-4909-a0a5-131007b62175,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-4fa4f35a-e406-4f76-beac-aac3b27ab1df,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-69ee89c0-220e-4f4a-8193-3e3823b3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-4dedaa58-4eb1-4671-a55d-0e51e29be0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-a3da77d9-db68-4a95-95bb-cdd813f53f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-3a8aefdc-6fbc-4beb-987e-bbd0a3eb7fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-e58e2f57-f456-4fb8-922d-3440bff15436,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-5500639b-bfef-48a4-ae1c-5f41289b32a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627078424-172.17.0.14-1599293223868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-a5f82e1c-44c3-4909-a0a5-131007b62175,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-4fa4f35a-e406-4f76-beac-aac3b27ab1df,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-69ee89c0-220e-4f4a-8193-3e3823b3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-4dedaa58-4eb1-4671-a55d-0e51e29be0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-a3da77d9-db68-4a95-95bb-cdd813f53f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-3a8aefdc-6fbc-4beb-987e-bbd0a3eb7fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-e58e2f57-f456-4fb8-922d-3440bff15436,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-5500639b-bfef-48a4-ae1c-5f41289b32a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925351975-172.17.0.14-1599293426036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-92e3eb8f-c7d4-44ac-a482-b193b9ad1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-0a6925b7-bc08-491b-b6dc-611f9d8550e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-46609fec-3ed3-427b-91ef-2f32d8ba2568,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-1ea7605a-aefe-40bd-8115-3a1042060ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e3770e47-29ca-4639-81d6-f9824332952a,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-34f9dd1d-49b2-474f-b52b-aa15cbcf8259,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-fadcae39-5db0-442a-94b6-b4df108feaef,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-38e64a36-33b3-4763-af60-3ed4c8e5b547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925351975-172.17.0.14-1599293426036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-92e3eb8f-c7d4-44ac-a482-b193b9ad1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-0a6925b7-bc08-491b-b6dc-611f9d8550e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-46609fec-3ed3-427b-91ef-2f32d8ba2568,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-1ea7605a-aefe-40bd-8115-3a1042060ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e3770e47-29ca-4639-81d6-f9824332952a,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-34f9dd1d-49b2-474f-b52b-aa15cbcf8259,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-fadcae39-5db0-442a-94b6-b4df108feaef,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-38e64a36-33b3-4763-af60-3ed4c8e5b547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514229107-172.17.0.14-1599293556759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-dfb82cbd-10cf-4d74-b944-3548c331435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-1f0e0833-b55c-4c77-bdb6-1eeb8a9a906b,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-0a6fd086-1387-49b8-b4d1-2a43ecbecbae,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c87b629b-f973-4201-9b84-d4c19b8dbe48,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-76fd2441-e8b0-499f-96bb-218153ad2056,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9e0ab245-80bb-402f-85ba-43bf9b5d47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-8def6ac5-753a-4f85-8519-7b3febd44ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-57f04e4a-52aa-42f3-93ab-882be29d8a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514229107-172.17.0.14-1599293556759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-dfb82cbd-10cf-4d74-b944-3548c331435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-1f0e0833-b55c-4c77-bdb6-1eeb8a9a906b,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-0a6fd086-1387-49b8-b4d1-2a43ecbecbae,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-c87b629b-f973-4201-9b84-d4c19b8dbe48,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-76fd2441-e8b0-499f-96bb-218153ad2056,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9e0ab245-80bb-402f-85ba-43bf9b5d47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-8def6ac5-753a-4f85-8519-7b3febd44ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-57f04e4a-52aa-42f3-93ab-882be29d8a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899923179-172.17.0.14-1599294024939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-1581393e-5b9d-4fb9-afb7-fc44ef687339,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-eb3525bc-951f-4f98-8d84-55fad4fab467,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-fdc81007-5cf1-4005-9e30-1d99ef175733,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-64e5a406-9730-4b32-ac59-f0c997290f78,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-8ca6ab88-d3fa-4bdc-bbbc-9f1bac9e40c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-eb6e84d4-1d83-47d4-8227-4aef737a5e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-bb9f0fee-7d34-4a39-839d-2312c46b87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-f09a03e3-9eb3-4d4c-ab1a-5c95ee7e6a78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899923179-172.17.0.14-1599294024939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-1581393e-5b9d-4fb9-afb7-fc44ef687339,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-eb3525bc-951f-4f98-8d84-55fad4fab467,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-fdc81007-5cf1-4005-9e30-1d99ef175733,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-64e5a406-9730-4b32-ac59-f0c997290f78,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-8ca6ab88-d3fa-4bdc-bbbc-9f1bac9e40c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-eb6e84d4-1d83-47d4-8227-4aef737a5e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-bb9f0fee-7d34-4a39-839d-2312c46b87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-f09a03e3-9eb3-4d4c-ab1a-5c95ee7e6a78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727202721-172.17.0.14-1599294075268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-8d601877-6bfb-4b74-8f53-c7d20fff2430,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-366b1136-0179-458b-aa4d-7352d686158d,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-9a5892f1-0cd1-4563-bdfc-c3e7df7f07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-6ecffab6-137b-43e6-a8f6-880e7964a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-547383e0-7ddc-4ba8-bb41-7293e6fd4b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-807ef88e-3356-483c-9305-0044e860d92b,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-5061d6a1-cd76-4e07-b544-0c15aed59b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-2e5524c6-3cfc-4299-9448-596f5d85c3e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727202721-172.17.0.14-1599294075268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-8d601877-6bfb-4b74-8f53-c7d20fff2430,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-366b1136-0179-458b-aa4d-7352d686158d,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-9a5892f1-0cd1-4563-bdfc-c3e7df7f07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-6ecffab6-137b-43e6-a8f6-880e7964a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-547383e0-7ddc-4ba8-bb41-7293e6fd4b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-807ef88e-3356-483c-9305-0044e860d92b,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-5061d6a1-cd76-4e07-b544-0c15aed59b54,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-2e5524c6-3cfc-4299-9448-596f5d85c3e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874224942-172.17.0.14-1599294167265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-8ca10db3-af7a-4495-b1fe-5cd94c601d66,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-0cf7a67d-af72-4eb8-827a-d22073729451,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-2f09f853-b324-49bf-b188-04fd6a31e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-2c87d386-d89a-4cb8-babb-12491d58addc,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6f80c473-456f-4140-8ce0-ef5cc1029581,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-931aab78-bdeb-4595-9ef5-a8accf8bfa87,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-d88e232f-8f69-423d-a0c3-21a6bba5368e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-5f146952-deff-4608-8035-c16b820c440c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874224942-172.17.0.14-1599294167265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43982,DS-8ca10db3-af7a-4495-b1fe-5cd94c601d66,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-0cf7a67d-af72-4eb8-827a-d22073729451,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-2f09f853-b324-49bf-b188-04fd6a31e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-2c87d386-d89a-4cb8-babb-12491d58addc,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6f80c473-456f-4140-8ce0-ef5cc1029581,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-931aab78-bdeb-4595-9ef5-a8accf8bfa87,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-d88e232f-8f69-423d-a0c3-21a6bba5368e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-5f146952-deff-4608-8035-c16b820c440c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187939014-172.17.0.14-1599294335088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-6e5adff3-0743-4e05-9f18-5018695d743c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-70b1665e-36c2-41de-a66a-f168721b81ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-168935a4-3e2a-4a06-be1e-f4693efc0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2f1c1863-7c89-44ca-b09d-e5020f525255,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-2117fbcb-8acd-44ee-9a6f-be1a7e97a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-ed0293c9-ea8b-4386-bb14-27164193814f,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b1c20025-d613-47a3-8ffe-b76d220a4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8289a56a-95f1-4fdc-9c23-fd57a10b02d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187939014-172.17.0.14-1599294335088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-6e5adff3-0743-4e05-9f18-5018695d743c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-70b1665e-36c2-41de-a66a-f168721b81ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-168935a4-3e2a-4a06-be1e-f4693efc0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2f1c1863-7c89-44ca-b09d-e5020f525255,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-2117fbcb-8acd-44ee-9a6f-be1a7e97a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-ed0293c9-ea8b-4386-bb14-27164193814f,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b1c20025-d613-47a3-8ffe-b76d220a4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8289a56a-95f1-4fdc-9c23-fd57a10b02d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714614839-172.17.0.14-1599294380094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36980,DS-0af11864-bba3-4cbe-aec4-9b6701e2b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-8cd6c1b3-4104-41fa-af11-5c22874ab443,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-7ed3b002-d597-4f15-8814-37c04ea27f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c2537c97-6e07-4b65-92d0-e0d5cb4aaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-b00f2f19-87bb-4cf3-b1bb-8949abfa3f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-86817b52-2ab3-4753-a4eb-663ca1dd4a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-932b7226-8b69-4855-9470-a9dd537ffb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-e4632f54-0b26-47f4-b9ed-d56251e56f96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714614839-172.17.0.14-1599294380094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36980,DS-0af11864-bba3-4cbe-aec4-9b6701e2b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-8cd6c1b3-4104-41fa-af11-5c22874ab443,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-7ed3b002-d597-4f15-8814-37c04ea27f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c2537c97-6e07-4b65-92d0-e0d5cb4aaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-b00f2f19-87bb-4cf3-b1bb-8949abfa3f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-86817b52-2ab3-4753-a4eb-663ca1dd4a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-932b7226-8b69-4855-9470-a9dd537ffb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-e4632f54-0b26-47f4-b9ed-d56251e56f96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077115823-172.17.0.14-1599294426553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36912,DS-c5c77559-f52f-4d66-bb82-9da77207f275,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-a58a41c0-1c3a-4cbc-bb4e-a06c255d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-df6a1d60-3bf7-4cd5-89d5-f5b13516e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-24b761de-6342-4e45-9288-a70e57a7a171,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-e8755727-1ae2-4a89-af52-3eb9640c919f,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-c394b3f1-6a90-4af2-b956-8dbba0fe8ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-73e1212f-0fe1-4a32-abd8-15bf8847bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-a7d6ce1f-4bc5-4680-85e2-a7988b36af69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077115823-172.17.0.14-1599294426553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36912,DS-c5c77559-f52f-4d66-bb82-9da77207f275,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-a58a41c0-1c3a-4cbc-bb4e-a06c255d2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-df6a1d60-3bf7-4cd5-89d5-f5b13516e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-24b761de-6342-4e45-9288-a70e57a7a171,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-e8755727-1ae2-4a89-af52-3eb9640c919f,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-c394b3f1-6a90-4af2-b956-8dbba0fe8ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-73e1212f-0fe1-4a32-abd8-15bf8847bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-a7d6ce1f-4bc5-4680-85e2-a7988b36af69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604636927-172.17.0.14-1599294547678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-eca411b0-1503-4696-87bc-386b093bea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-9d3821b2-5f0e-4f72-a13f-eac5c1b0eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-c17ab314-d3d9-4d65-86b9-e2811a9d8c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-fdae817d-cb91-4309-bcd5-5062fe3f5829,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-8d420a8c-ee28-4719-b8c4-2f3a63ee94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-874306cd-015c-40ba-bbf1-f7e3c6ac9555,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-91877d9c-c5f5-47a6-b3aa-22a33a54ff07,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-f8a40780-601f-42ae-b09a-fac79fecce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604636927-172.17.0.14-1599294547678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-eca411b0-1503-4696-87bc-386b093bea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-9d3821b2-5f0e-4f72-a13f-eac5c1b0eff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-c17ab314-d3d9-4d65-86b9-e2811a9d8c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-fdae817d-cb91-4309-bcd5-5062fe3f5829,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-8d420a8c-ee28-4719-b8c4-2f3a63ee94ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-874306cd-015c-40ba-bbf1-f7e3c6ac9555,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-91877d9c-c5f5-47a6-b3aa-22a33a54ff07,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-f8a40780-601f-42ae-b09a-fac79fecce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676917228-172.17.0.14-1599294629762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-3e2512bc-09d5-48b0-8103-140a809817d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-c709c13b-1724-4a46-b889-b14f75a4e69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-7b5d0b70-c24d-4d6c-ad9d-8d3b775748b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3b69f53d-704d-46c1-aca5-09c77027792b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-efe23fb6-b975-4225-85ae-e1fcde254eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f51e2497-8793-413f-92ae-5ab2a39294f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-07ef6e21-3e93-4ec7-86d3-b7e4a76f802c,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-910a3d11-cd9b-4e6c-949b-cd5045bc4cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676917228-172.17.0.14-1599294629762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-3e2512bc-09d5-48b0-8103-140a809817d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-c709c13b-1724-4a46-b889-b14f75a4e69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-7b5d0b70-c24d-4d6c-ad9d-8d3b775748b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3b69f53d-704d-46c1-aca5-09c77027792b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-efe23fb6-b975-4225-85ae-e1fcde254eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f51e2497-8793-413f-92ae-5ab2a39294f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-07ef6e21-3e93-4ec7-86d3-b7e4a76f802c,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-910a3d11-cd9b-4e6c-949b-cd5045bc4cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905775569-172.17.0.14-1599294666352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-f0acdb22-ebbb-4f79-831a-f89eb8ab0c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-9ba08be2-8919-47de-a81c-dad72f4ee7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-80044e80-6921-4ca3-97c2-ebb6cbcf3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-793e48d8-28bd-4e10-83a8-e9c1655e5759,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-114c0bc6-8efc-4e08-af59-4beed60e0338,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-f9145e84-c72c-47f1-acf7-c7930383e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-8a74892f-a63f-47f6-bf9b-a59cbafa4a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-8aeac225-403e-4fe8-a26a-fb15a71f198c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905775569-172.17.0.14-1599294666352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-f0acdb22-ebbb-4f79-831a-f89eb8ab0c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-9ba08be2-8919-47de-a81c-dad72f4ee7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-80044e80-6921-4ca3-97c2-ebb6cbcf3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-793e48d8-28bd-4e10-83a8-e9c1655e5759,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-114c0bc6-8efc-4e08-af59-4beed60e0338,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-f9145e84-c72c-47f1-acf7-c7930383e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-8a74892f-a63f-47f6-bf9b-a59cbafa4a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-8aeac225-403e-4fe8-a26a-fb15a71f198c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579019795-172.17.0.14-1599294859414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-42e723e3-ad68-4449-b639-769206d6b808,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-39792744-73b3-4f56-a6c5-ef6dd9181b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-3173c7d9-61d8-4929-8d15-94a7b3cc85d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-2b53cdfc-c660-4f03-b3a4-10a3afd3adf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7985e326-d271-446f-91f1-0e51e6807ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-1873a1fc-2e8c-4ad3-aef5-3ca1c2aad42b,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-f3a84e6e-b62d-4683-a2c7-2f336652df69,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1f12a365-61d8-4463-b295-8fa949df44a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579019795-172.17.0.14-1599294859414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-42e723e3-ad68-4449-b639-769206d6b808,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-39792744-73b3-4f56-a6c5-ef6dd9181b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-3173c7d9-61d8-4929-8d15-94a7b3cc85d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-2b53cdfc-c660-4f03-b3a4-10a3afd3adf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7985e326-d271-446f-91f1-0e51e6807ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-1873a1fc-2e8c-4ad3-aef5-3ca1c2aad42b,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-f3a84e6e-b62d-4683-a2c7-2f336652df69,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1f12a365-61d8-4463-b295-8fa949df44a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766907677-172.17.0.14-1599294902921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-845059e3-4dda-44b3-8867-507f647e24c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-273bd41f-cceb-407b-a889-1fef0c364c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-415da65e-4425-48eb-834e-7b356b5537dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4fdd9e22-e825-43cf-bfb1-2d6eaa0fe7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-256efc10-a08b-485a-8410-6031ee7db222,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-6fd0362a-509e-4c8c-986e-c1219a3324e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-ee37e5bb-dda2-423a-bb9d-1075c0dd18fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-b2c45566-58dc-45e0-9c99-89bd793d45bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766907677-172.17.0.14-1599294902921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-845059e3-4dda-44b3-8867-507f647e24c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-273bd41f-cceb-407b-a889-1fef0c364c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-415da65e-4425-48eb-834e-7b356b5537dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4fdd9e22-e825-43cf-bfb1-2d6eaa0fe7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-256efc10-a08b-485a-8410-6031ee7db222,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-6fd0362a-509e-4c8c-986e-c1219a3324e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-ee37e5bb-dda2-423a-bb9d-1075c0dd18fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-b2c45566-58dc-45e0-9c99-89bd793d45bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844513732-172.17.0.14-1599294986167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36601,DS-89d0fab7-6d87-4133-af79-38068cdf2276,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3672bc4e-d723-4f97-9f22-b4bb58cc988c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-c0d2a851-c997-48e2-8e00-aceb00a6dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-31b2a461-676c-441b-8c6d-bda3e75a836a,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-677dd828-a121-443c-adb6-e81a2c99c705,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-b8a8cd9d-07eb-4692-af21-46e78cfaeb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-5d1201de-70ae-40ac-9cec-f8e8d53a9569,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-6afb7aed-4e96-49d5-a954-34e4f8c9368d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844513732-172.17.0.14-1599294986167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36601,DS-89d0fab7-6d87-4133-af79-38068cdf2276,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3672bc4e-d723-4f97-9f22-b4bb58cc988c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-c0d2a851-c997-48e2-8e00-aceb00a6dd45,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-31b2a461-676c-441b-8c6d-bda3e75a836a,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-677dd828-a121-443c-adb6-e81a2c99c705,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-b8a8cd9d-07eb-4692-af21-46e78cfaeb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-5d1201de-70ae-40ac-9cec-f8e8d53a9569,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-6afb7aed-4e96-49d5-a954-34e4f8c9368d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999767416-172.17.0.14-1599295018926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-04cc1309-1ff3-4e3d-814a-fdbb684a9457,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-97f96298-85e3-4907-aa37-8b9b24c21680,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-8dc09f2c-a452-463a-9d14-1aad70c956f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-76510099-0265-43db-8739-40e5a738538b,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-4166a29d-4c0d-4de0-a7a6-667544c85738,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-50119e5e-ce0c-44ae-8662-dc1218d48d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-4021b20d-835f-4f5a-9680-144b73768673,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-cfdd3ea6-b510-460b-8e6d-20b1a732c217,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999767416-172.17.0.14-1599295018926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-04cc1309-1ff3-4e3d-814a-fdbb684a9457,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-97f96298-85e3-4907-aa37-8b9b24c21680,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-8dc09f2c-a452-463a-9d14-1aad70c956f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-76510099-0265-43db-8739-40e5a738538b,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-4166a29d-4c0d-4de0-a7a6-667544c85738,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-50119e5e-ce0c-44ae-8662-dc1218d48d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-4021b20d-835f-4f5a-9680-144b73768673,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-cfdd3ea6-b510-460b-8e6d-20b1a732c217,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614848601-172.17.0.14-1599295500742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42837,DS-76905284-71b5-4a44-8638-4a4efc6ed76f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-42b50d2e-66f7-4d48-948b-412ef7ef7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2c5f283e-f875-4c89-bbb2-da0a0de33bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-9d1d3799-0b23-49ec-ad85-8b3cb12c6b06,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f8b4c378-8a2d-447f-a421-cb8e30b8fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-2feb15d3-c83a-4483-a705-13b298e26a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0ada8637-3635-46bb-b60b-2bc0886264de,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-0dff465e-52de-461e-9d2f-eec1cfd11907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614848601-172.17.0.14-1599295500742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42837,DS-76905284-71b5-4a44-8638-4a4efc6ed76f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-42b50d2e-66f7-4d48-948b-412ef7ef7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2c5f283e-f875-4c89-bbb2-da0a0de33bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-9d1d3799-0b23-49ec-ad85-8b3cb12c6b06,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f8b4c378-8a2d-447f-a421-cb8e30b8fda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-2feb15d3-c83a-4483-a705-13b298e26a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0ada8637-3635-46bb-b60b-2bc0886264de,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-0dff465e-52de-461e-9d2f-eec1cfd11907,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234456658-172.17.0.14-1599295579469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34636,DS-11fd2573-d941-4dca-94ba-7401d7ad01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-2e3ad070-b0c6-4574-8828-a44453b80511,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-c1a6eb7d-6598-4bae-b875-5beff719e23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-98d91c26-7bdd-400c-9ee5-fb16de6dbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-0cca7867-e57a-4b11-b8b8-f1e82abc8fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-688a0ecb-8286-4502-8d7c-1ce9088a3e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-bcb2baf1-f706-492d-a322-8904ee8388d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-3cc26625-dab8-490f-9f4f-4633411edac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234456658-172.17.0.14-1599295579469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34636,DS-11fd2573-d941-4dca-94ba-7401d7ad01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-2e3ad070-b0c6-4574-8828-a44453b80511,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-c1a6eb7d-6598-4bae-b875-5beff719e23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-98d91c26-7bdd-400c-9ee5-fb16de6dbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-0cca7867-e57a-4b11-b8b8-f1e82abc8fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-688a0ecb-8286-4502-8d7c-1ce9088a3e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-bcb2baf1-f706-492d-a322-8904ee8388d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-3cc26625-dab8-490f-9f4f-4633411edac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309578347-172.17.0.14-1599295652701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-d392d51e-9b7f-4d76-9bee-e421f8b90244,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-9a7114ab-d3d3-465f-8d28-46571c71eb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-92641f62-dd9f-49ee-8071-71389dc63281,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-c1ffe06a-2152-48f2-b1cd-9c3ad036e657,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-7e6429e2-6d59-40df-9e34-05c83093e919,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-5c2fd218-ca0a-417a-af4f-02142b0334f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-c5422d31-74c1-4b3e-989f-da97817ebbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e5a2207d-68f1-4ae8-a9c6-cb959de26af2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309578347-172.17.0.14-1599295652701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-d392d51e-9b7f-4d76-9bee-e421f8b90244,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-9a7114ab-d3d3-465f-8d28-46571c71eb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-92641f62-dd9f-49ee-8071-71389dc63281,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-c1ffe06a-2152-48f2-b1cd-9c3ad036e657,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-7e6429e2-6d59-40df-9e34-05c83093e919,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-5c2fd218-ca0a-417a-af4f-02142b0334f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-c5422d31-74c1-4b3e-989f-da97817ebbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e5a2207d-68f1-4ae8-a9c6-cb959de26af2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5697
