reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304362339-172.17.0.3-1599329953378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-505213a2-f0e9-4d79-a28c-4438a65afdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-7b690688-d9e3-4be0-81c3-829131118b85,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e415da86-e857-4536-9f40-e9f9e2fce70d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-c4056276-3e03-4a20-8188-11f2d94a24c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-918558cd-c890-480b-8518-861131f2858e,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-589958c4-a95c-48cc-9286-8a466407629d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-d095da3c-7788-4482-8935-eae188c1a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-0e6f95ef-8c62-42ec-b1a0-f7b6fd1d3344,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304362339-172.17.0.3-1599329953378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-505213a2-f0e9-4d79-a28c-4438a65afdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-7b690688-d9e3-4be0-81c3-829131118b85,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e415da86-e857-4536-9f40-e9f9e2fce70d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-c4056276-3e03-4a20-8188-11f2d94a24c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-918558cd-c890-480b-8518-861131f2858e,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-589958c4-a95c-48cc-9286-8a466407629d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-d095da3c-7788-4482-8935-eae188c1a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-0e6f95ef-8c62-42ec-b1a0-f7b6fd1d3344,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569290980-172.17.0.3-1599330039907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-269caf26-d385-40d6-8405-55f44a7c575b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-8a157af9-c0fb-4a4b-bf21-1e27a288092d,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-f30d3fc4-d48c-409a-9123-2d6a6812c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-401b6ded-57c3-4ffa-9f4b-546f1f142beb,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-32fe223a-50cf-4697-92c7-b55dfecd5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-cf184992-c35a-4063-bb98-6ca57c2456c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-365e3496-398f-4ac8-8310-4d544efa07d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-bcd50faf-f21c-434e-a456-6f7aee7d185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569290980-172.17.0.3-1599330039907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-269caf26-d385-40d6-8405-55f44a7c575b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-8a157af9-c0fb-4a4b-bf21-1e27a288092d,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-f30d3fc4-d48c-409a-9123-2d6a6812c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-401b6ded-57c3-4ffa-9f4b-546f1f142beb,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-32fe223a-50cf-4697-92c7-b55dfecd5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-cf184992-c35a-4063-bb98-6ca57c2456c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-365e3496-398f-4ac8-8310-4d544efa07d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-bcd50faf-f21c-434e-a456-6f7aee7d185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153755387-172.17.0.3-1599330068208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-ce1bf0e9-455f-4f3e-a1d0-e841ddef8df2,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d0c94e9f-5afd-49bf-9ba3-30cecca19ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-98900581-3f79-49bc-803a-542668dd282a,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-9a4770e2-4572-4c2c-8b10-7ee26c6dd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b0529232-606e-4369-ab25-529b71f657bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-9759957b-7948-4283-a8d2-0094abdfc557,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-6388ead7-b588-4543-a8c4-b81fc5b07df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-e0342f89-7c76-430d-89a9-16b049c32105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153755387-172.17.0.3-1599330068208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-ce1bf0e9-455f-4f3e-a1d0-e841ddef8df2,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d0c94e9f-5afd-49bf-9ba3-30cecca19ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-98900581-3f79-49bc-803a-542668dd282a,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-9a4770e2-4572-4c2c-8b10-7ee26c6dd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b0529232-606e-4369-ab25-529b71f657bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-9759957b-7948-4283-a8d2-0094abdfc557,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-6388ead7-b588-4543-a8c4-b81fc5b07df4,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-e0342f89-7c76-430d-89a9-16b049c32105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886852741-172.17.0.3-1599330212634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-13750450-176f-438d-8bbc-05a123dc7974,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-56637547-b551-4ccc-8fd8-038ba4159012,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-dd058f45-148b-4e61-9a20-b2b5a7474ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-246daa6f-e8b2-42ee-8714-4f6ca33f294c,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-746b8f49-2b77-428d-b726-2b893aa66d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-3c714a61-f525-4a00-b3ec-6da408f4fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-3c377e36-b0c2-45fe-8fcd-adeae85bac69,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-77994555-20eb-4375-bcd2-1e54e65dfdb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886852741-172.17.0.3-1599330212634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-13750450-176f-438d-8bbc-05a123dc7974,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-56637547-b551-4ccc-8fd8-038ba4159012,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-dd058f45-148b-4e61-9a20-b2b5a7474ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-246daa6f-e8b2-42ee-8714-4f6ca33f294c,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-746b8f49-2b77-428d-b726-2b893aa66d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-3c714a61-f525-4a00-b3ec-6da408f4fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-3c377e36-b0c2-45fe-8fcd-adeae85bac69,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-77994555-20eb-4375-bcd2-1e54e65dfdb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019048945-172.17.0.3-1599330239995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-829954bf-ead7-4142-9ebc-37b55646be51,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-a4a2bdcd-f003-48d0-a805-a508194fd093,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-7b3900ce-aba0-43a6-a3f8-923a58ff4309,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-9c270581-16a0-4b88-bf22-c021d7f598b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-b76ff7fb-453b-4a5e-9fd6-aac5b483074b,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-bcb821b7-f5f3-4e99-b250-7c8ed0f654eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-6c172d5d-3061-4de0-86c1-e61a26ef495b,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2bf0f4c8-84fa-42fb-9d35-53fe6d857c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019048945-172.17.0.3-1599330239995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-829954bf-ead7-4142-9ebc-37b55646be51,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-a4a2bdcd-f003-48d0-a805-a508194fd093,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-7b3900ce-aba0-43a6-a3f8-923a58ff4309,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-9c270581-16a0-4b88-bf22-c021d7f598b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-b76ff7fb-453b-4a5e-9fd6-aac5b483074b,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-bcb821b7-f5f3-4e99-b250-7c8ed0f654eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-6c172d5d-3061-4de0-86c1-e61a26ef495b,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2bf0f4c8-84fa-42fb-9d35-53fe6d857c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802713096-172.17.0.3-1599330385446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-1dc7b31e-3d44-4e5b-9b58-82162d06e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-bbcb29d8-11e9-4759-a85f-754eed0a0c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-2c4fd21d-f8ad-491a-a9c9-87fc04ae4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-9e68a39f-f136-4f4d-833c-1c11b5f96faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-931636f9-f48a-4bd1-89b7-3ce066da1802,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6e107e78-01f7-41be-b8aa-61736c82a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-454c7bb4-c4fa-4d2d-af6d-ba4cb62f13ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-2617c927-13c1-49b1-b405-a41ef28db1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802713096-172.17.0.3-1599330385446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-1dc7b31e-3d44-4e5b-9b58-82162d06e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-bbcb29d8-11e9-4759-a85f-754eed0a0c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-2c4fd21d-f8ad-491a-a9c9-87fc04ae4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-9e68a39f-f136-4f4d-833c-1c11b5f96faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-931636f9-f48a-4bd1-89b7-3ce066da1802,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6e107e78-01f7-41be-b8aa-61736c82a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-454c7bb4-c4fa-4d2d-af6d-ba4cb62f13ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-2617c927-13c1-49b1-b405-a41ef28db1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862700352-172.17.0.3-1599330411303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-bb6552ef-748f-4fa4-a28a-a7bb036766d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-bca314a0-32f6-4afe-b17d-fd352bb71fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f44aa305-6911-4901-9ebf-35fef6e71660,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-443007a4-2a54-4421-ad37-bedb7e42131e,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c71393a0-7172-4219-a859-ac11fcc0b511,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-166036f1-6f84-45f4-8e63-ed2efca28c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-cbf25040-b708-4bc6-a2f8-6f9e9ae5d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-bb37f1ac-7cfc-4e0c-a504-05c8575a198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862700352-172.17.0.3-1599330411303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-bb6552ef-748f-4fa4-a28a-a7bb036766d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-bca314a0-32f6-4afe-b17d-fd352bb71fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f44aa305-6911-4901-9ebf-35fef6e71660,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-443007a4-2a54-4421-ad37-bedb7e42131e,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c71393a0-7172-4219-a859-ac11fcc0b511,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-166036f1-6f84-45f4-8e63-ed2efca28c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-cbf25040-b708-4bc6-a2f8-6f9e9ae5d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-bb37f1ac-7cfc-4e0c-a504-05c8575a198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697678015-172.17.0.3-1599330552760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-f6f14df0-fdce-4b07-a492-fed4a03869e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-a85fe3bc-5bf9-4885-8eb2-c8d0052cfad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-9073b1bc-6d00-4885-a781-5fd9d44bcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-facafe19-ec73-41ea-9e7a-ec392db9a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-b4a0eeba-d644-4d15-ae6b-02333be88593,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-32871250-b058-40f5-bb67-7d080f2f9a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-9c2506fc-d6dd-439a-ab29-3a76864dd00b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-e8dc6967-a421-4498-9d74-ff5f66edfc6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697678015-172.17.0.3-1599330552760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-f6f14df0-fdce-4b07-a492-fed4a03869e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-a85fe3bc-5bf9-4885-8eb2-c8d0052cfad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-9073b1bc-6d00-4885-a781-5fd9d44bcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-facafe19-ec73-41ea-9e7a-ec392db9a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-b4a0eeba-d644-4d15-ae6b-02333be88593,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-32871250-b058-40f5-bb67-7d080f2f9a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-9c2506fc-d6dd-439a-ab29-3a76864dd00b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-e8dc6967-a421-4498-9d74-ff5f66edfc6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241314063-172.17.0.3-1599330614137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36104,DS-e6a64b74-132c-4945-9a50-4fd297870790,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-3b7cb27c-f3d3-49eb-bc2a-44d9d8320513,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-44b90e9b-f5eb-4c84-b818-bf1d81d8def0,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-9dcb8c13-63a2-40b9-aa56-49e922adf2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-b7e9003a-77ca-4730-86db-fe6a33f55e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-a77ea709-29b2-4fa2-8ea3-f90337a4ba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-6e9aa07b-678f-4d93-bbec-f32393742f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-e49cee08-90f3-4086-8818-b250958ba4f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241314063-172.17.0.3-1599330614137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36104,DS-e6a64b74-132c-4945-9a50-4fd297870790,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-3b7cb27c-f3d3-49eb-bc2a-44d9d8320513,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-44b90e9b-f5eb-4c84-b818-bf1d81d8def0,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-9dcb8c13-63a2-40b9-aa56-49e922adf2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-b7e9003a-77ca-4730-86db-fe6a33f55e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-a77ea709-29b2-4fa2-8ea3-f90337a4ba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-6e9aa07b-678f-4d93-bbec-f32393742f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-e49cee08-90f3-4086-8818-b250958ba4f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246410497-172.17.0.3-1599330753654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-4fb62faf-00ad-4e2e-8fc7-9011ce5644f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-2099e31a-8e68-47b7-b229-ece0d3404017,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-40fed4f0-2850-4c1c-a817-ee239d243b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-3d90dddd-1553-4618-87e1-da0f0903c458,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-917a40c4-e1ff-410b-83af-f8cbef5a8218,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-ea710eb1-8d94-4a52-8c48-6c786d1c2523,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-08baf4b7-781d-4263-a02a-d89c95c7188b,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-c7e1026f-a67b-42bc-b0d4-284429752563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246410497-172.17.0.3-1599330753654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-4fb62faf-00ad-4e2e-8fc7-9011ce5644f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-2099e31a-8e68-47b7-b229-ece0d3404017,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-40fed4f0-2850-4c1c-a817-ee239d243b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-3d90dddd-1553-4618-87e1-da0f0903c458,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-917a40c4-e1ff-410b-83af-f8cbef5a8218,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-ea710eb1-8d94-4a52-8c48-6c786d1c2523,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-08baf4b7-781d-4263-a02a-d89c95c7188b,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-c7e1026f-a67b-42bc-b0d4-284429752563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067831599-172.17.0.3-1599330916805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-a40611fa-a64b-4cf4-b54e-0c1362297d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-b7b7ce28-b949-454b-b01d-f461aeaad487,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5dc68267-1316-4c68-ab88-368d0ab5979a,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ac264695-60e8-4a52-a01b-94ce6e7ab66f,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-a9d965d3-d11e-4125-9b37-261758dda8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-1b173e95-9945-4f54-9402-814952d08b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-9b70c2fc-17ac-4ac8-9abd-ee33161e3337,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-d7d5cecb-7115-4fcd-bd10-cb12a395f9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067831599-172.17.0.3-1599330916805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-a40611fa-a64b-4cf4-b54e-0c1362297d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-b7b7ce28-b949-454b-b01d-f461aeaad487,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-5dc68267-1316-4c68-ab88-368d0ab5979a,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ac264695-60e8-4a52-a01b-94ce6e7ab66f,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-a9d965d3-d11e-4125-9b37-261758dda8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-1b173e95-9945-4f54-9402-814952d08b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-9b70c2fc-17ac-4ac8-9abd-ee33161e3337,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-d7d5cecb-7115-4fcd-bd10-cb12a395f9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981472601-172.17.0.3-1599331030296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-dfa79f37-4b9f-466e-abc5-9b4a35f29c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-388265b0-0a8f-44dd-b2e9-346c53c19da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-c0eaa6c9-74cb-4e5e-a621-4ddcd45b59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3033dfbd-baf8-450e-ac3e-c7b65aef4116,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-5560e513-4754-48c7-8db5-76f699850ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-63596319-1389-401c-893e-8a95f037aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-6fd324d2-9a1c-4873-b45b-418dee74b241,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-989addd3-b4aa-4834-bf5a-a0a7c3043ac1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981472601-172.17.0.3-1599331030296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-dfa79f37-4b9f-466e-abc5-9b4a35f29c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-388265b0-0a8f-44dd-b2e9-346c53c19da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-c0eaa6c9-74cb-4e5e-a621-4ddcd45b59dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3033dfbd-baf8-450e-ac3e-c7b65aef4116,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-5560e513-4754-48c7-8db5-76f699850ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-63596319-1389-401c-893e-8a95f037aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-6fd324d2-9a1c-4873-b45b-418dee74b241,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-989addd3-b4aa-4834-bf5a-a0a7c3043ac1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388848379-172.17.0.3-1599331179932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-ac447bbf-3752-4421-9b8b-f7241bcfd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-d344d309-688a-4222-9bd5-bd29905bc60d,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-3cfe7ad6-c08e-4464-bc27-3cad3df87404,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-f520d6c1-cfed-41ee-9553-5da0d4c96bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-4a898be4-c39b-4298-8407-4b799c70a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-956cc465-928b-4e70-8ec3-6f23476a7689,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-bcd6bda2-8b8f-4f0c-9d3a-2752684c1516,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-1008051d-5f07-4e54-997e-353009be3751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388848379-172.17.0.3-1599331179932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-ac447bbf-3752-4421-9b8b-f7241bcfd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-d344d309-688a-4222-9bd5-bd29905bc60d,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-3cfe7ad6-c08e-4464-bc27-3cad3df87404,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-f520d6c1-cfed-41ee-9553-5da0d4c96bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-4a898be4-c39b-4298-8407-4b799c70a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-956cc465-928b-4e70-8ec3-6f23476a7689,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-bcd6bda2-8b8f-4f0c-9d3a-2752684c1516,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-1008051d-5f07-4e54-997e-353009be3751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003016977-172.17.0.3-1599331409181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-97e7e6d5-db46-494c-9cce-4164b5804551,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-aab20c31-60be-4881-a04d-fdd1d070d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0a38ecf4-9382-49ca-b19d-974e6be70be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-f4d41998-c1a7-479f-b217-41445b4a14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-e0f97969-8d8c-486a-9e32-a13bafde891e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-2618a8c8-c677-4a0a-9221-4791e8a4f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-f04a7572-decf-4c31-887d-f58c5c0b1a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-30768ecb-dcb7-4a8b-b654-cd4a60c0900b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003016977-172.17.0.3-1599331409181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42346,DS-97e7e6d5-db46-494c-9cce-4164b5804551,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-aab20c31-60be-4881-a04d-fdd1d070d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0a38ecf4-9382-49ca-b19d-974e6be70be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-f4d41998-c1a7-479f-b217-41445b4a14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-e0f97969-8d8c-486a-9e32-a13bafde891e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-2618a8c8-c677-4a0a-9221-4791e8a4f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-f04a7572-decf-4c31-887d-f58c5c0b1a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-30768ecb-dcb7-4a8b-b654-cd4a60c0900b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38192471-172.17.0.3-1599331510311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-d120672e-76a9-49c9-ac65-8da59ca969cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-095600d0-8a7f-4687-89fe-d0f43cb58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-2c08d9ef-00b7-4a9b-a0ce-441519fb52ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-cc6c995a-8b5f-488f-a657-122c4841b388,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-4ae09bd4-55fc-435a-b1a2-279498619f23,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-3927a291-3f41-49b6-983c-296765608bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-50efc045-8a54-4512-80da-13bf675521a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-da178583-78c6-4e17-bf47-b543716a711e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38192471-172.17.0.3-1599331510311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-d120672e-76a9-49c9-ac65-8da59ca969cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-095600d0-8a7f-4687-89fe-d0f43cb58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-2c08d9ef-00b7-4a9b-a0ce-441519fb52ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-cc6c995a-8b5f-488f-a657-122c4841b388,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-4ae09bd4-55fc-435a-b1a2-279498619f23,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-3927a291-3f41-49b6-983c-296765608bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-50efc045-8a54-4512-80da-13bf675521a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-da178583-78c6-4e17-bf47-b543716a711e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259556215-172.17.0.3-1599331619403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-fb36b635-e18a-4153-9523-af11c379811a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-a1c19881-f971-4dc2-b6b6-48907586fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-7aef1847-5d29-4fe9-9443-ff6d79c7c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-7e67cb46-d517-4ece-973c-58eccd12de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-12b2301e-e010-49ef-922e-a91ef0ea3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-d64bb909-6a54-4240-b6f7-195e264f1404,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-3d0eb72f-a101-463d-bc7c-ede238448418,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-fa47cae0-bab7-41c4-8918-31a33d0beaab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259556215-172.17.0.3-1599331619403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-fb36b635-e18a-4153-9523-af11c379811a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-a1c19881-f971-4dc2-b6b6-48907586fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-7aef1847-5d29-4fe9-9443-ff6d79c7c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-7e67cb46-d517-4ece-973c-58eccd12de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-12b2301e-e010-49ef-922e-a91ef0ea3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-d64bb909-6a54-4240-b6f7-195e264f1404,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-3d0eb72f-a101-463d-bc7c-ede238448418,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-fa47cae0-bab7-41c4-8918-31a33d0beaab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737378334-172.17.0.3-1599331818242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-fc5302a6-d4bd-4f81-acf3-00df23da3859,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-fbae3baf-3c0f-4402-bae5-4a6297099755,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-6f6e1dec-bef5-4a38-81dc-6610f999a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-0b81a8c3-3a82-485b-95c8-0b0b8cc8ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0f54014a-7ade-4a3a-8f06-d04669d194fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-932bded9-6c5e-4f13-a84b-610a351b1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-c7a03eca-05f9-42e4-8cd0-ffe655f520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-84b81bf1-77e0-4bdc-8773-826bb7382c99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737378334-172.17.0.3-1599331818242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-fc5302a6-d4bd-4f81-acf3-00df23da3859,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-fbae3baf-3c0f-4402-bae5-4a6297099755,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-6f6e1dec-bef5-4a38-81dc-6610f999a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-0b81a8c3-3a82-485b-95c8-0b0b8cc8ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0f54014a-7ade-4a3a-8f06-d04669d194fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-932bded9-6c5e-4f13-a84b-610a351b1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-c7a03eca-05f9-42e4-8cd0-ffe655f520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-84b81bf1-77e0-4bdc-8773-826bb7382c99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538182088-172.17.0.3-1599331908918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-bd27f5ef-c311-4359-a321-3890640f0deb,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9c9ddcfd-7dfc-470d-a3e6-f7ca7fec003c,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-efae2c99-fcc9-426c-b3a7-07cd89680775,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-2c9a81d2-3147-4d50-aacc-6f7409a84e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-25ef7d1d-7e5d-4808-b24d-2515e7b47b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-58dc64cb-f7f7-45c6-be3c-aa05d7263f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-6235574d-50f7-4d7d-8d4d-fec498e392c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-cd7950e4-cb9f-458c-a6a7-16a498f72431,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538182088-172.17.0.3-1599331908918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35828,DS-bd27f5ef-c311-4359-a321-3890640f0deb,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9c9ddcfd-7dfc-470d-a3e6-f7ca7fec003c,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-efae2c99-fcc9-426c-b3a7-07cd89680775,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-2c9a81d2-3147-4d50-aacc-6f7409a84e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-25ef7d1d-7e5d-4808-b24d-2515e7b47b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-58dc64cb-f7f7-45c6-be3c-aa05d7263f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-6235574d-50f7-4d7d-8d4d-fec498e392c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-cd7950e4-cb9f-458c-a6a7-16a498f72431,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616160956-172.17.0.3-1599331964047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-164de433-05ab-4a4e-9609-4bdd78927e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-0ef8f293-0815-4477-badf-ec24b045184a,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f020987b-ad17-432d-813e-5e43c7e1aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-c1786785-2d69-4b01-903b-9ad757148616,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-25547c09-a4b9-49c5-9e5c-a0f4ce666f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-5c0fab2a-0af7-4350-b710-51f8ed347457,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b8caf110-6350-46d6-8307-b95c6eba1d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-4a83c3ac-1973-4c52-9bdf-4d9ea1378a96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616160956-172.17.0.3-1599331964047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-164de433-05ab-4a4e-9609-4bdd78927e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-0ef8f293-0815-4477-badf-ec24b045184a,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f020987b-ad17-432d-813e-5e43c7e1aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-c1786785-2d69-4b01-903b-9ad757148616,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-25547c09-a4b9-49c5-9e5c-a0f4ce666f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-5c0fab2a-0af7-4350-b710-51f8ed347457,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b8caf110-6350-46d6-8307-b95c6eba1d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-4a83c3ac-1973-4c52-9bdf-4d9ea1378a96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740408764-172.17.0.3-1599332249138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-a365a432-363a-4988-813f-a670f67a3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-1c1ac825-f037-416d-9c4f-4b8097751dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-ced4c52f-5988-410b-ab3a-16342f03ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-0117590b-6b37-4b95-807e-3786fdc8fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-fc33c1a0-b2c3-4958-afc4-416cbaec7421,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-b8f0a3fd-1a09-4238-87eb-415ea6c92182,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-d3ef16e1-6ce4-4e4d-a875-70f304ca24e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-13ade5e1-30ec-428f-aa8b-53be0a78eae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740408764-172.17.0.3-1599332249138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-a365a432-363a-4988-813f-a670f67a3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-1c1ac825-f037-416d-9c4f-4b8097751dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-ced4c52f-5988-410b-ab3a-16342f03ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-0117590b-6b37-4b95-807e-3786fdc8fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-fc33c1a0-b2c3-4958-afc4-416cbaec7421,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-b8f0a3fd-1a09-4238-87eb-415ea6c92182,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-d3ef16e1-6ce4-4e4d-a875-70f304ca24e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-13ade5e1-30ec-428f-aa8b-53be0a78eae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571268908-172.17.0.3-1599332302037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-dcf39b6f-ca65-44dc-bc25-c507ea9e50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-0cf2a4c8-c355-4437-aa24-a9623b20fd58,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-59cb5e2a-59ca-4e8d-a6f4-78f5eda85e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-d740698a-43cf-4b97-8575-f0114f932b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-a551f648-330d-48df-9060-4aff6427e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-7833b1b8-0286-4dd2-88b3-c81326e1fd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-5870a20e-ca79-4f85-a7a8-c3e82cb7b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-d0356261-ae37-4000-9b1f-eb9cc84b2c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571268908-172.17.0.3-1599332302037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-dcf39b6f-ca65-44dc-bc25-c507ea9e50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-0cf2a4c8-c355-4437-aa24-a9623b20fd58,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-59cb5e2a-59ca-4e8d-a6f4-78f5eda85e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-d740698a-43cf-4b97-8575-f0114f932b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-a551f648-330d-48df-9060-4aff6427e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-7833b1b8-0286-4dd2-88b3-c81326e1fd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-5870a20e-ca79-4f85-a7a8-c3e82cb7b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-d0356261-ae37-4000-9b1f-eb9cc84b2c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387624676-172.17.0.3-1599332409591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-4fc1491d-9aea-4aa1-a2bf-857358811f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-64ad2ddd-4869-4047-bde0-047bfbf1ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-34ede88d-fa85-418f-b0ed-8cfdefc7ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-29a4a9bf-f0bf-4618-ac73-379fe8691f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-78f346ba-4517-440c-b9b5-d64bc1370348,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-aa38a8fd-a058-4ef4-8f54-3410055f90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-598993db-7b94-4c14-980a-b1b21cba5887,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-2078dc6b-489e-4b8f-98b1-89b9ccc9839c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387624676-172.17.0.3-1599332409591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-4fc1491d-9aea-4aa1-a2bf-857358811f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-64ad2ddd-4869-4047-bde0-047bfbf1ac77,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-34ede88d-fa85-418f-b0ed-8cfdefc7ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-29a4a9bf-f0bf-4618-ac73-379fe8691f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-78f346ba-4517-440c-b9b5-d64bc1370348,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-aa38a8fd-a058-4ef4-8f54-3410055f90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-598993db-7b94-4c14-980a-b1b21cba5887,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-2078dc6b-489e-4b8f-98b1-89b9ccc9839c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294524412-172.17.0.3-1599332463242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-dfa06d28-6cf0-4f22-8c02-6b9fae5539f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-991f50cb-e401-497e-a644-9eae076dc5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-24748eaa-17cb-4374-a782-9a6a4f07bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-91dd2593-6fdb-4965-8d62-152a4ad2de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-d46ce645-7979-4208-a232-aa098da0ccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f41e38f2-d8de-48f3-afdf-8173b62c879e,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b059f9e7-2075-4d90-848e-d992d328a425,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f2fd2506-cdc3-4004-a8bd-ffe03f060ce1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294524412-172.17.0.3-1599332463242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-dfa06d28-6cf0-4f22-8c02-6b9fae5539f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-991f50cb-e401-497e-a644-9eae076dc5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-24748eaa-17cb-4374-a782-9a6a4f07bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-91dd2593-6fdb-4965-8d62-152a4ad2de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-d46ce645-7979-4208-a232-aa098da0ccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f41e38f2-d8de-48f3-afdf-8173b62c879e,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b059f9e7-2075-4d90-848e-d992d328a425,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-f2fd2506-cdc3-4004-a8bd-ffe03f060ce1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928068410-172.17.0.3-1599332551032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-fe6960b0-5392-44f8-80ad-4a86461c4924,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-232858c9-21af-408d-ab1f-8c55974e6c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-36ea0a13-f513-4542-9156-ffd224123e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a113c467-7245-4650-be90-6bb711838aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-e5c8b3ea-b870-4423-8dd7-f3e23662b727,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-43b099c2-409f-4da7-abcc-267162ea5e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-42bd7bf2-16bf-4be2-865c-671f27eac5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-eee90e10-0c2f-4dd2-b692-bbcd1279da1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928068410-172.17.0.3-1599332551032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-fe6960b0-5392-44f8-80ad-4a86461c4924,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-232858c9-21af-408d-ab1f-8c55974e6c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-36ea0a13-f513-4542-9156-ffd224123e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a113c467-7245-4650-be90-6bb711838aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-e5c8b3ea-b870-4423-8dd7-f3e23662b727,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-43b099c2-409f-4da7-abcc-267162ea5e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-42bd7bf2-16bf-4be2-865c-671f27eac5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-eee90e10-0c2f-4dd2-b692-bbcd1279da1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137715538-172.17.0.3-1599332680441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-291560a7-96e8-4643-9f8d-d0e0ea376104,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-288da9ec-02ca-4709-b0ea-10963b1831fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-930874ed-10b3-4a04-931a-59a11f50f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-667f13f0-2dc4-4596-b0c1-5e1c44e11b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-4826bb80-88c9-407b-9788-112f9e89d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e03432d1-3d88-4d16-a420-da85511e1918,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-45427847-6879-45b0-8b64-752f141d5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7d87da98-d355-4f7f-bf92-d2291652f60e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137715538-172.17.0.3-1599332680441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-291560a7-96e8-4643-9f8d-d0e0ea376104,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-288da9ec-02ca-4709-b0ea-10963b1831fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-930874ed-10b3-4a04-931a-59a11f50f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-667f13f0-2dc4-4596-b0c1-5e1c44e11b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-4826bb80-88c9-407b-9788-112f9e89d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e03432d1-3d88-4d16-a420-da85511e1918,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-45427847-6879-45b0-8b64-752f141d5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7d87da98-d355-4f7f-bf92-d2291652f60e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342020516-172.17.0.3-1599332788569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-8e3a2828-0a42-4a85-8066-c236ed63bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-0da0f737-420b-4c38-8acc-35231e628f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e2b82cfc-b93b-4500-8222-51bc10f9d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f6131891-f243-4584-ac11-ec5794e2c21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-98731204-9a90-4a97-87ea-78b7d1a83339,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-a8f90bd3-d213-45a6-8921-26d4ac8c6636,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-d6183914-a298-4930-8e39-655b39c244f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-f40c4809-d638-4c0c-8247-f7e4d1e7e713,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342020516-172.17.0.3-1599332788569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-8e3a2828-0a42-4a85-8066-c236ed63bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-0da0f737-420b-4c38-8acc-35231e628f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e2b82cfc-b93b-4500-8222-51bc10f9d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f6131891-f243-4584-ac11-ec5794e2c21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-98731204-9a90-4a97-87ea-78b7d1a83339,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-a8f90bd3-d213-45a6-8921-26d4ac8c6636,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-d6183914-a298-4930-8e39-655b39c244f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-f40c4809-d638-4c0c-8247-f7e4d1e7e713,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632409931-172.17.0.3-1599332812897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-e7a47073-1f8a-42cb-b4c5-556cfcc6e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-7151305b-8cb7-48c0-a034-ee6697bc0959,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-42bbe65d-e0fd-4e1e-a138-c9ffdee2de58,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-22991692-aa43-4f3f-b8da-a551494eb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-d7722c2d-ef61-446e-ab46-59ea52b946c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-9cd89d62-435e-4bbf-9329-42b343efdf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-c0910784-13d4-42e9-9ea8-10d7d8b2c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-98c98caf-bbeb-46ab-b245-b8b1b4f973bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632409931-172.17.0.3-1599332812897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-e7a47073-1f8a-42cb-b4c5-556cfcc6e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-7151305b-8cb7-48c0-a034-ee6697bc0959,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-42bbe65d-e0fd-4e1e-a138-c9ffdee2de58,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-22991692-aa43-4f3f-b8da-a551494eb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-d7722c2d-ef61-446e-ab46-59ea52b946c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-9cd89d62-435e-4bbf-9329-42b343efdf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-c0910784-13d4-42e9-9ea8-10d7d8b2c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-98c98caf-bbeb-46ab-b245-b8b1b4f973bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734160488-172.17.0.3-1599333060444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35776,DS-31f5e8cc-147d-4f0c-86b6-7bb33f618b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-cbfaaef6-4cb0-40b9-9c66-3b2e6bbdc980,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e9cb38b9-cc67-43b3-b07c-cc8d1ff1c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-868e065b-fc95-46af-b786-c712e4153446,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-aa8f4441-af23-4765-957b-131dc87a8ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-eb75f1a1-a758-4a3f-b204-85c3a8e626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-6b836995-25cc-490f-b181-1cf475820462,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-9d614593-2b83-4f4e-9a10-968a65de80cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734160488-172.17.0.3-1599333060444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35776,DS-31f5e8cc-147d-4f0c-86b6-7bb33f618b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-cbfaaef6-4cb0-40b9-9c66-3b2e6bbdc980,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e9cb38b9-cc67-43b3-b07c-cc8d1ff1c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-868e065b-fc95-46af-b786-c712e4153446,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-aa8f4441-af23-4765-957b-131dc87a8ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-eb75f1a1-a758-4a3f-b204-85c3a8e626d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-6b836995-25cc-490f-b181-1cf475820462,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-9d614593-2b83-4f4e-9a10-968a65de80cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757317819-172.17.0.3-1599333090987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-50be6234-28e6-4d7b-bc51-02665e70b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-b420ec31-0bc4-416c-ac26-3cbb4aed41c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-076fc290-2fb9-4fa2-b190-02d161ae9ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-1510839d-c9ff-4137-a801-06054fd43a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-27dcf8e8-6275-4fd2-9c44-97b2b12be7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-9a1dc060-1933-4645-85ad-0b0c601b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-891ff271-b81e-4575-b70e-d0f87e6edf52,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-f89fc88a-1e67-4ef6-a8ff-0dcb6c352238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757317819-172.17.0.3-1599333090987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-50be6234-28e6-4d7b-bc51-02665e70b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-b420ec31-0bc4-416c-ac26-3cbb4aed41c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-076fc290-2fb9-4fa2-b190-02d161ae9ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-1510839d-c9ff-4137-a801-06054fd43a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-27dcf8e8-6275-4fd2-9c44-97b2b12be7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-9a1dc060-1933-4645-85ad-0b0c601b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-891ff271-b81e-4575-b70e-d0f87e6edf52,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-f89fc88a-1e67-4ef6-a8ff-0dcb6c352238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949127981-172.17.0.3-1599333115509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-e3cf7ec0-db24-4d95-9218-f8350d7bc9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-b366b538-942f-4c74-9cc8-9b3fa1763a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-ef9e41f0-7514-4e6b-997b-c3c154f7c776,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-84e6a959-27c9-49e5-81bc-c80cec3635b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-844e7612-b3fd-4c05-bf96-9e734a83a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-7d6b56fb-2284-4e85-a8bc-ff64c9feba75,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-cac8e5e0-6f0c-4fba-802e-f0f206a34a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-36694861-3892-4f52-b5ac-7921ec964a6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949127981-172.17.0.3-1599333115509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40672,DS-e3cf7ec0-db24-4d95-9218-f8350d7bc9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-b366b538-942f-4c74-9cc8-9b3fa1763a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-ef9e41f0-7514-4e6b-997b-c3c154f7c776,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-84e6a959-27c9-49e5-81bc-c80cec3635b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-844e7612-b3fd-4c05-bf96-9e734a83a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-7d6b56fb-2284-4e85-a8bc-ff64c9feba75,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-cac8e5e0-6f0c-4fba-802e-f0f206a34a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-36694861-3892-4f52-b5ac-7921ec964a6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188134227-172.17.0.3-1599333193644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-89c24c63-70a2-410f-840d-119e716fd1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-a6d7c8b3-bf04-4562-81e4-2c441b312012,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-9ff1352e-aa91-4fef-9802-a1f20f4a7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-46daa3a2-d99c-4e5b-a363-7868dbf9d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-62234e96-a3e8-4720-a41b-9bbb670110c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-ae30c5a8-13d1-4e67-8925-0c384074e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-0c0466a7-c217-4c53-b225-c3cad4905482,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-4303c4a9-d471-4c94-aa82-905791d7d572,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188134227-172.17.0.3-1599333193644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-89c24c63-70a2-410f-840d-119e716fd1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-a6d7c8b3-bf04-4562-81e4-2c441b312012,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-9ff1352e-aa91-4fef-9802-a1f20f4a7fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-46daa3a2-d99c-4e5b-a363-7868dbf9d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-62234e96-a3e8-4720-a41b-9bbb670110c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-ae30c5a8-13d1-4e67-8925-0c384074e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-0c0466a7-c217-4c53-b225-c3cad4905482,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-4303c4a9-d471-4c94-aa82-905791d7d572,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598862381-172.17.0.3-1599333327359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-0cee18c1-1957-47ad-aaab-b8d845434985,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-69d0d476-c1c6-4699-a6e1-48df35e57d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-e7ffc385-605e-44e5-99ad-b2e7d76a60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2560ba28-ad7c-4dae-911c-0a9b0c3c9dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-68c9a989-09ca-4df9-8192-30c8aebdc940,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-184bae09-4c3e-47c2-8308-973a57ea71b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-07b420f7-ae9f-4524-a6f8-b0fa1334b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-179f734c-722a-45f4-859e-b23bba293c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598862381-172.17.0.3-1599333327359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-0cee18c1-1957-47ad-aaab-b8d845434985,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-69d0d476-c1c6-4699-a6e1-48df35e57d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-e7ffc385-605e-44e5-99ad-b2e7d76a60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2560ba28-ad7c-4dae-911c-0a9b0c3c9dce,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-68c9a989-09ca-4df9-8192-30c8aebdc940,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-184bae09-4c3e-47c2-8308-973a57ea71b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-07b420f7-ae9f-4524-a6f8-b0fa1334b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-179f734c-722a-45f4-859e-b23bba293c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937612707-172.17.0.3-1599333376372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-fbdbe19a-a71a-4889-a26d-6914d170d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-7f022f46-7a50-4bb1-b9ae-246b4f271844,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-ebf0457e-f634-4ff0-aae6-51dfd490619b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-2987bd53-99d6-4885-b3b6-c62601d0fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-a934b42c-3c22-4fe9-8b66-ee01b7b8652e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7aae389c-ef08-4d7e-9ab0-00d8c7d485d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-3fcd9463-db1f-4e75-93a4-e31e06ba8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-4754ed83-f09f-4d50-9fec-0c6d9f5faf6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937612707-172.17.0.3-1599333376372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35017,DS-fbdbe19a-a71a-4889-a26d-6914d170d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-7f022f46-7a50-4bb1-b9ae-246b4f271844,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-ebf0457e-f634-4ff0-aae6-51dfd490619b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-2987bd53-99d6-4885-b3b6-c62601d0fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-a934b42c-3c22-4fe9-8b66-ee01b7b8652e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-7aae389c-ef08-4d7e-9ab0-00d8c7d485d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-3fcd9463-db1f-4e75-93a4-e31e06ba8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-4754ed83-f09f-4d50-9fec-0c6d9f5faf6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622266998-172.17.0.3-1599333598094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-292b9909-a726-4d90-926c-fde81081579b,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-de4dc3c8-32bf-4abc-ac46-9f393fc5675c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-dd407d57-3795-4a5d-af15-b2cd62b839d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ae6f7b02-376e-412b-abd3-9c451b2400a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-479f642c-dd9f-438b-8c39-0b59fb30d796,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-c19a0871-d290-4336-b405-7378957a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-ff3ab114-2d2e-4cac-8f8c-0ed3fe17e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2046a77d-6f16-4aeb-9693-c93cca5e8d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622266998-172.17.0.3-1599333598094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-292b9909-a726-4d90-926c-fde81081579b,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-de4dc3c8-32bf-4abc-ac46-9f393fc5675c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-dd407d57-3795-4a5d-af15-b2cd62b839d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ae6f7b02-376e-412b-abd3-9c451b2400a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-479f642c-dd9f-438b-8c39-0b59fb30d796,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-c19a0871-d290-4336-b405-7378957a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-ff3ab114-2d2e-4cac-8f8c-0ed3fe17e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-2046a77d-6f16-4aeb-9693-c93cca5e8d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253235953-172.17.0.3-1599333684007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-f664d2be-9fb6-4abf-9fae-286b375ad561,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-a92fe59e-0ebd-4daa-93c1-a8248d65fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-46cb8310-d537-4324-9071-c54c5ee90eca,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-2c8d3eb9-df44-448b-90ff-7fb9965fa907,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-5233d14e-56c5-47ac-8756-7b4ca5d30c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-3e5769ab-7ef4-4117-8b1f-6d287d449d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-9a8f1102-5300-4c41-a7d2-cdb1926fa3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-84e64f70-e830-4aed-900f-ea4544821cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253235953-172.17.0.3-1599333684007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-f664d2be-9fb6-4abf-9fae-286b375ad561,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-a92fe59e-0ebd-4daa-93c1-a8248d65fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-46cb8310-d537-4324-9071-c54c5ee90eca,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-2c8d3eb9-df44-448b-90ff-7fb9965fa907,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-5233d14e-56c5-47ac-8756-7b4ca5d30c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-3e5769ab-7ef4-4117-8b1f-6d287d449d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-9a8f1102-5300-4c41-a7d2-cdb1926fa3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-84e64f70-e830-4aed-900f-ea4544821cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42363149-172.17.0.3-1599333770196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46065,DS-74d6b1e7-0823-4695-9f3a-1f23d47fd51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-dd60e33f-425c-4e20-a931-70a3ca72cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-b87dcbb5-ffe8-4e57-815a-bacec54f1441,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-3878ff3b-53ca-473d-8d74-e537fd6dbc30,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-c80af8a3-906b-44a9-a2e6-bf7a12c1bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-320b195b-de45-43bf-9d5d-9278576ced47,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-289a50d5-5c50-445d-b7f7-c2037b016c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-23f26b9c-b432-46a3-80c3-9381c072e4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42363149-172.17.0.3-1599333770196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46065,DS-74d6b1e7-0823-4695-9f3a-1f23d47fd51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-dd60e33f-425c-4e20-a931-70a3ca72cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-b87dcbb5-ffe8-4e57-815a-bacec54f1441,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-3878ff3b-53ca-473d-8d74-e537fd6dbc30,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-c80af8a3-906b-44a9-a2e6-bf7a12c1bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-320b195b-de45-43bf-9d5d-9278576ced47,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-289a50d5-5c50-445d-b7f7-c2037b016c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-23f26b9c-b432-46a3-80c3-9381c072e4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468944427-172.17.0.3-1599333828146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-c918ec44-6969-4868-a937-2daa6022d517,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-d023863b-e913-4ce6-b2ee-6cd2b4f3c4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-f5a0f1ad-c753-4384-9658-7182fc9f81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-eb295026-5d3b-434a-9e6f-fcfdf89c6692,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-527ce804-5a4b-49f1-9afa-f0c416ba3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-b97c5db3-5fd2-4914-a107-2ff2b857f786,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-cb3c2a5f-7e67-4f20-bd4c-29a5de26ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-36179e26-4fcb-4ef2-af5c-7ba5aeded8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468944427-172.17.0.3-1599333828146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-c918ec44-6969-4868-a937-2daa6022d517,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-d023863b-e913-4ce6-b2ee-6cd2b4f3c4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-f5a0f1ad-c753-4384-9658-7182fc9f81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-eb295026-5d3b-434a-9e6f-fcfdf89c6692,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-527ce804-5a4b-49f1-9afa-f0c416ba3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-b97c5db3-5fd2-4914-a107-2ff2b857f786,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-cb3c2a5f-7e67-4f20-bd4c-29a5de26ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-36179e26-4fcb-4ef2-af5c-7ba5aeded8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595485641-172.17.0.3-1599333887502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-d0b025c6-b2e6-4446-b567-330c41dbc9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-89889014-ab93-4594-a987-2838bb191d99,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-3576515f-60cd-4170-9526-46844a60c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-ee35d821-1a5e-4702-986f-7c10af3f2621,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-f3ac2d30-ca22-4543-a3da-1302ef8c039e,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-7e988a20-91bb-42a8-8c80-4ec99406a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-f59e0e68-b51d-4b7a-bc4c-32a828aead8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-b2837542-a4ab-4112-ab8e-b0ce7605f1e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595485641-172.17.0.3-1599333887502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-d0b025c6-b2e6-4446-b567-330c41dbc9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-89889014-ab93-4594-a987-2838bb191d99,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-3576515f-60cd-4170-9526-46844a60c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-ee35d821-1a5e-4702-986f-7c10af3f2621,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-f3ac2d30-ca22-4543-a3da-1302ef8c039e,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-7e988a20-91bb-42a8-8c80-4ec99406a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-f59e0e68-b51d-4b7a-bc4c-32a828aead8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-b2837542-a4ab-4112-ab8e-b0ce7605f1e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: File /striped/stripedFileChecksum1 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

stackTrace: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /striped/stripedFileChecksum1 could only be written to 5 of the 6 required nodes for RS-6-3-1024k. There are 5 datanode(s) running and 5 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2226)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy26.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:517)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy27.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1081)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock(DFSStripedOutputStream.java:480)
	at org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:526)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:217)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:125)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:111)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)
	at org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:865)
	at org.apache.hadoop.hdfs.TestFileChecksum.prepareTestFiles(TestFileChecksum.java:602)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:292)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 18 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 4247
