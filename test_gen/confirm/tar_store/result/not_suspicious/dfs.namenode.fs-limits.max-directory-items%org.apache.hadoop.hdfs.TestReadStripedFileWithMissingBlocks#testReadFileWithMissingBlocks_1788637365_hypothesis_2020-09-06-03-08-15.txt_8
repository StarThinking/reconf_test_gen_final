reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-68adbd2d-c669-452d-9371-494ae96f643f,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-0629d6e4-9390-4bc7-aa47-1170a81baf31,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-12f15174-b2fa-4059-8db5-4151bd7dd124,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-48392c49-9e56-403b-950d-5cc8f2e19f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-2b386a35-5766-4dd8-90f4-5971bd6de531,DISK]]; indices=[3, 4, 5, 6, 8]}, LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6327db59-e894-4ae6-a24f-674f672e722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-a802154e-188b-4506-ba19-876df8e4c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-64905352-a3da-4738-b6f7-5612c404d693,DISK]]; indices=[6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6327db59-e894-4ae6-a24f-674f672e722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-a802154e-188b-4506-ba19-876df8e4c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-64905352-a3da-4738-b6f7-5612c404d693,DISK]]; indices=[6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-68adbd2d-c669-452d-9371-494ae96f643f,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-0629d6e4-9390-4bc7-aa47-1170a81baf31,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-12f15174-b2fa-4059-8db5-4151bd7dd124,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-48392c49-9e56-403b-950d-5cc8f2e19f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-2b386a35-5766-4dd8-90f4-5971bd6de531,DISK]]; indices=[3, 4, 5, 6, 8]}, LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6327db59-e894-4ae6-a24f-674f672e722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-a802154e-188b-4506-ba19-876df8e4c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-64905352-a3da-4738-b6f7-5612c404d693,DISK]]; indices=[6, 7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-1750799362-172.17.0.6-1599376620300:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-6327db59-e894-4ae6-a24f-674f672e722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-a802154e-188b-4506-ba19-876df8e4c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-64905352-a3da-4738-b6f7-5612c404d693,DISK]]; indices=[6, 7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-2843ff92-39c5-4dda-96ff-a4b63a5dc787,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-518945b6-5710-4a74-9c6f-c2d89ff05713,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fd4fa23d-7258-45bf-9714-054ae3afe64d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-dfaede88-9fbe-4555-96a5-9bcf3fed3283,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7cbacc55-3129-4b48-bfca-ca64e5ced157,DISK]]; indices=[2, 3, 4, 5, 6]}, LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-83b6d7ce-5f3f-4c5f-8639-603260525a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-df5976f0-d49e-4aff-8657-930b003bc543,DISK]]; indices=[7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-83b6d7ce-5f3f-4c5f-8639-603260525a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-df5976f0-d49e-4aff-8657-930b003bc543,DISK]]; indices=[7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=2097152, length=61, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=25165947;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775792_1001; getBlockSize()=25165824; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-2843ff92-39c5-4dda-96ff-a4b63a5dc787,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-518945b6-5710-4a74-9c6f-c2d89ff05713,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-fd4fa23d-7258-45bf-9714-054ae3afe64d,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-dfaede88-9fbe-4555-96a5-9bcf3fed3283,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7cbacc55-3129-4b48-bfca-ca64e5ced157,DISK]]; indices=[2, 3, 4, 5, 6]}, LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-83b6d7ce-5f3f-4c5f-8639-603260525a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-df5976f0-d49e-4aff-8657-930b003bc543,DISK]]; indices=[7, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-466233838-172.17.0.6-1599379589873:blk_-9223372036854775776_1002; getBlockSize()=123; corrupt=false; offset=25165824; locs=[DatanodeInfoWithStorage[127.0.0.1:44576,DS-83b6d7ce-5f3f-4c5f-8639-603260525a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-df5976f0-d49e-4aff-8657-930b003bc543,DISK]]; indices=[7, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.assertSeekAndRead(StripedFileTestUtil.java:207)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifySeek(StripedFileTestUtil.java:157)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:132)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: null
stackTrace: java.lang.NullPointerException
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2368)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.restartDeadDataNodes(TestReadStripedFileWithMissingBlocks.java:145)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.readFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:138)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks#testReadFileWithMissingBlocks
reconfPoint: 1
result: -1
failureMessage: Timed out waiting for /foo to have all the internalBlocks
stackTrace: java.util.concurrent.TimeoutException: Timed out waiting for /foo to have all the internalBlocks
	at org.apache.hadoop.hdfs.StripedFileTestUtil.waitBlockGroupsReported(StripedFileTestUtil.java:296)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.waitBlockGroupsReported(StripedFileTestUtil.java:257)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks(TestReadStripedFileWithMissingBlocks.java:90)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 28854
