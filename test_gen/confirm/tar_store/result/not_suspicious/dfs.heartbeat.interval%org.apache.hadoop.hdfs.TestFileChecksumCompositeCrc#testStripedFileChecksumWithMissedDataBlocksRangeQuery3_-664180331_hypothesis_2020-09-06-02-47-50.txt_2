reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415143776-172.17.0.2-1599361128034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-49e965dd-52f2-4912-a9a9-b2ca4dae7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-78836659-6ade-4b6c-a993-827debdfc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ab903170-9e71-42d5-9450-cc0e049fd53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-2fd03096-580c-4175-ba5b-02c0c1b8837c,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-81f54ad4-7fea-4b4f-b7ed-5a08315e4446,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-cd21a5bd-bbd5-4fd6-b8e3-ff812f3effc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-05eb3988-ced6-483f-a5b7-e7284032ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-755517f6-1c29-45ee-9ffe-818d7edf560e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415143776-172.17.0.2-1599361128034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-49e965dd-52f2-4912-a9a9-b2ca4dae7d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-78836659-6ade-4b6c-a993-827debdfc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ab903170-9e71-42d5-9450-cc0e049fd53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-2fd03096-580c-4175-ba5b-02c0c1b8837c,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-81f54ad4-7fea-4b4f-b7ed-5a08315e4446,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-cd21a5bd-bbd5-4fd6-b8e3-ff812f3effc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-05eb3988-ced6-483f-a5b7-e7284032ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-755517f6-1c29-45ee-9ffe-818d7edf560e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328216890-172.17.0.2-1599361777740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-e4af56af-4d01-4352-8110-e5afe7416854,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-38b04728-90c8-4ff3-a7e6-868656097880,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4f726ee6-8588-427d-8e25-2be817d8f698,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-d972489c-8135-4678-b79d-3e73c3fc882d,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-e9afac02-b20f-4ccd-afbb-98b824fedc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-e3811d60-ffa6-483c-abaf-832eb85b433a,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-539f4084-7171-47f3-89fa-39ce36933d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-cd6ae3a8-2778-4372-9282-82ffb519cf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328216890-172.17.0.2-1599361777740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-e4af56af-4d01-4352-8110-e5afe7416854,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-38b04728-90c8-4ff3-a7e6-868656097880,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4f726ee6-8588-427d-8e25-2be817d8f698,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-d972489c-8135-4678-b79d-3e73c3fc882d,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-e9afac02-b20f-4ccd-afbb-98b824fedc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-e3811d60-ffa6-483c-abaf-832eb85b433a,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-539f4084-7171-47f3-89fa-39ce36933d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-cd6ae3a8-2778-4372-9282-82ffb519cf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255365005-172.17.0.2-1599362011793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-59c9beca-44a9-4390-ad4d-531f2a0c992b,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-35116b5a-c824-4bde-9e84-972e297fc0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-d07d4fa2-b275-42bd-ab4b-c04ecbd170af,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-3487a3a9-3355-4840-84b2-31c8b12820e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-a377cedb-df5b-4c0e-91ad-b34835ff13ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0fb843c9-4016-44a3-861f-be6e3a0b55e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-cfc62bc5-3459-4f29-9dcb-ffc38a7d6f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-f2a41be9-118d-4762-9ea8-1f9dc45e6229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255365005-172.17.0.2-1599362011793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-59c9beca-44a9-4390-ad4d-531f2a0c992b,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-35116b5a-c824-4bde-9e84-972e297fc0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-d07d4fa2-b275-42bd-ab4b-c04ecbd170af,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-3487a3a9-3355-4840-84b2-31c8b12820e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-a377cedb-df5b-4c0e-91ad-b34835ff13ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0fb843c9-4016-44a3-861f-be6e3a0b55e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-cfc62bc5-3459-4f29-9dcb-ffc38a7d6f24,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-f2a41be9-118d-4762-9ea8-1f9dc45e6229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308564257-172.17.0.2-1599362250892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-da40c4ad-2317-4d85-8fbd-e124998f8402,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-59662eb6-c76f-4ff4-a40c-719a50d27d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-61852c55-4649-43cf-a2ed-f488fc76ab4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-bff39a74-f66c-4500-bf52-9acf7f01fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d34c648d-2111-4655-9606-e6d562b4993f,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-5308a364-a4ac-4e1a-b4d5-06cf54703508,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-aba65f56-b7e4-4903-8b5e-7562434fe473,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-9c1c8cb8-eac1-42f4-a34e-1cc687ac79a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308564257-172.17.0.2-1599362250892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-da40c4ad-2317-4d85-8fbd-e124998f8402,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-59662eb6-c76f-4ff4-a40c-719a50d27d13,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-61852c55-4649-43cf-a2ed-f488fc76ab4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-bff39a74-f66c-4500-bf52-9acf7f01fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d34c648d-2111-4655-9606-e6d562b4993f,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-5308a364-a4ac-4e1a-b4d5-06cf54703508,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-aba65f56-b7e4-4903-8b5e-7562434fe473,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-9c1c8cb8-eac1-42f4-a34e-1cc687ac79a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088077578-172.17.0.2-1599362307734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-4db6320c-01db-4609-b24e-18e39628a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-34d57a1c-64fd-43d4-a11f-6a96dec0d7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-84d9c67b-4b39-4229-a167-09ecb5ec74f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-c0544334-ebc9-4144-b470-c63350cc6e77,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-669720f8-1271-4cfb-b454-9720c3ed7a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-9a7d0783-4603-4e5f-88d5-28092dff253f,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-a6ec2dc5-f37a-4e7f-ab06-0a70767b1390,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-3433735d-3e53-4232-8eca-c64c19c576f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088077578-172.17.0.2-1599362307734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-4db6320c-01db-4609-b24e-18e39628a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-34d57a1c-64fd-43d4-a11f-6a96dec0d7da,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-84d9c67b-4b39-4229-a167-09ecb5ec74f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-c0544334-ebc9-4144-b470-c63350cc6e77,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-669720f8-1271-4cfb-b454-9720c3ed7a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-9a7d0783-4603-4e5f-88d5-28092dff253f,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-a6ec2dc5-f37a-4e7f-ab06-0a70767b1390,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-3433735d-3e53-4232-8eca-c64c19c576f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183156761-172.17.0.2-1599362749103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-d09dfebc-6153-4a7d-a2c4-3a907907c8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-baca5c62-3a47-4655-8974-9b18ce0f6f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-e2ed3957-94ae-4065-9403-14475d530fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-85f987e5-9bd9-44a9-bdb7-8be24dd40bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-06ab3ae5-dd9b-410c-b872-176c84b93b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-ec3777a9-6e6e-4ac4-bc86-992037510da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-b2f18c70-7139-4a53-b32c-fd8294b49232,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-06078819-e56a-4a6c-b1a6-f47f8c794c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183156761-172.17.0.2-1599362749103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-d09dfebc-6153-4a7d-a2c4-3a907907c8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-baca5c62-3a47-4655-8974-9b18ce0f6f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-e2ed3957-94ae-4065-9403-14475d530fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-85f987e5-9bd9-44a9-bdb7-8be24dd40bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-06ab3ae5-dd9b-410c-b872-176c84b93b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-ec3777a9-6e6e-4ac4-bc86-992037510da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-b2f18c70-7139-4a53-b32c-fd8294b49232,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-06078819-e56a-4a6c-b1a6-f47f8c794c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254446195-172.17.0.2-1599362779352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-3025dd4c-fa41-452a-8493-5bbfb9b8ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-18152710-2afb-4cb8-a105-b46ae409e628,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-71d660ab-1cca-4785-83f0-3757c0eea3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5f1421d8-3edd-4b2f-9175-6fd7f9607d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-93afcf58-07f9-4ec3-b279-8c5ae83f80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-12062791-205f-4113-b3e0-4a8a6f5f3051,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-82a1ad27-0a65-44c3-84ab-fbfcfe736a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-86af60a3-33e6-4c47-bbcf-30bea9e191fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254446195-172.17.0.2-1599362779352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-3025dd4c-fa41-452a-8493-5bbfb9b8ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-18152710-2afb-4cb8-a105-b46ae409e628,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-71d660ab-1cca-4785-83f0-3757c0eea3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5f1421d8-3edd-4b2f-9175-6fd7f9607d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-93afcf58-07f9-4ec3-b279-8c5ae83f80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-12062791-205f-4113-b3e0-4a8a6f5f3051,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-82a1ad27-0a65-44c3-84ab-fbfcfe736a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-86af60a3-33e6-4c47-bbcf-30bea9e191fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498273196-172.17.0.2-1599362894367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-6e793bf1-3ec2-4b57-a8b8-4848f4c23401,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-bc715190-b386-43e5-9528-3080e10d397f,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-60c6f634-c0e2-45f5-a5db-a986baba3be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-56f05bc3-969b-42f0-a2d2-05bb9f12554d,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-1876c991-1b4c-4bcf-8ab3-ad10f9345d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b1da1d69-4f30-4ec5-af47-b4c3c2f48488,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-07d31527-4f1f-4252-9540-f9ffa9f7922b,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-646fa68c-f070-4179-9d44-4a3695f40ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498273196-172.17.0.2-1599362894367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-6e793bf1-3ec2-4b57-a8b8-4848f4c23401,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-bc715190-b386-43e5-9528-3080e10d397f,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-60c6f634-c0e2-45f5-a5db-a986baba3be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-56f05bc3-969b-42f0-a2d2-05bb9f12554d,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-1876c991-1b4c-4bcf-8ab3-ad10f9345d86,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b1da1d69-4f30-4ec5-af47-b4c3c2f48488,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-07d31527-4f1f-4252-9540-f9ffa9f7922b,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-646fa68c-f070-4179-9d44-4a3695f40ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347734033-172.17.0.2-1599363134318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-46e4e973-cb2d-455c-ba0d-093a4ad5b688,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-d150c4b9-ba10-4d09-bb17-bda73ce501be,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-0e12bdb1-9d83-45eb-97e6-b25e91055afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-ba9309e2-3fb6-44ea-a223-7b6633db0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-59f3da7e-d21e-4358-a4dd-a579fa031807,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-254f106e-270d-4152-9d32-a4298d3c1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c41e4141-8e2d-4562-a3ae-9f89102be272,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-89f85c84-face-4cc5-bb16-dc1aaf489e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347734033-172.17.0.2-1599363134318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-46e4e973-cb2d-455c-ba0d-093a4ad5b688,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-d150c4b9-ba10-4d09-bb17-bda73ce501be,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-0e12bdb1-9d83-45eb-97e6-b25e91055afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-ba9309e2-3fb6-44ea-a223-7b6633db0c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-59f3da7e-d21e-4358-a4dd-a579fa031807,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-254f106e-270d-4152-9d32-a4298d3c1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c41e4141-8e2d-4562-a3ae-9f89102be272,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-89f85c84-face-4cc5-bb16-dc1aaf489e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004804006-172.17.0.2-1599363160803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-c49295fc-b31e-430d-8f8a-87905447e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-e1f2fe7b-7533-4cc3-a99a-8c85cb13fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-d31f820f-9a8f-47c7-97a8-c5f79d9545d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-a8b79e18-1f7b-41fa-87c1-d56174ab1574,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-9b0b4e76-d23a-41da-9e8a-65b44e540d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-f8d7e187-8191-40ae-899c-d34ead4cd8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-804ec259-cdfa-4ab5-96c9-dfd46569e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a4d28bd6-7fc4-43a7-b38f-d1f47ec908f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004804006-172.17.0.2-1599363160803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-c49295fc-b31e-430d-8f8a-87905447e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-e1f2fe7b-7533-4cc3-a99a-8c85cb13fcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-d31f820f-9a8f-47c7-97a8-c5f79d9545d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-a8b79e18-1f7b-41fa-87c1-d56174ab1574,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-9b0b4e76-d23a-41da-9e8a-65b44e540d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-f8d7e187-8191-40ae-899c-d34ead4cd8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-804ec259-cdfa-4ab5-96c9-dfd46569e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a4d28bd6-7fc4-43a7-b38f-d1f47ec908f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621651700-172.17.0.2-1599363441557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-a1b16307-98c2-47ab-8402-2294ed330357,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-afb695bd-a92f-4339-ae58-c1d790fd101a,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-078ee596-e506-4e21-9253-c5d29c9b8e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-497c92ce-2238-4c4a-8e89-dcdbcadc80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-ac61b14b-0026-4048-99c1-3ea0b81c6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-c0251d2c-26e8-40d4-8b4e-64fa7e41b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-fdcffceb-5675-4cde-a21a-bbf3bdf9e3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-6d950d09-801c-41b3-b206-eee0fa9c8e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621651700-172.17.0.2-1599363441557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-a1b16307-98c2-47ab-8402-2294ed330357,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-afb695bd-a92f-4339-ae58-c1d790fd101a,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-078ee596-e506-4e21-9253-c5d29c9b8e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-497c92ce-2238-4c4a-8e89-dcdbcadc80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-ac61b14b-0026-4048-99c1-3ea0b81c6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-c0251d2c-26e8-40d4-8b4e-64fa7e41b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-fdcffceb-5675-4cde-a21a-bbf3bdf9e3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-6d950d09-801c-41b3-b206-eee0fa9c8e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311806658-172.17.0.2-1599364032584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-eeb5624c-319b-435f-87bf-339439a3a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-96f2566c-5a53-4183-8c3e-e6f05ca1943d,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-fef5b348-3a80-4e50-9ba9-887f4b0fd7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-e96d20b8-8ffb-4654-8bf0-5f13bb7b3f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-96e52799-df51-4f84-89d8-725b6f829a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-44f966a3-7507-45ae-a36a-414f9d3fedbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-121946de-7067-49be-b0e6-194c7dbd449e,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-00138a23-fb56-4701-b295-fd74f3772d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311806658-172.17.0.2-1599364032584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-eeb5624c-319b-435f-87bf-339439a3a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-96f2566c-5a53-4183-8c3e-e6f05ca1943d,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-fef5b348-3a80-4e50-9ba9-887f4b0fd7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-e96d20b8-8ffb-4654-8bf0-5f13bb7b3f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-96e52799-df51-4f84-89d8-725b6f829a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-44f966a3-7507-45ae-a36a-414f9d3fedbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-121946de-7067-49be-b0e6-194c7dbd449e,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-00138a23-fb56-4701-b295-fd74f3772d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566204439-172.17.0.2-1599364395869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-4697cd85-8a9a-4d11-b093-5698ec5ca6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-6546b6fe-7ce4-4a64-9e55-8b0a8c950775,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-f63fb14f-c062-457a-8723-076ef0db6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-74681d6d-3b00-428d-854f-585bd26414a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-4d81e442-94ef-404a-b1bd-67416c9f420c,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8508dfa9-de2b-4281-a7fb-ce07ff159afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-800cc02c-21ed-4fe3-a0ac-e7e3b84ff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-6b52f908-ad3f-4d99-9c2b-9e8286614a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566204439-172.17.0.2-1599364395869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-4697cd85-8a9a-4d11-b093-5698ec5ca6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-6546b6fe-7ce4-4a64-9e55-8b0a8c950775,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-f63fb14f-c062-457a-8723-076ef0db6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-74681d6d-3b00-428d-854f-585bd26414a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-4d81e442-94ef-404a-b1bd-67416c9f420c,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8508dfa9-de2b-4281-a7fb-ce07ff159afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-800cc02c-21ed-4fe3-a0ac-e7e3b84ff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-6b52f908-ad3f-4d99-9c2b-9e8286614a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939791999-172.17.0.2-1599364485714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-95a6ccd5-72e4-4c68-9494-caaa52a1f701,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-a76f7eab-df5b-49c3-b5ae-1e3aaadd88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-25920f16-1824-4e78-b96a-98520264b018,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-b7f2ec7e-d289-4332-87b7-d93066de7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-28d29251-e0b6-44a3-8913-4329bc4475ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-02ba4db3-e51e-4fe6-b427-99a66b827edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-8ae54c78-4a88-49e5-a38d-2e1e7b50a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-0f4c4d3b-47fc-4398-a7fd-6ff1232af87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939791999-172.17.0.2-1599364485714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-95a6ccd5-72e4-4c68-9494-caaa52a1f701,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-a76f7eab-df5b-49c3-b5ae-1e3aaadd88b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-25920f16-1824-4e78-b96a-98520264b018,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-b7f2ec7e-d289-4332-87b7-d93066de7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-28d29251-e0b6-44a3-8913-4329bc4475ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-02ba4db3-e51e-4fe6-b427-99a66b827edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-8ae54c78-4a88-49e5-a38d-2e1e7b50a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-0f4c4d3b-47fc-4398-a7fd-6ff1232af87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565854447-172.17.0.2-1599364576026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-6d2a51b6-cfb8-450d-864d-7577270fab33,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-80bd8f86-74d4-4b0d-ae20-7895894bc43f,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c859a3a2-7663-4659-86e5-73b5f665d7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-ad212c22-0a53-4459-9b1e-95b61e2afdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-0a9cd388-8a3e-46cb-af8e-6878c922cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-5cfcdd5b-9994-4618-9142-35b888de6428,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-91d6a5b0-b15c-4515-9570-4a74a0766b37,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-3e59a27f-4e1b-49c0-bc11-b6fa9aeac1e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565854447-172.17.0.2-1599364576026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-6d2a51b6-cfb8-450d-864d-7577270fab33,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-80bd8f86-74d4-4b0d-ae20-7895894bc43f,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c859a3a2-7663-4659-86e5-73b5f665d7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-ad212c22-0a53-4459-9b1e-95b61e2afdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-0a9cd388-8a3e-46cb-af8e-6878c922cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-5cfcdd5b-9994-4618-9142-35b888de6428,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-91d6a5b0-b15c-4515-9570-4a74a0766b37,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-3e59a27f-4e1b-49c0-bc11-b6fa9aeac1e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011552743-172.17.0.2-1599364940227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-e4a63098-a757-4ec2-9c55-d1553e86547d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1d538527-84b1-49c5-8cec-da36d57db2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-2a6f6043-afd5-477a-9733-9c4c3585c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c5d18cf2-32ae-44bd-afa2-3e578c4f59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-79cc8b55-120d-4f39-9531-19318d598409,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-5833e754-d74c-4c7a-bce3-6885f3ce43a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f1627aaf-5ac6-4494-8ab8-a824b9e5b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5f59f265-8e7b-4e1c-a9c3-187bc27ac6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011552743-172.17.0.2-1599364940227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-e4a63098-a757-4ec2-9c55-d1553e86547d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1d538527-84b1-49c5-8cec-da36d57db2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-2a6f6043-afd5-477a-9733-9c4c3585c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c5d18cf2-32ae-44bd-afa2-3e578c4f59ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-79cc8b55-120d-4f39-9531-19318d598409,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-5833e754-d74c-4c7a-bce3-6885f3ce43a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f1627aaf-5ac6-4494-8ab8-a824b9e5b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5f59f265-8e7b-4e1c-a9c3-187bc27ac6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3s
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610556114-172.17.0.2-1599364976160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-2f88b1db-2af7-4ac5-8fb2-8f8a892f9476,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-e136f529-379c-494d-80c9-7184df44b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-e4ba1f0e-e766-435f-9890-5f175ea34272,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-02e3d6b5-f462-4e4a-bddd-c839d532e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-f51d0804-f82e-49b8-b348-8215fbc88ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-612181e4-45c6-4efc-ab2b-9685f5d28333,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8d6dbf60-9b21-40b7-a1ca-0c777a458cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-b3356cd0-4cc9-496b-ae71-a4ed0f198b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610556114-172.17.0.2-1599364976160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-2f88b1db-2af7-4ac5-8fb2-8f8a892f9476,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-e136f529-379c-494d-80c9-7184df44b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-e4ba1f0e-e766-435f-9890-5f175ea34272,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-02e3d6b5-f462-4e4a-bddd-c839d532e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-f51d0804-f82e-49b8-b348-8215fbc88ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-612181e4-45c6-4efc-ab2b-9685f5d28333,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8d6dbf60-9b21-40b7-a1ca-0c777a458cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-b3356cd0-4cc9-496b-ae71-a4ed0f198b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4557
