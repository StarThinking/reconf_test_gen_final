reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389360712-172.17.0.7-1599354998207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-5c13492a-7e84-4e84-9aa2-c2b164397846,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-5e914aa8-385a-4050-aead-c2e7bb15839d,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-d28ab873-07a9-4675-b5c4-19a9f83c6305,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-ad9be33a-ddb0-4743-86d1-fbb1bb00795f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-a17dce2a-6d9a-447d-991c-1dd53c3bcf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-e10efab4-b8f7-4d40-b1a1-0e2c1f6980d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-fbc09aff-9c8d-4c44-b3a4-5643529d59bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-4e69b1dd-6138-4fff-9971-1622d7e4346c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389360712-172.17.0.7-1599354998207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-5c13492a-7e84-4e84-9aa2-c2b164397846,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-5e914aa8-385a-4050-aead-c2e7bb15839d,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-d28ab873-07a9-4675-b5c4-19a9f83c6305,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-ad9be33a-ddb0-4743-86d1-fbb1bb00795f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-a17dce2a-6d9a-447d-991c-1dd53c3bcf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-e10efab4-b8f7-4d40-b1a1-0e2c1f6980d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-fbc09aff-9c8d-4c44-b3a4-5643529d59bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-4e69b1dd-6138-4fff-9971-1622d7e4346c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466856782-172.17.0.7-1599355027199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39170,DS-116833c7-a320-4bd1-a439-6cf55d2c87a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3147e45d-42f5-4579-873c-b36a8742fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-a26cc1d7-cfb5-47a5-b697-eb337680b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-21b52a59-3e11-412b-a97d-15f81c2daa80,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-5f76f3fe-26a6-45e5-8777-93a645a95ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-5c24da83-89f0-475b-8747-e41c099998d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-a1b7891f-7c5c-4b87-a1c2-156756182e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fb677393-f220-48fd-a140-08d80886a90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466856782-172.17.0.7-1599355027199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39170,DS-116833c7-a320-4bd1-a439-6cf55d2c87a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-3147e45d-42f5-4579-873c-b36a8742fcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-a26cc1d7-cfb5-47a5-b697-eb337680b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-21b52a59-3e11-412b-a97d-15f81c2daa80,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-5f76f3fe-26a6-45e5-8777-93a645a95ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-5c24da83-89f0-475b-8747-e41c099998d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-a1b7891f-7c5c-4b87-a1c2-156756182e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fb677393-f220-48fd-a140-08d80886a90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275311015-172.17.0.7-1599355141826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-ff7f5a4d-39ea-43e3-ad8c-45c88180b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-2f58e5d2-63de-4eb6-88eb-17ed3d85406b,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-085fe365-5539-45f8-8d6c-ca49a20df744,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-8f5fe9a2-42d0-4204-b7aa-36f8014f67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-4754d645-cdfa-4897-9c62-533431ba578f,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-48fa84b5-8b5c-4192-98ee-33df9c71c33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-d92854ba-ace6-4716-b5bc-e3db992db6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-71e3c41e-1025-49f7-97f1-49a6efddca93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275311015-172.17.0.7-1599355141826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43079,DS-ff7f5a4d-39ea-43e3-ad8c-45c88180b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-2f58e5d2-63de-4eb6-88eb-17ed3d85406b,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-085fe365-5539-45f8-8d6c-ca49a20df744,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-8f5fe9a2-42d0-4204-b7aa-36f8014f67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-4754d645-cdfa-4897-9c62-533431ba578f,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-48fa84b5-8b5c-4192-98ee-33df9c71c33b,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-d92854ba-ace6-4716-b5bc-e3db992db6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-71e3c41e-1025-49f7-97f1-49a6efddca93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638712534-172.17.0.7-1599355313433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-2e35fdb6-ccc3-46d2-ae82-418dd8669495,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-69871297-ab6a-4ec3-87e8-3d5efeb3e166,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-a6dd6e4d-9376-4265-a99e-05b7b8b65b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-ce775708-57e5-4c75-bca6-6b05e9c28a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-eb6f4b5f-cc45-4f6e-9f6b-ad91da60dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-555324e8-a9e4-431f-b4e8-01d024f40f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a45bdcaf-2800-481a-b84c-2af8068c757a,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-2edac58b-dba4-40bb-a756-2645946861ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638712534-172.17.0.7-1599355313433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-2e35fdb6-ccc3-46d2-ae82-418dd8669495,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-69871297-ab6a-4ec3-87e8-3d5efeb3e166,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-a6dd6e4d-9376-4265-a99e-05b7b8b65b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-ce775708-57e5-4c75-bca6-6b05e9c28a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-eb6f4b5f-cc45-4f6e-9f6b-ad91da60dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-555324e8-a9e4-431f-b4e8-01d024f40f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a45bdcaf-2800-481a-b84c-2af8068c757a,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-2edac58b-dba4-40bb-a756-2645946861ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494232507-172.17.0.7-1599355471223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-fde12a07-83f6-4f5a-b4da-ae83eb7ca5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-e80cdef3-0d1e-4569-b4a2-2594aa0a7623,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-27012719-ee3a-4d5d-9566-e412610830d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-5cf978cc-0a4a-4524-9749-8145c5d598fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-3ea720f5-cc6a-468a-93b6-70e0eb4e4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-a19edc32-b718-4146-8615-78ce0299e8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4bf19df8-ba1f-47c3-a7cb-77650f0a12d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-78335e90-50a6-4430-9e02-dee34c0b499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494232507-172.17.0.7-1599355471223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-fde12a07-83f6-4f5a-b4da-ae83eb7ca5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-e80cdef3-0d1e-4569-b4a2-2594aa0a7623,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-27012719-ee3a-4d5d-9566-e412610830d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-5cf978cc-0a4a-4524-9749-8145c5d598fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-3ea720f5-cc6a-468a-93b6-70e0eb4e4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-a19edc32-b718-4146-8615-78ce0299e8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4bf19df8-ba1f-47c3-a7cb-77650f0a12d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-78335e90-50a6-4430-9e02-dee34c0b499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20537918-172.17.0.7-1599355542555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-53732157-81c8-494d-be97-8ff50d02ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-eace68cc-262c-4807-ad8c-0954c7b2961a,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-8fca2e07-da3d-4e74-af1f-a20a2fbd9179,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-377c6361-7f73-4d6f-a601-24fb6e2cdeda,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-0570ce06-3419-4440-9a4f-dbc9d84591fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-cb42d0db-9f6b-49e3-b003-327847f56a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-5fe4ce6e-0422-4548-91cf-dc87d607206c,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-e41813ca-99d9-4d2f-b661-e6883b2331bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20537918-172.17.0.7-1599355542555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-53732157-81c8-494d-be97-8ff50d02ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-eace68cc-262c-4807-ad8c-0954c7b2961a,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-8fca2e07-da3d-4e74-af1f-a20a2fbd9179,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-377c6361-7f73-4d6f-a601-24fb6e2cdeda,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-0570ce06-3419-4440-9a4f-dbc9d84591fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-cb42d0db-9f6b-49e3-b003-327847f56a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-5fe4ce6e-0422-4548-91cf-dc87d607206c,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-e41813ca-99d9-4d2f-b661-e6883b2331bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645259616-172.17.0.7-1599356106140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-ce4c58fc-ab36-4290-afbf-ea232de18056,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-247be232-bb2d-4a9b-a500-b51ab6305259,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-9612dbfb-e1f3-4c88-b095-d234d2e72d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-ebd4a9d9-970f-4ce3-bfef-ed1b7d931d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-ac1f30a2-6ddd-4d4e-b226-0b670216ed32,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-44fd97f3-37c0-4612-9b02-f08a860c6822,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-543c4f50-ea67-4c5d-a860-926df7adfe57,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-8f285531-d950-4f22-aa36-1bf2567532f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645259616-172.17.0.7-1599356106140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-ce4c58fc-ab36-4290-afbf-ea232de18056,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-247be232-bb2d-4a9b-a500-b51ab6305259,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-9612dbfb-e1f3-4c88-b095-d234d2e72d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-ebd4a9d9-970f-4ce3-bfef-ed1b7d931d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-ac1f30a2-6ddd-4d4e-b226-0b670216ed32,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-44fd97f3-37c0-4612-9b02-f08a860c6822,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-543c4f50-ea67-4c5d-a860-926df7adfe57,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-8f285531-d950-4f22-aa36-1bf2567532f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111376001-172.17.0.7-1599356166258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-a59f9106-c16f-4be1-b2f8-e9e47d9acbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-c4ae1eab-b67d-448d-8b50-1c1d05b71452,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-55be4663-0198-40fb-8979-f11b69c26f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-95f898c1-7991-45ec-a774-fa25c5bef125,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-d2dced96-0cd3-470d-b19a-4bec525e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-637c6bbb-29c8-44de-bf7e-73d7a6e0398c,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-5c4a0a65-ab63-43dd-a0b8-8de2864d4359,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-668064f3-af99-4259-854b-8506bd83fca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111376001-172.17.0.7-1599356166258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-a59f9106-c16f-4be1-b2f8-e9e47d9acbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-c4ae1eab-b67d-448d-8b50-1c1d05b71452,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-55be4663-0198-40fb-8979-f11b69c26f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-95f898c1-7991-45ec-a774-fa25c5bef125,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-d2dced96-0cd3-470d-b19a-4bec525e1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-637c6bbb-29c8-44de-bf7e-73d7a6e0398c,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-5c4a0a65-ab63-43dd-a0b8-8de2864d4359,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-668064f3-af99-4259-854b-8506bd83fca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378704454-172.17.0.7-1599356292324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-70938ad4-c1de-4ce3-9b65-a6da128c7fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-84c6d475-1fc7-47ab-a050-cdc9384ec7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-fa87cb00-3141-4686-b9f3-ebd8675c454f,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-cc5f1d33-ff08-42ff-a3e8-fd3d6d9838aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b74a9a24-e498-44c6-8f18-36a21ab6e886,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-e8748837-4ea0-4c20-ad8c-efe58180bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-38dd0ad2-bae5-4255-9097-ce4be5018644,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-6644c7a8-b618-40a3-b8ed-3f838e2c1990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378704454-172.17.0.7-1599356292324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46757,DS-70938ad4-c1de-4ce3-9b65-a6da128c7fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-84c6d475-1fc7-47ab-a050-cdc9384ec7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-fa87cb00-3141-4686-b9f3-ebd8675c454f,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-cc5f1d33-ff08-42ff-a3e8-fd3d6d9838aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b74a9a24-e498-44c6-8f18-36a21ab6e886,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-e8748837-4ea0-4c20-ad8c-efe58180bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-38dd0ad2-bae5-4255-9097-ce4be5018644,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-6644c7a8-b618-40a3-b8ed-3f838e2c1990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287232620-172.17.0.7-1599356322232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-1bad901e-cf56-47cd-a2ac-0fb72347b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4bbbae1d-504d-4349-b0b1-56c58f1a78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-be13843a-80bc-47cc-9af3-657ca0fc8219,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-7a77b1f6-5037-447d-8f13-704c664b77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-07eb4f72-f143-41b1-9697-12a7e6e1af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-13ba7222-8e73-42b0-bdc7-c7320da41742,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d7925809-fb5d-462f-bcdd-5f273f968dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-e8d78b45-8442-4210-9a09-052a8351ba5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287232620-172.17.0.7-1599356322232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-1bad901e-cf56-47cd-a2ac-0fb72347b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4bbbae1d-504d-4349-b0b1-56c58f1a78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-be13843a-80bc-47cc-9af3-657ca0fc8219,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-7a77b1f6-5037-447d-8f13-704c664b77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-07eb4f72-f143-41b1-9697-12a7e6e1af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-13ba7222-8e73-42b0-bdc7-c7320da41742,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d7925809-fb5d-462f-bcdd-5f273f968dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-e8d78b45-8442-4210-9a09-052a8351ba5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342777649-172.17.0.7-1599356860716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-8a71cca4-e785-43aa-b155-6ff914fc77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-16e3a0f3-b72d-45bb-b1eb-7a7903726bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-efb4bdd9-1bb7-40fa-bd52-a3e523423bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-78f4f37e-71f7-44db-b060-28cf2f4b49d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-e7a2d7ac-b1c9-4fc9-9677-0845cd64fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-65033313-9139-4407-bea0-45f932c94eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-bfe95717-7083-40c1-9531-2b26551d1e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-34f8f01e-b79b-4770-85be-b14bf1ef7d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342777649-172.17.0.7-1599356860716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-8a71cca4-e785-43aa-b155-6ff914fc77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-16e3a0f3-b72d-45bb-b1eb-7a7903726bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-efb4bdd9-1bb7-40fa-bd52-a3e523423bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-78f4f37e-71f7-44db-b060-28cf2f4b49d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-e7a2d7ac-b1c9-4fc9-9677-0845cd64fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-65033313-9139-4407-bea0-45f932c94eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-bfe95717-7083-40c1-9531-2b26551d1e41,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-34f8f01e-b79b-4770-85be-b14bf1ef7d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273441185-172.17.0.7-1599357112941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37102,DS-91262fd9-e0d2-493d-80bf-001378a7da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ecffc448-5638-4993-b382-21882ce9944e,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-addd81d1-068d-4cd9-9527-18d7073b7b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-3de23887-9a75-4a08-807b-0a6dbc34a6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-58182774-518d-4189-a725-c4d0db2d5c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-fcee6bd9-0ad7-4346-9721-49cd4c93a46a,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-833ca196-aebd-4db2-a5a8-3f71f007af0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-bdb85a04-c0b4-41de-8c58-c3666d840355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273441185-172.17.0.7-1599357112941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37102,DS-91262fd9-e0d2-493d-80bf-001378a7da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ecffc448-5638-4993-b382-21882ce9944e,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-addd81d1-068d-4cd9-9527-18d7073b7b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-3de23887-9a75-4a08-807b-0a6dbc34a6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-58182774-518d-4189-a725-c4d0db2d5c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-fcee6bd9-0ad7-4346-9721-49cd4c93a46a,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-833ca196-aebd-4db2-a5a8-3f71f007af0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-bdb85a04-c0b4-41de-8c58-c3666d840355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854525498-172.17.0.7-1599357624100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-4f123d0e-599d-4c1e-95f1-9688f811d402,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-07a3b314-df14-4857-bf38-3bee3fba5382,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-488839a1-094a-49fd-8e80-16b0f56fc0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-1aad758e-7786-4725-a797-e0034efb4eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-614303e7-1a72-41b9-81d2-e42d72f7f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-b451aa66-0f8c-4011-bdff-4c2cabb03e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-489413dd-7812-42a6-83ab-7fc4f15a4b65,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-538a7de0-68f8-42ef-a25d-78a047ed5b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854525498-172.17.0.7-1599357624100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-4f123d0e-599d-4c1e-95f1-9688f811d402,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-07a3b314-df14-4857-bf38-3bee3fba5382,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-488839a1-094a-49fd-8e80-16b0f56fc0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-1aad758e-7786-4725-a797-e0034efb4eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-614303e7-1a72-41b9-81d2-e42d72f7f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-b451aa66-0f8c-4011-bdff-4c2cabb03e50,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-489413dd-7812-42a6-83ab-7fc4f15a4b65,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-538a7de0-68f8-42ef-a25d-78a047ed5b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137100314-172.17.0.7-1599357860852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-02b47d25-c6cb-4007-90cd-6e9081f7196b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-6f2ddb33-b17e-4174-8565-d5913f9c854a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-472dd62f-07a0-4db2-9e04-0733a1e94edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-f50d6cdc-19f8-43e0-8dec-8bc08e1f989a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f00d7aab-1a6f-452b-b82e-abb97396563a,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-eb153788-b34b-4a09-995f-3018fedb455a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-417b519e-fc8d-48cf-bc80-5ff8cb465ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-7163407e-3c55-429d-b850-cb0aa5cc46da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137100314-172.17.0.7-1599357860852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-02b47d25-c6cb-4007-90cd-6e9081f7196b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-6f2ddb33-b17e-4174-8565-d5913f9c854a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-472dd62f-07a0-4db2-9e04-0733a1e94edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-f50d6cdc-19f8-43e0-8dec-8bc08e1f989a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-f00d7aab-1a6f-452b-b82e-abb97396563a,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-eb153788-b34b-4a09-995f-3018fedb455a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-417b519e-fc8d-48cf-bc80-5ff8cb465ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-7163407e-3c55-429d-b850-cb0aa5cc46da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626317031-172.17.0.7-1599358171769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43471,DS-7c2e96ea-17be-4259-83d9-a667d62edd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-8e7c3f51-13ea-4f47-beb9-318781ce8222,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-200f2aaf-1df9-4a0d-90b5-fb28f6e4529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-b0e97a21-f2e8-429e-86a1-708cee42ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-4ef7e4d4-5b7a-43e9-a6f1-0475dc125e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5847bdd9-19ef-43ea-98ca-d28f6af1ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-c60bcbe8-0f17-416d-a453-1196ac4fd271,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-bf9fba23-8eb7-466c-8f39-79d5d94c69c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626317031-172.17.0.7-1599358171769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43471,DS-7c2e96ea-17be-4259-83d9-a667d62edd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-8e7c3f51-13ea-4f47-beb9-318781ce8222,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-200f2aaf-1df9-4a0d-90b5-fb28f6e4529b,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-b0e97a21-f2e8-429e-86a1-708cee42ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-4ef7e4d4-5b7a-43e9-a6f1-0475dc125e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5847bdd9-19ef-43ea-98ca-d28f6af1ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-c60bcbe8-0f17-416d-a453-1196ac4fd271,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-bf9fba23-8eb7-466c-8f39-79d5d94c69c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908316827-172.17.0.7-1599358248291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-77bba2a4-1678-4d91-81a2-dc4d4a1061ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-7eb95189-1fbe-4021-b696-0541dc557eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-fcf76f86-d911-4bbd-86ec-538dd48208d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-1d3bab01-e3a4-4107-b7f2-19c64abdec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-e4f0667f-7a6c-4f3c-93dc-890a9363b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-7ac14b14-995a-4175-947d-a28ad6ab22de,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-f498d816-c0de-4bb5-adef-2196c17ac978,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-22773e22-27d6-419b-8679-396101a15f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908316827-172.17.0.7-1599358248291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-77bba2a4-1678-4d91-81a2-dc4d4a1061ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-7eb95189-1fbe-4021-b696-0541dc557eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-fcf76f86-d911-4bbd-86ec-538dd48208d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-1d3bab01-e3a4-4107-b7f2-19c64abdec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-e4f0667f-7a6c-4f3c-93dc-890a9363b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-7ac14b14-995a-4175-947d-a28ad6ab22de,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-f498d816-c0de-4bb5-adef-2196c17ac978,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-22773e22-27d6-419b-8679-396101a15f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553986311-172.17.0.7-1599358319825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33840,DS-0e305983-f386-421f-8104-ebb25db7f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-fc0ba0c9-75fb-4054-bab0-fcd0e8ae8856,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b4b00025-a148-4f80-8ccc-61950131eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-0e29c328-09a5-42d9-806a-8af45ac229d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-becf9bdd-b427-4759-9c4f-22bac9b0398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-f70f0d9e-ad25-40c3-8ae3-88a82cf1b638,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-950a7640-b203-449e-a09a-a8972d5d92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-e87a7a1e-6c17-451c-a4fa-4d965ae95d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553986311-172.17.0.7-1599358319825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33840,DS-0e305983-f386-421f-8104-ebb25db7f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-fc0ba0c9-75fb-4054-bab0-fcd0e8ae8856,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b4b00025-a148-4f80-8ccc-61950131eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-0e29c328-09a5-42d9-806a-8af45ac229d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-becf9bdd-b427-4759-9c4f-22bac9b0398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-f70f0d9e-ad25-40c3-8ae3-88a82cf1b638,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-950a7640-b203-449e-a09a-a8972d5d92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-e87a7a1e-6c17-451c-a4fa-4d965ae95d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135315099-172.17.0.7-1599359199944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-2cb6d11c-a733-4bd1-b25f-a297b7088166,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-72a66f3f-9d18-48b2-aaea-3dff2445c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-53caeab5-07a2-48e7-af59-4ecbefde662d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-89527796-4ac5-4545-95c1-30e6aae60b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-bf7d2878-b0bc-4e9e-a04e-c1dc8782d088,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-1a29474c-c6e0-46ec-83a1-541760ac7520,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-12fc1ad8-64fb-4a1d-82f3-a76bc837f7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d9fac958-f256-43c7-8f0b-d2d638ed20c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135315099-172.17.0.7-1599359199944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-2cb6d11c-a733-4bd1-b25f-a297b7088166,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-72a66f3f-9d18-48b2-aaea-3dff2445c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-53caeab5-07a2-48e7-af59-4ecbefde662d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-89527796-4ac5-4545-95c1-30e6aae60b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-bf7d2878-b0bc-4e9e-a04e-c1dc8782d088,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-1a29474c-c6e0-46ec-83a1-541760ac7520,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-12fc1ad8-64fb-4a1d-82f3-a76bc837f7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d9fac958-f256-43c7-8f0b-d2d638ed20c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930725872-172.17.0.7-1599359399728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-ef9aaac9-dd17-4de6-b639-5c054e712ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-95f44bb7-77ee-4ec6-bc2d-32187e3d4942,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-301429cd-f958-4567-8245-95a77453c09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-bde95faa-a4d1-4495-87ee-410fa05efd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-a87ffa32-cb7f-416a-975a-5aaa295c0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-c0762cf2-2c1d-4a0a-920b-542c2198cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-84e2235b-8a46-4c6a-886e-0b8921e80ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-73ce8ba5-22e7-4e42-bd19-94d6ea1c200f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930725872-172.17.0.7-1599359399728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-ef9aaac9-dd17-4de6-b639-5c054e712ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-95f44bb7-77ee-4ec6-bc2d-32187e3d4942,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-301429cd-f958-4567-8245-95a77453c09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-bde95faa-a4d1-4495-87ee-410fa05efd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-a87ffa32-cb7f-416a-975a-5aaa295c0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-c0762cf2-2c1d-4a0a-920b-542c2198cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-84e2235b-8a46-4c6a-886e-0b8921e80ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-73ce8ba5-22e7-4e42-bd19-94d6ea1c200f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317088362-172.17.0.7-1599359744126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-89f6eaef-d60f-47d1-856c-abcf4622b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-3b6124f8-1a41-4f66-bb40-8aa5dec7403a,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-9dbd1882-3725-425a-a98b-9b2354ffb7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-aaeab159-5ebe-440b-b5c0-0df375045e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-87f9803f-7b91-410c-a81a-317a25e7363f,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-46a7f029-f4a5-4ac3-aabc-b714cff789e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-77270408-bb70-4b81-ae7b-59f86e370622,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-2792a65c-8c96-4dd6-ba2c-0357df650854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317088362-172.17.0.7-1599359744126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-89f6eaef-d60f-47d1-856c-abcf4622b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-3b6124f8-1a41-4f66-bb40-8aa5dec7403a,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-9dbd1882-3725-425a-a98b-9b2354ffb7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-aaeab159-5ebe-440b-b5c0-0df375045e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-87f9803f-7b91-410c-a81a-317a25e7363f,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-46a7f029-f4a5-4ac3-aabc-b714cff789e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-77270408-bb70-4b81-ae7b-59f86e370622,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-2792a65c-8c96-4dd6-ba2c-0357df650854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148767269-172.17.0.7-1599359918196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-a4e25da2-cfa5-4cd9-a40f-80e2ff3c8703,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-98f750c0-f628-4d6c-9c1c-0c837bea4e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f9596d38-d8bf-4517-bbe2-df1825762de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d3a7de2d-8719-4644-9b08-7ed7649a0920,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-7653ef7b-225e-414e-814e-54e4f423afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-56763681-3926-4053-846d-4528f00980ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-9dd314ec-365e-4d88-a8b0-b3ed6d610e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-2e2da26c-9644-471b-9bdb-68e10f5714cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148767269-172.17.0.7-1599359918196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-a4e25da2-cfa5-4cd9-a40f-80e2ff3c8703,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-98f750c0-f628-4d6c-9c1c-0c837bea4e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f9596d38-d8bf-4517-bbe2-df1825762de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-d3a7de2d-8719-4644-9b08-7ed7649a0920,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-7653ef7b-225e-414e-814e-54e4f423afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-56763681-3926-4053-846d-4528f00980ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-9dd314ec-365e-4d88-a8b0-b3ed6d610e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-2e2da26c-9644-471b-9bdb-68e10f5714cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386289353-172.17.0.7-1599359952210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-4ae7c3c7-efb6-4ebc-990a-9fb5cbb11e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-846a9c3b-44c0-43ea-987e-f7ee0f87faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-12abd993-14e8-460c-9691-9e5e38e2a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-7aa8a3eb-829e-464d-9cfe-206706ef06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-80bfc875-a1f7-4928-8d3e-f903a0f1a282,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-d2f11e15-5eb7-405d-ae97-2f67440f3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-2fc4f0ff-7108-4cfd-8a51-b6157ee12f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5ea5301c-0b1a-4190-9b43-e345e78f2f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386289353-172.17.0.7-1599359952210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-4ae7c3c7-efb6-4ebc-990a-9fb5cbb11e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-846a9c3b-44c0-43ea-987e-f7ee0f87faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-12abd993-14e8-460c-9691-9e5e38e2a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-7aa8a3eb-829e-464d-9cfe-206706ef06d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-80bfc875-a1f7-4928-8d3e-f903a0f1a282,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-d2f11e15-5eb7-405d-ae97-2f67440f3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-2fc4f0ff-7108-4cfd-8a51-b6157ee12f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5ea5301c-0b1a-4190-9b43-e345e78f2f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5134
