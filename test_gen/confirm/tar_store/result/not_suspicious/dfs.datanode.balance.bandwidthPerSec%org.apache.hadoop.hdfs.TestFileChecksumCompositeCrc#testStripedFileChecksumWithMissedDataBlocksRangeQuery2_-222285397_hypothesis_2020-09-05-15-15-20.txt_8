reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888564794-172.17.0.14-1599319182708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-7b993f93-087f-4369-97fa-ff7bc724698c,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-c4f46f25-dc1c-402a-be8b-5cdd55c4d787,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e2550cc2-f51e-43e8-9ad3-3311fab0b5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-c1276bf3-5193-42b2-beb2-f60040d7e89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-7cb07026-ce3f-497b-a86d-8b88b74af85c,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-cdddbcc9-4341-42e4-8008-defa62c334ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-74704b65-ac5d-4cde-9365-34d1354e99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3aa4a11e-db2b-4895-8b80-57a0d7a614e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888564794-172.17.0.14-1599319182708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-7b993f93-087f-4369-97fa-ff7bc724698c,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-c4f46f25-dc1c-402a-be8b-5cdd55c4d787,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e2550cc2-f51e-43e8-9ad3-3311fab0b5be,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-c1276bf3-5193-42b2-beb2-f60040d7e89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-7cb07026-ce3f-497b-a86d-8b88b74af85c,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-cdddbcc9-4341-42e4-8008-defa62c334ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-74704b65-ac5d-4cde-9365-34d1354e99ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3aa4a11e-db2b-4895-8b80-57a0d7a614e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907807380-172.17.0.14-1599319438020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-4979d821-21f0-4614-9eb4-ffe99c047e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-be5db67c-5a32-416d-ac58-41ca5654f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-95ac9127-416d-41ae-aa09-b9661df93802,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-2ab5180d-c018-417f-a81d-c001ab74b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-0c329383-986e-43b5-8d16-9734fba9ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-10053c83-cef4-460c-8355-ae85a8baa3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-7755f966-fbbc-4de2-b15e-2f843ca6edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-699ec10e-cc05-4f43-8e7f-9e862d6516fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907807380-172.17.0.14-1599319438020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44501,DS-4979d821-21f0-4614-9eb4-ffe99c047e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-be5db67c-5a32-416d-ac58-41ca5654f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-95ac9127-416d-41ae-aa09-b9661df93802,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-2ab5180d-c018-417f-a81d-c001ab74b69e,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-0c329383-986e-43b5-8d16-9734fba9ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-10053c83-cef4-460c-8355-ae85a8baa3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-7755f966-fbbc-4de2-b15e-2f843ca6edbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-699ec10e-cc05-4f43-8e7f-9e862d6516fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671923307-172.17.0.14-1599319477185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-c563715c-8e2e-4d66-8c76-456bde2b318d,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-994cd395-4acc-4afa-8a7b-85cd294282bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-b7ef7afa-de80-41b3-870c-27c99229b73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-0ca777e6-b6ed-4aca-a85b-0b2df538b4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-291a3b52-c5f8-40ed-96de-bb091fab8868,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-02fc0dca-35f0-41d0-9434-dba7d3e43fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-33e6d7cd-4721-4831-a6b7-6571099e8b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e1c7bcd1-9c17-4455-9984-5954f4716aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671923307-172.17.0.14-1599319477185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-c563715c-8e2e-4d66-8c76-456bde2b318d,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-994cd395-4acc-4afa-8a7b-85cd294282bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-b7ef7afa-de80-41b3-870c-27c99229b73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-0ca777e6-b6ed-4aca-a85b-0b2df538b4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-291a3b52-c5f8-40ed-96de-bb091fab8868,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-02fc0dca-35f0-41d0-9434-dba7d3e43fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-33e6d7cd-4721-4831-a6b7-6571099e8b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e1c7bcd1-9c17-4455-9984-5954f4716aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155172775-172.17.0.14-1599319639940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-5ee818e7-c7f4-47cc-8dae-6fea2e1186ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-ea4a2162-611d-4219-b02f-13efc8a9cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-9cd369b9-ba6b-422a-84ac-ba7ec7ec89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-9252ecc5-6e44-4cda-a90a-8574264f8356,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-d430599b-cd75-4c74-ad80-05140ebbf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-7ba8ecbe-35ae-4d05-8d17-d39ce28921b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-3a37d791-61ec-472e-b394-adad038a8314,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-1489136d-7dc4-4f6e-80fb-0801df60282d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155172775-172.17.0.14-1599319639940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-5ee818e7-c7f4-47cc-8dae-6fea2e1186ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-ea4a2162-611d-4219-b02f-13efc8a9cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-9cd369b9-ba6b-422a-84ac-ba7ec7ec89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-9252ecc5-6e44-4cda-a90a-8574264f8356,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-d430599b-cd75-4c74-ad80-05140ebbf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-7ba8ecbe-35ae-4d05-8d17-d39ce28921b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-3a37d791-61ec-472e-b394-adad038a8314,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-1489136d-7dc4-4f6e-80fb-0801df60282d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669938899-172.17.0.14-1599319871157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37706,DS-fc74b3c3-1c12-44ff-8108-5ef18a131823,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-e599099e-f077-4326-b771-98a32cfc1656,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-54716f48-2241-4b12-a1a0-28d9fd6e9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-b467c874-ac6d-4ccc-9341-4834c6033c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-4cdb872b-7735-4c27-bafb-c11bd5f140e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-9db0282a-5648-49de-9b1c-f18b6bb3e115,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-691bd285-0f47-4dd3-95e7-379e524c5d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-7d6c4b6a-5204-407f-96e5-ef9612cb8535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669938899-172.17.0.14-1599319871157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37706,DS-fc74b3c3-1c12-44ff-8108-5ef18a131823,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-e599099e-f077-4326-b771-98a32cfc1656,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-54716f48-2241-4b12-a1a0-28d9fd6e9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-b467c874-ac6d-4ccc-9341-4834c6033c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-4cdb872b-7735-4c27-bafb-c11bd5f140e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-9db0282a-5648-49de-9b1c-f18b6bb3e115,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-691bd285-0f47-4dd3-95e7-379e524c5d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-7d6c4b6a-5204-407f-96e5-ef9612cb8535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376149262-172.17.0.14-1599320322117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-5502dd0c-af73-472a-8d61-c102ca56f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-e3dfbd21-e644-4d36-9a3b-b3f08e61989a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-b5a685b8-fb86-4988-a3b0-14b6eabb61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-57572de5-3c94-4c31-ad48-b75b599af507,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-b6611250-e41e-4bcd-a1dd-bef5bfba5053,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-7bcc70d8-c2c9-4a88-a0d3-4a55342a5694,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-1359c571-69e0-4f5e-9d92-b9f058cacb09,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b82d1991-0135-4aef-979d-11765110360f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376149262-172.17.0.14-1599320322117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-5502dd0c-af73-472a-8d61-c102ca56f83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-e3dfbd21-e644-4d36-9a3b-b3f08e61989a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-b5a685b8-fb86-4988-a3b0-14b6eabb61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-57572de5-3c94-4c31-ad48-b75b599af507,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-b6611250-e41e-4bcd-a1dd-bef5bfba5053,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-7bcc70d8-c2c9-4a88-a0d3-4a55342a5694,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-1359c571-69e0-4f5e-9d92-b9f058cacb09,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b82d1991-0135-4aef-979d-11765110360f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327864034-172.17.0.14-1599320807230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-9c88656d-d38d-4224-b728-fd391e48f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-2ab964dc-bbbd-4cc0-a3eb-cc7a0f628fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f321f40a-9b74-4843-ac67-a758ba458847,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-2af68aa2-66b1-428f-9ab0-66a62f69beac,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-efba5d2f-d69b-40cc-a7cd-b5c17e6cd552,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-bb770585-aafe-4641-8a63-86391540e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-0e1be187-f5a4-410a-bdf3-4633f99ca3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d531cfbf-bbba-4170-a1ab-70b203287d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327864034-172.17.0.14-1599320807230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-9c88656d-d38d-4224-b728-fd391e48f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-2ab964dc-bbbd-4cc0-a3eb-cc7a0f628fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f321f40a-9b74-4843-ac67-a758ba458847,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-2af68aa2-66b1-428f-9ab0-66a62f69beac,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-efba5d2f-d69b-40cc-a7cd-b5c17e6cd552,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-bb770585-aafe-4641-8a63-86391540e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-0e1be187-f5a4-410a-bdf3-4633f99ca3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d531cfbf-bbba-4170-a1ab-70b203287d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20302136-172.17.0.14-1599320935725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-d023f297-60fc-4e30-afbc-b6f43de92b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-2f0020ae-4f7f-4b6e-9480-11ec215ba1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-acf27b36-db4c-47de-9422-1f8731b60b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b03c745e-3529-435b-a133-f1990555a69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-14b2cc9c-3599-47bb-a0db-22992dcfd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-9f32076e-6e92-4d3e-a58c-22e4f1ac2976,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-ef485744-5ddd-4c98-a712-199bd1156e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-43acd8c2-7ce8-4c93-88e2-2d3224be155e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20302136-172.17.0.14-1599320935725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-d023f297-60fc-4e30-afbc-b6f43de92b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-2f0020ae-4f7f-4b6e-9480-11ec215ba1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-acf27b36-db4c-47de-9422-1f8731b60b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b03c745e-3529-435b-a133-f1990555a69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-14b2cc9c-3599-47bb-a0db-22992dcfd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-9f32076e-6e92-4d3e-a58c-22e4f1ac2976,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-ef485744-5ddd-4c98-a712-199bd1156e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-43acd8c2-7ce8-4c93-88e2-2d3224be155e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040140342-172.17.0.14-1599321041865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-26eef37e-fc3e-4ea7-bcb3-8d7c380f7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-b59f657b-e860-436d-9f47-6c593a3394fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-1a7138ef-464a-454e-a488-da53ff6fc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-2e84f4ee-0206-460c-896a-fad792a00c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-44a6d0a5-b9e7-48c4-9bd0-96b6b1a73ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-c679ad0a-e0ad-41dc-86fb-1e1b88126b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-25365a96-f58b-407a-b42b-186266c11df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-dadeaeb3-11df-4284-84dd-42d2319d5536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040140342-172.17.0.14-1599321041865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-26eef37e-fc3e-4ea7-bcb3-8d7c380f7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-b59f657b-e860-436d-9f47-6c593a3394fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-1a7138ef-464a-454e-a488-da53ff6fc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-2e84f4ee-0206-460c-896a-fad792a00c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-44a6d0a5-b9e7-48c4-9bd0-96b6b1a73ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-c679ad0a-e0ad-41dc-86fb-1e1b88126b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-25365a96-f58b-407a-b42b-186266c11df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-dadeaeb3-11df-4284-84dd-42d2319d5536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069056416-172.17.0.14-1599321290736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-e0b2892e-16b6-4489-9632-3c1337bc8945,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-7fb53542-7152-4f45-bb6b-220580e69faf,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-01c83b59-5dd5-4d37-bf90-968da076e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-5f1c188e-96d9-472f-b655-0e2e8c16bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-dcaf6342-eaa4-4fb3-b847-7a9a78d0dcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-401218c9-3ba4-4fe1-ab66-7f6dd993a484,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-e0b177bc-ba4b-4b26-a882-22b712566bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-ee93edf0-65be-4d18-b90b-1e738e2c3a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069056416-172.17.0.14-1599321290736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-e0b2892e-16b6-4489-9632-3c1337bc8945,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-7fb53542-7152-4f45-bb6b-220580e69faf,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-01c83b59-5dd5-4d37-bf90-968da076e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-5f1c188e-96d9-472f-b655-0e2e8c16bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-dcaf6342-eaa4-4fb3-b847-7a9a78d0dcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-401218c9-3ba4-4fe1-ab66-7f6dd993a484,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-e0b177bc-ba4b-4b26-a882-22b712566bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-ee93edf0-65be-4d18-b90b-1e738e2c3a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608250652-172.17.0.14-1599322666145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-99a7298b-ff91-48ec-893f-0a725aff1bff,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ab244139-18ac-42e8-9e0e-d789fad717dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8232bcc7-c68f-4378-82f8-c21e33c4466d,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-ef04a4ce-216b-4d7c-bbd6-2af20f1f0bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-324d9ad3-f191-444f-be57-66211bfc567c,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-0dafb77c-ba06-4688-a97b-776e415146fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-4be2c613-1803-4853-b1e0-05b7a3927cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-4fbfe227-e5c8-49c1-b527-1dd5c9da6d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608250652-172.17.0.14-1599322666145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-99a7298b-ff91-48ec-893f-0a725aff1bff,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ab244139-18ac-42e8-9e0e-d789fad717dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8232bcc7-c68f-4378-82f8-c21e33c4466d,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-ef04a4ce-216b-4d7c-bbd6-2af20f1f0bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-324d9ad3-f191-444f-be57-66211bfc567c,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-0dafb77c-ba06-4688-a97b-776e415146fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-4be2c613-1803-4853-b1e0-05b7a3927cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-4fbfe227-e5c8-49c1-b527-1dd5c9da6d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038296913-172.17.0.14-1599322829077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-20c8a5e2-923f-4918-a95f-5743ecfb27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-b7b9d4cf-f931-4345-96cf-09d74e0915f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5d51de3f-8a7a-4c11-9258-c81e3e78a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-50127998-4cfc-4b2f-91a2-7efed50cf057,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-162452db-7159-449e-873f-8997c4f772bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c2113c91-fa47-4f8f-a36a-84a5bfdbf443,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-f6161420-4209-4e67-b9a8-fb2672d01c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-48848f71-db80-4f2d-9118-2df55904c705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038296913-172.17.0.14-1599322829077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-20c8a5e2-923f-4918-a95f-5743ecfb27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-b7b9d4cf-f931-4345-96cf-09d74e0915f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5d51de3f-8a7a-4c11-9258-c81e3e78a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-50127998-4cfc-4b2f-91a2-7efed50cf057,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-162452db-7159-449e-873f-8997c4f772bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c2113c91-fa47-4f8f-a36a-84a5bfdbf443,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-f6161420-4209-4e67-b9a8-fb2672d01c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-48848f71-db80-4f2d-9118-2df55904c705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151086546-172.17.0.14-1599323324187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-21d8a048-ecfa-46fc-a791-db56d3c5395f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-52094c13-5695-4e4b-892c-d920e22f4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-1104d435-e681-49cc-82be-ab499ed63421,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-139becfa-136e-4692-9c6e-a4f38bd2fb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-70749bd1-6995-4916-8d00-baf2ba00e046,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-488875b2-343d-4a71-b1b5-c8847f0f45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-79d231c4-7df7-4e34-8ce8-dacac77736cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-63cda3f7-3ed5-4197-952b-c7ace5ae7b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151086546-172.17.0.14-1599323324187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-21d8a048-ecfa-46fc-a791-db56d3c5395f,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-52094c13-5695-4e4b-892c-d920e22f4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-1104d435-e681-49cc-82be-ab499ed63421,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-139becfa-136e-4692-9c6e-a4f38bd2fb71,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-70749bd1-6995-4916-8d00-baf2ba00e046,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-488875b2-343d-4a71-b1b5-c8847f0f45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-79d231c4-7df7-4e34-8ce8-dacac77736cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-63cda3f7-3ed5-4197-952b-c7ace5ae7b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048251418-172.17.0.14-1599323788262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41259,DS-64da5e9d-3fa1-40ea-9a0f-b6fe56ed13a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-76da82cb-04d0-4dc7-b94b-72c4eb6e6779,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-f21cdcb5-8974-446b-be4f-33912edd9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8068151d-a531-408e-9749-ae36c76c8141,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-7590ccba-f7b3-4487-bc49-8788e5cf0751,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-722c0cf2-cb2a-400c-8625-11ff3af69c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-155c4d40-0714-4b48-adad-c6e791b5e154,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-da9fc2ea-54ee-4b5a-a393-01a4ca44994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048251418-172.17.0.14-1599323788262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41259,DS-64da5e9d-3fa1-40ea-9a0f-b6fe56ed13a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-76da82cb-04d0-4dc7-b94b-72c4eb6e6779,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-f21cdcb5-8974-446b-be4f-33912edd9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8068151d-a531-408e-9749-ae36c76c8141,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-7590ccba-f7b3-4487-bc49-8788e5cf0751,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-722c0cf2-cb2a-400c-8625-11ff3af69c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-155c4d40-0714-4b48-adad-c6e791b5e154,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-da9fc2ea-54ee-4b5a-a393-01a4ca44994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176841580-172.17.0.14-1599324115615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-c79a1d4a-a880-4b8f-8121-997abba24e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3f4b3fc7-b0fd-40d0-943d-6f693f8f7334,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-53ccb5fa-8248-489e-8635-7d55c464fada,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-0d536db0-b673-4b9a-87f1-0f92c745ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f7c240ae-56ac-4f7a-a393-55d73c442734,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-61bca35b-c81d-4e3d-9905-dbeeab9dd277,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-a8bd1fab-d685-44f9-ad8d-e1ac8536de65,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-3de3c848-de0a-4770-a3dc-d4f18cb2c0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176841580-172.17.0.14-1599324115615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-c79a1d4a-a880-4b8f-8121-997abba24e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3f4b3fc7-b0fd-40d0-943d-6f693f8f7334,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-53ccb5fa-8248-489e-8635-7d55c464fada,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-0d536db0-b673-4b9a-87f1-0f92c745ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f7c240ae-56ac-4f7a-a393-55d73c442734,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-61bca35b-c81d-4e3d-9905-dbeeab9dd277,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-a8bd1fab-d685-44f9-ad8d-e1ac8536de65,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-3de3c848-de0a-4770-a3dc-d4f18cb2c0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245862887-172.17.0.14-1599324412457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-f892f25c-4f6b-4538-8b33-3b4607a84cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-1ce86eed-8936-40b9-8249-60b8c488f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-388cc380-a1d5-4f7b-9bc6-1954f30dbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-ad9d7d37-d874-4bc1-9cab-d60fa1d95143,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-53001cc2-37a4-4109-8603-7656c3f1018c,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-06b31c9c-b138-4be6-a87f-53e4293dd32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-a929bf26-3959-4741-a96d-1c3ef1dc2cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-d028b70f-4012-4105-8090-58d80c8e60a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245862887-172.17.0.14-1599324412457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-f892f25c-4f6b-4538-8b33-3b4607a84cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-1ce86eed-8936-40b9-8249-60b8c488f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-388cc380-a1d5-4f7b-9bc6-1954f30dbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-ad9d7d37-d874-4bc1-9cab-d60fa1d95143,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-53001cc2-37a4-4109-8603-7656c3f1018c,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-06b31c9c-b138-4be6-a87f-53e4293dd32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-a929bf26-3959-4741-a96d-1c3ef1dc2cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-d028b70f-4012-4105-8090-58d80c8e60a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295698810-172.17.0.14-1599324518390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-7f84e7b2-a0d7-421e-88cb-96546c36d268,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-e89edb5e-7b09-425a-9d72-4668f0ad8c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-5e395118-e98d-46d0-88a7-085578d53562,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0c5c619a-0706-4e70-bc1b-83b6305dc50f,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-615361a6-5db9-4853-bcfa-f94a74210c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-6be89df7-d186-4ab5-a625-024f8ca17f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-73a1bf66-627a-4630-8444-39e7c7a61d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-74a7f8f6-0df5-4011-8397-6f60cd642b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295698810-172.17.0.14-1599324518390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-7f84e7b2-a0d7-421e-88cb-96546c36d268,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-e89edb5e-7b09-425a-9d72-4668f0ad8c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-5e395118-e98d-46d0-88a7-085578d53562,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0c5c619a-0706-4e70-bc1b-83b6305dc50f,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-615361a6-5db9-4853-bcfa-f94a74210c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-6be89df7-d186-4ab5-a625-024f8ca17f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-73a1bf66-627a-4630-8444-39e7c7a61d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-74a7f8f6-0df5-4011-8397-6f60cd642b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5725
