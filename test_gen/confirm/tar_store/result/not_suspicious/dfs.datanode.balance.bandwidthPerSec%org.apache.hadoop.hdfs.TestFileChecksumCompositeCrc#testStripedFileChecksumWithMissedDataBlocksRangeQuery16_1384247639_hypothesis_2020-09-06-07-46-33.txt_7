reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816663000-172.17.0.15-1599379312463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-3ddc5911-3e7e-41ea-a35e-487178f62754,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6378e92b-e58d-4909-864a-225bcd1ed208,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c0cf4cbd-83ed-4a61-9f85-571b72ac1080,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-35ac9a6c-5c7a-44b7-ae95-719990f7422b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-2fb00618-09fa-48da-b1b0-f813347853d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-3df6bb10-7bdc-4a60-9fac-a451bd7a05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-f4382724-c325-45ce-9e8f-4895dbf4bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-9793e4b5-72a8-4862-b71f-34e339083298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816663000-172.17.0.15-1599379312463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-3ddc5911-3e7e-41ea-a35e-487178f62754,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6378e92b-e58d-4909-864a-225bcd1ed208,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c0cf4cbd-83ed-4a61-9f85-571b72ac1080,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-35ac9a6c-5c7a-44b7-ae95-719990f7422b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-2fb00618-09fa-48da-b1b0-f813347853d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-3df6bb10-7bdc-4a60-9fac-a451bd7a05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-f4382724-c325-45ce-9e8f-4895dbf4bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-9793e4b5-72a8-4862-b71f-34e339083298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573402854-172.17.0.15-1599379382756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d44413de-b74d-4a0d-8db7-346c9a92be47,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-829b19cf-1c3c-4591-ba1d-790568fbd302,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-d09d7918-ba2b-4ecd-acb7-5dd92ef0172a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-cf9d68a6-eacc-4a77-bf48-e7ed1362a3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-0031c9be-00de-48e5-8741-c1fd4af5de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-57ee6bad-6cd8-4c1e-94c8-f517033031c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-35e7d76a-e035-481f-9793-43a3e1c1d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-9976f9fe-28b0-4049-a9bc-7cb3eafeaa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573402854-172.17.0.15-1599379382756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d44413de-b74d-4a0d-8db7-346c9a92be47,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-829b19cf-1c3c-4591-ba1d-790568fbd302,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-d09d7918-ba2b-4ecd-acb7-5dd92ef0172a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-cf9d68a6-eacc-4a77-bf48-e7ed1362a3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-0031c9be-00de-48e5-8741-c1fd4af5de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-57ee6bad-6cd8-4c1e-94c8-f517033031c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-35e7d76a-e035-481f-9793-43a3e1c1d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-9976f9fe-28b0-4049-a9bc-7cb3eafeaa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901335841-172.17.0.15-1599379503566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-569243c3-c21b-45b4-9a06-933a7d6cea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-19681f36-0e57-4cb0-b7f3-f05eaf3cea76,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-c12f6253-4169-4b6b-b04a-969d50ad539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-55ccf2e6-83fb-4009-a4f7-5ba1587aa872,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-20c69d09-c24b-4b79-b863-4d97865f0ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-fa64536f-c858-4acc-8647-a5753cf5ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-22e3910b-8bc4-4da0-857d-0e6414822f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-48b90b68-3094-487f-8715-d56cb2b2dffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901335841-172.17.0.15-1599379503566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-569243c3-c21b-45b4-9a06-933a7d6cea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-19681f36-0e57-4cb0-b7f3-f05eaf3cea76,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-c12f6253-4169-4b6b-b04a-969d50ad539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-55ccf2e6-83fb-4009-a4f7-5ba1587aa872,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-20c69d09-c24b-4b79-b863-4d97865f0ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-fa64536f-c858-4acc-8647-a5753cf5ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-22e3910b-8bc4-4da0-857d-0e6414822f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-48b90b68-3094-487f-8715-d56cb2b2dffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216940636-172.17.0.15-1599379694789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-3d0a9b2c-dc9d-4d50-aa32-c4795bfdaf40,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0fafa63d-3d02-4241-9de6-08b7ae692c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-af0c7c50-e02f-44a8-a377-7ed4de01d491,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-14806503-e27b-4520-9814-1b83da1bf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-445ad629-86da-49d5-b8bd-a36db3d1aef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-bc9331aa-f505-472d-b345-bdcc9c98a070,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-369eb77f-df23-4b44-abc1-8ad5dc60198b,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-5314ba57-1aa3-4729-94a7-dc91d0a0cea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216940636-172.17.0.15-1599379694789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-3d0a9b2c-dc9d-4d50-aa32-c4795bfdaf40,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-0fafa63d-3d02-4241-9de6-08b7ae692c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-af0c7c50-e02f-44a8-a377-7ed4de01d491,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-14806503-e27b-4520-9814-1b83da1bf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-445ad629-86da-49d5-b8bd-a36db3d1aef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-bc9331aa-f505-472d-b345-bdcc9c98a070,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-369eb77f-df23-4b44-abc1-8ad5dc60198b,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-5314ba57-1aa3-4729-94a7-dc91d0a0cea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473059295-172.17.0.15-1599380068420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-22fbcb2e-3476-44a8-a1aa-d9487f356b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-ca1ffd4a-279b-47dd-acce-51716c90f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-71829aca-354b-4c9d-aaf1-efd0f8507b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b71bc001-1409-412d-b5df-24de4681accf,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-0229c168-b991-46be-ad69-5a262ddcf800,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-17815b0f-292b-4034-9c2b-108fc4f4839f,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-eb8b8f98-1353-4e41-bea1-0cc4f0bfa7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-45d08059-19d8-49bf-ab3f-573b0d83e4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473059295-172.17.0.15-1599380068420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-22fbcb2e-3476-44a8-a1aa-d9487f356b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-ca1ffd4a-279b-47dd-acce-51716c90f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-71829aca-354b-4c9d-aaf1-efd0f8507b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b71bc001-1409-412d-b5df-24de4681accf,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-0229c168-b991-46be-ad69-5a262ddcf800,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-17815b0f-292b-4034-9c2b-108fc4f4839f,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-eb8b8f98-1353-4e41-bea1-0cc4f0bfa7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-45d08059-19d8-49bf-ab3f-573b0d83e4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791618652-172.17.0.15-1599380662298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-efaba90a-8ba9-4f3c-869a-4d7385db8553,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-166ad113-9632-4d7e-9927-f0fbdd2eeca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1031da7a-2739-4f86-97cb-d4b99a1d3207,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2e517497-f578-4cb0-b4f4-1844641f3542,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b4173dcf-329a-42bc-a9c2-4d37f66be925,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-2efdd8a2-6d44-43f4-944c-9e55dbf3d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-4b9884e2-5555-4fb4-88ed-3669421c57db,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-057441d1-beb9-4a56-8524-5555f51f599c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791618652-172.17.0.15-1599380662298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-efaba90a-8ba9-4f3c-869a-4d7385db8553,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-166ad113-9632-4d7e-9927-f0fbdd2eeca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1031da7a-2739-4f86-97cb-d4b99a1d3207,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2e517497-f578-4cb0-b4f4-1844641f3542,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b4173dcf-329a-42bc-a9c2-4d37f66be925,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-2efdd8a2-6d44-43f4-944c-9e55dbf3d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-4b9884e2-5555-4fb4-88ed-3669421c57db,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-057441d1-beb9-4a56-8524-5555f51f599c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905178274-172.17.0.15-1599380799260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-ea418038-168e-46e7-a2c9-f328dd3f2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-452265ba-e08e-4207-985e-7e346420c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ca8ae2e0-8b3c-4a9d-a878-c63a4f8d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-23efde36-0b19-41e4-b71a-1827329338c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-2642d18f-496f-4afb-b6ff-23b5ab4b0048,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-3a72bfd0-19a3-446c-a086-ccc152f058bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-3da7ca31-6ea7-4d80-838d-83897f03b405,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e228dbc2-edc4-42e1-9181-e8e44666f1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905178274-172.17.0.15-1599380799260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-ea418038-168e-46e7-a2c9-f328dd3f2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-452265ba-e08e-4207-985e-7e346420c9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ca8ae2e0-8b3c-4a9d-a878-c63a4f8d6535,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-23efde36-0b19-41e4-b71a-1827329338c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-2642d18f-496f-4afb-b6ff-23b5ab4b0048,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-3a72bfd0-19a3-446c-a086-ccc152f058bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-3da7ca31-6ea7-4d80-838d-83897f03b405,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-e228dbc2-edc4-42e1-9181-e8e44666f1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910103920-172.17.0.15-1599381108568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-48335e72-9730-4822-8156-718f766a238d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-f35b59aa-c65d-422e-b3b7-303c87db0f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-567a591c-18fe-4a1e-88e9-188a68070602,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-84134801-b20f-4fe6-8db7-513de052636a,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-5de4ad79-896a-4cdb-af8a-505ea34625a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-0be27c3a-55c9-40df-ac7f-177913b080f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-058e7a7b-bed2-4c90-b029-5406db6d2234,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c318122f-22ba-425a-9f0c-a79b95e5a323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910103920-172.17.0.15-1599381108568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41812,DS-48335e72-9730-4822-8156-718f766a238d,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-f35b59aa-c65d-422e-b3b7-303c87db0f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-567a591c-18fe-4a1e-88e9-188a68070602,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-84134801-b20f-4fe6-8db7-513de052636a,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-5de4ad79-896a-4cdb-af8a-505ea34625a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-0be27c3a-55c9-40df-ac7f-177913b080f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-058e7a7b-bed2-4c90-b029-5406db6d2234,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c318122f-22ba-425a-9f0c-a79b95e5a323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155820783-172.17.0.15-1599381140495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-0e9335c2-a191-4315-a13c-409bc8001ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-622cb120-35ff-4cbe-9025-963768fec2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-08864979-88b3-45ee-89a0-c76615d989b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-9f3ae49e-0d67-4964-bab2-42a4e7009cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-516f9a8c-9296-4a17-adb6-d6d8e448f116,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-e94029fb-12cd-4424-bb44-2240ff1511f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3f0876ad-ca1c-434e-876a-8967e3ed6a35,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-38fa3579-6211-47c5-aba4-08a3a9a57947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155820783-172.17.0.15-1599381140495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-0e9335c2-a191-4315-a13c-409bc8001ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-622cb120-35ff-4cbe-9025-963768fec2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-08864979-88b3-45ee-89a0-c76615d989b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-9f3ae49e-0d67-4964-bab2-42a4e7009cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-516f9a8c-9296-4a17-adb6-d6d8e448f116,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-e94029fb-12cd-4424-bb44-2240ff1511f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3f0876ad-ca1c-434e-876a-8967e3ed6a35,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-38fa3579-6211-47c5-aba4-08a3a9a57947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169154893-172.17.0.15-1599381718288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-7939057b-2f88-4810-b3c5-4bfa116ebfda,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9a7ac858-5bc1-42c2-8abf-6da66d4fd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e0508a4c-c024-4698-8f2a-fa406ed87e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-4051553d-eafb-44a2-ad03-ae3bff06f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-42eb6b62-f54f-4cc1-a2ac-8368f5c92eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-3a3f7406-7676-4b8f-ad05-4ebbc478bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a5a4462f-8139-47d0-9428-811b763a6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-69060249-b0f3-4227-8236-c00d259adb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169154893-172.17.0.15-1599381718288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-7939057b-2f88-4810-b3c5-4bfa116ebfda,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-9a7ac858-5bc1-42c2-8abf-6da66d4fd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e0508a4c-c024-4698-8f2a-fa406ed87e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-4051553d-eafb-44a2-ad03-ae3bff06f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-42eb6b62-f54f-4cc1-a2ac-8368f5c92eee,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-3a3f7406-7676-4b8f-ad05-4ebbc478bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a5a4462f-8139-47d0-9428-811b763a6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-69060249-b0f3-4227-8236-c00d259adb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479621830-172.17.0.15-1599381933525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-41b582f2-d5ab-4962-abe6-3ce50a316aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-302bfc07-fd92-41cb-b413-15d828fee71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-03f5efbd-21ed-4908-a07b-e39f31dd8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-1915e5f8-27d5-4ec4-9615-9524e4a8fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-51883358-c90f-46f2-ae52-52a01d679ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-b7b007f4-90a2-4029-8e29-424d2b49020f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-d0dfe109-7935-4114-b0e5-f74f2d6a410c,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-845f6a85-3b3d-4d90-8dc4-08742d050974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479621830-172.17.0.15-1599381933525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-41b582f2-d5ab-4962-abe6-3ce50a316aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-302bfc07-fd92-41cb-b413-15d828fee71e,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-03f5efbd-21ed-4908-a07b-e39f31dd8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-1915e5f8-27d5-4ec4-9615-9524e4a8fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-51883358-c90f-46f2-ae52-52a01d679ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-b7b007f4-90a2-4029-8e29-424d2b49020f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-d0dfe109-7935-4114-b0e5-f74f2d6a410c,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-845f6a85-3b3d-4d90-8dc4-08742d050974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668558696-172.17.0.15-1599382381442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-16150058-c951-4396-826d-95a6f3e45af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-a8370c7b-874d-48a5-b2b7-e8fdb142489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-b092dcc4-370f-41af-b61a-461eae3b30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-956c63ba-4cad-4ef6-89ab-cea0e05c3009,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-ff53dc37-3558-4471-a4bc-44f0b90a448a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-ad2cdc5f-fcce-42fd-8973-6820ccee6aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-ce5fcc0d-c5e1-4c37-a526-edce7f4d663a,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-cba097c4-1be4-4472-97e3-253911c2fc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668558696-172.17.0.15-1599382381442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-16150058-c951-4396-826d-95a6f3e45af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-a8370c7b-874d-48a5-b2b7-e8fdb142489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-b092dcc4-370f-41af-b61a-461eae3b30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-956c63ba-4cad-4ef6-89ab-cea0e05c3009,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-ff53dc37-3558-4471-a4bc-44f0b90a448a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-ad2cdc5f-fcce-42fd-8973-6820ccee6aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-ce5fcc0d-c5e1-4c37-a526-edce7f4d663a,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-cba097c4-1be4-4472-97e3-253911c2fc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246706350-172.17.0.15-1599382718959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-e16613be-7b78-4572-a4bf-00614efa2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-4fe34ac6-2c96-45fb-97c4-68a7bf08cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-32515cf8-54cb-4697-9e64-33edcaf09155,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-ff56f31e-717e-4d64-8589-635d6bf79f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-82d6a75b-6a46-47c7-bd03-656bd6d4feed,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-aa487c1e-e9df-4ca5-bd08-0852e6301e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-80f89349-0e55-4aa3-87b3-ec4013660414,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-747441f7-52b6-47d9-bdfb-0485d229b03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246706350-172.17.0.15-1599382718959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-e16613be-7b78-4572-a4bf-00614efa2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-4fe34ac6-2c96-45fb-97c4-68a7bf08cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-32515cf8-54cb-4697-9e64-33edcaf09155,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-ff56f31e-717e-4d64-8589-635d6bf79f39,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-82d6a75b-6a46-47c7-bd03-656bd6d4feed,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-aa487c1e-e9df-4ca5-bd08-0852e6301e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-80f89349-0e55-4aa3-87b3-ec4013660414,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-747441f7-52b6-47d9-bdfb-0485d229b03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901266079-172.17.0.15-1599382829733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-1f6198c2-9402-40ab-b817-dab2652e6e25,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-2ee3fd21-08a3-44df-85a4-eac6f28d3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ac7fa0ac-adf8-4e27-b038-cc000a14730d,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-cbdd4915-856c-4f53-a285-edcacfe440d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-c2b0292b-620f-4bb3-a33f-06bcc138cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ee4b7de-dd59-4615-b7a8-acacf13119f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-cae4b269-0a7c-42df-94c4-bef694219df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-04b4fad1-d638-458e-8dce-a6fcd26acd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901266079-172.17.0.15-1599382829733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41984,DS-1f6198c2-9402-40ab-b817-dab2652e6e25,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-2ee3fd21-08a3-44df-85a4-eac6f28d3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ac7fa0ac-adf8-4e27-b038-cc000a14730d,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-cbdd4915-856c-4f53-a285-edcacfe440d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-c2b0292b-620f-4bb3-a33f-06bcc138cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ee4b7de-dd59-4615-b7a8-acacf13119f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-cae4b269-0a7c-42df-94c4-bef694219df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-04b4fad1-d638-458e-8dce-a6fcd26acd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993473404-172.17.0.15-1599383167611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-bfccb3fb-d69f-4e7e-84d3-4a7acae2d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-e75e5647-07dd-402b-89af-d7f3ccf92e78,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-4d250975-4017-42ce-aa3e-0c32aa1a5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-dd1a21ce-c732-4213-ad28-b855c696c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-79d7600c-ae77-48f5-8069-7cabd368c023,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-8d534bc7-931f-4546-9152-3b6b04148069,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-365fbe2e-2b28-40ef-8008-d2c402190e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-06facdcf-d2a2-4b7a-8287-e5974c85a9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993473404-172.17.0.15-1599383167611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-bfccb3fb-d69f-4e7e-84d3-4a7acae2d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-e75e5647-07dd-402b-89af-d7f3ccf92e78,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-4d250975-4017-42ce-aa3e-0c32aa1a5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-dd1a21ce-c732-4213-ad28-b855c696c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-79d7600c-ae77-48f5-8069-7cabd368c023,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-8d534bc7-931f-4546-9152-3b6b04148069,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-365fbe2e-2b28-40ef-8008-d2c402190e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-06facdcf-d2a2-4b7a-8287-e5974c85a9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 20m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292487842-172.17.0.15-1599383367207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-505e29e1-663f-42e6-8220-aa13c729530a,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-c3139fd1-2bba-4e25-a1f6-3db527d9221c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-76f1459e-ed67-4310-8b2e-67742b99b543,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3a988d84-85d5-4552-aa36-8500cdeaa3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-961e5177-dd1c-4d3b-89d4-f7ef3ee0126e,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-923da4cc-9cfb-4bb3-84d1-9f655654b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-50d8f8c9-7963-47f1-bc29-e5377f16ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f9164ac3-a5d0-4507-92a4-8c558ee1b93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292487842-172.17.0.15-1599383367207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-505e29e1-663f-42e6-8220-aa13c729530a,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-c3139fd1-2bba-4e25-a1f6-3db527d9221c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-76f1459e-ed67-4310-8b2e-67742b99b543,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3a988d84-85d5-4552-aa36-8500cdeaa3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-961e5177-dd1c-4d3b-89d4-f7ef3ee0126e,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-923da4cc-9cfb-4bb3-84d1-9f655654b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-50d8f8c9-7963-47f1-bc29-e5377f16ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-f9164ac3-a5d0-4507-92a4-8c558ee1b93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5358
