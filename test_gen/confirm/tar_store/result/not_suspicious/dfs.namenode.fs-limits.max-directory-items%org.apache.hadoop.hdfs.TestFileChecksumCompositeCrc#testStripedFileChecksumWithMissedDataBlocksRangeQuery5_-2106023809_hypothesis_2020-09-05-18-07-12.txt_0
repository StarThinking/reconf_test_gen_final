reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339702553-172.17.0.20-1599329325090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40135,DS-57cb7f93-e057-4d99-8af3-1973c56c01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-3fae52c9-47c4-4971-9bcf-e32fbf8889fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-7b7a4db1-e4cb-4bf9-8472-2c5e62a20e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-12d39610-a4fe-402a-92ee-eb33c9156470,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-dde000fc-e1d6-4693-9a03-5d66a7d79ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-acb7f4bd-51d2-4e2e-b525-f39c459d5820,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-ff4f5471-2ea6-4f56-bb08-1b4c733a4245,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-d5319969-fb0e-4b02-9943-1ee7a3fa4676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339702553-172.17.0.20-1599329325090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40135,DS-57cb7f93-e057-4d99-8af3-1973c56c01f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-3fae52c9-47c4-4971-9bcf-e32fbf8889fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-7b7a4db1-e4cb-4bf9-8472-2c5e62a20e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-12d39610-a4fe-402a-92ee-eb33c9156470,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-dde000fc-e1d6-4693-9a03-5d66a7d79ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-acb7f4bd-51d2-4e2e-b525-f39c459d5820,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-ff4f5471-2ea6-4f56-bb08-1b4c733a4245,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-d5319969-fb0e-4b02-9943-1ee7a3fa4676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361567496-172.17.0.20-1599329359601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-68bf16e5-f48c-400c-9125-1e9876ceb086,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-af147715-a57c-4b95-a825-5a61b78c76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-100e377b-25b5-46a7-9ffe-bbc1cf764c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-b043706d-bb42-46a0-a33b-426303623b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-56a8145c-973b-4337-9f76-9e3d6635c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-7d795dbc-d64b-48a2-8aec-44a5cb03b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-6c63b3ff-91c0-4f43-8832-0cb42f2c3d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-3471971b-63a9-4711-86f4-3ea7812dd8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361567496-172.17.0.20-1599329359601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-68bf16e5-f48c-400c-9125-1e9876ceb086,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-af147715-a57c-4b95-a825-5a61b78c76ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-100e377b-25b5-46a7-9ffe-bbc1cf764c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-b043706d-bb42-46a0-a33b-426303623b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-56a8145c-973b-4337-9f76-9e3d6635c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-7d795dbc-d64b-48a2-8aec-44a5cb03b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-6c63b3ff-91c0-4f43-8832-0cb42f2c3d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-3471971b-63a9-4711-86f4-3ea7812dd8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694166392-172.17.0.20-1599329780492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-28c053d3-ba96-47ac-b2d8-ad495a90f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-1975b209-b3bc-42a8-9514-ab9c17cde364,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-d929834f-ba06-4672-bd0a-d61161827dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-c74a0ce2-8f59-4358-962a-7325b429ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-732e0caf-3d6a-4547-920c-991fd7b7caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-4659056c-293c-4906-bf6e-7c68a8438093,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-f122a517-2a6c-42b6-a236-a9812eaea1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-e253f27b-9299-40a1-b625-5a452d4f2b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694166392-172.17.0.20-1599329780492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-28c053d3-ba96-47ac-b2d8-ad495a90f408,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-1975b209-b3bc-42a8-9514-ab9c17cde364,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-d929834f-ba06-4672-bd0a-d61161827dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-c74a0ce2-8f59-4358-962a-7325b429ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-732e0caf-3d6a-4547-920c-991fd7b7caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-4659056c-293c-4906-bf6e-7c68a8438093,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-f122a517-2a6c-42b6-a236-a9812eaea1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-e253f27b-9299-40a1-b625-5a452d4f2b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86160708-172.17.0.20-1599329837686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-0e1c9b8a-6518-433f-837f-80d3ef10f999,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d5ecf06f-b673-4b3b-b76b-44593a48c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-c409052c-e0b1-4246-8810-a8f84d8ac76d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-de9ffe67-a052-42a2-8c81-3ba3a29f0408,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-39feccc2-9491-4ae8-9545-d029e41a33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-4a671f2f-ea32-44c4-8924-dbadc178f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-d4cdf770-03c6-45da-b016-6425adc99936,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-8af68a40-4f5a-486d-bc57-710123abc156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86160708-172.17.0.20-1599329837686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-0e1c9b8a-6518-433f-837f-80d3ef10f999,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d5ecf06f-b673-4b3b-b76b-44593a48c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-c409052c-e0b1-4246-8810-a8f84d8ac76d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-de9ffe67-a052-42a2-8c81-3ba3a29f0408,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-39feccc2-9491-4ae8-9545-d029e41a33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-4a671f2f-ea32-44c4-8924-dbadc178f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-d4cdf770-03c6-45da-b016-6425adc99936,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-8af68a40-4f5a-486d-bc57-710123abc156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45768740-172.17.0.20-1599330358705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-77a4a7cf-e25f-46b5-b8d7-cb6c95788938,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-76a56fa2-cd04-4184-8813-1e3c8bcb28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-5ac01e44-c5de-4b20-ba5c-90e096b5eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-67bf003e-cbc6-48aa-bd20-8e35df631714,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-ba3ae4cf-2d6e-4916-b177-b9d154ce4f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-0aeb4eff-4a1a-4d6b-b25d-8c5f86ca3791,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-c761c6e6-481d-4c5b-836f-0120e2b49012,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-3e2a6fd1-4123-48b6-bd7d-8297dd2759fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45768740-172.17.0.20-1599330358705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37661,DS-77a4a7cf-e25f-46b5-b8d7-cb6c95788938,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-76a56fa2-cd04-4184-8813-1e3c8bcb28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-5ac01e44-c5de-4b20-ba5c-90e096b5eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-67bf003e-cbc6-48aa-bd20-8e35df631714,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-ba3ae4cf-2d6e-4916-b177-b9d154ce4f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-0aeb4eff-4a1a-4d6b-b25d-8c5f86ca3791,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-c761c6e6-481d-4c5b-836f-0120e2b49012,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-3e2a6fd1-4123-48b6-bd7d-8297dd2759fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115139917-172.17.0.20-1599330471634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-482a6e4e-6702-4530-837b-70936fa66a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-e6acd208-07be-4f27-8a5f-7e01346650c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e7051b5e-0690-4fcc-aedd-50d7a0aaa2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-88ecf065-7daa-4d71-bda6-916c0799cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-597397a3-4fcb-4c21-b30a-9cf3474680b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-77f8b1e1-8dcc-4bef-b3a9-c0d92cef5078,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ec975cd2-00b2-482a-82ab-1e20e941ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-4e65a103-8e8c-4f92-904e-c4f42d803be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115139917-172.17.0.20-1599330471634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-482a6e4e-6702-4530-837b-70936fa66a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-e6acd208-07be-4f27-8a5f-7e01346650c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e7051b5e-0690-4fcc-aedd-50d7a0aaa2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-88ecf065-7daa-4d71-bda6-916c0799cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-597397a3-4fcb-4c21-b30a-9cf3474680b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-77f8b1e1-8dcc-4bef-b3a9-c0d92cef5078,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ec975cd2-00b2-482a-82ab-1e20e941ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-4e65a103-8e8c-4f92-904e-c4f42d803be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555586106-172.17.0.20-1599330711283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34916,DS-31a28757-c48b-4c3d-a37a-dd11a7d06083,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-9aee0647-b432-465a-a604-d838667418d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8eb72884-338f-4c59-800c-182289e091c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-26a0da7c-ca12-40b0-af97-630629576f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-bc5e209e-570d-4e00-8f98-d06ed509e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33da0b5d-4539-4f4f-ba21-0a49cd8c2e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-0c4631c1-ceab-4530-836f-638333e7987d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-59914d11-f9b1-44ef-bb5a-e6a3b2174d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555586106-172.17.0.20-1599330711283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34916,DS-31a28757-c48b-4c3d-a37a-dd11a7d06083,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-9aee0647-b432-465a-a604-d838667418d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8eb72884-338f-4c59-800c-182289e091c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-26a0da7c-ca12-40b0-af97-630629576f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-bc5e209e-570d-4e00-8f98-d06ed509e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33da0b5d-4539-4f4f-ba21-0a49cd8c2e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-0c4631c1-ceab-4530-836f-638333e7987d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-59914d11-f9b1-44ef-bb5a-e6a3b2174d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846446835-172.17.0.20-1599330844410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-031bb108-1b30-4cfa-a696-89702ddc60da,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-3d960825-a6f1-4c64-b037-33a411b76f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-dc7cea31-5d7b-4ef6-a801-d4e970916686,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-111e5986-a795-4685-9380-d6e17ee47828,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-cf138d8c-91b3-4e14-91c5-6f49421cd6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-c28035af-06fb-4ce9-8600-934c5bbe8fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-f3192735-09f9-44fa-9d52-687c8a88038a,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-b0748076-2780-4d5c-a321-9c60bf2c6d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846446835-172.17.0.20-1599330844410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-031bb108-1b30-4cfa-a696-89702ddc60da,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-3d960825-a6f1-4c64-b037-33a411b76f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-dc7cea31-5d7b-4ef6-a801-d4e970916686,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-111e5986-a795-4685-9380-d6e17ee47828,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-cf138d8c-91b3-4e14-91c5-6f49421cd6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-c28035af-06fb-4ce9-8600-934c5bbe8fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-f3192735-09f9-44fa-9d52-687c8a88038a,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-b0748076-2780-4d5c-a321-9c60bf2c6d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040396897-172.17.0.20-1599331967350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-a0636497-fcbb-4e98-b55e-9d6a9df6809a,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-cb40e0eb-6065-414e-bf15-c0efd07465a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-dfad1833-be27-4b21-8e2c-159b7e3754cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e542767f-9385-46d4-b09f-c85bdfd8e693,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-f016f2bc-1cdd-4afc-b1a2-128c77f181cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-136f6e7d-7521-4504-898e-9543da450923,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1370839c-e7e4-47f6-8a24-6160eaaf7c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-c1397ecc-7d07-4118-af04-685025b5630f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040396897-172.17.0.20-1599331967350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-a0636497-fcbb-4e98-b55e-9d6a9df6809a,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-cb40e0eb-6065-414e-bf15-c0efd07465a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-dfad1833-be27-4b21-8e2c-159b7e3754cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e542767f-9385-46d4-b09f-c85bdfd8e693,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-f016f2bc-1cdd-4afc-b1a2-128c77f181cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-136f6e7d-7521-4504-898e-9543da450923,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1370839c-e7e4-47f6-8a24-6160eaaf7c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-c1397ecc-7d07-4118-af04-685025b5630f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355410403-172.17.0.20-1599332343806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-808918c1-07f4-44fd-806c-3ba802348b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-7115de98-5407-487b-9542-38d84d44c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-eb21fd3b-200a-423c-9fb7-b40c34c6bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-22d8b71a-90e0-4b36-ac80-6e8ddd336270,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-1124ac28-386b-4bf6-b3ee-b64d31d2c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-feaf44b3-68d9-49f6-8de2-ca5a716ae75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-dd4fce7d-f332-4f29-8ffa-7ba4bf72fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-d29693e9-ca03-4743-af91-570141f06ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355410403-172.17.0.20-1599332343806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-808918c1-07f4-44fd-806c-3ba802348b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-7115de98-5407-487b-9542-38d84d44c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-eb21fd3b-200a-423c-9fb7-b40c34c6bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-22d8b71a-90e0-4b36-ac80-6e8ddd336270,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-1124ac28-386b-4bf6-b3ee-b64d31d2c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-feaf44b3-68d9-49f6-8de2-ca5a716ae75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-dd4fce7d-f332-4f29-8ffa-7ba4bf72fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-d29693e9-ca03-4743-af91-570141f06ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881586617-172.17.0.20-1599332426563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-68f0cb96-77fc-4abb-a3fb-b93d376b4664,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-a9da70ac-4248-44c4-94b6-bcf639ab6540,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-507687c5-f7f2-470d-9870-81478128bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-e7eca6f7-22cc-4037-8bae-45ffb8581451,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-6d24722b-9e7c-4cc0-af3c-cb78b4d97542,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-22a654d1-e4a1-4e2e-98d5-cbaa8caf9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-cda12fae-f532-4177-b95a-55b31ffefb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-dc8692fa-09a9-487b-8d6f-46ba8a800c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881586617-172.17.0.20-1599332426563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-68f0cb96-77fc-4abb-a3fb-b93d376b4664,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-a9da70ac-4248-44c4-94b6-bcf639ab6540,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-507687c5-f7f2-470d-9870-81478128bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-e7eca6f7-22cc-4037-8bae-45ffb8581451,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-6d24722b-9e7c-4cc0-af3c-cb78b4d97542,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-22a654d1-e4a1-4e2e-98d5-cbaa8caf9b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-cda12fae-f532-4177-b95a-55b31ffefb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-dc8692fa-09a9-487b-8d6f-46ba8a800c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960352482-172.17.0.20-1599332666852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-edad4b87-fc8e-44da-acc4-c61a1b978f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-b2f5a39a-971a-4192-98ba-cf779ad1bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-fb952d36-f1e9-4a30-a59a-5a45fb306787,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-edc3f250-d142-4d03-b9b4-fc42ae83815d,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-652fbf5d-c931-4b7b-aca9-902e0dac421b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-efaffb34-e335-44d6-8ae8-5616d9df3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-76cc08c7-561a-481d-a6e2-df9e20830c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-519a04d7-ee90-488a-a366-687b1ecb6cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960352482-172.17.0.20-1599332666852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-edad4b87-fc8e-44da-acc4-c61a1b978f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-b2f5a39a-971a-4192-98ba-cf779ad1bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-fb952d36-f1e9-4a30-a59a-5a45fb306787,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-edc3f250-d142-4d03-b9b4-fc42ae83815d,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-652fbf5d-c931-4b7b-aca9-902e0dac421b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-efaffb34-e335-44d6-8ae8-5616d9df3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-76cc08c7-561a-481d-a6e2-df9e20830c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-519a04d7-ee90-488a-a366-687b1ecb6cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322625116-172.17.0.20-1599332741301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-8062c263-bc25-47ea-a943-c8d523948b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-f27161ec-a0be-43ab-9dd5-3bff61ab66b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-1979af0a-c9a2-4172-9d7c-71e86062c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-67df3227-6d1f-4db1-b9c2-61ebe30b570b,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-674ac1cb-e0eb-46eb-b7b7-e08071de16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-9c809536-ab78-44a3-b332-da1a10273cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-e0a71e36-75a4-4b1c-ab83-d92a98da3f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-dddb2e15-370f-4865-b2a5-fc03290a38e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322625116-172.17.0.20-1599332741301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-8062c263-bc25-47ea-a943-c8d523948b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-f27161ec-a0be-43ab-9dd5-3bff61ab66b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-1979af0a-c9a2-4172-9d7c-71e86062c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-67df3227-6d1f-4db1-b9c2-61ebe30b570b,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-674ac1cb-e0eb-46eb-b7b7-e08071de16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-9c809536-ab78-44a3-b332-da1a10273cea,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-e0a71e36-75a4-4b1c-ab83-d92a98da3f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-dddb2e15-370f-4865-b2a5-fc03290a38e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026371132-172.17.0.20-1599333155675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-e05657f4-ed12-4538-bc08-672e53f87b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-7a1e1a8d-f1c3-482b-a5e3-79fbf6a5b003,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-38930774-6813-48fb-a4a3-ddc34f6699ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-672b5f39-74a1-4a75-b35b-e1e32788cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7c6a03f3-ce64-4df7-bd13-1c8a18e87c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-57688d4a-6ef5-49c9-85c4-57dc91904db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-51bf512a-e162-4cda-9eea-a2816186cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-54485765-5c01-4c6d-b0c5-7b4627cbf3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026371132-172.17.0.20-1599333155675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-e05657f4-ed12-4538-bc08-672e53f87b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-7a1e1a8d-f1c3-482b-a5e3-79fbf6a5b003,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-38930774-6813-48fb-a4a3-ddc34f6699ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-672b5f39-74a1-4a75-b35b-e1e32788cb46,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-7c6a03f3-ce64-4df7-bd13-1c8a18e87c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-57688d4a-6ef5-49c9-85c4-57dc91904db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-51bf512a-e162-4cda-9eea-a2816186cc27,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-54485765-5c01-4c6d-b0c5-7b4627cbf3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51037253-172.17.0.20-1599333195505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-47f6efe7-6770-4727-ab2f-948be09d9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-b9c24a9d-ec4c-481a-8ebf-1d5551a4b743,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-72e317f6-9e34-4409-ad04-3febdd475af5,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-47078635-927b-498c-a2f8-335af351811e,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-36466263-8903-49b2-939e-ae43f3028c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-4d799729-0358-447a-9941-29a2970178e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ca54f44a-90fe-4251-9770-440f06e6d137,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-7f9ed504-fd3f-48c1-9ad9-bb8dcbca4a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51037253-172.17.0.20-1599333195505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-47f6efe7-6770-4727-ab2f-948be09d9ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-b9c24a9d-ec4c-481a-8ebf-1d5551a4b743,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-72e317f6-9e34-4409-ad04-3febdd475af5,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-47078635-927b-498c-a2f8-335af351811e,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-36466263-8903-49b2-939e-ae43f3028c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-4d799729-0358-447a-9941-29a2970178e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ca54f44a-90fe-4251-9770-440f06e6d137,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-7f9ed504-fd3f-48c1-9ad9-bb8dcbca4a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876163697-172.17.0.20-1599333432283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-d2edaa6a-f5dd-43ad-bd11-4344d25f6401,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-a448fa0c-4d93-41a3-9041-6e609cdb35c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5f93c46a-adc5-4aec-a360-fc4489e218a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b89bd08f-5d08-42c9-94ca-2945482f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-b81254e9-2340-4ddb-a389-c3d7fc413e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-a5e63f47-b797-484e-995f-f811edea417c,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e2ae6023-9ea3-402c-b53c-f01301167ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-cc237cf7-67ea-4700-8bef-d4039b5f19e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876163697-172.17.0.20-1599333432283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-d2edaa6a-f5dd-43ad-bd11-4344d25f6401,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-a448fa0c-4d93-41a3-9041-6e609cdb35c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5f93c46a-adc5-4aec-a360-fc4489e218a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b89bd08f-5d08-42c9-94ca-2945482f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-b81254e9-2340-4ddb-a389-c3d7fc413e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-a5e63f47-b797-484e-995f-f811edea417c,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-e2ae6023-9ea3-402c-b53c-f01301167ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-cc237cf7-67ea-4700-8bef-d4039b5f19e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476689722-172.17.0.20-1599333954943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-4de3f075-32e0-438d-acaa-f240f67dd9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-56217e6d-3b55-4397-aa8f-0c80a32c24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b3ff5070-473c-46f1-a063-aa03e1fff4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-978aeadb-48a3-4db5-be07-ccb177a12017,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-777c8bd2-6776-4896-bc03-971373adff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-9947967f-53ae-4dd2-b095-3f1cbadd1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-8ebc7beb-ed03-458b-a522-5cc16af638b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f0b56a90-abfe-40c0-bea0-7d048dff91ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476689722-172.17.0.20-1599333954943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-4de3f075-32e0-438d-acaa-f240f67dd9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-56217e6d-3b55-4397-aa8f-0c80a32c24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b3ff5070-473c-46f1-a063-aa03e1fff4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-978aeadb-48a3-4db5-be07-ccb177a12017,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-777c8bd2-6776-4896-bc03-971373adff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-9947967f-53ae-4dd2-b095-3f1cbadd1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-8ebc7beb-ed03-458b-a522-5cc16af638b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f0b56a90-abfe-40c0-bea0-7d048dff91ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001698295-172.17.0.20-1599334054773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-a4a1f461-f0cb-4704-bd50-f3913915a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-6f1b2a51-9945-4988-8b3b-41f2d5e2babf,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-6e484090-34c1-456d-a020-c922893df141,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8beec463-df1c-4d9e-bfe3-436864ee6398,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-5131808c-2c81-4288-a255-2739dd11b653,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-77332913-c658-4e5c-9728-8840925e5dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-acc8b056-57ed-4e99-b2df-25b875a64e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-03090201-062f-47ab-b64b-2bc8620887b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001698295-172.17.0.20-1599334054773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-a4a1f461-f0cb-4704-bd50-f3913915a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-6f1b2a51-9945-4988-8b3b-41f2d5e2babf,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-6e484090-34c1-456d-a020-c922893df141,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8beec463-df1c-4d9e-bfe3-436864ee6398,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-5131808c-2c81-4288-a255-2739dd11b653,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-77332913-c658-4e5c-9728-8840925e5dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-acc8b056-57ed-4e99-b2df-25b875a64e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-03090201-062f-47ab-b64b-2bc8620887b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019023418-172.17.0.20-1599334301440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-672edb73-4e44-451c-b1c8-e0799c61f683,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-e089c059-dfee-4f0d-91d8-7ebece32c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1d466e2e-4a4d-4c04-ae49-1b526f79ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-cff89403-fe56-40c5-9350-5fc2131be2df,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-cf6c90a8-e2ad-4c11-9973-e9738f00ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-a4023503-a617-44be-a0df-436803f6cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-eb5092d3-9c88-4c25-9aa0-21cb04582aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-fb7eab53-220e-437b-b15f-5ce268f10266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019023418-172.17.0.20-1599334301440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-672edb73-4e44-451c-b1c8-e0799c61f683,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-e089c059-dfee-4f0d-91d8-7ebece32c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1d466e2e-4a4d-4c04-ae49-1b526f79ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-cff89403-fe56-40c5-9350-5fc2131be2df,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-cf6c90a8-e2ad-4c11-9973-e9738f00ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-a4023503-a617-44be-a0df-436803f6cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-eb5092d3-9c88-4c25-9aa0-21cb04582aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-fb7eab53-220e-437b-b15f-5ce268f10266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 128
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386997907-172.17.0.20-1599334421440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-8d8f0664-6ff8-4dc1-8b34-6b73e3032b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-ebb1fa28-b9d4-4771-94f9-5775fbf289ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-d1350053-2345-454e-b4f6-3438b71b6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-16168fbf-1264-4728-a22d-990979dfdf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-5ade457d-d665-470b-a750-adb3c2b87afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-56cd1537-22f0-4bf3-8e29-10e681d47856,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-83fcb4f6-760c-4c8b-b652-7a8258be2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2212fc96-820e-40fd-8808-63fca836e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386997907-172.17.0.20-1599334421440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-8d8f0664-6ff8-4dc1-8b34-6b73e3032b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-ebb1fa28-b9d4-4771-94f9-5775fbf289ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-d1350053-2345-454e-b4f6-3438b71b6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-16168fbf-1264-4728-a22d-990979dfdf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-5ade457d-d665-470b-a750-adb3c2b87afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-56cd1537-22f0-4bf3-8e29-10e681d47856,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-83fcb4f6-760c-4c8b-b652-7a8258be2f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2212fc96-820e-40fd-8808-63fca836e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5619
